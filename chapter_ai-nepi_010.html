<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Boulanger, David Carreto Fidalgo &amp; Andreas Wagner">
<meta name="dcterms.date" content="2025-01-01">

<title>10&nbsp; Large Language Models for Footnote Parsing in Law and Humanities Scholarship – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_011.html" rel="next">
<link href="./chapter_ai-nepi_009.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_010.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Transformer’s Legacy: Understanding Large Language Models and their Application in HPSS Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Workflow and Utility of OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Beyond Traditional Views of Science Funding</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#the-imperative-of-citation-graphs-addressing-bibliometric-gaps-in-social-sciences-and-humanities" id="toc-the-imperative-of-citation-graphs-addressing-bibliometric-gaps-in-social-sciences-and-humanities" class="nav-link" data-scroll-target="#the-imperative-of-citation-graphs-addressing-bibliometric-gaps-in-social-sciences-and-humanities"><span class="header-section-number">10.1</span> The Imperative of Citation Graphs: Addressing Bibliometric Gaps in Social Sciences and Humanities</a></li>
  <li><a href="#the-intricacies-of-humanities-footnotes-limitations-of-conventional-tools" id="toc-the-intricacies-of-humanities-footnotes-limitations-of-conventional-tools" class="nav-link" data-scroll-target="#the-intricacies-of-humanities-footnotes-limitations-of-conventional-tools"><span class="header-section-number">10.2</span> The Intricacies of Humanities Footnotes: Limitations of Conventional Tools</a></li>
  <li><a href="#large-language-models-for-reference-extraction-the-imperative-of-rigorous-evaluation" id="toc-large-language-models-for-reference-extraction-the-imperative-of-rigorous-evaluation" class="nav-link" data-scroll-target="#large-language-models-for-reference-extraction-the-imperative-of-rigorous-evaluation"><span class="header-section-number">10.3</span> Large Language Models for Reference Extraction: The Imperative of Rigorous Evaluation</a></li>
  <li><a href="#crafting-a-high-quality-gold-standard-a-tei-xml-approach" id="toc-crafting-a-high-quality-gold-standard-a-tei-xml-approach" class="nav-link" data-scroll-target="#crafting-a-high-quality-gold-standard-a-tei-xml-approach"><span class="header-section-number">10.4</span> Crafting a High-Quality Gold Standard: A TEI XML Approach</a></li>
  <li><a href="#llamore-a-python-package-for-llm-driven-reference-extraction-and-assessment" id="toc-llamore-a-python-package-for-llm-driven-reference-extraction-and-assessment" class="nav-link" data-scroll-target="#llamore-a-python-package-for-llm-driven-reference-extraction-and-assessment"><span class="header-section-number">10.5</span> <em>Llamore</em>: A Python Package for LLM-Driven Reference Extraction and Assessment</a></li>
  <li><a href="#comparative-performance-key-insights-and-future-directions" id="toc-comparative-performance-key-insights-and-future-directions" class="nav-link" data-scroll-target="#comparative-performance-key-insights-and-future-directions"><span class="header-section-number">10.6</span> Comparative Performance, Key Insights, and Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Christian Boulanger, David Carreto Fidalgo &amp; Andreas Wagner <a href="mailto:boulanger@lhlt.mpg.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Max Planck Institute for Legal History and Legal Theory
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Researchers investigate the complexities of parsing footnotes within law and humanities scholarship, a domain poorly served by conventional bibliometric databases. Their work addresses the critical need for accurate citation data to construct citation graphs. These graphs prove invaluable for tracing patterns in knowledge production, reconstructing influences, and measuring the reception of ideas in intellectual history. The project identifies significant deficiencies in existing data sources such as <em>Web of Science</em>, <em>Scopus</em>, and even <em>OpenAlex</em>, particularly concerning non-English, pre-digital, and non-“A-journal” publications. A primary challenge stems from the intricate nature of humanities footnotes—often termed “footnotes from hell”—which contain extensive commentary and messy, embedded references that traditional machine learning tools, such as those based on conditional random forests, struggle to process effectively.</p>
<p>To overcome these limitations, the research explores the potential of Large Language Models (LLMs) and Vision Language Models (VLMs) for reference extraction. Recognising the paramount importance of result trustworthiness, the team embarked on creating a high-quality gold standard dataset. This dataset comprises over 1,100 footnotes from 25 articles spanning various languages (French, German, Spanish, Italian, Portuguese) and a significant historical period (1958-2018), meticulously encoded in TEI XML. This standard facilitates interoperability, allows for contextual markup beyond simple reference management, and enables comparison with existing tools like <em>Grobid</em>.</p>
<p>Furthermore, the researchers developed <em>Llamore</em>, a lightweight Python package designed for reference extraction from text or PDFs using LLMs/VLMs. <em>Llamore</em> supports both open and closed models and provides an evaluation framework based on the F1 score, incorporating a sophisticated alignment process for comparing extracted references against gold standard data. Initial results demonstrate <em>Llamore</em>, using <em>Gemini 2.0 Flash</em>, significantly outperforms <em>Grobid</em> on their specialised humanities dataset. Nevertheless, <em>Grobid</em> remains competitive on datasets it was trained for, such as the <em>PLOS 1000</em> biomedical dataset. Future work aims to expand the training data, enhance evaluation metrics, and add support for more nuanced citation analysis, including citation context and resolution of abbreviations like <em>op cit.</em></p>
</section>
<section id="the-imperative-of-citation-graphs-addressing-bibliometric-gaps-in-social-sciences-and-humanities" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="the-imperative-of-citation-graphs-addressing-bibliometric-gaps-in-social-sciences-and-humanities"><span class="header-section-number">10.1</span> The Imperative of Citation Graphs: Addressing Bibliometric Gaps in Social Sciences and Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Researchers embark upon the challenge of parsing footnotes within law and humanities scholarship, a task with which current Large Language Models (LLMs) and other algorithms often struggle. Their primary objective involves generating the specific data required to construct comprehensive citation graphs. Such graphs offer powerful tools for intellectual historians, enabling the discovery of patterns and intricate relationships within the production of knowledge. Moreover, they facilitate the reconstruction of scholarly influences and allow for the measurement of how published ideas are received over time. An illustrative application involves tracking shifts in the most-cited authors, exemplified by an interactive web application analysing the <em>Journal of Law and Society</em> between 1994 and 2003.</p>
<p>An extremely poor coverage of historical Social Sciences and Humanities (SSH) material by established bibliometric datasources significantly impedes this research. Prominent databases like <em>Web of Science</em>, <em>Scopus</em>, and even the more accessible <em>OpenAlex</em>, prove largely inadequate for this domain, as they simply do not contain the requisite data. Compounding this issue, <em>Web of Science</em> and <em>Scopus</em> prove prohibitively expensive and operate under highly restrictive licences, creating dependencies undesirable for open scholarly inquiry. Whilst <em>OpenAlex</em> offers an open-access alternative, its coverage for the specialised content needed—particularly non-“A-journals,” pre-digital publications, and non-English language works—remains insufficient. For instance, data for the <em>Zeitschrift für Rechtssoziologie</em>, a German journal for law and society, reveals a stark lack of citation information prior to the 2000s in both <em>Dimensions</em> and <em>OpenAlex</em>.</p>
<p>Several factors contribute to this poor coverage. Primarily, commercial interest in humanities scholarship pales in comparison to that for STEM fields, medicine, and economics, which dominate these large bibliometric databases. Furthermore, these platforms typically prioritise the “impact factor” as a metric for science evaluation, a concern quite distinct from the nuanced inquiries of intellectual history.</p>
</section>
<section id="the-intricacies-of-humanities-footnotes-limitations-of-conventional-tools" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="the-intricacies-of-humanities-footnotes-limitations-of-conventional-tools"><span class="header-section-number">10.2</span> The Intricacies of Humanities Footnotes: Limitations of Conventional Tools</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Beyond database limitations, researchers identify the inherent complexity of humanities footnotes—aptly termed “footnotes from hell”—as a core challenge. These footnotes frequently feature extensive commentary and disordered data, all embedded within a significant amount of textual “noise,” as examples of German and English academic texts illustrate. Consequently, creating accurate training data for these intricate structures becomes an arduous task. Traditional annotation methods demand a laborious process of manually identifying and tagging various bibliographic elements, such as author, title, and publication date, often within specialised software interfaces.</p>
<p>Furthermore, existing tools, predominantly reliant on Conditional Random Forests and similar machine learning approaches, prove incapable of effectively handling such complex footnotes. Their performance significantly degrades when confronted with this type of data. For instance, performance metrics for the <em>ExCite</em> tool, detailed by Boulanger and Iurshina (2022), demonstrate variable extraction and segmentation accuracy across different training datasets, highlighting the difficulties with footnoted material. The challenges are multifaceted, encompassing varying citation styles, the complexities of multilingual terminology, and the pervasive use of ellipses, abbreviations (like <em>idem</em> or <em>derselbe</em>), and cross-references. Ambiguities, such as discerning whether an initial numeral signifies a volume or a page number, can perplex even human readers. Misleading capitalisation and the appearance of personal names within titles, which are then erroneously identified as authors, further complicate automated extraction. Language models may also struggle with specialised terminology with which they are unacquainted.</p>
</section>
<section id="large-language-models-for-reference-extraction-the-imperative-of-rigorous-evaluation" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="large-language-models-for-reference-extraction-the-imperative-of-rigorous-evaluation"><span class="header-section-number">10.3</span> Large Language Models for Reference Extraction: The Imperative of Rigorous Evaluation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>Scientists now explore Large Language Models (LLMs) as a promising avenue for tackling reference extraction. Early experiments conducted in 2022 with models like <em>text-davinci-003</em> already indicated the considerable power of LLMs to extract references from disordered textual data. Newer models, including Vision Language Models (VLMs) capable of directly processing PDF documents, hold the promise of even greater efficacy. Researchers investigate various methods, such as prompt engineering, Retrieval Augmented Generation (RAG), and finetuning, to harness these capabilities.</p>
<p>Nevertheless, a critical question looms: can one trust the results generated by these models? The potential for error, exemplified by a widely reported incident of a lawyer misusing <em>ChatGPT</em> in federal court, underscores this concern. A guiding principle for the research, therefore, necessitates avoiding attempts to solve problems for which no validation data exists. This requires developing a robust testing and evaluation solution. Such a solution must rest upon three pillars:</p>
<ul>
<li><p>a high-quality Gold Standard dataset</p></li>
<li><p>a flexible framework that can readily adapt to the fast-moving landscape of AI technology</p></li>
<li><p>solid testing and evaluation algorithms capable of producing comparable and reliable metrics</p></li>
</ul>
</section>
<section id="crafting-a-high-quality-gold-standard-a-tei-xml-approach" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="crafting-a-high-quality-gold-standard-a-tei-xml-approach"><span class="header-section-number">10.4</span> Crafting a High-Quality Gold Standard: A TEI XML Approach</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>Andreas Wagner detailed the team’s efforts to compile a high-quality dataset suitable for both training and evaluation, opting for TEI XML encoding. This choice, whilst perhaps less common in contemporary machine learning circles, stands as the preeminent standard within text-based humanities and digital editorics. Several compelling reasons underpin this decision. TEI XML provides a well-established, comprehensively specified standard for text interchange, surpassing the capabilities of purely bibliographical standards like CSL or BibTeX by covering a broader range of textual phenomena. Crucially, it extends beyond mere reference management to include citations, cross-references, and other forms of contextual markup, which can prove invaluable for tasks such as classifying citation intention. Furthermore, adopting TEI allows researchers to tap into a wealth of existing text collections and corpora from digital editorics projects, many of which publish their source data in this format, sometimes including detailed reference encodings.</p>
<p>Another significant advantage of TEI XML lies in the extensive tooling available. <em>Grobid</em>, a prominent tool for reference and information extraction, notably employs TEI XML for its training and evaluation processes. Utilising the same data format enables direct performance comparisons with <em>Grobid</em>, facilitates the sharing of training data with the <em>Grobid</em> team and others, and allows the project to leverage <em>Grobid</em>’s existing training resources.</p>
<p>The dataset currently under development draws from open-access journals. It involves the meticulous encoding of over 1,100 footnotes extracted from 25 articles, encompassing a diverse range of languages—French, German, Spanish, Italian, and Portuguese—and spanning a considerable period from 1958 to 2018. This collection anticipates yielding over 1,600 individual references; importantly, multiple references to the same work are encoded separately to capture the context of each occurrence. This endeavour remains a work in progress, having adapted its strategy midway to focus on Open Access journals and to incorporate PDFs alongside text, reference strings, and parsed TEI structures. Despite its strengths, TEI XML is no panacea; conceptual challenges, such as distinguishing pointers from references, and technical complexities, like handling constrained elements versus elliptic material, persist. These considerations lead to a fundamental question: how precisely should “performance” be defined and measured in this context?</p>
</section>
<section id="llamore-a-python-package-for-llm-driven-reference-extraction-and-assessment" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="llamore-a-python-package-for-llm-driven-reference-extraction-and-assessment"><span class="header-section-number">10.5</span> <em>Llamore</em>: A Python Package for LLM-Driven Reference Extraction and Assessment</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_14.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>David Carreto Fidalgo introduced <em>Llamore</em>, an acronym for Large Language Models for Reference Extraction. Engineers developed this Python package to perform two primary functions: firstly, to extract citation data from raw input text or PDF documents utilising (multimodal) LLMs, and secondly, to evaluate the performance of this extraction process. <em>Llamore</em> processes textual or PDF inputs and outputs references formatted as TEI XML. When provided with gold standard references, it generates an F1 score as an evaluation metric.</p>
<p>Two principal objectives guided <em>Llamore</em>’s creation. It needed to be lightweight, containing fewer than 2000 lines of code and functioning as an interface to a user’s chosen model rather than embedding models itself. Concurrently, compatibility with both open and closed-source LLMs and VLMs formed a key design consideration. Users can install <em>Llamore</em> via pip. For extraction, one defines an extractor based on the desired model (e.g., <em>GeminiExtractor</em>, <em>OpenAIExtractor</em>). Notably, the <em>OpenAIExtractor</em> ensures broad compatibility with open model serving frameworks like <em>Ollama</em> and <em>VLLM</em>, which typically offer OpenAI-compatible API endpoints. The chosen extractor then processes a PDF or a raw text string, returning references that can be exported to an XML file in TEI <em>biblStruct</em> format. For evaluation, the <em>F1</em> class is imported and used to compute a macro-average F1 score by comparing the extracted references against gold standard references; users can specify parameters like Levenshtein distance for matching.</p>
<p>The evaluation hinges on the F1 score, a well-established metric for structured data comparison, deriving from precision (matches divided by predicted elements) and recall (matches divided by gold elements). An F1 score of 1 signifies perfect extraction, whilst 0 indicates no matches. A crucial aspect of evaluation involves aligning the set of extracted references with the set of gold references. <em>Llamore</em> tackles this by formulating it as an Unbalanced Assignment Problem, employing a solver from the <em>SciPy</em> library. This process involves calculating F1 scores for every possible pairing of extracted and gold references, constructing a matrix of these scores, and then identifying the assignment that maximises the total F1 score under the constraint of unique pairings. This sophisticated alignment ensures accurate macro-averaging, with missing or hallucinated references appropriately penalised with an F1 score of zero. This alignment methodology strongly resembles recent work by Baka and colleagues.</p>
</section>
<section id="comparative-performance-key-insights-and-future-directions" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="comparative-performance-key-insights-and-future-directions"><span class="header-section-number">10.6</span> Comparative Performance, Key Insights, and Future Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_20.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
<p>To assess <em>Llamore</em>’s efficacy, researchers conducted comparative performance evaluations. On the <em>PLOS 1000</em> dataset, comprising 1000 PDFs from the biomedical domain, <em>Llamore</em> (utilising <em>Gemini 2.0 Flash</em>) achieved an F1 score (macro average, exact match) of 0.62, performing on par with <em>Grobid</em>’s score of 0.61. This result is notable given that <em>Grobid</em> was trained on portions of this type of biomedical literature. However, a stark contrast emerged during evaluation on the team’s custom humanities dataset. Here, <em>Grobid</em>’s F1 score plummeted to 0.14, indicating significant difficulty in extracting references. In contrast, <em>Llamore</em> achieved an F1 score of 0.45, demonstrating substantially better, indeed threefold improved, performance on this challenging, footnoted material.</p>
<p>These findings lead to several key takeaways. <em>Grobid</em> remains a preferable option for literature similar to its training data, primarily because it operates much faster and consumes fewer resources. Nevertheless, for the complex, footnoted literature characteristic of the humanities, experiments with <em>Llamore</em> paired with <em>Gemini</em> models reveal a significant performance advantage. One must note that these current performance metrics pertain to pure reference extraction and do not yet encompass more nuanced analyses such as citation context or cross-referencing.</p>
<p>Looking ahead, the team plans to expand their efforts by producing more training data and further refining test metrics. A significant focus will augment <em>Llamore</em>’s capabilities to support more sophisticated analyses. This includes identifying citations in their context (e.g., determining if a citation is approving or critical), resolving abbreviations like <em>op cit.</em>, extracting specific pages cited, and accurately counting multiple citations to the same work.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_009.html" class="pagination-link" aria-label="Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_011.html" class="pagination-link" aria-label="Science Dynamics and AI">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>