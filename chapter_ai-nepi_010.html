<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Boulanger, David Carreto Fidalgo &amp; Andreas Wagner">
<meta name="dcterms.date" content="2025-01-01">

<title>10&nbsp; Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_011.html" rel="next">
<link href="./chapter_ai-nepi_009.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_010.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">LLM: Evolution of competence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#citation-graphs-in-intellectual-history" id="toc-citation-graphs-in-intellectual-history" class="nav-link" data-scroll-target="#citation-graphs-in-intellectual-history"><span class="header-section-number">10.1</span> Citation Graphs in Intellectual History</a></li>
  <li><a href="#deficiencies-in-existing-bibliometric-databases-for-ssh" id="toc-deficiencies-in-existing-bibliometric-databases-for-ssh" class="nav-link" data-scroll-target="#deficiencies-in-existing-bibliometric-databases-for-ssh"><span class="header-section-number">10.2</span> Deficiencies in Existing Bibliometric Databases for SSH</a></li>
  <li><a href="#limitations-of-commercial-and-open-bibliometric-databases" id="toc-limitations-of-commercial-and-open-bibliometric-databases" class="nav-link" data-scroll-target="#limitations-of-commercial-and-open-bibliometric-databases"><span class="header-section-number">10.3</span> Limitations of Commercial and Open Bibliometric Databases</a></li>
  <li><a href="#challenges-in-humanities-data-coverage-and-footnote-complexity" id="toc-challenges-in-humanities-data-coverage-and-footnote-complexity" class="nav-link" data-scroll-target="#challenges-in-humanities-data-coverage-and-footnote-complexity"><span class="header-section-number">10.4</span> Challenges in Humanities Data Coverage and Footnote Complexity</a></li>
  <li><a href="#limitations-of-traditional-tools-and-promise-of-llms" id="toc-limitations-of-traditional-tools-and-promise-of-llms" class="nav-link" data-scroll-target="#limitations-of-traditional-tools-and-promise-of-llms"><span class="header-section-number">10.5</span> Limitations of Traditional Tools and Promise of LLMs</a></li>
  <li><a href="#ensuring-trustworthiness-and-robust-evaluation" id="toc-ensuring-trustworthiness-and-robust-evaluation" class="nav-link" data-scroll-target="#ensuring-trustworthiness-and-robust-evaluation"><span class="header-section-number">10.6</span> Ensuring Trustworthiness and Robust Evaluation</a></li>
  <li><a href="#tei-annotated-gold-standard-dataset-development" id="toc-tei-annotated-gold-standard-dataset-development" class="nav-link" data-scroll-target="#tei-annotated-gold-standard-dataset-development"><span class="header-section-number">10.7</span> TEI-Annotated Gold Standard Dataset Development</a></li>
  <li><a href="#dataset-strategy-evolution-and-tooling-integration" id="toc-dataset-strategy-evolution-and-tooling-integration" class="nav-link" data-scroll-target="#dataset-strategy-evolution-and-tooling-integration"><span class="header-section-number">10.8</span> Dataset Strategy Evolution and Tooling Integration</a></li>
  <li><a href="#introducing-llamore-a-reference-extraction-and-evaluation-package" id="toc-introducing-llamore-a-reference-extraction-and-evaluation-package" class="nav-link" data-scroll-target="#introducing-llamore-a-reference-extraction-and-evaluation-package"><span class="header-section-number">10.9</span> Introducing Llamore: A Reference Extraction and Evaluation Package</a></li>
  <li><a href="#llamore-implementation-and-workflow" id="toc-llamore-implementation-and-workflow" class="nav-link" data-scroll-target="#llamore-implementation-and-workflow"><span class="header-section-number">10.10</span> Llamore Implementation and Workflow</a></li>
  <li><a href="#llamores-evaluation-methodology-f1-score-and-reference-alignment" id="toc-llamores-evaluation-methodology-f1-score-and-reference-alignment" class="nav-link" data-scroll-target="#llamores-evaluation-methodology-f1-score-and-reference-alignment"><span class="header-section-number">10.11</span> Llamore’s Evaluation Methodology: F1-Score and Reference Alignment</a></li>
  <li><a href="#performance-evaluation-of-llamore" id="toc-performance-evaluation-of-llamore" class="nav-link" data-scroll-target="#performance-evaluation-of-llamore"><span class="header-section-number">10.12</span> Performance Evaluation of Llamore</a></li>
  <li><a href="#conclusion-and-takeaways" id="toc-conclusion-and-takeaways" class="nav-link" data-scroll-target="#conclusion-and-takeaways"><span class="header-section-number">10.13</span> Conclusion and Takeaways</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Christian Boulanger, David Carreto Fidalgo &amp; Andreas Wagner <a href="mailto:boulanger@lhlt.mpg.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Max Planck Institute for Legal History and Legal Theory
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter details an innovative approach to extracting citation data from law and humanities scholarship, a domain historically underserved by conventional bibliometric databases. The research team has developed a specialised methodology to overcome the challenges posed by complex, often multilingual, footnotes and the poor coverage of non-STEM fields in existing data sources. At the core of this solution lies the strategic leverage of <em>Large Language Models</em> (<em>LLMs</em>) and <em>Vision Language Models</em> (<em>VLMs</em>), underpinned by a meticulously crafted, <em>TEI XML</em>-encoded gold standard dataset.</p>
<p>The project directly addresses critical limitations inherent in current bibliometric tools, such as <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em>. These platforms frequently lack comprehensive coverage for pre-digital, non-English, or non-“A-journal” content, whilst also imposing prohibitive costs and restrictive licences. Furthermore, the intricate nature of humanities footnotes, often laden with commentary and varied citation styles, renders traditional machine learning tools largely ineffective.</p>
<p>To ensure the reliability of <em>LLM</em>-extracted data, the team has established a robust testing and evaluation framework. This framework relies on a high-quality gold standard dataset, comprising over 1,000 footnotes from 20 open-access articles across multiple languages and historical periods, yielding more than 1,500 references. This dataset is encoded in <em>TEI XML</em>, a well-established standard in digital humanities, which facilitates detailed contextual markup beyond mere reference management.</p>
<p>A key technological contribution from the authors is “<em>Llamore</em>”, a lightweight <em>Python</em> package engineered for <em>LLM</em>-based reference extraction and performance evaluation. <em>Llamore</em> extracts citation data from raw text or PDFs, outputting <em>TEI XML</em>, and assesses extraction accuracy using the <em>F1-score</em>. It employs an unbalanced assignment problem solver to align extracted references with gold standard data, thereby maximising the total <em>F1-score</em> for robust evaluation.</p>
<p>Initial evaluations demonstrate <em>Llamore</em>’s efficacy. When tested against the <em>PLOS 1000</em> biomedical dataset, <em>Llamore</em> (using <em>Gemini 2.0 Flash</em>) achieved an <em>F1-score</em> of 0.62, comparable to <em>Grobid</em>’s 0.61. Crucially, on the specialised footnoted humanities dataset, <em>Llamore</em> significantly outperformed <em>Grobid</em>, achieving an <em>F1-score</em> of 0.45 compared to <em>Grobid</em>’s 0.14. Whilst <em>Grobid</em> remains more resource-efficient for its trained literature, <em>Llamore</em> proves three times more effective for complex footnoted content. This research paves the way for generating comprehensive citation graphs, enabling deeper insights into intellectual history, influence reconstruction, and the reception of ideas within the humanities.</p>
</section>
<section id="citation-graphs-in-intellectual-history" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="citation-graphs-in-intellectual-history"><span class="header-section-number">10.1</span> Citation Graphs in Intellectual History</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>Scholars primarily employ citation graphs to illuminate patterns and relationships within knowledge production, particularly in the realm of intellectual history. These analytical tools prove invaluable for reconstructing influences and meticulously measuring the reception of published ideas. Consequently, researchers can identify, for instance, the most-cited authors across specific timeframes. An illustrative example involves an analysis of the <em>Journal of Law and Society</em>, for which an interactive web application provides detailed insights.</p>
</section>
<section id="deficiencies-in-existing-bibliometric-databases-for-ssh" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="deficiencies-in-existing-bibliometric-databases-for-ssh"><span class="header-section-number">10.2</span> Deficiencies in Existing Bibliometric Databases for SSH</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>A significant challenge arises from the extremely poor coverage of historical Social Sciences and Humanities (<em>SSH</em>) within existing bibliometric data sources. The research team deems these databases, including prominent platforms such as <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em>, fundamentally unusable for the specific domain under investigation, primarily owing to their pervasive lack of relevant data.</p>
</section>
<section id="limitations-of-commercial-and-open-bibliometric-databases" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="limitations-of-commercial-and-open-bibliometric-databases"><span class="header-section-number">10.3</span> Limitations of Commercial and Open Bibliometric Databases</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Beyond the general inadequacy, specific limitations plague both commercial and open bibliometric databases. <em>Web of Science</em> and <em>Scopus</em>, for instance, impose exorbitant costs and operate under highly restrictive licences; consequently, the authors advocate for a decisive shift away from reliance on these proprietary systems. Whilst <em>OpenAlex</em> offers the significant advantage of open access, it nonetheless presents considerable shortcomings for Social Sciences and Humanities research. Specifically, it frequently lacks comprehensive coverage for numerous “A-journals,” provides insufficient data from the pre-digital era, and typically omits content published in languages other than English.</p>
</section>
<section id="challenges-in-humanities-data-coverage-and-footnote-complexity" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="challenges-in-humanities-data-coverage-and-footnote-complexity"><span class="header-section-number">10.4</span> Challenges in Humanities Data Coverage and Footnote Complexity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The <em>Zeitschrift für Rechtssoziologie</em>, a German Journal for Law and Society established in 1980, exemplifies the pervasive issue of poor data coverage within the humanities. Its citation data, as observed in bibliometric databases, only demonstrates significant improvement after the year 2000, with minimal records available for the preceding decades. This deficiency stems from several factors. Primarily, the humanities attract less commercial interest compared to STEM, medicine, and economics, which typically dominate large bibliometric databases. Moreover, these databases prioritise the “impact factor” for scientific evaluation, a metric largely irrelevant to research in intellectual history.</p>
<p>Crucially, the literature of interest in humanities scholarship frequently features highly complex footnotes, colloquially termed “footnotes from hell.” These are not mere citations; they often incorporate extensive commentary and various “messy” elements, all embedded within a considerable amount of non-citation “noise,” making automated extraction profoundly challenging.</p>
</section>
<section id="limitations-of-traditional-tools-and-promise-of-llms" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="limitations-of-traditional-tools-and-promise-of-llms"><span class="header-section-number">10.5</span> Limitations of Traditional Tools and Promise of LLMs</h2>
<p>Creating training data presents a formidable challenge, necessitating a labour-intensive annotation process that demands substantial time investment. Furthermore, existing tools, particularly those reliant on traditional machine learning methods such as <em>Conditional Random Forests</em>, exhibit poor performance when confronted with complex footnotes. For instance, <em>ExCite</em>’s performance, as documented by Boulanger and Iurshina in 2022, reveals consistently low extraction and segmentation accuracies across various training datasets.</p>
<p>Nevertheless, <em>Large Language Models</em> (<em>LLMs</em>) offer a promising avenue for resolution. Early experiments conducted in 2022 with models like <em>text-davinci-003</em> already demonstrated the significant power of <em>LLMs</em> in extracting references from highly unstructured textual data. Newer models promise even better results, whilst <em>Vision Language Models</em> (<em>VLMs</em>) extend this capability to direct PDF processing. The research team is currently exploring various methods to harness these advanced models effectively.</p>
</section>
<section id="ensuring-trustworthiness-and-robust-evaluation" class="level2" data-number="10.6">
<h2 data-number="10.6" class="anchored" data-anchor-id="ensuring-trustworthiness-and-robust-evaluation"><span class="header-section-number">10.6</span> Ensuring Trustworthiness and Robust Evaluation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>A fundamental concern centres on the trustworthiness of results generated by <em>Large Language Models</em>. Instances of <em>LLMs</em> fabricating non-existent citations, as exemplified by a lawyer’s disastrous use of <em>ChatGPT</em> in federal court, underscore this critical issue. Consequently, a guiding principle dictates against attempting to solve problems for which no validation data exists.</p>
<p>To address this, the authors necessitate a robust testing and evaluation solution. This solution comprises three essential components:</p>
<ul>
<li><p>A high-quality Gold Standard dataset.</p></li>
<li><p>A flexible framework capable of adapting to the rapidly evolving technological landscape.</p></li>
<li><p>Solid testing and evaluation algorithms designed to produce comparable metrics.</p></li>
</ul>
</section>
<section id="tei-annotated-gold-standard-dataset-development" class="level2" data-number="10.7">
<h2 data-number="10.7" class="anchored" data-anchor-id="tei-annotated-gold-standard-dataset-development"><span class="header-section-number">10.7</span> TEI-Annotated Gold Standard Dataset Development</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The research team has embarked upon compiling a comprehensive training dataset, specifically designed for dual utility as evaluation data, employing <em>TEI XML</em> encoding. This choice stems from <em>TEI</em>’s status as a well-established, meticulously specified, and comprehensive standard for text interchange within the humanities and digital editorics. Unlike more constrained bibliographical standards such as <em>CSL</em> or <em>BibTeX</em>, <em>TEI</em> encompasses a broader array of phenomena, extending beyond mere reference management to facilitate the encoding of contextual information, including citation intention. Furthermore, its adoption enables the integration of existing <em>TEI XML</em> corpora from various digital editorics projects, thereby supporting the testing of generalisation and robustness features.</p>
<p>Despite its advantages, the <em>TEI</em> standard presents certain challenges, both conceptual—concerning the distinction between pointers and references—and technical—regarding constrained elements versus elliptic material. The dataset development process involves several stages: initially, capturing PDF screenshots; subsequently, segmenting the reference string to isolate the citation from surrounding non-reference text within footnotes; and finally, parsing the content into a structured data format, utilising <em>TEI</em> elements such as <code>biblStruct</code>, <code>analytic</code>, <code>monogr</code>, <code>author</code>, <code>title</code>, <code>imprint</code>, <code>date</code>, <code>biblScope</code>, and <code>biblRef</code>. This dataset is currently under active development.</p>
</section>
<section id="dataset-strategy-evolution-and-tooling-integration" class="level2" data-number="10.8">
<h2 data-number="10.8" class="anchored" data-anchor-id="dataset-strategy-evolution-and-tooling-integration"><span class="header-section-number">10.8</span> Dataset Strategy Evolution and Tooling Integration</h2>
<p>The strategy for constructing this dataset has evolved significantly. Initially, the focus centred on compiling data directly relevant to the primary research question. More recently, however, the authors made a strategic decision to incorporate PDFs, thereby enabling the utilisation of <em>Vision Language Model</em> (<em>VLM</em>) mechanisms. The overarching aim now involves publishing the complete dataset, encompassing everything from the raw PDFs to the meticulously parsed references. To achieve this, the team is sourcing material from open-access journals. The current scope involves coding over 1,000 footnotes derived from 20 articles, spanning several languages and a broad historical timeframe, which are expected to yield more than 1,500 references. Notably, even multiple occurrences of the same work are encoded separately to capture their distinct contexts.</p>
<p>A significant benefit of adopting the <em>TEI XML</em> standard lies in the extensive tooling available for this interoperable format. <em>Grobid</em>, a widely recognised tool for reference and information extraction, notably employs <em>TEI XML</em> for its training and evaluation processes. This alignment facilitates direct performance comparisons with <em>Grobid</em> and enables the provision of new training data to the <em>Grobid</em> team, fostering collaborative advancement.</p>
</section>
<section id="introducing-llamore-a-reference-extraction-and-evaluation-package" class="level2" data-number="10.9">
<h2 data-number="10.9" class="anchored" data-anchor-id="introducing-llamore-a-reference-extraction-and-evaluation-package"><span class="header-section-number">10.9</span> Introducing Llamore: A Reference Extraction and Evaluation Package</h2>
<p>The research team has developed “<em>Llamore</em>”, an acronym for <em>Large LANguage MOdels for Reference Extraction</em>, as a dedicated <em>Python</em> package. This tool serves a dual purpose: it extracts citation data from either raw text or PDF documents, leveraging multimodal <em>Large Language Models</em>, and subsequently evaluates the performance of this extraction. Specifically, <em>Llamore</em> processes textual or PDF inputs to generate references in <em>TEI XML</em> format, whilst also accepting gold standard references to produce an <em>F1-score</em> as an evaluation metric. The design of <em>Llamore</em> prioritises two key objectives: it remains lightweight, comprising fewer than 2,000 lines of code, and ensures broad compatibility with both open and closed <em>Large Language Models</em>.</p>
</section>
<section id="llamore-implementation-and-workflow" class="level2" data-number="10.10">
<h2 data-number="10.10" class="anchored" data-anchor-id="llamore-implementation-and-workflow"><span class="header-section-number">10.10</span> Llamore Implementation and Workflow</h2>
<p><em>Llamore</em> is readily available on <em>Pypi</em>, enabling straightforward installation via <code>pip</code>. The extraction workflow commences with defining an extractor, which is contingent upon the specific <em>Large Language Model</em> selected. For instance, the <em>OpenAI</em> extractor offers broad compatibility, as many open model serving frameworks, including <em>Olama</em> and <em>VLLM</em>, provide <em>OpenAI</em>-compatible APIs. Subsequently, users supply either a PDF or raw text as input to this extractor, which then yields the extracted references. These references can then be exported conveniently to an <em>XML</em> file. For evaluation purposes, users import the dedicated <em>F1</em> class and provide both the gold standard references and the extracted references to compute the macro average of performance metrics.</p>
</section>
<section id="llamores-evaluation-methodology-f1-score-and-reference-alignment" class="level2" data-number="10.11">
<h2 data-number="10.11" class="anchored" data-anchor-id="llamores-evaluation-methodology-f1-score-and-reference-alignment"><span class="header-section-number">10.11</span> Llamore’s Evaluation Methodology: F1-Score and Reference Alignment</h2>
<p><em>Llamore</em> employs the <em>F1-score</em> as its primary evaluation metric, a well-established standard for comparing structured data. This score represents the harmonic mean of <em>Precision</em> and <em>Recall</em>, where <em>Precision</em> is calculated as the ratio of matches to predicted elements, and <em>Recall</em> as the ratio of matches to gold elements. An <em>F1-score</em> of 1 signifies perfect extraction, whilst a score of 0 indicates no matches whatsoever. For instance, an extracted reference might align perfectly with a gold reference on fields such as <code>analytic_title</code>, <code>monographic_title</code>, <code>surname</code>, and <code>publication_date</code>, yet exhibit a mismatch in the <code>forename</code> due to a minor discrepancy like an extraneous dot in the gold standard.</p>
<p>A more complex challenge arises in aligning multiple extracted references with their corresponding gold references. <em>Llamore</em> addresses this as an unbalanced assignment problem. The system computes <em>F1-scores</em> for every possible combination of extracted and gold references, subsequently constructing a matrix from these scores. It then leverages <em>SciPy</em>’s solver to maximise the total <em>F1-score</em> whilst ensuring a unique assignment between the extracted and gold references. Following this alignment, the individual <em>F1-scores</em> are macro-averaged to provide an overall performance metric.</p>
</section>
<section id="performance-evaluation-of-llamore" class="level2" data-number="10.12">
<h2 data-number="10.12" class="anchored" data-anchor-id="performance-evaluation-of-llamore"><span class="header-section-number">10.12</span> Performance Evaluation of Llamore</h2>
<p>Performance evaluations of <em>Llamore</em> reveal distinct capabilities across different datasets. When tested against the <em>PLOS 1000</em> dataset, comprising 1,000 PDFs from the biomedical field, <em>Llamore</em> (utilising <em>Gemini 2.0 Flash</em>) achieved an exact match <em>F1-score</em> of 0.62, closely aligning with <em>Grobid</em>’s score of 0.61. This indicates comparable performance on literature for which <em>Grobid</em> was specifically trained. However, it is crucial to note that <em>Grobid</em> maintains a significant advantage in resource efficiency, requiring orders of magnitude less computational power than <em>Gemini</em>.</p>
<p>Conversely, on the custom humanities dataset, which features complex footnoted literature, <em>Llamore</em> demonstrated a marked superiority. <em>Grobid</em> struggled considerably, yielding an <em>F1-score</em> of merely 0.14, whilst <em>Llamore</em> (<em>Gemini 2.0 Flash</em>) achieved a substantially higher score of 0.45. This represents approximately a threefold improvement in performance for the challenging domain of footnoted humanities scholarship.</p>
</section>
<section id="conclusion-and-takeaways" class="level2" data-number="10.13">
<h2 data-number="10.13" class="anchored" data-anchor-id="conclusion-and-takeaways"><span class="header-section-number">10.13</span> Conclusion and Takeaways</h2>
<p><em>Grobid</em> remains the preferred choice for literature upon which it has been specifically trained, primarily owing to its significantly faster processing speed and reduced resource intensity. Conversely, <em>Llamore</em>, when paired with <em>Gemini</em>, demonstrates approximately three times better performance for the challenging domain of footnoted literature. This performance specifically pertains to pure reference extraction, excluding contextual or cross-referencing information.</p>
<p>A critical aspect of utilising open-source databases, such as <em>OpenAlex</em>, involves the burden of quality assurance falling directly upon the user. The authors advise a cautious approach towards both <em>OpenAlex</em> and commercial databases like <em>Web of Science</em> and <em>Scopus</em>, as their quality assurance priorities may not align with specific research questions. <em>Large Language Models</em>, whilst powerful, can produce false positives by inventing citations, thus necessitating the attainment of reliable results before any large-scale application. The ultimate ambition extends beyond mere reference string extraction to obtaining reliable results for nuanced contextual information, such as whether a citation is approving or not.</p>
<p>Analysis reveals that <em>Grobid</em>’s poor performance on humanities data stems from its training data being out of distribution for this domain. <em>Large Language Models</em>, however, exhibit their own distinct failure modes. These include difficulty discerning ambiguous elements, such as whether a number represents a volume or a page, and being misled by capitalisation. They frequently misidentify personal names appearing within titles as authors and struggle with specialised terminology like <em>Idem</em>, <em>Derselbe</em>, <em>passim</em>, <em>ibid</em>, or <em>n.d.</em>. Furthermore, canonical citations found in fields such as Bible studies, Roman law, and classical literature, along with ellipses, abbreviations, and cross-references, present considerable challenges.</p>
<p>The requisite <em>F1-score</em> for a gold standard dataset is contingent upon the analytical ambition; a lower score might suffice for identifying broad tendencies, whilst high accuracy demands a much higher score. For less precise needs, such as fuzzy searching in bibliographical databases using only a title and author, an exact match may not be essential. Nevertheless, the current stage of research prioritises achieving highly reliable results to facilitate the extraction of richer contextual information. A human-in-the-loop approach has been considered for the dataset establishment workflow, where <em>Llamore</em> could pre-annotate data for subsequent human correction. However, intermediate stages, such as merely marking the referring string without full parsing, still necessitate substantial manual effort.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_009.html" class="pagination-link" aria-label="The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_011.html" class="pagination-link" aria-label="Science dynamics and AI">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>