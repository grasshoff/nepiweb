---
title: "AI, Computational Epistemology, and Open Science Infrastructure"
author:
- name: "Gerd Graßhoff"
  affiliation: "Humboldt Universität zu Berlin"
  email: "gerd.grasshoff@hu-berlin.de"
date: '2025-06-21'
bibliography: bibliography.bib
---
## Overview {.unnumbered}

The authors chart a course for integrating Artificial Intelligence into scholarly research, progressing from the foundational concepts of Large Language Model evolution towards a robust framework grounded in validation and critical thinking. Their work identifies key deficiencies in current AI, such as a lack of information verification, and proposes a solution centred on computational epistemology and epistemic agency.

To realise this vision, the team introduces a suite of tools and platforms. The *Scholarium* initiative, governed by a curated editorial board, provides access to validated historical sources, including the collected works of Euler. A digital academic workspace, featuring an *AI Cockpit*, demonstrates how scholars can interact with LLMs to analyse historical documents. The entire technical infrastructure is built upon the principles of Open Science Technology—embracing open source, open access, open data, and open collaboration—and exemplifies FAIR data principles through platforms like *Zenodo*, a repository for the academic community.

## The Evolution of LLM Competence

![Slide 02](images/ai-nepi_008_slide_02.png)

The authors trace the evolution of competence in Large Language Models (LLMs) through three distinct conceptual stages. This progression begins with the foundational mechanism of *attention*, which allows models to weigh the significance of different words in a sequence.

Subsequently, development advanced to incorporate *context*, enabling LLMs to understand and process information within a broader frame of reference. The most recent stage in this evolution introduces the capacity for *thinking*, characterising a move towards more sophisticated reasoning and problem-solving capabilities.

## Deficiencies in Current AI Systems

![Slide 03](images/ai-nepi_008_slide_03.png)

A critical examination of current AI capabilities reveals fundamental principles that are largely absent from contemporary systems. These deficiencies primarily concern the need for robust critical thinking, a capacity that extends far beyond mere pattern recognition.

Furthermore, a significant gap exists in the domain of information verification, as models often generate content without a reliable mechanism for confirming its accuracy. This analysis also highlights the inherent limitations of AI representations, acknowledging that they are not infallible and require careful scrutiny.

## Validation in Computational Epistemology

![Slide 04](images/ai-nepi_008_slide_04.png)

Validation emerges as a central theme in the authors' framework for advancing trustworthy AI. This principle applies not only to the propositions an AI generates but also to the actions it recommends or undertakes, ensuring both are sound and justifiable.

Situating this work within the field of *Computational Epistemology* provides a formal structure for analysing knowledge in computational systems. Moreover, it connects directly to the nature of *Epistemic Agency*, exploring how systems can responsibly and accurately acquire, assess, and use information.

## AI-Assisted Document Analysis

![Slide 05](images/ai-nepi_008_slide_05.png)

A digital academic workspace, developed by the team, demonstrates the practical application of AI in scholarly research, particularly within the humanities. The user interface presents a historical document, such as a PDF, alongside an AI-powered analysis panel.

In a specific use case, the system processes a document related to a historical art commission. The AI successfully extracts and organises key information, identifying all the individuals involved and detailing their respective roles in the commission, thereby accelerating the research process.

## The Scholarium Platform

![Slide 06](images/ai-nepi_008_slide_06.png)

The *Scholarium* initiative provides a dedicated platform for high-integrity academic work, distinguishing itself through rigorous oversight. A Curated Scholarly Editorial Board governs the platform, ensuring that all included sources meet stringent academic standards.

The scope of its collection includes the major collected works of influential historical scientists. To illustrate its function, the system showcases a digital viewer for navigating the comprehensive works of Leonhard Euler, offering researchers direct access to this foundational scientific corpus.

## The AI Cockpit Interface

![Slide 08](images/ai-nepi_008_slide_08.png)

The team has engineered the *AI Cockpit*, a specialised user interface designed to streamline interaction with Large Language Models. This tool provides a focused environment for conducting complex, AI-assisted tasks.

Its capabilities are demonstrated through its effective use in processing historical documents. The *AI Cockpit* can automatically extract salient information and generate concise summaries, enabling scholars to grasp the core content of archival materials with greater efficiency.

## FAIR Principles and the Zenodo Repository

![Slide 09](images/ai-nepi_008_slide_09.png)

The authors highlight the *Zenodo* research data repository as a prime example of an infrastructure built upon FAIR principles. By design, it ensures that research outputs are Findable, Accessible, Interoperable, and Reusable, promoting transparency and collaboration across academic communities.

As a general-purpose repository, it supports a wide range of disciplines and data types. Its active and continuous use is evident from its interface, which showcases a dynamic list of recent uploads from researchers worldwide, underscoring its role in the scholarly ecosystem.

## Principles of Open Science Technology

![Slide 10](images/ai-nepi_008_slide_10.png)

The technical support framework for this scholarly ecosystem rests upon the core principles of Open Science Technology. This commitment manifests in four key areas.

- It embraces open-source software, ensuring that the underlying tools are transparent and customisable.

- It champions open access to publications, removing barriers to knowledge.

- It mandates open data, allowing for the verification of results and the reuse of datasets.

- It fosters open collaboration, creating an environment where researchers can work together effectively.