<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vera Danilova">
<meta name="dcterms.date" content="2025-06-21">

<title>5&nbsp; Genre Classification for Historical Medical Periodicals – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_006.html" rel="next">
<link href="./chapter_ai-nepi_004.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_005.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#presentation-outline-and-scope" id="toc-presentation-outline-and-scope" class="nav-link" data-scroll-target="#presentation-outline-and-scope"><span class="header-section-number">5.1</span> Presentation Outline and Scope</a></li>
  <li><a href="#the-actdisease-project-objectives-and-scope" id="toc-the-actdisease-project-objectives-and-scope" class="nav-link" data-scroll-target="#the-actdisease-project-objectives-and-scope"><span class="header-section-number">5.2</span> The ActDisease Project: Objectives and Scope</a></li>
  <li><a href="#actdisease-dataset-composition" id="toc-actdisease-dataset-composition" class="nav-link" data-scroll-target="#actdisease-dataset-composition"><span class="header-section-number">5.3</span> ActDisease Dataset Composition</a></li>
  <li><a href="#digitization-challenges-and-ocr-issues" id="toc-digitization-challenges-and-ocr-issues" class="nav-link" data-scroll-target="#digitization-challenges-and-ocr-issues"><span class="header-section-number">5.4</span> Digitization Challenges and OCR Issues</a></li>
  <li><a href="#challenges-in-analysing-historical-periodicals" id="toc-challenges-in-analysing-historical-periodicals" class="nav-link" data-scroll-target="#challenges-in-analysing-historical-periodicals"><span class="header-section-number">5.5</span> Challenges in Analysing Historical Periodicals</a></li>
  <li><a href="#rationale-for-genre-classification" id="toc-rationale-for-genre-classification" class="nav-link" data-scroll-target="#rationale-for-genre-classification"><span class="header-section-number">5.6</span> Rationale for Genre Classification</a></li>
  <li><a href="#illustrating-genre-diversity-poetry-example" id="toc-illustrating-genre-diversity-poetry-example" class="nav-link" data-scroll-target="#illustrating-genre-diversity-poetry-example"><span class="header-section-number">5.7</span> Illustrating Genre Diversity: Poetry Example</a></li>
  <li><a href="#illustrating-genre-diversity-patient-experiences" id="toc-illustrating-genre-diversity-patient-experiences" class="nav-link" data-scroll-target="#illustrating-genre-diversity-patient-experiences"><span class="header-section-number">5.8</span> Illustrating Genre Diversity: Patient Experiences</a></li>
  <li><a href="#defining-genre-labels-for-classification" id="toc-defining-genre-labels-for-classification" class="nav-link" data-scroll-target="#defining-genre-labels-for-classification"><span class="header-section-number">5.9</span> Defining Genre Labels for Classification</a></li>
  <li><a href="#operational-genre-definitions" id="toc-operational-genre-definitions" class="nav-link" data-scroll-target="#operational-genre-definitions"><span class="header-section-number">5.10</span> Operational Genre Definitions</a></li>
  <li><a href="#dataset-annotation-methodology" id="toc-dataset-annotation-methodology" class="nav-link" data-scroll-target="#dataset-annotation-methodology"><span class="header-section-number">5.11</span> Dataset Annotation Methodology</a></li>
  <li><a href="#illustrative-annotation-example" id="toc-illustrative-annotation-example" class="nav-link" data-scroll-target="#illustrative-annotation-example"><span class="header-section-number">5.12</span> Illustrative Annotation Example</a></li>
  <li><a href="#dataset-splitting-for-experiments" id="toc-dataset-splitting-for-experiments" class="nav-link" data-scroll-target="#dataset-splitting-for-experiments"><span class="header-section-number">5.13</span> Dataset Splitting for Experiments</a></li>
  <li><a href="#genre-distribution-in-actdisease-dataset" id="toc-genre-distribution-in-actdisease-dataset" class="nav-link" data-scroll-target="#genre-distribution-in-actdisease-dataset"><span class="header-section-number">5.14</span> Genre Distribution in ActDisease Dataset</a></li>
  <li><a href="#external-datasets-for-zero-shot-classification" id="toc-external-datasets-for-zero-shot-classification" class="nav-link" data-scroll-target="#external-datasets-for-zero-shot-classification"><span class="header-section-number">5.15</span> External Datasets for Zero-Shot Classification</a></li>
  <li><a href="#cross-dataset-genre-mapping" id="toc-cross-dataset-genre-mapping" class="nav-link" data-scroll-target="#cross-dataset-genre-mapping"><span class="header-section-number">5.16</span> Cross-Dataset Genre Mapping</a></li>
  <li><a href="#training-data-creation-and-configuration" id="toc-training-data-creation-and-configuration" class="nav-link" data-scroll-target="#training-data-creation-and-configuration"><span class="header-section-number">5.17</span> Training Data Creation and Configuration</a></li>
  <li><a href="#multilingual-encoder-models-utilised" id="toc-multilingual-encoder-models-utilised" class="nav-link" data-scroll-target="#multilingual-encoder-models-utilised"><span class="header-section-number">5.18</span> Multilingual Encoder Models Utilised</a></li>
  <li><a href="#model-fine-tuning-process" id="toc-model-fine-tuning-process" class="nav-link" data-scroll-target="#model-fine-tuning-process"><span class="header-section-number">5.19</span> Model Fine-tuning Process</a></li>
  <li><a href="#zero-shot-learning-evaluation-phase" id="toc-zero-shot-learning-evaluation-phase" class="nav-link" data-scroll-target="#zero-shot-learning-evaluation-phase"><span class="header-section-number">5.20</span> Zero-Shot Learning Evaluation Phase</a></li>
  <li><a href="#zero-shot-prediction-evaluation-methodology" id="toc-zero-shot-prediction-evaluation-methodology" class="nav-link" data-scroll-target="#zero-shot-prediction-evaluation-methodology"><span class="header-section-number">5.21</span> Zero-Shot Prediction Evaluation Methodology</a></li>
  <li><a href="#summary-of-zero-shot-classification-results" id="toc-summary-of-zero-shot-classification-results" class="nav-link" data-scroll-target="#summary-of-zero-shot-classification-results"><span class="header-section-number">5.22</span> Summary of Zero-Shot Classification Results</a></li>
  <li><a href="#zero-shot-classification-confusion-matrices" id="toc-zero-shot-classification-confusion-matrices" class="nav-link" data-scroll-target="#zero-shot-classification-confusion-matrices"><span class="header-section-number">5.23</span> Zero-Shot Classification Confusion Matrices</a></li>
  <li><a href="#zero-shot-per-category-f1-scores" id="toc-zero-shot-per-category-f1-scores" class="nav-link" data-scroll-target="#zero-shot-per-category-f1-scores"><span class="header-section-number">5.24</span> Zero-Shot Per-Category F1 Scores</a></li>
  <li><a href="#impact-of-configuration-on-zero-shot-performance" id="toc-impact-of-configuration-on-zero-shot-performance" class="nav-link" data-scroll-target="#impact-of-configuration-on-zero-shot-performance"><span class="header-section-number">5.25</span> Impact of Configuration on Zero-Shot Performance</a></li>
  <li><a href="#few-shot-learning-evaluation-phase" id="toc-few-shot-learning-evaluation-phase" class="nav-link" data-scroll-target="#few-shot-learning-evaluation-phase"><span class="header-section-number">5.26</span> Few-Shot Learning Evaluation Phase</a></li>
  <li><a href="#few-shot-learning-performance-trends" id="toc-few-shot-learning-performance-trends" class="nav-link" data-scroll-target="#few-shot-learning-performance-trends"><span class="header-section-number">5.27</span> Few-Shot Learning Performance Trends</a></li>
  <li><a href="#detailed-few-shot-learning-performance-metrics" id="toc-detailed-few-shot-learning-performance-metrics" class="nav-link" data-scroll-target="#detailed-few-shot-learning-performance-metrics"><span class="header-section-number">5.28</span> Detailed Few-Shot Learning Performance Metrics</a></li>
  <li><a href="#few-shot-classification-confusion-matrix-and-insights" id="toc-few-shot-classification-confusion-matrix-and-insights" class="nav-link" data-scroll-target="#few-shot-classification-confusion-matrix-and-insights"><span class="header-section-number">5.29</span> Few-Shot Classification Confusion Matrix and Insights</a></li>
  <li><a href="#few-shot-prompting-evaluation-phase" id="toc-few-shot-prompting-evaluation-phase" class="nav-link" data-scroll-target="#few-shot-prompting-evaluation-phase"><span class="header-section-number">5.30</span> Few-Shot Prompting Evaluation Phase</a></li>
  <li><a href="#llama-3.1-8b-instruct-model-prompting" id="toc-llama-3.1-8b-instruct-model-prompting" class="nav-link" data-scroll-target="#llama-3.1-8b-instruct-model-prompting"><span class="header-section-number">5.31</span> Llama-3.1 8b Instruct Model Prompting</a></li>
  <li><a href="#llama-3.1-8b-instruct-performance" id="toc-llama-3.1-8b-instruct-performance" class="nav-link" data-scroll-target="#llama-3.1-8b-instruct-performance"><span class="header-section-number">5.32</span> Llama-3.1 8b Instruct Performance</a></li>
  <li><a href="#challenges-of-popular-magazine-text-mining" id="toc-challenges-of-popular-magazine-text-mining" class="nav-link" data-scroll-target="#challenges-of-popular-magazine-text-mining"><span class="header-section-number">5.33</span> Challenges of Popular Magazine Text Mining</a></li>
  <li><a href="#enabling-text-mining-through-genre-classification" id="toc-enabling-text-mining-through-genre-classification" class="nav-link" data-scroll-target="#enabling-text-mining-through-genre-classification"><span class="header-section-number">5.34</span> Enabling Text Mining through Genre Classification</a></li>
  <li><a href="#key-conclusions-and-performance-insights" id="toc-key-conclusions-and-performance-insights" class="nav-link" data-scroll-target="#key-conclusions-and-performance-insights"><span class="header-section-number">5.35</span> Key Conclusions and Performance Insights</a></li>
  <li><a href="#future-research-directions" id="toc-future-research-directions" class="nav-link" data-scroll-target="#future-research-directions"><span class="header-section-number">5.36</span> Future Research Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Vera Danilova <a href="mailto:vera.danilova@idehist.uu.se" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Uppsala University
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This report systematically documents the research conducted within the ActDisease project at Uppsala University, focusing on genre classification for historical medical periodicals. Researchers aimed to develop automated methods for categorising diverse text types found in these publications, thereby enhancing their accessibility for digital humanities research. The project, funded by the ERC, investigates how patient organisations influenced modern medicine in 20th-century Europe, primarily utilising their periodicals as source material. The methodology encompassed rigorous data collection, addressing significant digitisation challenges such as Optical Character Recognition (OCR) errors and complex layouts. Experiments explored both zero-shot and few-shot classification approaches, employing multilingual encoder models like XLM-RoBERTa, mBERT, and historical mBERT, alongside instruction-tuned generative models such as Llama-3.1 8b Instruct. Key findings highlight the efficacy of genre classification in making heterogeneous historical sources amenable to text mining, demonstrating that leveraging modern datasets and few-shot learning with pre-trained multilingual encoders significantly improves performance, particularly for historical BERT models. Future work involves applying these methods to specific historical hypotheses, refining annotation schemes, generating synthetic data, and implementing active learning strategies.</p>
</section>
<section id="presentation-outline-and-scope" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="presentation-outline-and-scope"><span class="header-section-number">5.1</span> Presentation Outline and Scope</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>This presentation systematically outlines the research on genre classification for historical medical periodicals. It commences by introducing the ActDisease project, detailing its objectives, the characteristics of its unique dataset, and the inherent challenges encountered during data digitisation. Subsequently, the report transitions to the core experimental work, elucidating the motivation behind genre classification, the methodologies employed for zero-shot and few-shot classification, and specific experiments involving the Llama-3.1 8b Instruct model. The presentation concludes by summarising key findings and discussing future research directions.</p>
</section>
<section id="the-actdisease-project-objectives-and-scope" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="the-actdisease-project-objectives-and-scope"><span class="header-section-number">5.2</span> The ActDisease Project: Objectives and Scope</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The ActDisease project, formally known as ‘Acting out Disease - How Patient Organizations Shaped Modern Medicine’, constitutes an ERC-funded research initiative. This endeavour primarily investigates the historical role of patient organisations in 20th-century Europe. Its central purpose involves scrutinising how these organisations influenced the evolution of disease concepts, the lived experience of illness, and prevailing medical practices. The project specifically focuses on ten European patient organisations across Sweden, Germany, France, and Great Britain, spanning the period from approximately 1890 to 1990. Patient organisation periodicals, predominantly magazines, serve as the main source material. Notably, the Hay Fever Association of Heligoland, founded in 1897, provides a historical anchor for the project’s scope.</p>
</section>
<section id="actdisease-dataset-composition" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="actdisease-dataset-composition"><span class="header-section-number">5.3</span> ActDisease Dataset Composition</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The ActDisease project leverages a substantial, recently digitised private collection of patient organisation magazines, collectively comprising 96,186 pages. This comprehensive dataset encompasses periodicals from several European countries, addressing a range of diseases. German contributions include two allergy/asthma magazines (10,926 pages, 1901-1985), one diabetes magazine (19,324 pages, 1931-1990), and one multiple sclerosis magazine (5,646 pages, 1954-1990). From Sweden, the collection features one allergy/asthma magazine (4,054 pages, 1957-1990), one diabetes magazine (7,150 pages, 1949-1990), and one lung diseases magazine (16,790 pages, 1938-1991). French sources comprise one diabetes magazine (6,206 pages, 1947-1990) and three rheumatism/paralysis magazines (9,317 pages, 1935-1990). Finally, the UK contributes one diabetes magazine (11,127 pages, 1935-1990) and one rheumatism magazine (5,646 pages, 1950-1990). Visual examples, such as the ‘BRA Review’ and ‘Allergia’ (5/1991), illustrate the diverse nature of these historical medical periodicals.</p>
</section>
<section id="digitization-challenges-and-ocr-issues" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="digitization-challenges-and-ocr-issues"><span class="header-section-number">5.4</span> Digitization Challenges and OCR Issues</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The digitisation process for the ActDisease dataset encountered several significant challenges, primarily stemming from Optical Character Recognition (OCR). Whilst ABBYY FineReader Server 14 generally performed well on common layouts and fonts, complex layouts, slanted text, rare fonts, and inconsistent scan or photo quality persistently challenged its accuracy. Consequently, the digitised texts exhibited remaining issues, notably OCR errors, particularly prevalent in German and French materials, and disrupted reading order. Researchers addressed these limitations by conducting experiments on post-OCR correction of German texts, employing instruction-tuned generative models. They observed frequent OCR errors within creative text types, such as advertisements, humour pages, and poems. This work aligns with ongoing research, including a publication by Danilova and Aangenendt on post-OCR correction of historical German periodicals using Large Language Models.</p>
</section>
<section id="challenges-in-analysing-historical-periodicals" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="challenges-in-analysing-historical-periodicals"><span class="header-section-number">5.5</span> Challenges in Analysing Historical Periodicals</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>Analysing historical medical periodicals presents distinct challenges due to the inherent diversity of their textual content. These materials consistently feature a wide array of text types, a characteristic observed across all magazines within the collection. Critically, different genres frequently co-occur on a single page; for instance, an administrative report might appear alongside an advertisement and a humour section. This textual heterogeneity poses a significant problem for conventional analytical methods. Standard yearly and decade-based topic models or term counts fail to account for such intricate textual variations. Consequently, this unclassified mixture of genres introduces a likely bias into topic models and term counts, potentially distorting analytical outcomes.</p>
</section>
<section id="rationale-for-genre-classification" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="rationale-for-genre-classification"><span class="header-section-number">5.6</span> Rationale for Genre Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>Genre has emerged as a particularly useful concept within language technology, offering a robust framework for textual analysis. Researchers define genre as a class of documents united by a shared communicative purpose, a definition supported by scholars such as Petrenz (2004) and Kessler (1997). This classification approach directly supports the project’s key objective: to explore the historical material from diverse perspectives, thereby enabling more nuanced historical arguments. Crucially, genre classification facilitates the study of communicative strategies as they evolve over time, allowing for comparative analysis across different countries, diseases, and publications, as highlighted by Broersma (2010). Furthermore, it enables a fine-grained analysis of term distributions and topic models specifically within identified genres, offering deeper insights than broad, unclassified analyses.</p>
</section>
<section id="illustrating-genre-diversity-poetry-example" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="illustrating-genre-diversity-poetry-example"><span class="header-section-number">5.7</span> Illustrating Genre Diversity: Poetry Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>To illustrate the inherent genre diversity within the historical medical periodicals, researchers present a scanned page featuring multiple text columns and an illustration of a human figure. This visual example clearly demonstrates how various text types coexist within a single publication. A specific section of the text is highlighted as ‘Poetry’, encased within a distinctive white box with a purple border. Surrounding this poetic content, other snippets are visible, including a discussion on ‘Människokroppen’ (The Human Body), a recipe for ‘Cadbury sugar-free chocolate for diabetics’, and practical instructions such as ‘Put oil in saucepan’. This composite layout underscores the challenge of analysing such materials without explicit genre classification.</p>
</section>
<section id="illustrating-genre-diversity-patient-experiences" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="illustrating-genre-diversity-patient-experiences"><span class="header-section-number">5.8</span> Illustrating Genre Diversity: Patient Experiences</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>Further illustrating the textual heterogeneity within historical medical periodicals, another scanned page displays multiple text columns and an illustration. A specific text block is prominently labelled ‘Patient Experiences’, demarcated by a white box with a purple border. The embedded text vividly describes a personal narrative of awakening from a diabetic coma, recounting semi-conscious ramblings that were so realistic they remained imprinted on the memory. This example clearly demonstrates a distinct personal narrative genre. Other visible text snippets on the page include a continuation of the ‘Cadbury sugar-free chocolate’ recipe and instructions for ‘Put oil in saucepan’, reinforcing the co-occurrence of diverse content types.</p>
</section>
<section id="defining-genre-labels-for-classification" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="defining-genre-labels-for-classification"><span class="header-section-number">5.9</span> Defining Genre Labels for Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Researchers meticulously defined the genre labels employed in this project under the direct supervision of the main historian, an expert in patient organisations. This interdisciplinary approach ensured that the genre categories possessed both historical relevance and practical utility. The labels proved instrumental in segmenting the diverse content within the materials, thereby facilitating more focused and granular historical analysis. Furthermore, the design principle prioritised general applicability, aiming for labels that could serve broad analytical purposes beyond the immediate dataset.</p>
</section>
<section id="operational-genre-definitions" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="operational-genre-definitions"><span class="header-section-number">5.10</span> Operational Genre Definitions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>For the purpose of genre classification, researchers established nine distinct categories, each with a precise operational definition. ‘Academic’ texts encompass research-based reports or explanations of scientific ideas, such as research articles or formal reports. ‘Administrative’ documents pertain to organisational activities, including meeting minutes, financial reports, or announcements. ‘Advertisements’ specifically promote products or services for commercial gain. ‘Guides’ offer step-by-step instructions, exemplified by health tips, legal advice, or recipes. ‘Fiction’ aims to entertain and emotionally engage, comprising stories, poems, humour, or myths. ‘Legal’ texts explain terms and conditions, such as contracts or amendments. ‘News’ reports recent events and developments. ‘Nonfiction Prose’ narrates real events or describes cultural and historical topics, encompassing memoirs, essays, or documentary prose. Finally, ‘QA’ (Question and Answer) refers to texts structured as questions followed by expert answers.</p>
</section>
<section id="dataset-annotation-methodology" class="level2" data-number="5.11">
<h2 data-number="5.11" class="anchored" data-anchor-id="dataset-annotation-methodology"><span class="header-section-number">5.11</span> Dataset Annotation Methodology</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Researchers meticulously annotated the dataset to establish ground truth for genre classification. The annotation unit was defined at the paragraph level, specifically ABBYY-generated paragraphs merged based on consistent font patterns, including type, size, bolding, and italics, within a single page. The annotation effort focused on two key periodicals: the Swedish ‘Diabetes’ and the German ‘Diabetiker Journal’, specifically their first and mid-year issues for each year. A multidisciplinary team comprising four historians and two computational linguists, all native or proficient in Swedish and German, performed the annotations. To ensure robustness and reliability, two independent annotations were collected for each paragraph. This rigorous process yielded a remarkably high average inter-annotator agreement of 0.95, as measured by Krippendorff’s alpha, indicating strong consistency across annotators.</p>
</section>
<section id="illustrative-annotation-example" class="level2" data-number="5.12">
<h2 data-number="5.12" class="anchored" data-anchor-id="illustrative-annotation-example"><span class="header-section-number">5.12</span> Illustrative Annotation Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>An illustrative example from ‘Der Diabetiker’ vividly demonstrates the annotation process. Researchers organised the annotation data within a table format, featuring columns for ‘Year’, ‘Volume’, ‘Issue_Nr’, ‘Title’, and ‘Paragraph’, alongside binary indicators for each genre label: ‘academic’, ‘administrative’, ‘advertisement’, ‘fiction’, ‘guide’, ‘nf_prose’, ‘legal’, ‘QA’, and ‘news’. For instance, a paragraph from 1958, titled ‘THE ISLAND (Diabetes was not an obstacle)’, received a ‘1’ under ‘nf_prose’, whilst all other genre categories were marked ‘0’. Another paragraph from the same source similarly received a ‘1’ for ‘nf_prose’. Annotators utilised a .numbers file for this task. Although the original sentences were in German, they were translated using Google Translate for presentation purposes, ensuring clarity of the annotation assignments.</p>
</section>
<section id="dataset-splitting-for-experiments" class="level2" data-number="5.13">
<h2 data-number="5.13" class="anchored" data-anchor-id="dataset-splitting-for-experiments"><span class="header-section-number">5.13</span> Dataset Splitting for Experiments</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>Researchers meticulously partitioned the ActDisease annotated dataset to facilitate various experimental setups. The main split comprised a training set of 1182 paragraphs and a held-out set of 552 paragraphs, constituting approximately 30% of the total data, with stratification applied by genre label to maintain distribution. For few-shot experiments, six distinct training set sizes—100, 200, 300, 400, 500, and the full 1182 paragraphs—were randomly sampled from the main training set, ensuring label balance within each subset. The held-out set was subsequently divided into equally sized validation and test sets, also balanced by label. Notably, the ‘legal’ and ‘news’ genres were excluded from these validation and test sets due to insufficient training data. For zero-shot experiments, the entire test set was utilised, allowing for evaluation without direct training on the ActDisease data.</p>
</section>
<section id="genre-distribution-in-actdisease-dataset" class="level2" data-number="5.14">
<h2 data-number="5.14" class="anchored" data-anchor-id="genre-distribution-in-actdisease-dataset"><span class="header-section-number">5.14</span> Genre Distribution in ActDisease Dataset</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The distribution of genres within the ActDisease dataset, across both training and held-out samples, is visually represented through two distinct bar charts. The left chart illustrates the number of training paragraphs categorised by language and genre, whilst the right chart presents the corresponding distribution for the held-out sample. Both charts employ a y-axis indicating the number of instances and an x-axis denoting the language, specifically German and Swedish. A comprehensive legend maps colours to each of the nine genre labels: ‘QA’, ‘academic’, ‘administrative’, ‘advertisement’, ‘fiction’, ‘guide’, ‘legal’, ‘news’, and ‘non_fiction_prose’. These visualisations reveal varying frequencies; for instance, ‘advertisement’ appears as a dominant genre within the German training set, whilst ‘guide’ shows prominence in the Swedish held-out set, highlighting the heterogeneous nature of the dataset’s composition.</p>
</section>
<section id="external-datasets-for-zero-shot-classification" class="level2" data-number="5.15">
<h2 data-number="5.15" class="anchored" data-anchor-id="external-datasets-for-zero-shot-classification"><span class="header-section-number">5.15</span> External Datasets for Zero-Shot Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>For zero-shot classification experiments, researchers leveraged several publicly available external datasets. Two primary Automatic Genre Identification datasets, annotated at the document level, included the Corpus of Online Registers of English (CORE), developed by Egbert et al.&nbsp;(2015), which primarily features English texts but also includes main categories in Swedish, Finnish, and French. The Functional Text Dimensions (FTD) dataset of web genres, introduced by Sharoff (2018), provides a balanced collection of English and Russian texts, having previously served in automatic web genre classification, as noted by Kuzman et al.&nbsp;(2023). Additionally, the UD-MULTIGENRE (UDM) dataset, a subset of Universal Dependencies (de Marneffe et al., 2021), offered sentence-level genre annotations across 38 languages, with recovered annotations by Danilova and Stymne (2023). These diverse datasets provided crucial external knowledge for cross-dataset genre classification.</p>
</section>
<section id="cross-dataset-genre-mapping" class="level2" data-number="5.16">
<h2 data-number="5.16" class="anchored" data-anchor-id="cross-dataset-genre-mapping"><span class="header-section-number">5.16</span> Cross-Dataset Genre Mapping</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_18.png" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
<p>To enable zero-shot learning across diverse datasets, researchers meticulously mapped genre labels between the ActDisease project’s categories and those found in CORE, UDM, and FTD. For instance, ‘Academic’ in ActDisease corresponds to ‘research article (RA)’ in CORE, ‘academic’ in UDM, and ‘academic (A14)’ in FTD. ‘Administrative’ uniquely maps to ‘parliament’ in UDM, lacking direct equivalents in CORE or FTD. ‘Advertisement’ aligns with ‘advertisement (AD)’ and ‘description with intent to sell (DS)’ in CORE, and ‘commercial (A12)’ in FTD. ‘Guide’ finds multiple mappings in CORE, including ‘how-to (HT)’ and ‘recipe (RE)’, whilst directly mapping to ‘guide’ in UDM and ‘instruct (A7)’ in FTD. ‘Fiction’ is represented by ‘poem (PO)’ and ‘short story (SS)’ in CORE, ‘fiction’ in UDM, and ‘fictive (A4)’ and ‘poetic (A19)’ in FTD. ‘Legal’ maps to ‘legal terms and conditions (LT)’ in CORE, ‘legal’ in UDM, and ‘legal (A9)’ in FTD. ‘News’ corresponds to ‘news report/blog (NE)’ in CORE, ‘news’ in UDM, and ‘reporting (A8)’ in FTD. ‘Nonfiction’ encompasses a broad range, including various blog types and articles in CORE, ‘nonfiction prose’ and ‘blog’ in UDM, and ‘personal (A11)’ and ‘argumentative (A1)’ in FTD. Finally, ‘QA’ maps to ‘question/answer forum (QA)’ and ‘advice (AV)’ in CORE, and ‘QA’ in UDM, with no direct FTD equivalent. This comprehensive mapping ensures comparability across the disparate datasets.</p>
</section>
<section id="training-data-creation-and-configuration" class="level2" data-number="5.17">
<h2 data-number="5.17" class="anchored" data-anchor-id="training-data-creation-and-configuration"><span class="header-section-number">5.17</span> Training Data Creation and Configuration</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_19.png" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>Researchers meticulously crafted the training data through a multi-stage pipeline, beginning with a ‘Genre Map’ and subsequent ‘Mapping’ process that populated a ‘DataFrame’ designated ‘new genre mapping’. This DataFrame then underwent a crucial ‘Pre-process’ step, which systematically removed web addresses, emails, XML-tags, and emojis to clean the data. Following this, the data entered a ‘SAMPLING’ stage. The process integrated three external datasets—CORE, FTD, and UDM—as inputs to the initial mapping. Four distinct configuration options guided the data preparation: ‘[G+]’ restricted the dataset to only Germanic languages, whilst ‘[G-]’ included all language families. Concurrently, ‘[B1]’ implemented balancing based on the ActDisease project’s defined labels, and ‘[B2]’ combined balancing by ActDisease labels with the original labels from the source datasets. These language scope and balancing methods were combined, as indicated by connections between [G+] and [G-] with [B1] and [B2]. Visual representations of the sampled data, including four FTD training samples, four CORE training samples (specifically G+ B1, G+ B2, G- B1, G- B2), and UDM training samples, illustrate the comprehensive nature of this data preparation pipeline.</p>
</section>
<section id="multilingual-encoder-models-utilised" class="level2" data-number="5.18">
<h2 data-number="5.18" class="anchored" data-anchor-id="multilingual-encoder-models-utilised"><span class="header-section-number">5.18</span> Multilingual Encoder Models Utilised</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_20.png" class="img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
<p>Researchers employed a selection of multilingual encoder models for the genre classification task. The primary models included XLM-Roberta, introduced by Conneau et al.&nbsp;(2020), mBERT, developed by Devlin et al.&nbsp;(2019), and a specialised historical mBERT, presented by Schweter et al.&nbsp;(2022). BERT-like models, such as these, have seen extensive application in prior work for web register and genre classification, as evidenced by studies from Lepekhin and Sharoff (2022), Kuzman and Ljubešić (2023), and Laippala et al.&nbsp;(2023). XLM-RoBERTa stands out as a state-of-the-art web genre classifier, according to Kuzman et al.&nbsp;(2023). The historical mBERT model, specifically, benefits from pretraining on a substantial corpus of multilingual historical newspapers, rendering it particularly relevant for this project. Conversely, mBERT served as a comparative baseline against hmBERT, given their non-direct comparability with XLM-Roberta.</p>
</section>
<section id="model-fine-tuning-process" class="level2" data-number="5.19">
<h2 data-number="5.19" class="anchored" data-anchor-id="model-fine-tuning-process"><span class="header-section-number">5.19</span> Model Fine-tuning Process</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_21.png" class="img-fluid figure-img"></p>
<figcaption>Slide 21</figcaption>
</figure>
</div>
<p>Researchers systematically fine-tuned the selected models through a structured process. Each training set was prepared in four distinct configurations, providing varied data inputs. These datasets included FTD (Functional Text Dimensions), CORE (Corpus of Online Registers of English), UDM (UD-MULTIGENRE), and a combined Merged dataset. A central ‘finetuning’ step applied uniformly across all three chosen models: XLM-Roberta, mBERT, and hmBERT. This comprehensive experimental setup ultimately yielded a total of 48 fine-tuned models, representing the permutations of dataset configurations and model types, ready for subsequent evaluation.</p>
</section>
<section id="zero-shot-learning-evaluation-phase" class="level2" data-number="5.20">
<h2 data-number="5.20" class="anchored" data-anchor-id="zero-shot-learning-evaluation-phase"><span class="header-section-number">5.20</span> Zero-Shot Learning Evaluation Phase</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_22.png" class="img-fluid figure-img"></p>
<figcaption>Slide 22</figcaption>
</figure>
</div>
<p>This section initiates the evaluation phase for the zero-shot learning experiments, presenting the methodologies and results derived from the classification tasks performed without direct training on the target dataset.</p>
</section>
<section id="zero-shot-prediction-evaluation-methodology" class="level2" data-number="5.21">
<h2 data-number="5.21" class="anchored" data-anchor-id="zero-shot-prediction-evaluation-methodology"><span class="header-section-number">5.21</span> Zero-Shot Prediction Evaluation Methodology</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_23.png" class="img-fluid figure-img"></p>
<figcaption>Slide 23</figcaption>
</figure>
</div>
<p>Evaluating zero-shot predictions presented a significant challenge due to the imperfect overlap of label sets across different datasets, which precluded direct comparison of overall performance metrics. Consequently, researchers adopted a granular approach, assessing the performance of each genre independently and meticulously analysing confusion matrices. The X-GENRE web genre classifier, as described by Kuzman et al.&nbsp;(2023), served as a crucial baseline. The evaluation specifically focused on predictions made on labels most similar to and directly mappable to the ActDisease categories. Furthermore, the experiments inherently involved cross-lingual scenarios: the FTD and X-GENRE datasets were entirely cross-lingual, lacking German or Swedish training data, whilst the UDM and CORE datasets exhibited partial cross-lingual characteristics.</p>
</section>
<section id="summary-of-zero-shot-classification-results" class="level2" data-number="5.22">
<h2 data-number="5.22" class="anchored" data-anchor-id="summary-of-zero-shot-classification-results"><span class="header-section-number">5.22</span> Summary of Zero-Shot Classification Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_24.png" class="img-fluid figure-img"></p>
<figcaption>Slide 24</figcaption>
</figure>
</div>
<p>The zero-shot classification experiments yielded several key findings. Models fine-tuned on the FTD dataset demonstrated superior performance when employing the ActDisease genre mapping. Conversely, other datasets exhibited distinct class-specific biases. In the UDM dataset, a bias towards ‘news’ emerged, primarily because the news training data contained the highest number of Germanic instances, predominantly German. For the CORE dataset, a bias towards ‘guide’ was observed, as only the guide training data was truly multilingual. Intriguingly, XLM-Roberta, when trained on UDM, achieved an average of 32% more correct predictions in the ‘QA’ genre compared to mBERT and hmBERT. Conversely, hmBERT, also on UDM, showed an average of 16% more correct predictions in ‘Administrative’ texts than XLM-Roberta and mBERT. Furthermore, models trained on CORE consistently performed well in predicting the ‘legal’ genre.</p>
</section>
<section id="zero-shot-classification-confusion-matrices" class="level2" data-number="5.23">
<h2 data-number="5.23" class="anchored" data-anchor-id="zero-shot-classification-confusion-matrices"><span class="header-section-number">5.23</span> Zero-Shot Classification Confusion Matrices</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_25.png" class="img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
<p>Four distinct confusion matrices visually represent the performance of various models and dataset configurations in the zero-shot classification task. Each matrix plots ‘True Genre’ against ‘Predicted Genre’, with a colour scale indicating the count of instances. The genres consistently include ‘QA’, ‘academic’, ‘administrative’, ‘advertisement’, ‘fiction’, ‘guide’, ‘legal’, ‘news’, and ‘nf_prose’. For instance, the ‘hmBERT_UDM_True_True’ matrix shows 43 instances of ‘academic’ and 31 instances of ‘guide’ were correctly classified, whilst 3 instances of ‘news’ were incorrectly predicted as ‘administrative’. The ‘xlmr_CORE_True_False’ matrix highlights 85 correct ‘guide’ predictions, but also 30 ‘academic’ instances misclassified as ‘administrative’. In the ‘xlmr_UDM_False_False’ matrix, 35 ‘administrative’ instances were correctly predicted, yet 8 ‘QA’ instances were misclassified as ‘administrative’. Finally, the ‘xlmr_FTD_False_False’ matrix demonstrates 108 correct ‘advertisement’ predictions, alongside 30 ‘news’ instances incorrectly classified as ‘administrative’. These matrices provide granular insights into the models’ strengths and specific misclassification patterns across different datasets.</p>
</section>
<section id="zero-shot-per-category-f1-scores" class="level2" data-number="5.24">
<h2 data-number="5.24" class="anchored" data-anchor-id="zero-shot-per-category-f1-scores"><span class="header-section-number">5.24</span> Zero-Shot Per-Category F1 Scores</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_26.png" class="img-fluid figure-img"></p>
<figcaption>Slide 26</figcaption>
</figure>
</div>
<p>A comprehensive table presents the F1 scores for various genres and models across four distinct dataset configurations: FTD, CORE, UDM, and a merged dataset. The data is organised by dataset, then by model, including X-GENRE, hmBERT, mBERT, and XLM-RoBERTa, with columns representing each genre category. Notably, for the FTD dataset, XLM-RoBERTa consistently demonstrated strong performance, achieving an F1 score of 0.89 for ‘guide’, 0.82 for ‘legal’, and 0.74 for ‘advertisement’. Within the CORE dataset, both hmBERT and XLM-RoBERTa exhibited high F1 scores for ‘legal’, reaching 0.80 and 0.84 respectively. For the UDM dataset, XLM-RoBERTa secured the highest F1 for ‘QA’ at 0.53, whilst hmBERT led for ‘administrative’ at 0.43. Across the board, the ‘merged’ configuration generally yielded lower F1 scores for all models and genres when compared to individual dataset configurations. Bolded values within the table highlight the peak F1 score for each specific genre within its respective dataset configuration, providing clear quantitative insights into model performance.</p>
</section>
<section id="impact-of-configuration-on-zero-shot-performance" class="level2" data-number="5.25">
<h2 data-number="5.25" class="anchored" data-anchor-id="impact-of-configuration-on-zero-shot-performance"><span class="header-section-number">5.25</span> Impact of Configuration on Zero-Shot Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_27.png" class="img-fluid figure-img"></p>
<figcaption>Slide 27</figcaption>
</figure>
</div>
<p>Analysis of the average F1 performance across different configurations reveals distinct impacts on zero-shot classification. For the FTD dataset, configurations [B 1] and [G -] yielded the highest F1 scores of 0.56, whilst [B 2] and [G +] resulted in a decrease in performance. In the CORE dataset, F1 scores remained consistently around 0.32 across most configurations, with a marginal decrease to 0.31 for [G -]; the presence of a small number of Finnish and French instances, particularly within the ‘guide’ genre, marginally reduced overall performance. Conversely, for the UDM dataset, the presence of other language families and balancing strategies generally improved macro F1 performance, with [G -] achieving the highest score of 0.22 and [B 2] also performing strongly at 0.19. These findings underscore how data balancing and language family inclusion critically influence model efficacy in zero-shot settings.</p>
</section>
<section id="few-shot-learning-evaluation-phase" class="level2" data-number="5.26">
<h2 data-number="5.26" class="anchored" data-anchor-id="few-shot-learning-evaluation-phase"><span class="header-section-number">5.26</span> Few-Shot Learning Evaluation Phase</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_28.png" class="img-fluid figure-img"></p>
<figcaption>Slide 28</figcaption>
</figure>
</div>
<p>This section marks the commencement of the evaluation phase for few-shot learning experiments, detailing the performance and insights derived from models trained on limited data samples.</p>
</section>
<section id="few-shot-learning-performance-trends" class="level2" data-number="5.27">
<h2 data-number="5.27" class="anchored" data-anchor-id="few-shot-learning-performance-trends"><span class="header-section-number">5.27</span> Few-Shot Learning Performance Trends</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_29.png" class="img-fluid figure-img"></p>
<figcaption>Slide 29</figcaption>
</figure>
</div>
<p>A line graph visually depicts the performance of various models in a few-shot setting, illustrating the impact of Masked Language Model (MLM) fine-tuning. The x-axis represents dataset size, ranging from 200 to 1200 instances, whilst the y-axis indicates the F1 score, spanning from 0.2 to 0.8. Six distinct lines trace the performance of ‘hmbert’, ‘hmbert-mlm’, ‘mbert’, ‘mbert-mlm’, ‘xlmr’, and ‘xlmr-mlm’. Consistently, all models demonstrate an increasing trend in F1 score as the dataset size expands, underscoring the benefit of more training data. Crucially, further training on the ActDisease dataset, particularly with MLM fine-tuning, proves distinctly advantageous. Whilst F1 scores continue to rise with an increasing number of training instances, they remain below 0.8 even at the largest size of 1182. Notably, the hmBERT-MLM model consistently outperforms its counterparts, achieving the highest F1 scores.</p>
</section>
<section id="detailed-few-shot-learning-performance-metrics" class="level2" data-number="5.28">
<h2 data-number="5.28" class="anchored" data-anchor-id="detailed-few-shot-learning-performance-metrics"><span class="header-section-number">5.28</span> Detailed Few-Shot Learning Performance Metrics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_30.png" class="img-fluid figure-img"></p>
<figcaption>Slide 30</figcaption>
</figure>
</div>
<p>A comprehensive table details the performance of six distinct models—XLMR, XLMR-MLM, hmBERT, hmBERT-MLM, mBERT, and mBERT-MLM—across two training sizes: 500 and 1182 instances. The table presents F1 scores for individual genre categories, including ‘QA’, ‘academic’, ‘administrative’, ‘advertisement’, ‘fiction’, ‘guide’, and ‘nf_prose’, alongside overall metrics such as ‘accuracy’ and ‘macro_F1’. For ‘QA’, XLMR-MLM at 1182 instances achieved the highest F1 of 0.84. Both XLMR-MLM and mBERT-MLM reached an F1 of 0.81 for ‘academic’ at the largest training size. In ‘administrative’ classification, hmBERT-MLM and mBERT-MLM both attained an F1 of 0.86. XLMR-MLM demonstrated exceptional performance for ‘advertisement’, securing an F1 of 0.93. For ‘fiction’, mBERT-MLM achieved 0.62, whilst hmBERT-MLM reached 0.51. XLMR-MLM led in ‘guide’ classification with 0.79, and hmBERT-MLM achieved 0.82 for ‘nf_prose’. Overall accuracy ranged from 0.63 to 0.81, whilst macro_F1 scores spanned 0.61 to 0.77, with hmBERT-MLM at 1182 instances achieving the highest macro_F1 of 0.77. Shaded cells and bolded values visually highlight superior performance within each category and size, underscoring the benefits of MLM fine-tuning and increased training data.</p>
</section>
<section id="few-shot-classification-confusion-matrix-and-insights" class="level2" data-number="5.29">
<h2 data-number="5.29" class="anchored" data-anchor-id="few-shot-classification-confusion-matrix-and-insights"><span class="header-section-number">5.29</span> Few-Shot Classification Confusion Matrix and Insights</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_31.png" class="img-fluid figure-img"></p>
<figcaption>Slide 31</figcaption>
</figure>
</div>
<p>A confusion matrix, specifically illustrating the XLM-Roberta-MLM classification results with a full-sized training dataset, provides granular insights into few-shot performance. The matrix plots ‘True Genre’ against ‘Predicted Genre’, encompassing ‘administrative’, ‘academic’, ‘fiction’, ‘nf_prose’, ‘QA’, ‘guide’, and ‘advertisement’ genres, with a colour scale indicating instance counts up to 120. For example, the model accurately predicted 59 ‘administrative’, 96 ‘nf_prose’, and 120 ‘advertisement’ instances. Qualitative observations derived from this analysis highlight several critical points. Researchers suggest that ‘fiction’ and ‘nonfictional prose’ may exhibit increasing similarity, posing a classification challenge. This phenomenon likely stems from the domain-specific nature of the dataset, as all genres are confined to patient organisation magazines primarily focused on diabetes. Consequently, both fictional and (auto)biographical texts frequently revolve around the experiences of diabetes patients, leading them to share common themes and narrative structures, which can blur genre boundaries.</p>
</section>
<section id="few-shot-prompting-evaluation-phase" class="level2" data-number="5.30">
<h2 data-number="5.30" class="anchored" data-anchor-id="few-shot-prompting-evaluation-phase"><span class="header-section-number">5.30</span> Few-Shot Prompting Evaluation Phase</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_32.png" class="img-fluid figure-img"></p>
<figcaption>Slide 32</figcaption>
</figure>
</div>
<p>This section introduces the evaluation phase dedicated to few-shot prompting experiments, focusing on the performance of large language models when guided by specific instructions and limited examples.</p>
</section>
<section id="llama-3.1-8b-instruct-model-prompting" class="level2" data-number="5.31">
<h2 data-number="5.31" class="anchored" data-anchor-id="llama-3.1-8b-instruct-model-prompting"><span class="header-section-number">5.31</span> Llama-3.1 8b Instruct Model Prompting</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_33.png" class="img-fluid figure-img"></p>
<figcaption>Slide 33</figcaption>
</figure>
</div>
<p>Researchers employed the Llama-3.1 8b Instruct model for few-shot prompting, providing it with a precise instruction: ‘Label the text with one of the following genres based on their purpose and content:’. This instruction was accompanied by explicit definitions for each genre. ‘Academic’ encompassed research-based articles and popular science. ‘Administrative’ included documents like meeting minutes and financial reports. ‘Advertisement’ covered promotions and invitations. ‘Guide’ provided dietary advice, exercise instructions, or recipes. ‘Fiction’ comprised poems, short stories, and humour. ‘Legal’ referred to contracts and terms. ‘News’ denoted daily reports. ‘Nonfictional_prose’ covered autobiographies, memoirs, and essays. ‘QA’ described question-answer formatted texts. An ‘Examples:’ section further guided the model, whilst the input format was specified as ‘[INST] test[i]“text” [/INST]’, with an expected ‘Genre:’ output. This detailed prompt engineering aimed to optimise the model’s genre classification capabilities.</p>
</section>
<section id="llama-3.1-8b-instruct-performance" class="level2" data-number="5.32">
<h2 data-number="5.32" class="anchored" data-anchor-id="llama-3.1-8b-instruct-performance"><span class="header-section-number">5.32</span> Llama-3.1 8b Instruct Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_34.png" class="img-fluid figure-img"></p>
<figcaption>Slide 34</figcaption>
</figure>
</div>
<p>The Llama-3.1 8b Instruct model demonstrated varied performance across genres in the few-shot prompting setup. Its F1-scores included 0.62 for ‘QA’, 0.72 for ‘academic’, 0.60 for ‘administrative’, 0.73 for ‘advertisement’, 0.64 for ‘fiction’, and 0.61 for ‘guide’. Notably, the model achieved its highest F1 score of 0.84 for ‘legal’ texts. Conversely, its performance on ‘news’ was exceptionally low, yielding an F1 of merely 0.08, whilst ‘nonfiction_prose’ scored 0.49. Overall metrics indicated an accuracy of 0.62, a macro average F1 of 0.59, and a weighted average F1 of 0.63. A visual confusion matrix, depicting few-shot prediction performance on the entire held-out set (used as a zero-shot test set), further illuminated these results. It showed successful classification for many genres, with 18 ‘QA’, 54 ‘academic’, 58 ‘administrative’, 77 ‘advertisement’, 30 ‘fiction’, 28 ‘guide’, 27 ‘legal’, and 49 ‘nf_prose’ instances correctly predicted. However, the matrix starkly highlighted the model’s struggle with ‘news’, correctly predicting only 1 instance, whilst misclassifying 8 instances as ‘nf_prose’, underscoring a significant area for improvement.</p>
</section>
<section id="challenges-of-popular-magazine-text-mining" class="level2" data-number="5.33">
<h2 data-number="5.33" class="anchored" data-anchor-id="challenges-of-popular-magazine-text-mining"><span class="header-section-number">5.33</span> Challenges of Popular Magazine Text Mining</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_35.png" class="img-fluid figure-img"></p>
<figcaption>Slide 35</figcaption>
</figure>
</div>
<p>A primary conclusion drawn from this research highlights the inherent complexity of text mining popular magazines. Unlike more homogeneous scientific journals and books, these periodicals frequently contain a multitude of genres. This textual diversity significantly increases the challenge of extracting meaningful information and patterns through automated text mining techniques.</p>
</section>
<section id="enabling-text-mining-through-genre-classification" class="level2" data-number="5.34">
<h2 data-number="5.34" class="anchored" data-anchor-id="enabling-text-mining-through-genre-classification"><span class="header-section-number">5.34</span> Enabling Text Mining through Genre Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_36.png" class="img-fluid figure-img"></p>
<figcaption>Slide 36</figcaption>
</figure>
</div>
<p>Whilst popular magazines inherently present a multitude of genres, rendering text mining more challenging than for scientific journals and books, a crucial finding emerges: genre classification offers a viable solution. By systematically categorising the diverse content, genre classification effectively renders these complex historical sources accessible for advanced text mining methodologies, thereby unlocking their rich informational potential.</p>
</section>
<section id="key-conclusions-and-performance-insights" class="level2" data-number="5.35">
<h2 data-number="5.35" class="anchored" data-anchor-id="key-conclusions-and-performance-insights"><span class="header-section-number">5.35</span> Key Conclusions and Performance Insights</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_37.png" class="img-fluid figure-img"></p>
<figcaption>Slide 37</figcaption>
</figure>
</div>
<p>The research yields five pivotal conclusions regarding genre classification in historical medical periodicals. Firstly, popular magazines, unlike more uniform scientific publications, contain a multitude of genres, which inherently complicates text mining efforts. Secondly, the implementation of genre classification effectively addresses this challenge, rendering these rich historical sources accessible for advanced text mining. Thirdly, even in the absence of specific training data, researchers successfully demonstrated the feasibility of leveraging existing modern datasets for effective classification. Fourthly, open generative models proved capable of achieving a decent quality of classification. Finally, and most significantly, few-shot learning applied to multilingual encoders, particularly when combined with prior Masked Language Model (MLM) fine-tuning, exhibited superior performance. This approach yielded particularly strong gains for the historical multilingual BERT model, achieving a 24% improvement, notably surpassing the 14.5% gain for mBERT-MLM and 16.9% for XLM-RoBERTa.</p>
</section>
<section id="future-research-directions" class="level2" data-number="5.36">
<h2 data-number="5.36" class="anchored" data-anchor-id="future-research-directions"><span class="header-section-number">5.36</span> Future Research Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_38.png" class="img-fluid figure-img"></p>
<figcaption>Slide 38</figcaption>
</figure>
</div>
<p>Future research within the ActDisease project will pursue several promising directions. Researchers plan to engage more deeply with specific historical hypotheses, leveraging the genre classification framework to address nuanced questions. A key methodological development involves crafting a new annotation scheme designed to capture more fine-grained genre distinctions. To support this, an annotation project, financed by Swe-CLARIN, is currently underway. Furthermore, the team intends to explore advanced data augmentation techniques, specifically through synthetic data generation, to expand the training corpus. Finally, the implementation of active learning strategies will optimise the annotation process, ensuring efficient and targeted data collection for continuous model improvement.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_004.html" class="pagination-link" aria-label="Introducing OpenAlex Mapper">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="The VERITRACE Project">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>