<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vera Danilova">
<meta name="dcterms.date" content="2025-01-01">

<title>5&nbsp; Genre Classification for Historical Medical Periodicals – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_006.html" rel="next">
<link href="./chapter_ai-nepi_004.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-fe5eeb5af71a333b155c360431d06b9a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e463572c889c87c7eefd27e1777fa793.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="5&nbsp; Genre Classification for Historical Medical Periodicals – AI-NEPI Conference Proceedings - Enhanced Edition">
<meta property="og:description" content="The ActDisease project at Uppsala University focuses on the history of patient organizations in 20th century Europe, using their periodicals as primary source material. The project aims to classify textual genres within these historical medical periodicals to facilitate nuanced historical analysis, study the evolution of communicative strategies, and enhance the accuracy of text mining techniques. The digitization of these periodicals involved Optical Character Recognition (OCR) using ABB…">
<meta property="og:image" content="images/ai-nepi_005_slide_01.jpg">
<meta property="og:site_name" content="AI-NEPI Conference Proceedings - Enhanced Edition">
<meta name="twitter:title" content="5&nbsp; Genre Classification for Historical Medical Periodicals – AI-NEPI Conference Proceedings - Enhanced Edition">
<meta name="twitter:description" content="The ActDisease project at Uppsala University focuses on the history of patient organizations in 20th century Europe, using their periodicals as primary source material. The project aims to classify textual genres within these historical medical periodicals to facilitate nuanced historical analysis, study the evolution of communicative strategies, and enhance the accuracy of text mining techniques. The digitization of these periodicals involved Optical Character Recognition (OCR) using ABB…">
<meta name="twitter:image" content="images/ai-nepi_005_slide_01.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_005.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">A Primer on Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OpenAlex Mapper: Transdisciplinary Investigations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Computational HPSS: Tracing Ancient Wisdom’s Influence with VERITRACE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and Scientific Insights in Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">5.1</span> Overview</a></li>
  <li><a href="#actdisease-project-and-dataset" id="toc-actdisease-project-and-dataset" class="nav-link" data-scroll-target="#actdisease-project-and-dataset"><span class="header-section-number">5.2</span> ActDisease Project and Dataset</a></li>
  <li><a href="#digitization-and-ocr-challenges" id="toc-digitization-and-ocr-challenges" class="nav-link" data-scroll-target="#digitization-and-ocr-challenges"><span class="header-section-number">5.3</span> Digitization and OCR Challenges</a></li>
  <li><a href="#motivation-for-genre-classification" id="toc-motivation-for-genre-classification" class="nav-link" data-scroll-target="#motivation-for-genre-classification"><span class="header-section-number">5.4</span> Motivation for Genre Classification</a></li>
  <li><a href="#genre-definitions-and-examples" id="toc-genre-definitions-and-examples" class="nav-link" data-scroll-target="#genre-definitions-and-examples"><span class="header-section-number">5.5</span> Genre Definitions and Examples</a></li>
  <li><a href="#annotation-process-and-dataset-preparation" id="toc-annotation-process-and-dataset-preparation" class="nav-link" data-scroll-target="#annotation-process-and-dataset-preparation"><span class="header-section-number">5.6</span> Annotation Process and Dataset Preparation</a></li>
  <li><a href="#zero-shot-genre-classification" id="toc-zero-shot-genre-classification" class="nav-link" data-scroll-target="#zero-shot-genre-classification"><span class="header-section-number">5.7</span> Zero-Shot Genre Classification</a></li>
  <li><a href="#few-shot-classification-with-encoder-models" id="toc-few-shot-classification-with-encoder-models" class="nav-link" data-scroll-target="#few-shot-classification-with-encoder-models"><span class="header-section-number">5.8</span> Few-Shot Classification with Encoder Models</a></li>
  <li><a href="#few-shot-prompting-with-llama-3.1-8b-instruct" id="toc-few-shot-prompting-with-llama-3.1-8b-instruct" class="nav-link" data-scroll-target="#few-shot-prompting-with-llama-3.1-8b-instruct"><span class="header-section-number">5.9</span> Few-Shot Prompting with <em>Llama-3.1 8b Instruct</em></a></li>
  <li><a href="#conclusions-and-future-work" id="toc-conclusions-and-future-work" class="nav-link" data-scroll-target="#conclusions-and-future-work"><span class="header-section-number">5.10</span> Conclusions and Future Work</a></li>
  <li><a href="#acknowledgements" id="toc-acknowledgements" class="nav-link" data-scroll-target="#acknowledgements"><span class="header-section-number">5.11</span> Acknowledgements</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Show code</button></div></div>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Vera Danilova <a href="mailto:vera.danilova@idehist.uu.se" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Uppsala University
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    The ActDisease project at Uppsala University focuses on the history of patient organizations in 20th century Europe, using their periodicals as primary source material. The project aims to classify textual genres within these historical medical periodicals to facilitate nuanced historical analysis, study the evolution of communicative strategies, and enhance the accuracy of text mining techniques. The digitization of these periodicals involved Optical Character Recognition (OCR) using ABB…
  </div>
</div>


</header>


<section id="overview" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">5.1</span> Overview</h2>
<p>The ActDisease project at Uppsala University focuses on the history of patient organizations in 20th century Europe, using their periodicals as primary source material. The project aims to classify textual genres within these historical medical periodicals to facilitate nuanced historical analysis, study the evolution of communicative strategies, and enhance the accuracy of text mining techniques.</p>
<p>The digitization of these periodicals involved Optical Character Recognition (OCR) using <em>ABBYY FineReader Server 14</em>. This process presented challenges with complex layouts, varied fonts, and scan quality, leading to OCR errors and disrupted reading order. Experiments were conducted for post-OCR correction of German texts using instruction-tuned generative models.</p>
<p>A key methodological component of the project is genre classification. Nine distinct genres were defined (Academic, Administrative, Advertisement, Guide, Fiction, Legal, News, Nonfiction Prose, QA) based on communicative purpose, under the supervision of a historian. Annotation was performed at the paragraph level on Swedish and German periodicals, achieving a Krippendorff’s alpha of 0.95.</p>
<p>The research explored both zero-shot and few-shot learning approaches. Zero-shot experiments involved mapping ActDisease genres to labels from publicly available datasets (<em>CORE</em>, <em>FTD</em>, <em>UDM</em>) and fine-tuning multilingual encoder models (<em>XLM-Roberta</em>, <em>mBERT</em>, historical <em>mBERT</em> - <em>hmBERT</em>). Results indicated that models fine-tuned on <em>FTD</em> with custom mapping performed well, and specific models showed aptitude for certain genres (e.g., <em>hmBERT</em> for ‘Administrative’).</p>
<p>Few-shot learning experiments assessed performance with varying training data sizes, with and without prior Masked Language Model (MLM) fine-tuning. MLM fine-tuning significantly boosted performance, with <em>hmBERT-MLM</em> showing the best results, particularly in distinguishing between fiction and nonfiction. Further experiments involved few-shot prompting of <em>Llama-3.1 8b Instruct</em>, which demonstrated decent quality but required more examples for complex genres.</p>
<p>The findings underscore that genre classification is vital for analyzing the diverse content of popular historical magazines. While zero-shot methods offer a viable starting point, few-shot learning with prior MLM fine-tuning of multilingual encoders, especially historical models like <em>hmBERT</em>, provides superior results. Future work includes refining annotation schemes, synthetic data generation, and active learning to improve classification quality. The tools and resources utilized include the ActDisease dataset, <em>ABBYY FineReader Server 14</em>, the <em>CORE</em>, <em>FTD</em>, and <em>UDM</em> datasets, and various language models (<em>XLM-Roberta</em>, <em>mBERT</em>, <em>hmBERT</em>, <em>Llama-3.1 8b Instruct</em>).</p>
</section>
<section id="actdisease-project-and-dataset" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="actdisease-project-and-dataset"><span class="header-section-number">5.2</span> ActDisease Project and Dataset</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>The ActDisease project, titled “Acting out Disease - How Patient Organizations Shaped Modern Medicine,” is an ERC-funded research initiative (ERC-2021-STG 101040999). It is based at the Department of History of Science and Ideas, Uppsala University, Sweden. Its primary purpose is to investigate the historical role of patient organizations in shaping disease concepts, illness experiences, and medical practices throughout 20th century Europe.</p>
<p>The project focuses on approximately 10 European patient organizations located in Sweden, Germany, France, and Great Britain, covering a period from around 1890 to 1990. The main source material for this research comprises periodicals, predominantly magazines, published by these patient organizations. This collection forms the ActDisease dataset, a private and recently digitized compilation totaling 96,186 pages.</p>
<p>The dataset includes materials related to various diseases and countries:</p>
<ul>
<li><p>Germany: Allergy/Asthma, Diabetes, Multiple Sclerosis.</p></li>
<li><p>Sweden: Allergy/Asthma, Diabetes, Lung Diseases.</p></li>
<li><p>France: Diabetes, Rheumatism/Paralysis.</p></li>
<li><p>UK: Diabetes, Rheumatism.</p></li>
</ul>
<p>Illustrative examples of these periodicals include “BRA Review” and “Allergia.” An example of the historical context is Heligoland, Germany, which was the founding place of the Hay Fever Association of Heligoland in 1897.</p>
</section>
<section id="digitization-and-ocr-challenges" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="digitization-and-ocr-challenges"><span class="header-section-number">5.3</span> Digitization and OCR Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>The digitization of the ActDisease dataset was performed using Optical Character Recognition (OCR). The software employed for this task was <em>ABBYY FineReader Server 14</em>. While this OCR model performed well in recognizing most common layouts and fonts, several challenges persisted. These included difficulties with complex page layouts, slanted text, rare or unusual fonts, and inconsistencies in scan or photograph quality.</p>
<p>Consequently, some issues remain in the digitized collection. These include OCR errors, which are especially prevalent in German and French texts, and instances of disrupted reading order. To address some of these problems, experiments were conducted on post-OCR correction, specifically for German texts, utilizing instruction-tuned generative models.</p>
<p>The findings of these experiments are detailed in a publication by Danilova and Aangenendt (<em>RESOURCEFUL-2025, ACL</em>). It was also observed that OCR errors occur frequently in texts with creative formatting, such as advertisements, humor pages, and poems.</p>
</section>
<section id="motivation-for-genre-classification" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="motivation-for-genre-classification"><span class="header-section-number">5.4</span> Motivation for Genre Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Exploration of the ActDisease materials revealed a high diversity of text types, which, however, exhibited similarities across the different magazines. A significant challenge identified is that various text types often appear concurrently on a single page—for instance, an administrative report might be placed next to an an advertisement and a humor section. This heterogeneity poses a problem for standard text mining approaches, as yearly and decade-based topic models and term counts typically do not differentiate between these text types, leading to a likely bias towards the most frequent genres.</p>
<p>To address these challenges, genre emerged as a useful concept. In language technology, genre is often defined as a class of documents that share a common communicative purpose, as described by Petrenz (2004) and Kessler (1997). The primary objective of implementing genre classification is to enable the exploration of the source material from multiple perspectives, thereby facilitating the formulation of historical arguments.</p>
<p>Specifically, genre classification allows for the study of how communicative strategies evolved over time, comparing these strategies across different countries, diseases, and publications. Furthermore, it permits a more fine-grained analysis of term distributions and topic models by examining them within distinct genre categories.</p>
</section>
<section id="genre-definitions-and-examples" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="genre-definitions-and-examples"><span class="header-section-number">5.5</span> Genre Definitions and Examples</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The ActDisease periodicals contain a variety of textual genres. Examples identified include poetry, academic reports (such as studies on the pancreas), legal documents (like deeds of covenant), advertisements (for instance, for diabetic chocolate), instructive or guidance texts (including recipes or dietary advice), patient organization reports detailing meetings and activities, and narratives about patient experiences and lives.</p>
<p>The genre labels used for classification were defined under the supervision of the project’s main historian, who specializes in patient organizations. The labels were designed to be useful for segregating content within the materials to support further historical analysis, while also being as general-purpose as possible to allow for potential application to similar datasets.</p>
<p>The following genres, along with their definitions and communicative purposes, were established:</p>
<ul>
<li><p>Academic: Consists of research-based reports or explanations of scientific ideas, such as research articles or reports. Its purpose is to convey information from the scientific and medical communities to the magazine’s audience.</p></li>
<li><p>Administrative: Includes documents pertaining to organizational activities, like meeting minutes, reports, and announcements. It aims to report on and inform about the events and activities of patient organizations.</p></li>
<li><p>Advertisement: Features content that promotes products or services for commercial purposes.</p></li>
<li><p>Guide: Provides step-by-step instructions, such as health tips, legal advice, or recipes.</p></li>
<li><p>Fiction: Encompasses texts designed to entertain and emotionally engage readers, including stories, poems, humor, and myths.</p></li>
<li><p>Legal: Contains texts that explain legal terms and conditions, such as contracts, rules, or amendments.</p></li>
<li><p>News: Comprises reports on recent events and developments.</p></li>
<li><p>Nonfiction Prose: Includes narratives of real events or descriptions of cultural or historical topics, such as memoirs, essays, or documentaries.</p></li>
<li><p>QA: Refers to sections structured as questions paired with expert answers, commonly found in the periodicals.</p></li>
</ul>
</section>
<section id="annotation-process-and-dataset-preparation" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="annotation-process-and-dataset-preparation"><span class="header-section-number">5.6</span> Annotation Process and Dataset Preparation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The annotation unit for genre classification was defined as paragraphs. These paragraphs were derived from the <em>ABBYY OCR</em> output and subsequently merged based on font patterns (type, size, bold, italic attributes) at the page level. For the annotation task, samples were drawn from two specific periodicals: the Swedish magazine “Diabetes” and the German magazine “Diabetiker Journal.” The selection comprised the first and mid-year issues from each year of these publications.</p>
<p>A team of six project members, consisting of four historians and two computational linguists, all either native speakers or proficient in Swedish and German, performed the annotations. Two independent annotations were collected for each paragraph. The inter-annotator agreement achieved was 0.95, measured by Krippendorff’s alpha, indicating a high level of consistency. An example of the annotation file shows a tabular structure with metadata (Year, Volume, Issue, etc.), the paragraph text, and columns for each genre where annotators made hard assignments.</p>
<p>The annotated dataset was split into a training set of 1182 paragraphs and a held-out set of 552 paragraphs (approximately 30% of the data), with stratification by label. For few-shot learning experiments, six different training set sizes were created (100, 200, 300, 400, 500, and 1182 paragraphs), randomly sampled from the main training set and balanced by label. The held-out set was further divided equally into validation and test sets, also balanced by label. The ‘legal’ and ‘news’ genres were excluded from these few-shot experiments due to insufficient training instances. For zero-shot experiments, the entire test portion of the held-out set was utilized. Analysis of genre distribution in the training and held-out samples revealed a strong imbalance for the ‘advertisement’ and ‘nonfictional prose’ genres across the German and Swedish languages.</p>
</section>
<section id="zero-shot-genre-classification" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="zero-shot-genre-classification"><span class="header-section-number">5.7</span> Zero-Shot Genre Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>For zero-shot genre classification, the research addressed two main questions: whether genre labels from publicly available datasets could be efficiently mapped to the custom ActDisease labels, and how classification performance would vary across different datasets and models. Three publicly available datasets were utilized: the <em>Corpus of Online Registers of English (CORE)</em> by Egbert et al.&nbsp;(2015), annotated at the document level primarily in English; the <em>Functional Text Dimensions (FTD)</em> dataset of web genres by Sharoff (2018), also document-level, covering English and Russian; and <em>UD-MULTIGENRE (UDM)</em>, a subset of <em>Universal Dependencies</em> with recovered sentence-level genre annotations in 38 languages (de Marneffe et al., 2021; Danilova and Stymne, 2023).</p>
<p>Genre mapping between ActDisease labels and those in <em>CORE</em>, <em>UDM</em>, and <em>FTD</em> was performed independently by two annotators, with final mappings chosen based on full agreement. For example, the ActDisease ‘Academic’ genre was mapped to ‘research article’ (RA) in <em>CORE</em>, ‘academic’ in <em>UDM</em>, and ‘academic’ (A14) in <em>FTD</em>. Some ActDisease genres, like ‘Administrative’ in <em>CORE</em> and <em>FTD</em>, lacked direct suitable mappings.</p>
<p>The training data creation pipeline involved this mapping, followed by preprocessing (removing web addresses, emails, XML tags, and emojis), chunking, and sampling. Four sampling configurations were applied: using only Germanic languages [G+], using all language families [G-], balancing by ActDisease labels [B1], and balancing by both ActDisease and original dataset labels [B2]. This process generated four distinct training samples for each of the <em>FTD</em>, <em>CORE</em>, and <em>UDM</em> datasets.</p>
<p>Three multilingual encoder models were employed: <em>XLM-Roberta</em> (Conneau et al., 2020), <em>mBERT</em> (Devlin et al., 2019), and <em>historical mBERT (hmBERT)</em> (Schweter et al., 2022). <em>hmBERT</em> was of particular interest due to its pretraining on multilingual historical newspapers, including German and Swedish. Each model was fine-tuned on all dataset samples and configurations, resulting in 48 fine-tuned models. Reported metrics are averages across these configurations.</p>
<p>Evaluation of zero-shot predictions was challenging due to imperfect label set overlaps. Therefore, performance was analyzed for each genre separately, supplemented by confusion matrix analysis. The <em>X-GENRE</em> web genre classifier (Kuzman et al., 2023) served as a baseline. The evaluation scenario was cross-lingual for <em>FTD</em> and <em>X-GENRE</em> (which lacked German or Swedish training data for the mapped labels) and partially cross-lingual for <em>UDM</em> and <em>CORE</em>.</p>
<p>Overall results for zero-shot learning indicated that models fine-tuned on the <em>FTD</em> dataset with the custom ActDisease mapping performed better. Models trained on <em>UDM</em> and <em>CORE</em> exhibited some class-specific biases; for instance, <em>UDM</em>-trained models showed a bias towards ‘news,’ while <em>CORE</em>-trained models leaned towards ‘guide.’ Certain models demonstrated strengths for specific genres: <em>XLM-Roberta</em> fine-tuned on <em>UDM</em> achieved, on average, 32% more correct predictions for ‘QA’ compared to <em>mBERT</em> and <em>hmBERT</em>. Conversely, <em>hmBERT</em> fine-tuned on <em>UDM</em> yielded 16% more correct predictions for ‘Administrative’ than <em>XLM-Roberta</em> and <em>mBERT</em>. <em>CORE</em>-based models were effective at predicting the ‘legal’ genre. Confusion matrices for configurations like <em>hmBERT_UDM_True_True</em> illustrated these behaviors. Detailed per-category F1 scores, averaged across data configurations, were presented, with highlighted values indicating robust performance not attributable to systematic biases. For instance, <em>hmBERT</em> (in its non-MLM version for zero-shot context) showed strong F1 scores for ‘administrative’ and ‘advertisement’. The different data sampling configurations (B1, B2, G+, G-) had varied impacts: for <em>FTD</em>, B2 and G+ decreased performance, while for <em>UDM</em>, including other language families and applying balancing generally improved macro F1 scores.</p>
</section>
<section id="few-shot-classification-with-encoder-models" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="few-shot-classification-with-encoder-models"><span class="header-section-number">5.8</span> Few-Shot Classification with Encoder Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Few-shot learning experiments aimed to understand how classification performance changes with varying training set sizes across different models, and whether prior fine-tuning on the full dataset (referred to as MLM, in the context of Masked Language Model pre-training benefits) significantly enhances performance. The models tested included <em>hmbert</em>, <em>mbert</em>, and <em>xlmr</em>, each with a version that had undergone prior MLM fine-tuning on the ActDisease dataset (<em>hmbert-mlm</em>, <em>mbert-mlm</em>, <em>xlmr-mlm</em>). Training dataset sizes ranged from 100 to 1182 instances.</p>
<p>The results demonstrated that prior MLM fine-tuning provided a clear advantage. F1 scores consistently increased with larger training set sizes for all models. However, even with the maximum training size of 1182 instances, F1 scores generally remained below 0.8. The <em>hmBERT-MLM</em> model slightly outperformed other models. For example, with 1182 training instances, <em>hmBERT-MLM</em> achieved a macro F1 of 0.77 and an accuracy of 0.82, showing strong performance in categories like ‘administrative’ (0.86 F1), ‘advertisement’ (0.93 F1), and ‘nonfiction prose’ (0.82 F1). In comparison, <em>XLMR-MLM</em> achieved a macro F1 of 0.76 and accuracy of 0.84, with high scores in ‘QA’ (0.84 F1) and ‘legal’ (0.89 F1), but lower for ‘nonfiction prose’ (0.56 F1).</p>
<p>The superior performance of <em>hmBERT-MLM</em> was partly attributed to its sustained ability to differentiate between ‘fiction’ and ‘nonfiction prose’ even with the full dataset, a task where other models, particularly <em>XLM-Roberta</em>, experienced a significant performance decline. An analysis of the <em>XLM-Roberta-MLM</em> confusion matrix using the full-sized training dataset revealed that ‘nonfictional prose’ was frequently misclassified as ‘fiction.’ This suggests that within the specific domain of diabetes-focused patient organization magazines, ‘fiction’ and ‘nonfictional prose’ might share many thematic and narrative elements, especially since both often revolve around patient experiences. This similarity could become more pronounced with larger datasets, indicating that further data or alternative methods might be necessary to better distinguish these genres.</p>
</section>
<section id="few-shot-prompting-with-llama-3.1-8b-instruct" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="few-shot-prompting-with-llama-3.1-8b-instruct"><span class="header-section-number">5.9</span> Few-Shot Prompting with <em>Llama-3.1 8b Instruct</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_16.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>Due to the limited availability of annotated data for comprehensive instruction tuning, few-shot prompting experiments were conducted using <em>Llama-3.1 8b Instruct</em>. This model is a popular, multilingual, generative language model with open weights. The method involved constructing a prompt that included an instruction section with definitions for each genre, followed by an examples section containing two to three carefully selected examples per genre. The input text from the test set was then provided, and the model was prompted to output the predicted genre.</p>
<p>The evaluation was performed on the zero-shot test set, which is the entire held-out portion of the annotated data. The results indicated that <em>Llama-3.1 8b Instruct</em> could handle certain genre labels reasonably well; for instance, it achieved an F1-score of 0.84 for the ‘legal’ genre. However, the small number of examples (two or three per genre) proved insufficient for the model to adequately learn and represent more complex or internally diverse genres, such as ‘nonfictional prose,’ ‘advertisement,’ and ‘administrative.’ The confusion matrix of its predictions showed correct classifications along the diagonal for several genres but also highlighted areas of confusion.</p>
</section>
<section id="conclusions-and-future-work" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="conclusions-and-future-work"><span class="header-section-number">5.10</span> Conclusions and Future Work</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_17.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>The research concludes that popular magazines, rich in varied content, present significant text mining challenges due to their multitude of genres, unlike more homogenous sources like scientific journals and books. These genres are indicative of chosen communicative strategies, and their consideration is vital for an accurate and detailed interpretation of text mining outputs. Genre classification serves as a key method to make these complex historical sources more accessible for computational analysis.</p>
<p>For scenarios with no training data, two potential approaches are suggested: leveraging existing modern datasets if their genre categories are sufficiently general-purpose and align with the target material, or employing few-shot prompting with a capable generative model. However, if some annotated data is available, few-shot learning using multilingual encoders such as <em>XLM-Roberta</em> or, particularly, <em>historical multilingual BERT (hmBERT)</em>, especially when combined with prior MLM fine-tuning, proves to be a more effective strategy. The most significant performance improvements from MLM fine-tuning were observed for <em>hmBERT</em>, which showed a 24% gain, compared to 14.5% for <em>mBERT-MLM</em> and 16.9% for <em>XLM-RoBERTa-MLM</em>.</p>
<p>Ongoing and future work aims to further enhance the quality of this research. This includes applying the classification to investigate specific historical hypotheses, developing and implementing a new annotation scheme with more fine-grained genre distinctions, undertaking a new annotation project funded by Swe-CLARIN, exploring synthetic data generation techniques to augment training sets, and employing active learning strategies to optimize the annotation process. These efforts are directed at improving genre classification quality for both the ActDisease project’s internal research needs and for the benefit of the wider research community.</p>
</section>
<section id="acknowledgements" class="level2" data-number="5.11">
<h2 data-number="5.11" class="anchored" data-anchor-id="acknowledgements"><span class="header-section-number">5.11</span> Acknowledgements</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_19.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>Acknowledgements are extended to the annotation team, composed of project members Ylva Söderfeldt, Julia Reed, Andrew Burchell, Maria Skeppstedt, and Gijs Aangenendt. The project received funding from the European Research Council (ERC) under grant ERC-2021-STG 101040999. Support in the form of GPU resources and data storage was provided by the Centre for Digital Humanities and Social Sciences. The contributions of reviewers, including Dr Maria Skeppstedt and anonymous reviewers, are also acknowledged. The project website can be accessed via a QR code presented on the final slide.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  // Create burger menu button
  const toggleButton = document.createElement('button');
  toggleButton.className = 'sidebar-toggle';
  toggleButton.setAttribute('aria-label', 'Toggle sidebar');
  toggleButton.innerHTML = `
    <div class="burger-icon">
      <span></span>
      <span></span>
      <span></span>
    </div>
  `;
  
  // Create backdrop for mobile
  const backdrop = document.createElement('div');
  backdrop.className = 'sidebar-backdrop';
  
  // Add elements to page
  document.body.appendChild(toggleButton);
  document.body.appendChild(backdrop);
  
  // Get sidebar and main content elements
  const sidebar = document.querySelector('.sidebar') || 
                 document.querySelector('.quarto-sidebar') || 
                 document.querySelector('.sidebar-navigation');
  const mainContent = document.querySelector('main') || 
                     document.querySelector('.main-content') || 
                     document.querySelector('.quarto-container') || 
                     document.body;
  
  // State management
  let sidebarOpen = window.innerWidth > 768; // Start open on desktop, closed on mobile
  
  // Initialize sidebar state
  function initializeSidebar() {
    if (window.innerWidth <= 768) {
      sidebarOpen = false;
    }
    updateSidebarState();
  }
  
  // Update sidebar state and classes
  function updateSidebarState() {
    if (sidebar) {
      if (sidebarOpen) {
        sidebar.classList.remove('collapsed');
        toggleButton.classList.add('sidebar-open');
        mainContent.classList.add('sidebar-open');
        mainContent.classList.remove('sidebar-closed');
        if (window.innerWidth <= 768) {
          backdrop.classList.add('active');
        }
      } else {
        sidebar.classList.add('collapsed');
        toggleButton.classList.remove('sidebar-open');
        mainContent.classList.remove('sidebar-open');
        mainContent.classList.add('sidebar-closed');
        backdrop.classList.remove('active');
      }
    }
    
    // Store state in localStorage
    localStorage.setItem('sidebarOpen', sidebarOpen);
  }
  
  // Toggle sidebar
  function toggleSidebar() {
    sidebarOpen = !sidebarOpen;
    updateSidebarState();
  }
  
  // Close sidebar (for chapter links)
  function closeSidebar() {
    if (window.innerWidth <= 768) { // Only auto-close on mobile
      sidebarOpen = false;
      updateSidebarState();
    }
  }
  
  // Event listeners
  toggleButton.addEventListener('click', toggleSidebar);
  backdrop.addEventListener('click', toggleSidebar);
  
  // Auto-close sidebar when clicking chapter links
  if (sidebar) {
    const chapterLinks = sidebar.querySelectorAll('a[href]');
    chapterLinks.forEach(link => {
      link.addEventListener('click', function(e) {
        // Small delay to allow navigation to start
        setTimeout(closeSidebar, 100);
      });
    });
  }
  
  // Handle window resize
  window.addEventListener('resize', function() {
    if (window.innerWidth > 768 && !sidebarOpen) {
      sidebarOpen = true;
      updateSidebarState();
    } else if (window.innerWidth <= 768 && sidebarOpen) {
      sidebarOpen = false;
      updateSidebarState();
    }
  });
  
  // Handle escape key
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && sidebarOpen && window.innerWidth <= 768) {
      closeSidebar();
    }
  });
  
  // Restore saved state from localStorage
  const savedState = localStorage.getItem('sidebarOpen');
  if (savedState !== null) {
    sidebarOpen = savedState === 'true';
  }
  
  // Initialize
  initializeSidebar();
  
  // Add keyboard navigation support
  toggleButton.addEventListener('keydown', function(e) {
    if (e.key === 'Enter' || e.key === ' ') {
      e.preventDefault();
      toggleSidebar();
    }
  });
  
  // Improve accessibility
  toggleButton.setAttribute('role', 'button');
  toggleButton.setAttribute('tabindex', '0');
  
  // Update aria-expanded attribute
  function updateAriaExpanded() {
    toggleButton.setAttribute('aria-expanded', sidebarOpen);
  }
  
  // Call updateAriaExpanded whenever sidebar state changes
  const originalUpdateSidebarState = updateSidebarState;
  updateSidebarState = function() {
    originalUpdateSidebarState();
    updateAriaExpanded();
  };
  
  updateAriaExpanded();
  
  // Ensure TOC sticky positioning works properly
  function ensureTOCSticky() {
    // Find all possible TOC elements
    const tocSelectors = [
      '#TOC',
      '.table-of-contents',
      '.quarto-sidebar-toc',
      '.toc',
      '.quarto-toc',
      'nav[role="doc-toc"]',
      '.margin-sidebar',
      '.sidebar-right',
      '.quarto-margin-sidebar',
      '.column-margin'
    ];
    
    let toc = null;
    for (const selector of tocSelectors) {
      toc = document.querySelector(selector);
      if (toc) break;
    }
    
    if (toc) {
      console.log('Found TOC element:', toc.className || toc.id);
      
      // Force sticky positioning with important styles
      toc.style.setProperty('position', 'sticky', 'important');
      toc.style.setProperty('top', '1rem', 'important');
      toc.style.setProperty('max-height', 'calc(100vh - 2rem)', 'important');
      toc.style.setProperty('overflow-y', 'auto', 'important');
      toc.style.setProperty('z-index', '100', 'important');
      
      // Ensure parent containers support sticky
      let parent = toc.parentElement;
      while (parent && parent !== document.body) {
        parent.style.setProperty('position', 'relative', 'important');
        parent.style.setProperty('height', 'auto', 'important');
        parent = parent.parentElement;
      }
      
      // Add scroll event listener to maintain visibility
      let lastScrollTop = 0;
      const scrollHandler = function() {
        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
        
        // Ensure TOC remains visible and properly positioned
        if (toc && window.innerWidth > 768) {
          toc.style.setProperty('position', 'sticky', 'important');
          toc.style.setProperty('top', '1rem', 'important');
        }
        
        lastScrollTop = scrollTop;
      };
      
      // Remove existing scroll listeners to avoid duplicates
      window.removeEventListener('scroll', scrollHandler);
      window.addEventListener('scroll', scrollHandler, { passive: true });
      
      // Also apply to any nested TOC elements
      const nestedTocs = toc.querySelectorAll('#TOC, .toc, .table-of-contents');
      nestedTocs.forEach(nestedToc => {
        nestedToc.style.setProperty('position', 'sticky', 'important');
        nestedToc.style.setProperty('top', '0', 'important');
      });
    } else {
      console.log('No TOC element found');
    }
  }
  
  // Initialize TOC sticky behavior
  ensureTOCSticky();
  
  // Re-initialize periodically to ensure it stays sticky
  setInterval(ensureTOCSticky, 2000);
  
  // Re-initialize on window resize
  window.addEventListener('resize', function() {
    setTimeout(ensureTOCSticky, 100);
  });
  
  // Re-initialize if content changes
  const observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      if (mutation.type === 'childList') {
        setTimeout(ensureTOCSticky, 100);
      }
    });
  });
  
  observer.observe(document.body, {
    childList: true,
    subtree: true
  });
  
  // Force re-initialization after page load
  window.addEventListener('load', function() {
    setTimeout(ensureTOCSticky, 500);
  });
});
</script>

<style>
/* Additional styles for better integration */
body {
  overflow-x: hidden;
}

.sidebar-toggle {
  -webkit-tap-highlight-color: transparent;
}

/* Ensure smooth transitions on all relevant elements */
.sidebar,
.sidebar-toggle,
.main-content,
.sidebar-backdrop {
  will-change: transform, opacity, margin;
}

/* Focus styles for accessibility */
.sidebar-toggle:focus {
  outline: 2px solid white;
  outline-offset: 2px;
}

/* Prevent text selection on burger icon */
.burger-icon {
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
</style> 
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_004.html" class="pagination-link" aria-label="OpenAlex Mapper: Transdisciplinary Investigations">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OpenAlex Mapper: Transdisciplinary Investigations</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="Computational HPSS: Tracing Ancient Wisdom's Influence with VERITRACE">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Computational HPSS: Tracing Ancient Wisdom’s Influence with VERITRACE</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="an">abstract:</span><span class="co"> "\n      The ActDisease project at Uppsala University focuses on the history\</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">  \ of patient organizations in 20th century Europe, using their periodicals as primary\</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co">  \ source material. The project aims to classify textual genres within these historical\</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co">  \ medical periodicals to facilitate nuanced historical analysis, study the evolution\</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">  \ of communicative strategies, and enhance the accuracy of text mining techniques.\</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">  \ The digitization of these periodicals involved Optical Character Recognition (OCR)\</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">  \ using ABB..."</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="an">author:</span></span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co">- affiliation: Uppsala University</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co">  email: vera.danilova@idehist.uu.se</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="co">  name: Vera Danilova</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="an">bibliography:</span><span class="co"> bibliography.bib</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="an">date:</span><span class="co"> '2025'</span></span>
<span id="cb1-16"><a href="#cb1-16"></a><span class="co">---</span></span>
<span id="cb1-17"><a href="#cb1-17"></a></span>
<span id="cb1-18"><a href="#cb1-18"></a><span class="fu"># Genre Classification for Historical Medical Periodicals</span></span>
<span id="cb1-19"><a href="#cb1-19"></a></span>
<span id="cb1-20"><a href="#cb1-20"></a><span class="fu">## Overview</span></span>
<span id="cb1-21"><a href="#cb1-21"></a></span>
<span id="cb1-22"><a href="#cb1-22"></a>The ActDisease project at Uppsala University focuses on the history of patient organizations in 20th century Europe, using their periodicals as primary source material. The project aims to classify textual genres within these historical medical periodicals to facilitate nuanced historical analysis, study the evolution of communicative strategies, and enhance the accuracy of text mining techniques.</span>
<span id="cb1-23"><a href="#cb1-23"></a></span>
<span id="cb1-24"><a href="#cb1-24"></a>The digitization of these periodicals involved Optical Character Recognition (OCR) using *ABBYY FineReader Server 14*. This process presented challenges with complex layouts, varied fonts, and scan quality, leading to OCR errors and disrupted reading order. Experiments were conducted for post-OCR correction of German texts using instruction-tuned generative models.</span>
<span id="cb1-25"><a href="#cb1-25"></a></span>
<span id="cb1-26"><a href="#cb1-26"></a>A key methodological component of the project is genre classification. Nine distinct genres were defined (Academic, Administrative, Advertisement, Guide, Fiction, Legal, News, Nonfiction Prose, QA) based on communicative purpose, under the supervision of a historian. Annotation was performed at the paragraph level on Swedish and German periodicals, achieving a Krippendorff's alpha of 0.95.</span>
<span id="cb1-27"><a href="#cb1-27"></a></span>
<span id="cb1-28"><a href="#cb1-28"></a>The research explored both zero-shot and few-shot learning approaches. Zero-shot experiments involved mapping ActDisease genres to labels from publicly available datasets (*CORE*, *FTD*, *UDM*) and fine-tuning multilingual encoder models (*XLM-Roberta*, *mBERT*, historical *mBERT* - *hmBERT*). Results indicated that models fine-tuned on *FTD* with custom mapping performed well, and specific models showed aptitude for certain genres (e.g., *hmBERT* for 'Administrative').</span>
<span id="cb1-29"><a href="#cb1-29"></a></span>
<span id="cb1-30"><a href="#cb1-30"></a>Few-shot learning experiments assessed performance with varying training data sizes, with and without prior Masked Language Model (MLM) fine-tuning. MLM fine-tuning significantly boosted performance, with *hmBERT-MLM* showing the best results, particularly in distinguishing between fiction and nonfiction. Further experiments involved few-shot prompting of *Llama-3.1 8b Instruct*, which demonstrated decent quality but required more examples for complex genres.</span>
<span id="cb1-31"><a href="#cb1-31"></a></span>
<span id="cb1-32"><a href="#cb1-32"></a>The findings underscore that genre classification is vital for analyzing the diverse content of popular historical magazines. While zero-shot methods offer a viable starting point, few-shot learning with prior MLM fine-tuning of multilingual encoders, especially historical models like *hmBERT*, provides superior results. Future work includes refining annotation schemes, synthetic data generation, and active learning to improve classification quality. The tools and resources utilized include the ActDisease dataset, *ABBYY FineReader Server 14*, the *CORE*, *FTD*, and *UDM* datasets, and various language models (*XLM-Roberta*, *mBERT*, *hmBERT*, *Llama-3.1 8b Instruct*).</span>
<span id="cb1-33"><a href="#cb1-33"></a></span>
<span id="cb1-34"><a href="#cb1-34"></a><span class="fu">## ActDisease Project and Dataset</span></span>
<span id="cb1-35"><a href="#cb1-35"></a></span>
<span id="cb1-36"><a href="#cb1-36"></a><span class="al">![Slide 01](images/ai-nepi_005_slide_01.jpg)</span></span>
<span id="cb1-37"><a href="#cb1-37"></a></span>
<span id="cb1-38"><a href="#cb1-38"></a>The ActDisease project, titled "Acting out Disease - How Patient Organizations Shaped Modern Medicine," is an ERC-funded research initiative (ERC-2021-STG 101040999). It is based at the Department of History of Science and Ideas, Uppsala University, Sweden. Its primary purpose is to investigate the historical role of patient organizations in shaping disease concepts, illness experiences, and medical practices throughout 20th century Europe.</span>
<span id="cb1-39"><a href="#cb1-39"></a></span>
<span id="cb1-40"><a href="#cb1-40"></a>The project focuses on approximately 10 European patient organizations located in Sweden, Germany, France, and Great Britain, covering a period from around 1890 to 1990. The main source material for this research comprises periodicals, predominantly magazines, published by these patient organizations. This collection forms the ActDisease dataset, a private and recently digitized compilation totaling 96,186 pages.</span>
<span id="cb1-41"><a href="#cb1-41"></a></span>
<span id="cb1-42"><a href="#cb1-42"></a>The dataset includes materials related to various diseases and countries:</span>
<span id="cb1-43"><a href="#cb1-43"></a></span>
<span id="cb1-44"><a href="#cb1-44"></a><span class="ss">-   </span>Germany: Allergy/Asthma, Diabetes, Multiple Sclerosis.</span>
<span id="cb1-45"><a href="#cb1-45"></a></span>
<span id="cb1-46"><a href="#cb1-46"></a><span class="ss">-   </span>Sweden: Allergy/Asthma, Diabetes, Lung Diseases.</span>
<span id="cb1-47"><a href="#cb1-47"></a></span>
<span id="cb1-48"><a href="#cb1-48"></a><span class="ss">-   </span>France: Diabetes, Rheumatism/Paralysis.</span>
<span id="cb1-49"><a href="#cb1-49"></a></span>
<span id="cb1-50"><a href="#cb1-50"></a><span class="ss">-   </span>UK: Diabetes, Rheumatism.</span>
<span id="cb1-51"><a href="#cb1-51"></a></span>
<span id="cb1-52"><a href="#cb1-52"></a>Illustrative examples of these periodicals include "BRA Review" and "Allergia." An example of the historical context is Heligoland, Germany, which was the founding place of the Hay Fever Association of Heligoland in 1897.</span>
<span id="cb1-53"><a href="#cb1-53"></a></span>
<span id="cb1-54"><a href="#cb1-54"></a><span class="fu">## Digitization and OCR Challenges</span></span>
<span id="cb1-55"><a href="#cb1-55"></a></span>
<span id="cb1-56"><a href="#cb1-56"></a><span class="al">![Slide 01](images/ai-nepi_005_slide_01.jpg)</span></span>
<span id="cb1-57"><a href="#cb1-57"></a></span>
<span id="cb1-58"><a href="#cb1-58"></a>The digitization of the ActDisease dataset was performed using Optical Character Recognition (OCR). The software employed for this task was *ABBYY FineReader Server 14*. While this OCR model performed well in recognizing most common layouts and fonts, several challenges persisted. These included difficulties with complex page layouts, slanted text, rare or unusual fonts, and inconsistencies in scan or photograph quality.</span>
<span id="cb1-59"><a href="#cb1-59"></a></span>
<span id="cb1-60"><a href="#cb1-60"></a>Consequently, some issues remain in the digitized collection. These include OCR errors, which are especially prevalent in German and French texts, and instances of disrupted reading order. To address some of these problems, experiments were conducted on post-OCR correction, specifically for German texts, utilizing instruction-tuned generative models.</span>
<span id="cb1-61"><a href="#cb1-61"></a></span>
<span id="cb1-62"><a href="#cb1-62"></a>The findings of these experiments are detailed in a publication by Danilova and Aangenendt (*RESOURCEFUL-2025, ACL*). It was also observed that OCR errors occur frequently in texts with creative formatting, such as advertisements, humor pages, and poems.</span>
<span id="cb1-63"><a href="#cb1-63"></a></span>
<span id="cb1-64"><a href="#cb1-64"></a><span class="fu">## Motivation for Genre Classification</span></span>
<span id="cb1-65"><a href="#cb1-65"></a></span>
<span id="cb1-66"><a href="#cb1-66"></a><span class="al">![Slide 01](images/ai-nepi_005_slide_01.jpg)</span></span>
<span id="cb1-67"><a href="#cb1-67"></a></span>
<span id="cb1-68"><a href="#cb1-68"></a>Exploration of the ActDisease materials revealed a high diversity of text types, which, however, exhibited similarities across the different magazines. A significant challenge identified is that various text types often appear concurrently on a single page—for instance, an administrative report might be placed next to an an advertisement and a humor section. This heterogeneity poses a problem for standard text mining approaches, as yearly and decade-based topic models and term counts typically do not differentiate between these text types, leading to a likely bias towards the most frequent genres.</span>
<span id="cb1-69"><a href="#cb1-69"></a></span>
<span id="cb1-70"><a href="#cb1-70"></a>To address these challenges, genre emerged as a useful concept. In language technology, genre is often defined as a class of documents that share a common communicative purpose, as described by Petrenz (2004) and Kessler (1997). The primary objective of implementing genre classification is to enable the exploration of the source material from multiple perspectives, thereby facilitating the formulation of historical arguments.</span>
<span id="cb1-71"><a href="#cb1-71"></a></span>
<span id="cb1-72"><a href="#cb1-72"></a>Specifically, genre classification allows for the study of how communicative strategies evolved over time, comparing these strategies across different countries, diseases, and publications. Furthermore, it permits a more fine-grained analysis of term distributions and topic models by examining them within distinct genre categories.</span>
<span id="cb1-73"><a href="#cb1-73"></a></span>
<span id="cb1-74"><a href="#cb1-74"></a><span class="fu">## Genre Definitions and Examples</span></span>
<span id="cb1-75"><a href="#cb1-75"></a></span>
<span id="cb1-76"><a href="#cb1-76"></a><span class="al">![Slide 03](images/ai-nepi_005_slide_03.jpg)</span></span>
<span id="cb1-77"><a href="#cb1-77"></a></span>
<span id="cb1-78"><a href="#cb1-78"></a>The ActDisease periodicals contain a variety of textual genres. Examples identified include poetry, academic reports (such as studies on the pancreas), legal documents (like deeds of covenant), advertisements (for instance, for diabetic chocolate), instructive or guidance texts (including recipes or dietary advice), patient organization reports detailing meetings and activities, and narratives about patient experiences and lives.</span>
<span id="cb1-79"><a href="#cb1-79"></a></span>
<span id="cb1-80"><a href="#cb1-80"></a>The genre labels used for classification were defined under the supervision of the project's main historian, who specializes in patient organizations. The labels were designed to be useful for segregating content within the materials to support further historical analysis, while also being as general-purpose as possible to allow for potential application to similar datasets.</span>
<span id="cb1-81"><a href="#cb1-81"></a></span>
<span id="cb1-82"><a href="#cb1-82"></a>The following genres, along with their definitions and communicative purposes, were established:</span>
<span id="cb1-83"><a href="#cb1-83"></a></span>
<span id="cb1-84"><a href="#cb1-84"></a><span class="ss">-   </span>Academic: Consists of research-based reports or explanations of scientific ideas, such as research articles or reports. Its purpose is to convey information from the scientific and medical communities to the magazine's audience.</span>
<span id="cb1-85"><a href="#cb1-85"></a></span>
<span id="cb1-86"><a href="#cb1-86"></a><span class="ss">-   </span>Administrative: Includes documents pertaining to organizational activities, like meeting minutes, reports, and announcements. It aims to report on and inform about the events and activities of patient organizations.</span>
<span id="cb1-87"><a href="#cb1-87"></a></span>
<span id="cb1-88"><a href="#cb1-88"></a><span class="ss">-   </span>Advertisement: Features content that promotes products or services for commercial purposes.</span>
<span id="cb1-89"><a href="#cb1-89"></a></span>
<span id="cb1-90"><a href="#cb1-90"></a><span class="ss">-   </span>Guide: Provides step-by-step instructions, such as health tips, legal advice, or recipes.</span>
<span id="cb1-91"><a href="#cb1-91"></a></span>
<span id="cb1-92"><a href="#cb1-92"></a><span class="ss">-   </span>Fiction: Encompasses texts designed to entertain and emotionally engage readers, including stories, poems, humor, and myths.</span>
<span id="cb1-93"><a href="#cb1-93"></a></span>
<span id="cb1-94"><a href="#cb1-94"></a><span class="ss">-   </span>Legal: Contains texts that explain legal terms and conditions, such as contracts, rules, or amendments.</span>
<span id="cb1-95"><a href="#cb1-95"></a></span>
<span id="cb1-96"><a href="#cb1-96"></a><span class="ss">-   </span>News: Comprises reports on recent events and developments.</span>
<span id="cb1-97"><a href="#cb1-97"></a></span>
<span id="cb1-98"><a href="#cb1-98"></a><span class="ss">-   </span>Nonfiction Prose: Includes narratives of real events or descriptions of cultural or historical topics, such as memoirs, essays, or documentaries.</span>
<span id="cb1-99"><a href="#cb1-99"></a></span>
<span id="cb1-100"><a href="#cb1-100"></a><span class="ss">-   </span>QA: Refers to sections structured as questions paired with expert answers, commonly found in the periodicals.</span>
<span id="cb1-101"><a href="#cb1-101"></a></span>
<span id="cb1-102"><a href="#cb1-102"></a><span class="fu">## Annotation Process and Dataset Preparation</span></span>
<span id="cb1-103"><a href="#cb1-103"></a></span>
<span id="cb1-104"><a href="#cb1-104"></a><span class="al">![Slide 07](images/ai-nepi_005_slide_07.jpg)</span></span>
<span id="cb1-105"><a href="#cb1-105"></a></span>
<span id="cb1-106"><a href="#cb1-106"></a>The annotation unit for genre classification was defined as paragraphs. These paragraphs were derived from the *ABBYY OCR* output and subsequently merged based on font patterns (type, size, bold, italic attributes) at the page level. For the annotation task, samples were drawn from two specific periodicals: the Swedish magazine "Diabetes" and the German magazine "Diabetiker Journal." The selection comprised the first and mid-year issues from each year of these publications.</span>
<span id="cb1-107"><a href="#cb1-107"></a></span>
<span id="cb1-108"><a href="#cb1-108"></a>A team of six project members, consisting of four historians and two computational linguists, all either native speakers or proficient in Swedish and German, performed the annotations. Two independent annotations were collected for each paragraph. The inter-annotator agreement achieved was 0.95, measured by Krippendorff's alpha, indicating a high level of consistency. An example of the annotation file shows a tabular structure with metadata (Year, Volume, Issue, etc.), the paragraph text, and columns for each genre where annotators made hard assignments.</span>
<span id="cb1-109"><a href="#cb1-109"></a></span>
<span id="cb1-110"><a href="#cb1-110"></a>The annotated dataset was split into a training set of 1182 paragraphs and a held-out set of 552 paragraphs (approximately 30% of the data), with stratification by label. For few-shot learning experiments, six different training set sizes were created (100, 200, 300, 400, 500, and 1182 paragraphs), randomly sampled from the main training set and balanced by label. The held-out set was further divided equally into validation and test sets, also balanced by label. The 'legal' and 'news' genres were excluded from these few-shot experiments due to insufficient training instances. For zero-shot experiments, the entire test portion of the held-out set was utilized. Analysis of genre distribution in the training and held-out samples revealed a strong imbalance for the 'advertisement' and 'nonfictional prose' genres across the German and Swedish languages.</span>
<span id="cb1-111"><a href="#cb1-111"></a></span>
<span id="cb1-112"><a href="#cb1-112"></a><span class="fu">## Zero-Shot Genre Classification</span></span>
<span id="cb1-113"><a href="#cb1-113"></a></span>
<span id="cb1-114"><a href="#cb1-114"></a><span class="al">![Slide 09](images/ai-nepi_005_slide_09.jpg)</span></span>
<span id="cb1-115"><a href="#cb1-115"></a></span>
<span id="cb1-116"><a href="#cb1-116"></a>For zero-shot genre classification, the research addressed two main questions: whether genre labels from publicly available datasets could be efficiently mapped to the custom ActDisease labels, and how classification performance would vary across different datasets and models. Three publicly available datasets were utilized: the *Corpus of Online Registers of English (CORE)* by Egbert et al. (2015), annotated at the document level primarily in English; the *Functional Text Dimensions (FTD)* dataset of web genres by Sharoff (2018), also document-level, covering English and Russian; and *UD-MULTIGENRE (UDM)*, a subset of *Universal Dependencies* with recovered sentence-level genre annotations in 38 languages (de Marneffe et al., 2021; Danilova and Stymne, 2023).</span>
<span id="cb1-117"><a href="#cb1-117"></a></span>
<span id="cb1-118"><a href="#cb1-118"></a>Genre mapping between ActDisease labels and those in *CORE*, *UDM*, and *FTD* was performed independently by two annotators, with final mappings chosen based on full agreement. For example, the ActDisease 'Academic' genre was mapped to 'research article' (RA) in *CORE*, 'academic' in *UDM*, and 'academic' (A14) in *FTD*. Some ActDisease genres, like 'Administrative' in *CORE* and *FTD*, lacked direct suitable mappings.</span>
<span id="cb1-119"><a href="#cb1-119"></a></span>
<span id="cb1-120"><a href="#cb1-120"></a>The training data creation pipeline involved this mapping, followed by preprocessing (removing web addresses, emails, XML tags, and emojis), chunking, and sampling. Four sampling configurations were applied: using only Germanic languages <span class="co">[</span><span class="ot">G+</span><span class="co">]</span>, using all language families <span class="co">[</span><span class="ot">G-</span><span class="co">]</span>, balancing by ActDisease labels <span class="co">[</span><span class="ot">B1</span><span class="co">]</span>, and balancing by both ActDisease and original dataset labels <span class="co">[</span><span class="ot">B2</span><span class="co">]</span>. This process generated four distinct training samples for each of the *FTD*, *CORE*, and *UDM* datasets.</span>
<span id="cb1-121"><a href="#cb1-121"></a></span>
<span id="cb1-122"><a href="#cb1-122"></a>Three multilingual encoder models were employed: *XLM-Roberta* (Conneau et al., 2020), *mBERT* (Devlin et al., 2019), and *historical mBERT (hmBERT)* (Schweter et al., 2022). *hmBERT* was of particular interest due to its pretraining on multilingual historical newspapers, including German and Swedish. Each model was fine-tuned on all dataset samples and configurations, resulting in 48 fine-tuned models. Reported metrics are averages across these configurations.</span>
<span id="cb1-123"><a href="#cb1-123"></a></span>
<span id="cb1-124"><a href="#cb1-124"></a>Evaluation of zero-shot predictions was challenging due to imperfect label set overlaps. Therefore, performance was analyzed for each genre separately, supplemented by confusion matrix analysis. The *X-GENRE* web genre classifier (Kuzman et al., 2023) served as a baseline. The evaluation scenario was cross-lingual for *FTD* and *X-GENRE* (which lacked German or Swedish training data for the mapped labels) and partially cross-lingual for *UDM* and *CORE*.</span>
<span id="cb1-125"><a href="#cb1-125"></a></span>
<span id="cb1-126"><a href="#cb1-126"></a>Overall results for zero-shot learning indicated that models fine-tuned on the *FTD* dataset with the custom ActDisease mapping performed better. Models trained on *UDM* and *CORE* exhibited some class-specific biases; for instance, *UDM*-trained models showed a bias towards 'news,' while *CORE*-trained models leaned towards 'guide.' Certain models demonstrated strengths for specific genres: *XLM-Roberta* fine-tuned on *UDM* achieved, on average, 32% more correct predictions for 'QA' compared to *mBERT* and *hmBERT*. Conversely, *hmBERT* fine-tuned on *UDM* yielded 16% more correct predictions for 'Administrative' than *XLM-Roberta* and *mBERT*. *CORE*-based models were effective at predicting the 'legal' genre. Confusion matrices for configurations like *hmBERT_UDM_True_True* illustrated these behaviors. Detailed per-category F1 scores, averaged across data configurations, were presented, with highlighted values indicating robust performance not attributable to systematic biases. For instance, *hmBERT* (in its non-MLM version for zero-shot context) showed strong F1 scores for 'administrative' and 'advertisement'. The different data sampling configurations (B1, B2, G+, G-) had varied impacts: for *FTD*, B2 and G+ decreased performance, while for *UDM*, including other language families and applying balancing generally improved macro F1 scores.</span>
<span id="cb1-127"><a href="#cb1-127"></a></span>
<span id="cb1-128"><a href="#cb1-128"></a><span class="fu">## Few-Shot Classification with Encoder Models</span></span>
<span id="cb1-129"><a href="#cb1-129"></a></span>
<span id="cb1-130"><a href="#cb1-130"></a><span class="al">![Slide 13](images/ai-nepi_005_slide_13.jpg)</span></span>
<span id="cb1-131"><a href="#cb1-131"></a></span>
<span id="cb1-132"><a href="#cb1-132"></a>Few-shot learning experiments aimed to understand how classification performance changes with varying training set sizes across different models, and whether prior fine-tuning on the full dataset (referred to as MLM, in the context of Masked Language Model pre-training benefits) significantly enhances performance. The models tested included *hmbert*, *mbert*, and *xlmr*, each with a version that had undergone prior MLM fine-tuning on the ActDisease dataset (*hmbert-mlm*, *mbert-mlm*, *xlmr-mlm*). Training dataset sizes ranged from 100 to 1182 instances.</span>
<span id="cb1-133"><a href="#cb1-133"></a></span>
<span id="cb1-134"><a href="#cb1-134"></a>The results demonstrated that prior MLM fine-tuning provided a clear advantage. F1 scores consistently increased with larger training set sizes for all models. However, even with the maximum training size of 1182 instances, F1 scores generally remained below 0.8. The *hmBERT-MLM* model slightly outperformed other models. For example, with 1182 training instances, *hmBERT-MLM* achieved a macro F1 of 0.77 and an accuracy of 0.82, showing strong performance in categories like 'administrative' (0.86 F1), 'advertisement' (0.93 F1), and 'nonfiction prose' (0.82 F1). In comparison, *XLMR-MLM* achieved a macro F1 of 0.76 and accuracy of 0.84, with high scores in 'QA' (0.84 F1) and 'legal' (0.89 F1), but lower for 'nonfiction prose' (0.56 F1).</span>
<span id="cb1-135"><a href="#cb1-135"></a></span>
<span id="cb1-136"><a href="#cb1-136"></a>The superior performance of *hmBERT-MLM* was partly attributed to its sustained ability to differentiate between 'fiction' and 'nonfiction prose' even with the full dataset, a task where other models, particularly *XLM-Roberta*, experienced a significant performance decline. An analysis of the *XLM-Roberta-MLM* confusion matrix using the full-sized training dataset revealed that 'nonfictional prose' was frequently misclassified as 'fiction.' This suggests that within the specific domain of diabetes-focused patient organization magazines, 'fiction' and 'nonfictional prose' might share many thematic and narrative elements, especially since both often revolve around patient experiences. This similarity could become more pronounced with larger datasets, indicating that further data or alternative methods might be necessary to better distinguish these genres.</span>
<span id="cb1-137"><a href="#cb1-137"></a></span>
<span id="cb1-138"><a href="#cb1-138"></a><span class="fu">## Few-Shot Prompting with *Llama-3.1 8b Instruct*</span></span>
<span id="cb1-139"><a href="#cb1-139"></a></span>
<span id="cb1-140"><a href="#cb1-140"></a><span class="al">![Slide 16](images/ai-nepi_005_slide_16.jpg)</span></span>
<span id="cb1-141"><a href="#cb1-141"></a></span>
<span id="cb1-142"><a href="#cb1-142"></a>Due to the limited availability of annotated data for comprehensive instruction tuning, few-shot prompting experiments were conducted using *Llama-3.1 8b Instruct*. This model is a popular, multilingual, generative language model with open weights. The method involved constructing a prompt that included an instruction section with definitions for each genre, followed by an examples section containing two to three carefully selected examples per genre. The input text from the test set was then provided, and the model was prompted to output the predicted genre.</span>
<span id="cb1-143"><a href="#cb1-143"></a></span>
<span id="cb1-144"><a href="#cb1-144"></a>The evaluation was performed on the zero-shot test set, which is the entire held-out portion of the annotated data. The results indicated that *Llama-3.1 8b Instruct* could handle certain genre labels reasonably well; for instance, it achieved an F1-score of 0.84 for the 'legal' genre. However, the small number of examples (two or three per genre) proved insufficient for the model to adequately learn and represent more complex or internally diverse genres, such as 'nonfictional prose,' 'advertisement,' and 'administrative.' The confusion matrix of its predictions showed correct classifications along the diagonal for several genres but also highlighted areas of confusion.</span>
<span id="cb1-145"><a href="#cb1-145"></a></span>
<span id="cb1-146"><a href="#cb1-146"></a><span class="fu">## Conclusions and Future Work</span></span>
<span id="cb1-147"><a href="#cb1-147"></a></span>
<span id="cb1-148"><a href="#cb1-148"></a><span class="al">![Slide 17](images/ai-nepi_005_slide_17.jpg)</span></span>
<span id="cb1-149"><a href="#cb1-149"></a></span>
<span id="cb1-150"><a href="#cb1-150"></a>The research concludes that popular magazines, rich in varied content, present significant text mining challenges due to their multitude of genres, unlike more homogenous sources like scientific journals and books. These genres are indicative of chosen communicative strategies, and their consideration is vital for an accurate and detailed interpretation of text mining outputs. Genre classification serves as a key method to make these complex historical sources more accessible for computational analysis.</span>
<span id="cb1-151"><a href="#cb1-151"></a></span>
<span id="cb1-152"><a href="#cb1-152"></a>For scenarios with no training data, two potential approaches are suggested: leveraging existing modern datasets if their genre categories are sufficiently general-purpose and align with the target material, or employing few-shot prompting with a capable generative model. However, if some annotated data is available, few-shot learning using multilingual encoders such as *XLM-Roberta* or, particularly, *historical multilingual BERT (hmBERT)*, especially when combined with prior MLM fine-tuning, proves to be a more effective strategy. The most significant performance improvements from MLM fine-tuning were observed for *hmBERT*, which showed a 24% gain, compared to 14.5% for *mBERT-MLM* and 16.9% for *XLM-RoBERTa-MLM*.</span>
<span id="cb1-153"><a href="#cb1-153"></a></span>
<span id="cb1-154"><a href="#cb1-154"></a>Ongoing and future work aims to further enhance the quality of this research. This includes applying the classification to investigate specific historical hypotheses, developing and implementing a new annotation scheme with more fine-grained genre distinctions, undertaking a new annotation project funded by Swe-CLARIN, exploring synthetic data generation techniques to augment training sets, and employing active learning strategies to optimize the annotation process. These efforts are directed at improving genre classification quality for both the ActDisease project's internal research needs and for the benefit of the wider research community.</span>
<span id="cb1-155"><a href="#cb1-155"></a></span>
<span id="cb1-156"><a href="#cb1-156"></a><span class="fu">## Acknowledgements</span></span>
<span id="cb1-157"><a href="#cb1-157"></a></span>
<span id="cb1-158"><a href="#cb1-158"></a><span class="al">![Slide 19](images/ai-nepi_005_slide_19.jpg)</span></span>
<span id="cb1-159"><a href="#cb1-159"></a></span>
<span id="cb1-160"><a href="#cb1-160"></a>Acknowledgements are extended to the annotation team, composed of project members Ylva Söderfeldt, Julia Reed, Andrew Burchell, Maria Skeppstedt, and Gijs Aangenendt. The project received funding from the European Research Council (ERC) under grant ERC-2021-STG 101040999. Support in the form of GPU resources and data storage was provided by the Centre for Digital Humanities and Social Sciences. The contributions of reviewers, including Dr Maria Skeppstedt and anonymous reviewers, are also acknowledged. The project website can be accessed via a QR code presented on the final slide.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>