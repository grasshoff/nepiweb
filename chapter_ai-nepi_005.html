<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.17">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Vera Danilova">
<meta name="dcterms.date" content="2025-06-21">

<title>5&nbsp; Genre Classification Experiments for Historical Patient Periodicals: The ActDisease Project – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_006.html" rel="next">
<link href="./chapter_ai-nepi_004.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-c2d8198b7f72dec16de60f0cb3fab69f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a0afd4a9b901cc50d8ed64d4ec5e2aec.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_005.html"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification Experiments for Historical Patient Periodicals: The ActDisease Project</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI-assisted Methods for History and Philosophy of Science Workshop: Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Transformer Architectures and LLM Adaptation for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OpenAlex Mapper presentation slide</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification Experiments for Historical Patient Periodicals: The ActDisease Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE: Tracing the Influence of Ancient Wisdom on Early Modern Natural Philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and Understanding LLMs &amp; AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">AI, Computational Epistemology, and Open Science Infrastructure</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">An Analysis of Sustainable Development Goal Research in Bibliometric Databases and the Application of Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">AI-NEPI: Citation extraction from scholarly publications in the humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Ghostwriter and EverythingData: An AI Solution for Interacting with Scientific Collections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Applying Retrieval-Augmented Generation to Philosophical Research: A Case Study and Methodological Insights</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Mapping the Landscape of Quantum Gravity: A Computational Analysis of Plural Pursuit</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">A Comparative Analysis of Topic Modeling Techniques for Scholarly Corpora</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Making Transformer-Based LLMs Time-Aware: A Proof of Concept</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context for Language Variation and Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#presentation-outline" id="toc-presentation-outline" class="nav-link" data-scroll-target="#presentation-outline"><span class="header-section-number">5.1</span> Presentation Outline</a></li>
  <li><a href="#the-actdisease-project" id="toc-the-actdisease-project" class="nav-link" data-scroll-target="#the-actdisease-project"><span class="header-section-number">5.2</span> The ActDisease Project</a></li>
  <li><a href="#dataset-composition" id="toc-dataset-composition" class="nav-link" data-scroll-target="#dataset-composition"><span class="header-section-number">5.3</span> Dataset Composition</a></li>
  <li><a href="#digitisation-and-ocr-challenges" id="toc-digitisation-and-ocr-challenges" class="nav-link" data-scroll-target="#digitisation-and-ocr-challenges"><span class="header-section-number">5.4</span> Digitisation and OCR Challenges</a></li>
  <li><a href="#genre-classification-challenges" id="toc-genre-classification-challenges" class="nav-link" data-scroll-target="#genre-classification-challenges"><span class="header-section-number">5.5</span> Genre Classification Challenges</a></li>
  <li><a href="#motivation-for-classification" id="toc-motivation-for-classification" class="nav-link" data-scroll-target="#motivation-for-classification"><span class="header-section-number">5.6</span> Motivation for Classification</a></li>
  <li><a href="#illustrating-genre-diversity" id="toc-illustrating-genre-diversity" class="nav-link" data-scroll-target="#illustrating-genre-diversity"><span class="header-section-number">5.7</span> Illustrating Genre Diversity</a></li>
  <li><a href="#textual-examples-of-variation" id="toc-textual-examples-of-variation" class="nav-link" data-scroll-target="#textual-examples-of-variation"><span class="header-section-number">5.8</span> Textual Examples of Variation</a></li>
  <li><a href="#defining-genre-labels" id="toc-defining-genre-labels" class="nav-link" data-scroll-target="#defining-genre-labels"><span class="header-section-number">5.9</span> Defining Genre Labels</a></li>
  <li><a href="#genre-classification-schema" id="toc-genre-classification-schema" class="nav-link" data-scroll-target="#genre-classification-schema"><span class="header-section-number">5.10</span> Genre Classification Schema</a></li>
  <li><a href="#annotation-methodology" id="toc-annotation-methodology" class="nav-link" data-scroll-target="#annotation-methodology"><span class="header-section-number">5.11</span> Annotation Methodology</a></li>
  <li><a href="#annotation-in-practice" id="toc-annotation-in-practice" class="nav-link" data-scroll-target="#annotation-in-practice"><span class="header-section-number">5.12</span> Annotation in Practice</a></li>
  <li><a href="#dataset-splits-for-experiments" id="toc-dataset-splits-for-experiments" class="nav-link" data-scroll-target="#dataset-splits-for-experiments"><span class="header-section-number">5.13</span> Dataset Splits for Experiments</a></li>
  <li><a href="#genre-and-language-distribution" id="toc-genre-and-language-distribution" class="nav-link" data-scroll-target="#genre-and-language-distribution"><span class="header-section-number">5.14</span> Genre and Language Distribution</a></li>
  <li><a href="#external-datasets-for-zero-shot" id="toc-external-datasets-for-zero-shot" class="nav-link" data-scroll-target="#external-datasets-for-zero-shot"><span class="header-section-number">5.15</span> External Datasets for Zero-Shot</a></li>
  <li><a href="#cross-dataset-label-mapping" id="toc-cross-dataset-label-mapping" class="nav-link" data-scroll-target="#cross-dataset-label-mapping"><span class="header-section-number">5.16</span> Cross-Dataset Label Mapping</a></li>
  <li><a href="#training-data-pipeline" id="toc-training-data-pipeline" class="nav-link" data-scroll-target="#training-data-pipeline"><span class="header-section-number">5.17</span> Training Data Pipeline</a></li>
  <li><a href="#multilingual-encoder-models" id="toc-multilingual-encoder-models" class="nav-link" data-scroll-target="#multilingual-encoder-models"><span class="header-section-number">5.18</span> Multilingual Encoder Models</a></li>
  <li><a href="#fine-tuning-setup" id="toc-fine-tuning-setup" class="nav-link" data-scroll-target="#fine-tuning-setup"><span class="header-section-number">5.19</span> Fine-Tuning Setup</a></li>
  <li><a href="#evaluating-zero-shot-learning" id="toc-evaluating-zero-shot-learning" class="nav-link" data-scroll-target="#evaluating-zero-shot-learning"><span class="header-section-number">5.20</span> Evaluating Zero-Shot Learning</a></li>
  <li><a href="#zero-shot-evaluation-methodology" id="toc-zero-shot-evaluation-methodology" class="nav-link" data-scroll-target="#zero-shot-evaluation-methodology"><span class="header-section-number">5.21</span> Zero-Shot Evaluation Methodology</a></li>
  <li><a href="#zero-shot-results-overview" id="toc-zero-shot-results-overview" class="nav-link" data-scroll-target="#zero-shot-results-overview"><span class="header-section-number">5.22</span> Zero-Shot Results Overview</a></li>
  <li><a href="#comparative-confusion-matrices" id="toc-comparative-confusion-matrices" class="nav-link" data-scroll-target="#comparative-confusion-matrices"><span class="header-section-number">5.23</span> Comparative Confusion Matrices</a></li>
  <li><a href="#zero-shot-f1-scores" id="toc-zero-shot-f1-scores" class="nav-link" data-scroll-target="#zero-shot-f1-scores"><span class="header-section-number">5.24</span> Zero-Shot F1 Scores</a></li>
  <li><a href="#impact-of-data-configuration" id="toc-impact-of-data-configuration" class="nav-link" data-scroll-target="#impact-of-data-configuration"><span class="header-section-number">5.25</span> Impact of Data Configuration</a></li>
  <li><a href="#evaluating-few-shot-learning" id="toc-evaluating-few-shot-learning" class="nav-link" data-scroll-target="#evaluating-few-shot-learning"><span class="header-section-number">5.26</span> Evaluating Few-Shot Learning</a></li>
  <li><a href="#few-shot-learning-performance" id="toc-few-shot-learning-performance" class="nav-link" data-scroll-target="#few-shot-learning-performance"><span class="header-section-number">5.27</span> Few-Shot Learning Performance</a></li>
  <li><a href="#few-shot-f1-score-details" id="toc-few-shot-f1-score-details" class="nav-link" data-scroll-target="#few-shot-f1-score-details"><span class="header-section-number">5.28</span> Few-Shot F1 Score Details</a></li>
  <li><a href="#full-dataset-performance" id="toc-full-dataset-performance" class="nav-link" data-scroll-target="#full-dataset-performance"><span class="header-section-number">5.29</span> Full-Dataset Performance</a></li>
  <li><a href="#evaluating-few-shot-prompting" id="toc-evaluating-few-shot-prompting" class="nav-link" data-scroll-target="#evaluating-few-shot-prompting"><span class="header-section-number">5.30</span> Evaluating Few-Shot Prompting</a></li>
  <li><a href="#instruction-based-classification" id="toc-instruction-based-classification" class="nav-link" data-scroll-target="#instruction-based-classification"><span class="header-section-number">5.31</span> Instruction-Based Classification</a></li>
  <li><a href="#llama-3.1-8b-performance" id="toc-llama-3.1-8b-performance" class="nav-link" data-scroll-target="#llama-3.1-8b-performance"><span class="header-section-number">5.32</span> Llama-3.1 8b Performance</a></li>
  <li><a href="#conclusion-on-text-mining" id="toc-conclusion-on-text-mining" class="nav-link" data-scroll-target="#conclusion-on-text-mining"><span class="header-section-number">5.33</span> Conclusion on Text Mining</a></li>
  <li><a href="#summary-of-conclusions" id="toc-summary-of-conclusions" class="nav-link" data-scroll-target="#summary-of-conclusions"><span class="header-section-number">5.34</span> Summary of Conclusions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification Experiments for Historical Patient Periodicals: The ActDisease Project</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Vera Danilova <a href="mailto:vera.danilova@idehist.uu.se" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Uppsala University
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The authors present a comprehensive study on genre classification within historical patient periodicals, conducted as part of the ERC-funded ActDisease project. This programme investigates how patient organisations in 20th-century Europe shaped concepts of disease and medical practices, employing their magazines as a primary data source. A substantial corpus, the ActDisease Dataset, underpins this work, comprising 96,186 digitised pages from patient magazines across Germany, Sweden, France, and the United Kingdom.</p>
<p>The core technical challenge the authors address is the classification of diverse and often ambiguous textual genres found within these historical documents. This task is complicated by issues in Optical Character Recognition (OCR) and the limitations of traditional methods like topic modelling. To overcome these obstacles, the research team developed a sophisticated, expert-driven genre-labelling scheme and conducted extensive experiments using both zero-shot and few-shot learning paradigms.</p>
<p>Their study evaluates a range of multilingual encoder models, including <em>XLM-Roberta</em>, <em>mBERT</em>, and a specialised historical <em>mBERT</em> (<em>hmBERT</em>), alongside generative models such as <em>Llama-3.1 8b</em>. Key findings demonstrate that few-shot learning, particularly with Masked Language Model (MLM) fine-tuning, significantly improves performance. The <em>hmBERT-MLM</em> model emerges as the most effective, highlighting the value of domain-specific pre-training for historical texts. The work concludes that the rich generic diversity of popular magazines makes them a more complex text mining target than scientific journals, underscoring the necessity of robust genre classification for fine-grained historical analysis.</p>
</section>
<section id="presentation-outline" class="level2" data-number="5.1">
<h2 data-number="5.1" class="anchored" data-anchor-id="presentation-outline"><span class="header-section-number">5.1</span> Presentation Outline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The authors structure their research programme into three principal sections. It begins with an introduction to the ActDisease project, followed by a detailed examination of the genre classification experiments. The presentation culminates in a summary of the key conclusions drawn from the research.</p>
</section>
<section id="the-actdisease-project" class="level2" data-number="5.2">
<h2 data-number="5.2" class="anchored" data-anchor-id="the-actdisease-project"><span class="header-section-number">5.2</span> The ActDisease Project</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The authors initiated the ‘ActDisease’ project, an ERC-funded research programme designed to explore the influence of patient organisations on medicine and society. Central to the project is an analysis of how these groups, active throughout 20th-century Europe, shaped concepts of disease, the personal experience of illness, and prevailing medical practices. To achieve this, the investigators use patient-published periodicals as the primary source material for their historical analysis. An image of Heligoland, Germany, provides visual context for the historical settings under investigation.</p>
</section>
<section id="dataset-composition" class="level2" data-number="5.3">
<h2 data-number="5.3" class="anchored" data-anchor-id="dataset-composition"><span class="header-section-number">5.3</span> Dataset Composition</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The project team compiled the ActDisease Dataset, a specialised corpus of digitised magazines published by patient organisations. This collection spans materials from Germany, Sweden, France, and the UK, amounting to a total of 96,186 pages. A summary table provides a detailed breakdown of the dataset, specifying the number of unique magazine titles, total page counts, and the range of publication years for different diseases within each country.</p>
</section>
<section id="digitisation-and-ocr-challenges" class="level2" data-number="5.4">
<h2 data-number="5.4" class="anchored" data-anchor-id="digitisation-and-ocr-challenges"><span class="header-section-number">5.4</span> Digitisation and OCR Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The digitisation of historical documents presented a significant technical hurdle. The process of Optical Character Recognition (OCR), in particular, often yields suboptimal results when applied to older, varied source materials. This challenge necessitates further research into effective post-OCR correction methods, which are crucial for enhancing the accuracy and utility of the digitised text for subsequent analysis.</p>
</section>
<section id="genre-classification-challenges" class="level2" data-number="5.5">
<h2 data-number="5.5" class="anchored" data-anchor-id="genre-classification-challenges"><span class="header-section-number">5.5</span> Genre Classification Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>Analysing patient periodicals introduces a distinct challenge in genre classification. The source materials contain a wide diversity of text types, ranging from medical advice to personal stories and advertisements. Consequently, conventional methods such as topic modelling or basic term-counting prove inadequate for accurately differentiating these nuanced genres, which often share overlapping vocabularies.</p>
</section>
<section id="motivation-for-classification" class="level2" data-number="5.6">
<h2 data-number="5.6" class="anchored" data-anchor-id="motivation-for-classification"><span class="header-section-number">5.6</span> Motivation for Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The authors’ focus on genre classification stems from its analytical utility. From a language technology standpoint, genre provides a framework for understanding the communicative purpose of a text. By classifying content into distinct genres, the team can conduct more rigorous historical investigations, separating, for instance, official announcements from personal testimonials. Ultimately, this capability enables a more fine-grained and context-aware analysis of the entire dataset.</p>
</section>
<section id="illustrating-genre-diversity" class="level2" data-number="5.7">
<h2 data-number="5.7" class="anchored" data-anchor-id="illustrating-genre-diversity"><span class="header-section-number">5.7</span> Illustrating Genre Diversity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>A collage of documents illustrates the project’s central challenge, showcasing the diverse textual genres related to a specific disease, likely diabetes. This visual representation effectively communicates the variety of formats and styles—from scientific articles to personal letters and advertisements—that the authors must categorise. It underscores the complexity of performing automated analysis on such heterogeneous source material.</p>
</section>
<section id="textual-examples-of-variation" class="level2" data-number="5.8">
<h2 data-number="5.8" class="anchored" data-anchor-id="textual-examples-of-variation"><span class="header-section-number">5.8</span> Textual Examples of Variation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>To reinforce the concept of genre diversity, the authors provide several concrete textual examples from the ‘ActDisease’ domain, specifically concerning diabetes. These snippets highlight the distinct linguistic and structural features of different genres found within the patient magazines. By presenting these varied examples, the team clarifies the practical difficulties and the importance of developing a robust classification system.</p>
</section>
<section id="defining-genre-labels" class="level2" data-number="5.9">
<h2 data-number="5.9" class="anchored" data-anchor-id="defining-genre-labels"><span class="header-section-number">5.9</span> Defining Genre Labels</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The authors established a formal set of genre labels to structure their classification task. Rather than being algorithmically derived, these labels were defined by subject-matter experts to ensure historical and contextual relevance. The primary function of this schema is to enable the systematic separation of content according to its type, which is essential for nuanced historical analysis. Moreover, the team designed the labels with a view towards general-purpose applicability, aiming for a system that could be adapted for other historical text analysis projects.</p>
</section>
<section id="genre-classification-schema" class="level2" data-number="5.10">
<h2 data-number="5.10" class="anchored" data-anchor-id="genre-classification-schema"><span class="header-section-number">5.10</span> Genre Classification Schema</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>A detailed classification schema formally defines the nine distinct text genres used in the project: <em>Academic</em>, <em>Administrative</em>, <em>Advertisement</em>, <em>Guide</em>, <em>Fiction</em>, <em>Legal</em>, <em>News</em>, <em>Nonfiction Prose</em>, and <em>QA (Question &amp; Answer)</em>. For clarity and consistency in annotation, a comprehensive table outlines the specific characteristics of each genre and provides representative examples drawn from the source material.</p>
</section>
<section id="annotation-methodology" class="level2" data-number="5.11">
<h2 data-number="5.11" class="anchored" data-anchor-id="annotation-methodology"><span class="header-section-number">5.11</span> Annotation Methodology</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>The team developed a rigorous methodology for creating the ground-truth dataset, establishing the paragraph as the fundamental unit for genre annotation. Two student annotators, working with German patient magazines focused on diabetes, applied the predefined genre labels to the text. To ensure the reliability of this process, the authors calculated the inter-annotator agreement, achieving a Cohen’s Kappa score of 0.77, which signifies a substantial level of consistency.</p>
</section>
<section id="annotation-in-practice" class="level2" data-number="5.12">
<h2 data-number="5.12" class="anchored" data-anchor-id="annotation-in-practice"><span class="header-section-number">5.12</span> Annotation in Practice</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>A practical example demonstrates the annotation process. Three sample paragraphs extracted from the German magazine <em>Der Diabetiker</em> are presented in a table. Each paragraph is paired with its assigned genre label, clearly illustrating how the classification schema is applied to actual source text. This example serves to clarify the task for both training and evaluation purposes.</p>
</section>
<section id="dataset-splits-for-experiments" class="level2" data-number="5.13">
<h2 data-number="5.13" class="anchored" data-anchor-id="dataset-splits-for-experiments"><span class="header-section-number">5.13</span> Dataset Splits for Experiments</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>For their machine learning experiments, the authors partitioned the annotated ActDisease data into specific training and held-out sets. They carefully designed this division to evaluate model performance in both few-shot and zero-shot learning scenarios. The training set consists exclusively of annotated German texts. In contrast, the held-out (test) set comprises texts in German, French, and Swedish, and crucially, it includes genres that are deliberately absent from the training data to test zero-shot generalisation.</p>
</section>
<section id="genre-and-language-distribution" class="level2" data-number="5.14">
<h2 data-number="5.14" class="anchored" data-anchor-id="genre-and-language-distribution"><span class="header-section-number">5.14</span> Genre and Language Distribution</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>An analysis of the dataset reveals the distribution of text instances across different languages and genres. A comparison between the training and held-out sets highlights two important characteristics. First, there are significant imbalances in the prevalence of certain genres, a common feature of real-world data. Second, the held-out set intentionally includes novel genres absent from the training set, a design critical for rigorously assessing the zero-shot classification capabilities of the models.</p>
</section>
<section id="external-datasets-for-zero-shot" class="level2" data-number="5.15">
<h2 data-number="5.15" class="anchored" data-anchor-id="external-datasets-for-zero-shot"><span class="header-section-number">5.15</span> External Datasets for Zero-Shot</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>To enhance their zero-shot learning experiments, the team incorporated several publicly available, multilingual datasets for genre classification. These external resources, which include <em>CORE</em>, <em>UDM</em>, and <em>FTD</em>, provide a mix of document-level and sentence-level annotations. Leveraging these datasets allows for more robust training and evaluation of the models’ ability to generalise to unseen labels and data distributions.</p>
</section>
<section id="cross-dataset-label-mapping" class="level2" data-number="5.16">
<h2 data-number="5.16" class="anchored" data-anchor-id="cross-dataset-label-mapping"><span class="header-section-number">5.16</span> Cross-Dataset Label Mapping</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_18.png" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
<p>A comparative table illustrates the mapping of genre labels across the four datasets used in the study: <em>ActDisease</em>, <em>CORE</em>, <em>UDM</em>, and <em>FTD</em>. This visualisation reveals considerable variation in the classification schemas, with different datasets using distinct and sometimes conflicting genre definitions. Such heterogeneity poses a significant challenge for zero-shot learning, as models trained on one schema must adapt to another, necessitating a thoughtful approach to label mapping.</p>
</section>
<section id="training-data-pipeline" class="level2" data-number="5.17">
<h2 data-number="5.17" class="anchored" data-anchor-id="training-data-pipeline"><span class="header-section-number">5.17</span> Training Data Pipeline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_19.png" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>The authors designed a comprehensive and flexible pipeline for generating training data. This process integrates data from all four sources—<em>ActDisease</em>, <em>CORE</em>, <em>UDM</em>, and <em>FTD</em>—and subjects them to a series of preprocessing steps. Crucially, the pipeline incorporates configurable sampling strategies, allowing the team to create various training set compositions to test different hypotheses about model performance and data balancing systematically.</p>
</section>
<section id="multilingual-encoder-models" class="level2" data-number="5.18">
<h2 data-number="5.18" class="anchored" data-anchor-id="multilingual-encoder-models"><span class="header-section-number">5.18</span> Multilingual Encoder Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_20.png" class="img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
<p>The experiments leverage several powerful multilingual encoder models as the basis for classification. The selected models include the widely used <em>XLM-Roberta</em> (<em>xlmr</em>) and multilingual <em>BERT</em> (<em>mBERT</em>). In addition, the team evaluates a specialised historical <em>mBERT</em> (<em>hmbert</em>), which has been pre-trained on a large corpus of historical texts. This selection allows for a comparison between general-purpose multilingual models and a model adapted for the specific domain of historical language.</p>
</section>
<section id="fine-tuning-setup" class="level2" data-number="5.19">
<h2 data-number="5.19" class="anchored" data-anchor-id="fine-tuning-setup"><span class="header-section-number">5.19</span> Fine-Tuning Setup</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_21.png" class="img-fluid figure-img"></p>
<figcaption>Slide 21</figcaption>
</figure>
</div>
<p>The experimental design for fine-tuning involved a systematic and large-scale approach. The authors created 16 unique training set configurations by varying the data sources and sampling strategies. They then fine-tuned each of the three base language models (<em>XLM-R</em>, <em>mBERT</em>, and <em>hmBERT</em>) on every one of these 16 configurations. This comprehensive methodology resulted in a total of 48 distinct fine-tuned models, enabling a thorough analysis of how training data composition affects performance.</p>
</section>
<section id="evaluating-zero-shot-learning" class="level2" data-number="5.20">
<h2 data-number="5.20" class="anchored" data-anchor-id="evaluating-zero-shot-learning"><span class="header-section-number">5.20</span> Evaluating Zero-Shot Learning</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_22.png" class="img-fluid figure-img"></p>
<figcaption>Slide 22</figcaption>
</figure>
</div>
<p>The investigation now shifts its focus towards evaluating the models’ performance in a zero-shot learning context. This phase assesses the ability of the fine-tuned models to classify genres that they have not encountered during their training phase.</p>
</section>
<section id="zero-shot-evaluation-methodology" class="level2" data-number="5.21">
<h2 data-number="5.21" class="anchored" data-anchor-id="zero-shot-evaluation-methodology"><span class="header-section-number">5.21</span> Zero-Shot Evaluation Methodology</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_23.png" class="img-fluid figure-img"></p>
<figcaption>Slide 23</figcaption>
</figure>
</div>
<p>Evaluating zero-shot predictions requires a specialised methodology to handle inherent complexities. The primary challenges include managing the partial overlap between genre label sets from different source datasets and accounting for cross-lingual scenarios where a model is tested on a language not present in its training data. The authors’ evaluation protocol is designed specifically to navigate these issues, ensuring a robust and fair assessment of model generalisation.</p>
</section>
<section id="zero-shot-results-overview" class="level2" data-number="5.22">
<h2 data-number="5.22" class="anchored" data-anchor-id="zero-shot-results-overview"><span class="header-section-number">5.22</span> Zero-Shot Results Overview</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_24.png" class="img-fluid figure-img"></p>
<figcaption>Slide 24</figcaption>
</figure>
</div>
<p>An overview of the zero-shot experiment results reveals several key patterns. For the <em>FTD</em> dataset, employing a specific label mapping strategy yields a noticeable improvement in model performance. Across other datasets, however, results indicate the presence of class-specific and language-related biases. On the <em>UDM</em> dataset, the investigators observed intriguing performance variations between the different models for certain classification tasks. Notably, models fine-tuned using the <em>CORE</em> dataset demonstrate a particular aptitude for correctly identifying texts belonging to the <em>Legal</em> genre.</p>
</section>
<section id="comparative-confusion-matrices" class="level2" data-number="5.23">
<h2 data-number="5.23" class="anchored" data-anchor-id="comparative-confusion-matrices"><span class="header-section-number">5.23</span> Comparative Confusion Matrices</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_25.png" class="img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
<p>Four confusion matrices provide a visual comparison of the performance of different genre classification models. The matrices detail the results for models such as <em>hmbert_UDM</em>, <em>xlmr_CORE</em>, <em>xlmr_UDM</em>, and <em>xlmr_FTD</em>, each representing a unique combination of base architecture and training data. These visualisations allow for a direct comparison of error patterns and classification accuracy under various experimental conditions when evaluated on the held-out ActDisease data.</p>
</section>
<section id="zero-shot-f1-scores" class="level2" data-number="5.24">
<h2 data-number="5.24" class="anchored" data-anchor-id="zero-shot-f1-scores"><span class="header-section-number">5.24</span> Zero-Shot F1 Scores</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_26.png" class="img-fluid figure-img"></p>
<figcaption>Slide 26</figcaption>
</figure>
</div>
<p>A summary table presents the zero-shot performance using the per-category F1 score as the primary metric. These scores, which measure the balance between precision and recall for each genre, are averaged across the various training data configurations. This allows for a consolidated view of how well each language model performs on individual genre categories in a zero-shot setting.</p>
</section>
<section id="impact-of-data-configuration" class="level2" data-number="5.25">
<h2 data-number="5.25" class="anchored" data-anchor-id="impact-of-data-configuration"><span class="header-section-number">5.25</span> Impact of Data Configuration</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_27.png" class="img-fluid figure-img"></p>
<figcaption>Slide 27</figcaption>
</figure>
</div>
<p>The authors analysed the average F1 performance of the classification models across three distinct target tasks, corresponding to the <em>FTD</em>, <em>CORE</em>, and <em>UDM</em> datasets. This analysis specifically investigates how performance is affected by two key factors in the training data construction: the application of data balancing techniques and the inclusion or exclusion of certain language families. The results illuminate the sensitivity of model performance to the composition of the training corpus.</p>
</section>
<section id="evaluating-few-shot-learning" class="level2" data-number="5.26">
<h2 data-number="5.26" class="anchored" data-anchor-id="evaluating-few-shot-learning"><span class="header-section-number">5.26</span> Evaluating Few-Shot Learning</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_28.png" class="img-fluid figure-img"></p>
<figcaption>Slide 28</figcaption>
</figure>
</div>
<p>The report now transitions to an evaluation of the models under a few-shot learning paradigm. This section assesses how effectively the models can learn to classify genres when provided with only a small number of training examples from the target ActDisease dataset.</p>
</section>
<section id="few-shot-learning-performance" class="level2" data-number="5.27">
<h2 data-number="5.27" class="anchored" data-anchor-id="few-shot-learning-performance"><span class="header-section-number">5.27</span> Few-Shot Learning Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_29.png" class="img-fluid figure-img"></p>
<figcaption>Slide 29</figcaption>
</figure>
</div>
<p>The evaluation of few-shot learning reveals clear performance trends. As expected, F1 scores for all models generally improve as the number of available training examples increases. A crucial finding is that an intermediate step of Masked Language Model (MLM) fine-tuning on the target domain’s text confers a distinct advantage, consistently boosting classification accuracy. Amongst all configurations, the <em>hmBERT-MLM</em> model, which combines historical pre-training with domain-specific MLM fine-tuning, achieves the highest performance.</p>
</section>
<section id="few-shot-f1-score-details" class="level2" data-number="5.28">
<h2 data-number="5.28" class="anchored" data-anchor-id="few-shot-f1-score-details"><span class="header-section-number">5.28</span> Few-Shot F1 Score Details</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_30.png" class="img-fluid figure-img"></p>
<figcaption>Slide 30</figcaption>
</figure>
</div>
<p>A detailed table presents the per-category F1 scores for the few-shot learning experiments. The results are broken down for each language model and are shown at two distinct levels of data availability (for example, with 16 and 32 training examples per class). In addition to the granular, per-category scores, the table also includes overall performance metrics, allowing for a comprehensive comparison of the models’ effectiveness in a data-scarce environment.</p>
</section>
<section id="full-dataset-performance" class="level2" data-number="5.29">
<h2 data-number="5.29" class="anchored" data-anchor-id="full-dataset-performance"><span class="header-section-number">5.29</span> Full-Dataset Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_31.png" class="img-fluid figure-img"></p>
<figcaption>Slide 31</figcaption>
</figure>
</div>
<p>When trained on the full dataset, the <em>XLM-Roberta-MLM</em> model demonstrates strong classification capabilities, as illustrated by a confusion matrix. The matrix reveals specific patterns of misclassification, which in turn provide insights into the nature of the data. For instance, it highlights the thematic and stylistic similarities between the <em>Guide</em>, <em>Nonfiction Prose</em>, and <em>QA</em> genres as they appear within the context of diabetes patient magazines, explaining why the model sometimes confuses them.</p>
</section>
<section id="evaluating-few-shot-prompting" class="level2" data-number="5.30">
<h2 data-number="5.30" class="anchored" data-anchor-id="evaluating-few-shot-prompting"><span class="header-section-number">5.30</span> Evaluating Few-Shot Prompting</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_32.png" class="img-fluid figure-img"></p>
<figcaption>Slide 32</figcaption>
</figure>
</div>
<p>The final experimental section shifts to an evaluation of few-shot prompting. This approach assesses the ability of large generative language models to perform genre classification based on instructions and a small number of examples provided directly in the input prompt.</p>
</section>
<section id="instruction-based-classification" class="level2" data-number="5.31">
<h2 data-number="5.31" class="anchored" data-anchor-id="instruction-based-classification"><span class="header-section-number">5.31</span> Instruction-Based Classification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_33.png" class="img-fluid figure-img"></p>
<figcaption>Slide 33</figcaption>
</figure>
</div>
<p>For the prompting experiment, the authors formulated a detailed set of instructions for a text genre classification task. The prompt explicitly defines the nine target genres, complete with illustrative examples for each, and specifies the required input and output format. The chosen language model for executing this instruction-based, few-shot task is <em>Llama-3.1 8b</em>.</p>
</section>
<section id="llama-3.1-8b-performance" class="level2" data-number="5.32">
<h2 data-number="5.32" class="anchored" data-anchor-id="llama-3.1-8b-performance"><span class="header-section-number">5.32</span> Llama-3.1 8b Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_34.png" class="img-fluid figure-img"></p>
<figcaption>Slide 34</figcaption>
</figure>
</div>
<p>The performance of the <em>Llama-3.1 8b Instruct</em> model on the few-shot prompting task is presented. The results include F1-scores for each genre, quantifying the model’s accuracy. A detailed confusion matrix is also provided, offering a granular view of the model’s classification decisions and revealing which genres were most frequently confused with one another.</p>
</section>
<section id="conclusion-on-text-mining" class="level2" data-number="5.33">
<h2 data-number="5.33" class="anchored" data-anchor-id="conclusion-on-text-mining"><span class="header-section-number">5.33</span> Conclusion on Text Mining</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_35.png" class="img-fluid figure-img"></p>
<figcaption>Slide 35</figcaption>
</figure>
</div>
<p>A primary conclusion from this work is that applying text mining techniques to popular magazines is an inherently more complex task than analysing more uniform corpora like scientific journals or books. The authors attribute this increased difficulty directly to the rich and varied multitude of genres that coexist within a single magazine issue, demanding more sophisticated analytical approaches.</p>
</section>
<section id="summary-of-conclusions" class="level2" data-number="5.34">
<h2 data-number="5.34" class="anchored" data-anchor-id="summary-of-conclusions"><span class="header-section-number">5.34</span> Summary of Conclusions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_005_slide_37.png" class="img-fluid figure-img"></p>
<figcaption>Slide 37</figcaption>
</figure>
</div>
<p>The authors’ research yields several key conclusions:</p>
<ul>
<li><p>The generic diversity of historical magazines poses a substantial challenge for text mining.</p></li>
<li><p>Genre classification proves to be an indispensable tool, enabling the kind of fine-grained analysis necessary for deep historical inquiry.</p></li>
<li><p>Modern, large-scale datasets can be successfully leveraged to improve the analysis of historical texts.</p></li>
<li><p>Contemporary generative models exhibit promising quality on these classification tasks.</p></li>
<li><p>Few-shot learning with multilingual encoders is a highly effective strategy, with performance being particularly strong when using models specifically adapted for historical language.</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_004.html" class="pagination-link" aria-label="OpenAlex Mapper presentation slide">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OpenAlex Mapper presentation slide</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="VERITRACE: Tracing the Influence of Ancient Wisdom on Early Modern Natural Philosophy">
        <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE: Tracing the Influence of Ancient Wisdom on Early Modern Natural Philosophy</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>