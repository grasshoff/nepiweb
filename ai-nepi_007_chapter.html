<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oliver Eberle">

<title>7&nbsp; Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./ai-nepi_008_chapter.html" rel="next">
<link href="./ai-nepi_006_chapter.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./ai-nepi_007_chapter.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Transformer’s Legacy: Understanding Large Language Models and their Application in HPSS Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Workflow and Utility of OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Beyond Traditional Views of Science Funding</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#understanding-explainable-ai-xai" id="toc-understanding-explainable-ai-xai" class="nav-link" data-scroll-target="#understanding-explainable-ai-xai"><span class="header-section-number">7.1</span> Understanding Explainable AI (XAI)</a>
  <ul class="collapse">
  <li><a href="#xai-1.0-feature-attributions" id="toc-xai-1.0-feature-attributions" class="nav-link" data-scroll-target="#xai-1.0-feature-attributions"><span class="header-section-number">7.1.1</span> XAI 1.0: Feature Attributions</a></li>
  <li><a href="#the-rationale-for-explainability" id="toc-the-rationale-for-explainability" class="nav-link" data-scroll-target="#the-rationale-for-explainability"><span class="header-section-number">7.1.2</span> The Rationale for Explainability</a></li>
  </ul></li>
  <li><a href="#the-advent-of-generative-ai-expanding-capabilities-and-challenges" id="toc-the-advent-of-generative-ai-expanding-capabilities-and-challenges" class="nav-link" data-scroll-target="#the-advent-of-generative-ai-expanding-capabilities-and-challenges"><span class="header-section-number">7.2</span> The Advent of Generative AI: Expanding Capabilities and Challenges</a></li>
  <li><a href="#the-imperative-of-recognising-model-errors" id="toc-the-imperative-of-recognising-model-errors" class="nav-link" data-scroll-target="#the-imperative-of-recognising-model-errors"><span class="header-section-number">7.3</span> The Imperative of Recognising Model Errors</a></li>
  <li><a href="#xai-2.0-towards-structured-interpretability" id="toc-xai-2.0-towards-structured-interpretability" class="nav-link" data-scroll-target="#xai-2.0-towards-structured-interpretability"><span class="header-section-number">7.4</span> XAI 2.0: Towards Structured Interpretability</a>
  <ul class="collapse">
  <li><a href="#first-order-explanations-identifying-key-features" id="toc-first-order-explanations-identifying-key-features" class="nav-link" data-scroll-target="#first-order-explanations-identifying-key-features"><span class="header-section-number">7.4.1</span> First-Order Explanations: Identifying Key Features</a></li>
  <li><a href="#second-order-explanations-uncovering-pairwise-relationships" id="toc-second-order-explanations-uncovering-pairwise-relationships" class="nav-link" data-scroll-target="#second-order-explanations-uncovering-pairwise-relationships"><span class="header-section-number">7.4.2</span> Second-Order Explanations: Uncovering Pairwise Relationships</a></li>
  <li><a href="#higher-order-interactions-revealing-complex-structures" id="toc-higher-order-interactions-revealing-complex-structures" class="nav-link" data-scroll-target="#higher-order-interactions-revealing-complex-structures"><span class="header-section-number">7.4.3</span> Higher-Order Interactions: Revealing Complex Structures</a></li>
  </ul></li>
  <li><a href="#applications-in-language-and-the-humanities" id="toc-applications-in-language-and-the-humanities" class="nav-link" data-scroll-target="#applications-in-language-and-the-humanities"><span class="header-section-number">7.5</span> Applications in Language and the Humanities</a>
  <ul class="collapse">
  <li><a href="#first-order-attributions-in-llms-sentiment-prediction-and-bias-detection" id="toc-first-order-attributions-in-llms-sentiment-prediction-and-bias-detection" class="nav-link" data-scroll-target="#first-order-attributions-in-llms-sentiment-prediction-and-bias-detection"><span class="header-section-number">7.5.1</span> First-Order Attributions in LLMs: Sentiment Prediction and Bias Detection</a></li>
  <li><a href="#first-order-attributions-for-long-range-dependencies-in-llms" id="toc-first-order-attributions-for-long-range-dependencies-in-llms" class="nav-link" data-scroll-target="#first-order-attributions-for-long-range-dependencies-in-llms"><span class="header-section-number">7.5.2</span> First-Order Attributions for Long-Range Dependencies in LLMs</a></li>
  <li><a href="#second-and-higher-order-interactions-in-text" id="toc-second-and-higher-order-interactions-in-text" class="nav-link" data-scroll-target="#second-and-higher-order-interactions-in-text"><span class="header-section-number">7.5.3</span> Second and Higher-Order Interactions in Text</a></li>
  <li><a href="#graph-neural-networks-for-structured-predictions-in-language" id="toc-graph-neural-networks-for-structured-predictions-in-language" class="nav-link" data-scroll-target="#graph-neural-networks-for-structured-predictions-in-language"><span class="header-section-number">7.5.4</span> Graph Neural Networks for Structured Predictions in Language</a></li>
  </ul></li>
  <li><a href="#ai-driven-scientific-insights-in-the-humanities" id="toc-ai-driven-scientific-insights-in-the-humanities" class="nav-link" data-scroll-target="#ai-driven-scientific-insights-in-the-humanities"><span class="header-section-number">7.6</span> AI-driven Scientific Insights in the Humanities</a>
  <ul class="collapse">
  <li><a href="#extracting-visual-definitions-from-corpora" id="toc-extracting-visual-definitions-from-corpora" class="nav-link" data-scroll-target="#extracting-visual-definitions-from-corpora"><span class="header-section-number">7.6.1</span> Extracting Visual Definitions from Corpora</a></li>
  <li><a href="#corpus-level-analysis-of-early-modern-astronomical-tables" id="toc-corpus-level-analysis-of-early-modern-astronomical-tables" class="nav-link" data-scroll-target="#corpus-level-analysis-of-early-modern-astronomical-tables"><span class="header-section-number">7.6.2</span> Corpus-Level Analysis of Early Modern Astronomical Tables</a></li>
  </ul></li>
  <li><a href="#conclusion-the-evolving-role-of-ai-based-methods-in-the-humanities" id="toc-conclusion-the-evolving-role-of-ai-based-methods-in-the-humanities" class="nav-link" data-scroll-target="#conclusion-the-evolving-role-of-ai-based-methods-in-the-humanities"><span class="header-section-number">7.7</span> Conclusion: The Evolving Role of AI-based Methods in the Humanities</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></h1>
</div>



<div class="quarto-title-meta">

    <div>
    <div class="quarto-title-meta-heading">Author</div>
    <div class="quarto-title-meta-contents">
             <p>Oliver Eberle </p>
          </div>
  </div>
    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">Invalid Date</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The field of explainable Artificial Intelligence (AI) garners increasing attention, yet a universally accepted definition of what constitutes an ‘explanation’, particularly within the machine learning community, remains an evolving concept. This chapter delves into the nuances of interpretability for Large Language Models (LLMs), exploring methods that offer transparency, practical applications, and the potential for novel scientific insights, especially within the humanities. We begin by establishing a foundational understanding of explanations in machine learning.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities. Speaker: Oliver Eberle, Senior Researcher, Berlin Institute for Learning and Data (BIFOLD), TU Berlin. Logos of BIFOLD and TU Berlin.</figcaption>
</figure>
</div>
</section>
<section id="understanding-explainable-ai-xai" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="understanding-explainable-ai-xai"><span class="header-section-number">7.1</span> Understanding Explainable AI (XAI)</h2>
<p>Historically, a significant portion of machine learning development centred on visual data, primarily images. Only in the last decade or so has the field intensified its focus on language, although foundational work in this area extends further into the past. The major shifts in language-focused AI, however, are relatively recent phenomena.</p>
<section id="xai-1.0-feature-attributions" class="level3" data-number="7.1.1">
<h3 data-number="7.1.1" class="anchored" data-anchor-id="xai-1.0-feature-attributions"><span class="header-section-number">7.1.1</span> XAI 1.0: Feature Attributions</h3>
<p>To comprehend the internal workings of ‘black box’ machine learning models, researchers initially concentrated on classification tasks. Typically, an input, such as an image containing a specific object, would be fed into a model, which would then, ideally, produce a correct prediction. Nevertheless, the user often remained unaware of the basis for this classification.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Explainable AI (XAI) 1.0’ with subtitle ‘Feature attributions’. Dark blue background with white text.</figcaption>
</figure>
</div>
<p>Consequently, the domain of explainable AI dedicated approximately a decade of research to understanding and tracing the origins of these predictions. A common output from such investigations was a heatmap, visually indicating which pixels were most influential in the model’s decision-making process. For instance, a heatmap might clearly show why a model recognised a rooster in an image.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Explainable AI (XAI) 1.0’ with subtitle ‘Feature attributions’. Dark blue background with white text.</figcaption>
</figure>
</div>
</section>
<section id="the-rationale-for-explainability" class="level3" data-number="7.1.2">
<h3 data-number="7.1.2" class="anchored" data-anchor-id="the-rationale-for-explainability"><span class="header-section-number">7.1.2</span> The Rationale for Explainability</h3>
<p>The pursuit of explainability addresses several critical needs. Primarily, it serves to verify predictions, ensuring that a model operates on a reasonable basis. Furthermore, explainability aids in correcting errors and understanding how models make mistakes. It can also illuminate the learning process itself, as models occasionally discover surprising or unconventional solutions to problems. Increasingly, explainability is vital for ensuring compliance with regulatory frameworks, such as the European AI Act.</p>
</section>
</section>
<section id="the-advent-of-generative-ai-expanding-capabilities-and-challenges" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="the-advent-of-generative-ai-expanding-capabilities-and-challenges"><span class="header-section-number">7.2</span> The Advent of Generative AI: Expanding Capabilities and Challenges</h2>
<p>The landscape of AI, once dominated by classification models, has undergone a significant transformation with the rise of Generative AI (GenAI) over approximately the last five years. This paradigm shift marks a departure from models designed for specific tasks towards those with multifaceted capabilities.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Diagram illustrating a black box AI system: input image of a rooster leads to ‘Black Box AI System’, which outputs ‘Rooster’. Citation: Samek et al.&nbsp;(2017).</figcaption>
</figure>
</div>
<p>Unlike their predecessors, contemporary GenAI models can classify, identify similar images, generate entirely new images, and respond to queries on a vast array of topics. This versatility, however, introduces considerable complexity in grounding a model’s prediction or an LLM’s answer to specific input features. The following discussion explores avenues beyond simple heatmap representations, considering feature interactions and more mechanistic perspectives to understand these advanced systems. Today’s foundation models function not only as multi-task systems but also as models of the world, capturing insights about society and the evolution of textual features over time, which underpins much of the current interest in them.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.jpg" class="img-fluid figure-img"></p>
<figcaption>Diagram contrasting classification models with generative AI. Generative AI can produce various outputs like ‘rooster’, ‘similar images’, ‘generate examples’, ‘Q&amp;A’. Mentions ‘beyond heatmaps’, ‘feature interactions’, ‘mechanistic view’. Citation: Samek et al.&nbsp;(2017).</figcaption>
</figure>
</div>
</section>
<section id="the-imperative-of-recognising-model-errors" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="the-imperative-of-recognising-model-errors"><span class="header-section-number">7.3</span> The Imperative of Recognising Model Errors</h2>
<p>It is crucial to acknowledge that even advanced models can, and do, make surprising mistakes. Two well-documented examples illustrate this point. In one instance, a standard object classifier incorrectly based its identification of a boat on the surrounding water rather than the boat itself. The water, being a correlated feature and texturally simpler to detect, became the misleading focal point for the model <span class="citation" data-cites="Lapuschkin2019">(<a href="#ref-Lapuschkin2019" role="doc-biblioref"><strong>Lapuschkin2019?</strong></a>)</span>.</p>
<p>Another, more recent, example involves multi-step planning errors in LLMs. When tasked with the Tower of Hanoi puzzle—moving disks from a starting peg to a destination peg according to specific rules—an LLM might incorrectly attempt to move the largest, inaccessible disk directly to the target. This demonstrates a failure to comprehend the fundamental physical constraints of the problem <span class="citation" data-cites="MondalWebb2024">(<a href="#ref-MondalWebb2024" role="doc-biblioref"><strong>MondalWebb2024?</strong></a>)</span>. While more recent reasoning models may exhibit improved performance, such errors have been observed in fairly standard models like Llama 3.something.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_06.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Models can make mistakes’. Left: Object detection example (boat identified by water, Lapuschkin et al., Nat Commun ’19). Right: Multi-step planning example (Tower of Hanoi error, Mondal &amp; Webb et al., arxiv ’24).</figcaption>
</figure>
</div>
</section>
<section id="xai-2.0-towards-structured-interpretability" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="xai-2.0-towards-structured-interpretability"><span class="header-section-number">7.4</span> XAI 2.0: Towards Structured Interpretability</h2>
<p>To move beyond the limitations of heatmap-based explanations, the concept of structured interpretability offers a more nuanced approach to understanding model behaviour. This progression is sometimes referred to as XAI 2.0.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘XAI 2.0’ with subtitle ‘Structured Interpretability’. Dark blue background with white text.</figcaption>
</figure>
</div>
<section id="first-order-explanations-identifying-key-features" class="level3" data-number="7.4.1">
<h3 data-number="7.4.1" class="anchored" data-anchor-id="first-order-explanations-identifying-key-features"><span class="header-section-number">7.4.1</span> First-Order Explanations: Identifying Key Features</h3>
<p>First-order explanations, as previously touched upon, are particularly useful for elucidating the decisions of classifiers. They allow for the generation of heatmaps that highlight influential features. For instance, in a project involving a table classifier for historical data, the goal was to distinguish subgroups within these tables. To ensure the classifier operated meaningfully, heatmaps verified that its predictions were based on relevant features. Indeed, these visualisations confirmed that the model correctly focused on numerical content to identify numerical tables—a sensible proxy.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_08.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Identifying relevant features and their interactions for interpretability’. Left side shows ‘first-order’ diagram with x₁ highlighted, and ‘classifier predictions’ with images of historical tables.</figcaption>
</figure>
</div>
</section>
<section id="second-order-explanations-uncovering-pairwise-relationships" class="level3" data-number="7.4.2">
<h3 data-number="7.4.2" class="anchored" data-anchor-id="second-order-explanations-uncovering-pairwise-relationships"><span class="header-section-number">7.4.2</span> Second-Order Explanations: Uncovering Pairwise Relationships</h3>
<p>Investigations then extended to second-order features, where pairwise relationships between features became significant. This was particularly evident when examining similarity. For example, when calculating a similarity score (e.g., a dot product) between the embeddings of two images or, in this context, two tables, explaining this prediction reveals the importance of feature interactions. Such explanations can highlight interactions between specific digits, confirming, for instance, that two tables are identical and that the model functions as intended.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Identifying relevant features and their interactions for interpretability’. Left side shows ‘first-order’ diagram and ‘classifier predictions’. Right side is mostly empty. This slide focuses on the first-order aspect before evolving.</figcaption>
</figure>
</div>
</section>
<section id="higher-order-interactions-revealing-complex-structures" class="level3" data-number="7.4.3">
<h3 data-number="7.4.3" class="anchored" data-anchor-id="higher-order-interactions-revealing-complex-structures"><span class="header-section-number">7.4.3</span> Higher-Order Interactions: Revealing Complex Structures</h3>
<p>More recent work delves into graph structures, where higher-order interactions prove more meaningful. Consider a citation network, or a network of books or other entities, upon which a classification task is trained. In such scenarios, subgraphs or feature walks—sets of features that become relevant collectively—can be identified. This approach yields more complex insights into model behaviour and moves towards a circuit-level understanding of their operations. These explorations represent ongoing efforts in the field of interpretability.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Identifying relevant features and their interactions for interpretability’. Three columns: ‘first-order’ (x₁ highlighted), ‘second-order’ (x₁-x₄ interaction), ‘higher-order’ (x₁, x₂, x₄ triangle). Below are examples: classifier predictions, pairwise relationships between tables, and graph structure.</figcaption>
</figure>
</div>
</section>
</section>
<section id="applications-in-language-and-the-humanities" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="applications-in-language-and-the-humanities"><span class="header-section-number">7.5</span> Applications in Language and the Humanities</h2>
<p>The principles of structured interpretability find compelling applications when analysing language models and deriving insights within humanities research.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_11.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Identifying relevant features and their interactions for interpretability’. Three columns: ‘first-order’, ‘second-order’, ‘higher-order’ with corresponding diagrams and examples. This slide serves as a visual summary before diving into specific examples.</figcaption>
</figure>
</div>
<section id="first-order-attributions-in-llms-sentiment-prediction-and-bias-detection" class="level3" data-number="7.5.1">
<h3 data-number="7.5.1" class="anchored" data-anchor-id="first-order-attributions-in-llms-sentiment-prediction-and-bias-detection"><span class="header-section-number">7.5.1</span> First-Order Attributions in LLMs: Sentiment Prediction and Bias Detection</h3>
<p>A standard application for first-order attributions involves sentiment prediction, often using movie reviews—a common dataset in the language processing community. By training a model on such reviews and subsequently examining the basis of its predictions, researchers can gain valuable insights. Heatmaps, generated using methods tailored for transformers, can rank sentences and highlight influential tokens.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘First-Order Attributions in LLMs’. Dark blue background with white text.</figcaption>
</figure>
</div>
<p>Such analyses have revealed that certain features disproportionately affect sentiment scores. For example, male Western names (e.g., Lee, Barry, Raphael, or references to the Cohen brothers) tend to correlate with positive reviews. Conversely, names perceived as foreign (e.g., Saddam, Castro, Chan) are more likely to be associated with negative scores. These findings underscore the presence of biases within models, a well-recognised issue in the AI community. Explainable AI techniques prove highly effective in detecting these fine-grained biases.</p>
</section>
<section id="first-order-attributions-for-long-range-dependencies-in-llms" class="level3" data-number="7.5.2">
<h3 data-number="7.5.2" class="anchored" data-anchor-id="first-order-attributions-for-long-range-dependencies-in-llms"><span class="header-section-number">7.5.2</span> First-Order Attributions for Long-Range Dependencies in LLMs</h3>
<p>Another area of investigation concerns long-range dependencies in LLMs. In a typical scenario, an LLM processes a long context window—perhaps up to 8,000 tokens from Wikipedia articles—and is then prompted to generate a summary. The model begins to produce free text, and the objective is to determine the origin of this generated information within the provided context. Specifically, researchers explore whether models can effectively utilise information from distant parts of the input.</p>
<p>Findings indicate that models predominantly focus on the latter portions of the context, prioritising information presented more recently. While they can access and pull information from earlier in the context, doing so is significantly less probable (note that analyses often use a log scale for counts). This tendency is important to bear in mind when using LLMs for summarisation; the output may not be a balanced representation of the entire text but rather skewed towards content nearer to the prompt <span class="citation" data-cites="Jafari2024">(<a href="#ref-Jafari2024" role="doc-biblioref"><strong>Jafari2024?</strong></a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Ex 1b: First-Order Attributions for Long-Range Dependencies in LLMs’. Setup: generating summaries for long inputs. Results: example text with highlighted tokens indicating source of generated summary. Citation: Jafari et al., MambaLRP (NeurIPS ’24).</figcaption>
</figure>
</div>
</section>
<section id="second-and-higher-order-interactions-in-text" class="level3" data-number="7.5.3">
<h3 data-number="7.5.3" class="anchored" data-anchor-id="second-and-higher-order-interactions-in-text"><span class="header-section-number">7.5.3</span> Second and Higher-Order Interactions in Text</h3>
<p>Moving to second and higher-order interactions, consider a standard scenario involving sentence embeddings. Given a pair of sentences, such as “A cat I really like” and “It is a great cat,” a model (e.g., BERT or Sentence-BERT) produces an embedding and a similarity score. However, the reasons behind this specific similarity value often remain opaque.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_14.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Second &amp; Higher-Order Interactions in Text’. Dark blue background with white text.</figcaption>
</figure>
</div>
<p>Second-order explanations can illuminate these reasons by providing interaction scores between tokens. These scores reveal why the model considered the sentences highly similar. Even in toy examples, common patterns emerge, such as noun-matching strategies (synonyms or identical noun tokens), noun-verb interactions, and connections involving separator tokens. The model’s strategy often resembles a ‘bag of token types’. This suggests that, despite their complexity, models are forced to compress vast amounts of information and, in doing so, may rely on relatively simplistic strategies. This observation, perhaps not immediately intuitive, is relevant for anyone embedding data and subsequently ranking items based on similarity.</p>
</section>
<section id="graph-neural-networks-for-structured-predictions-in-language" class="level3" data-number="7.5.4">
<h3 data-number="7.5.4" class="anchored" data-anchor-id="graph-neural-networks-for-structured-predictions-in-language"><span class="header-section-number">7.5.4</span> Graph Neural Networks for Structured Predictions in Language</h3>
<p>Graph Neural Networks (GNNs) offer another avenue for exploring structured information, yielding attributions in terms of ‘walks’ or feature interactions. Intriguingly, GNNs, which inherently encode structural information, can be framed as LLMs. This is because the attention mechanism within transformers essentially dictates how tokens can ‘message pass’ or influence one another. This conceptual link allows for the application of GNN-based interpretability methods to language.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_15.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Graph Neural Networks for Structured Predictions’. Shows input graph, interaction, and prediction stages.</figcaption>
</figure>
</div>
<p>For example, standard first-order explanations (akin to a Bag-of-Words approach) may fail to capture the complexity of language, such as negation. A sentence like “First, I didn’t like the boring pictures” might receive a high positive score simply due to the presence of “like,” overlooking the negation. In contrast, more sophisticated higher-order explanation methods can correctly identify that the initial negative phrase contributes negatively, whilst the subsequent positive part of a sentence (“but it is certainly one of the best movies I have ever seen”) is appropriately recognised, respecting the hierarchical structure of the language. This demonstrates how higher-order interactions can lead to a more accurate understanding of complex linguistic structures. Natural language’s hierarchical nature is well-suited to graph representations, and training a GNN (or an LLM framed as such) on tasks like movie review sentiment analysis allows for the extraction of these insightful walks <span class="citation" data-cites="Schnake2022">(<a href="#ref-Schnake2022" role="doc-biblioref"><strong>Schnake2022?</strong></a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_16.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Ex 3: Interaction of nodes learns complex language structure’. Setup: GNN/LLM on movie review sentiment. Example sentence with standard (BoW) vs.&nbsp;high-order interaction explanations. Citation: Schnake et al., Higher-Order Explanations of Graph Neural Networks via Relevant Walks. (TPAMI ’22).</figcaption>
</figure>
</div>
</section>
</section>
<section id="ai-driven-scientific-insights-in-the-humanities" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="ai-driven-scientific-insights-in-the-humanities"><span class="header-section-number">7.6</span> AI-driven Scientific Insights in the Humanities</h2>
<p>The application of AI, particularly explainable AI (XAI), extends into the humanities, offering novel methodologies for research and discovery. These techniques can help to analyse complex historical and cultural data at scale.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_17.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide with diagonal split: left dark blue, right beige with text ‘B. AI-based Scientific Insights in the Humanities’.</figcaption>
</figure>
</div>
<section id="extracting-visual-definitions-from-corpora" class="level3" data-number="7.6.1">
<h3 data-number="7.6.1" class="anchored" data-anchor-id="extracting-visual-definitions-from-corpora"><span class="header-section-number">7.6.1</span> Extracting Visual Definitions from Corpora</h3>
<p>Initial explorations using heatmap-based approaches have proven fruitful in projects involving historical artefacts. For instance, when working with a corpus of mathematical instruments, a classifier was developed to categorise items (e.g., as a ‘machine’ or a ‘mathematical instrument’). In collaboration with historians (Matteo Valleriani, Jochen Büttner, and others), these visual definitions generated by the AI were scrutinised to determine if they could provide more objective classification criteria. This process underscores the necessity of close collaboration with domain experts to ensure the meaningfulness of AI-derived definitions. One finding from this work was that fine-grained scales on mathematical instruments are highly relevant features for the model’s decision-making process <span class="citation" data-cites="ElHajjEberle2023">(<a href="#ref-ElHajjEberle2023" role="doc-biblioref"><strong>ElHajjEberle2023?</strong></a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_18.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Ex 4: Extracting visual definitions from corpora’. Left: Engraving of a machine and descriptions of historical instruments. Right: Class-specific heatmap explanations for ‘math. instrument’, ‘machine’, ‘scientific illustration’. Citation: El-Hajj &amp; Eberle+, Explainability and transparency in the realm of DH. (Int J Digit Humanities ’23).</figcaption>
</figure>
</div>
</section>
<section id="corpus-level-analysis-of-early-modern-astronomical-tables" class="level3" data-number="7.6.2">
<h3 data-number="7.6.2" class="anchored" data-anchor-id="corpus-level-analysis-of-early-modern-astronomical-tables"><span class="header-section-number">7.6.2</span> Corpus-Level Analysis of Early Modern Astronomical Tables</h3>
<p>A more extensive collaborative project focused on numerical tables from early modern texts, specifically the Sphaera corpus (1472-1650) <span class="citation" data-cites="Valleriani2019">(<a href="#ref-Valleriani2019" role="doc-biblioref"><strong>Valleriani2019?</strong></a>)</span>. Historians approached the Berlin Institute for Learning and Data (BIFOLD) with this data, seeking an automated method to match tables with similar semantics—a task previously unfeasible at scale.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_20.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Ex 5: Corpus-level analysis of early modern astronomical tables’. Images of various early modern astronomical tables. Corpora: Sphaera Corpus (Valleriani+’19), Sacrobosco Table Corpus (Eberle+’24).</figcaption>
</figure>
</div>
<section id="the-xai-historian-aiding-historical-research" class="level4" data-number="7.6.2.1">
<h4 data-number="7.6.2.1" class="anchored" data-anchor-id="the-xai-historian-aiding-historical-research"><span class="header-section-number">7.6.2.1</span> The XAI-Historian: Aiding Historical Research</h4>
<p>Together, a workflow was developed to assist historians in gaining insights from this large-scale data. This collaboration gave rise to the concept of the ‘XAI-Historian’—an historian equipped with AI and XAI tools to discover case studies and engage in more data-driven hypothesis generation. Instead of feeding entire tables into a large foundation model (which proved ineffective due to the out-of-domain nature of the data), a smaller, custom model was trained to detect numerical bigrams (pairs of adjacent numbers). XAI methods then verified that this model functioned as intended; for example, by confirming that identical bigrams (e.g., ‘38’ and ‘38’) in two different input tables were correctly identified and matched. This validation engendered trust in the model’s decisions, allowing its use for broader analysis <span class="citation" data-cites="Eberle2024SciAdv">(<a href="#ref-Eberle2024SciAdv" role="doc-biblioref"><strong>Eberle2024SciAdv?</strong></a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_21.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Ex 5: Historical insights at scale: xAI-Historian’. Setup: Historical tables, Sacrobosco Corpus. Diagram of workflow: data collections -&gt; atomization-recomposition (input table, bigram map, histograms) -&gt; corpus-level analysis (embedding, data similarity). Citation: Eberle et al., Historical insights at scale. (Sci Adv ’24).</figcaption>
</figure>
</div>
</section>
<section id="verifying-modelling-and-features-using-xai-and-historians" class="level4" data-number="7.6.2.2">
<h4 data-number="7.6.2.2" class="anchored" data-anchor-id="verifying-modelling-and-features-using-xai-and-historians"><span class="header-section-number">7.6.2.2</span> Verifying Modelling and Features using XAI and Historians</h4>
<p>Historical tables serve as carriers of scientific knowledge processes, such as the mathematisation of science. Representing these tables using a ‘bag of bigrams’ (e.g., ‘01’ or ‘21’) became a key strategy, especially given limited annotations. This involved a learned feature extractor combined with hard-coded structural information. The bigram model’s performance, when verified by expert ground truth, showed strong histogram correlations and superior cluster purity compared to unigram or standard VGG-16 approaches, confirming its efficacy <span class="citation" data-cites="Eberle2022TPAMI Eberle2024SciAdv">(<a href="#ref-Eberle2022TPAMI" role="doc-biblioref"><strong>Eberle2022TPAMI?</strong></a>; <a href="#ref-Eberle2024SciAdv" role="doc-biblioref"><strong>Eberle2024SciAdv?</strong></a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_22.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Verifying modeling and features using XAI and Historians’. Setup: tables as bag of bigrams. Results: scatter plot, bigram model matching, expert ground truth (histogram correlation table, cluster classification bar chart). Citations: Eberle et al.&nbsp;(TPAMI ’22), Eberle et al.&nbsp;(Sci Adv ’24).</figcaption>
</figure>
</div>
</section>
<section id="cluster-entropy-analysis-for-innovation-insights" class="level4" data-number="7.6.2.3">
<h4 data-number="7.6.2.3" class="anchored" data-anchor-id="cluster-entropy-analysis-for-innovation-insights"><span class="header-section-number">7.6.2.3</span> Cluster Entropy Analysis for Innovation Insights</h4>
<p>With a reliable model for table representation, case studies commenced. Cluster entropy was employed to investigate the spread of innovation across Europe during the early modern period. The publishing output of various cities was analysed; each city produced a ‘programme’ of printed works, some more diverse than others. Some locations focused on reprinting existing materials, whilst others fostered greater novelty. Quantifying this diversity at scale was previously challenging.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_23.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Cluster entropy analysis to investigate innovation’. Setup: cluster entropy. Results: clustering diagram (Lisbon, Venice, Wittenberg), map of Sphaera publication cities. Citation: Eberle et al.&nbsp;(Sci Adv ’24).</figcaption>
</figure>
</div>
<p>The approach involved using the model-derived representations to perform distance-based clustering of tables. The entropy of these clusters for each city then served as a measure of its print programme’s diversity. A low entropy score indicated repetitive content, whereas a higher entropy score signified a more varied output. This analysis identified Frankfurt and Wittenberg as cities with particularly low entropy. Frankfurt am Main was already known as a centre for reprinting editions. More strikingly, Wittenberg’s low diversity was linked to political control by Protestant reformers, who actively limited the print programme and dictated the curriculum to be published. This AI-driven finding corroborated existing historical intuition and uncovered a quantifiable aspect of this historical anomaly <span class="citation" data-cites="Eberle2024SciAdv">(<a href="#ref-Eberle2024SciAdv" role="doc-biblioref"><strong>Eberle2024SciAdv?</strong></a>)</span>.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_24.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Cluster entropy analysis to investigate innovation’. Setup: cluster entropy. Results: table clusters diagram, bar chart of H(p) - H(pmax) for cities, highlighting Frankfurt/Main and Wittenberg with explanations. Citation: Eberle et al.&nbsp;(Sci Adv ’24).</figcaption>
</figure>
</div>
</section>
</section>
</section>
<section id="conclusion-the-evolving-role-of-ai-based-methods-in-the-humanities" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="conclusion-the-evolving-role-of-ai-based-methods-in-the-humanities"><span class="header-section-number">7.7</span> Conclusion: The Evolving Role of AI-based Methods in the Humanities</h2>
<p>The integration of AI-based methods into humanities research presents both significant opportunities and distinct challenges.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_25.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide titled ‘Conclusion - AI-based methods for the Humanities’. Bullet points summarising challenges and opportunities.</figcaption>
</figure>
</div>
<p>Humanities and Digital Humanities (DH) researchers have historically focused extensively on the digitisation of source material. However, the automated analysis of these corpora is far from trivial, often complicated by data heterogeneity and a scarcity of labels. Multimodality further compounds these complexities.</p>
<p>Nevertheless, Machine Learning (ML) and Explainable AI (XAI) offer the potential to scale humanities research and foster novel research directions. Foundation Models, including LLMs, alongside prompting techniques, can assist with intermediate tasks such as labelling, data curation, and error correction. For more complex research questions, however, their utility currently remains limited.</p>
<p>A primary roadblock is the challenge posed by low-resource data, which impacts the scaling laws fundamental to many ML models. Furthermore, out-of-domain transfer, especially for historical and small-scale datasets, requires thorough evaluation. Current LLMs are predominantly trained and aligned for natural language tasks and code generation, and their applicability to specialised humanities data cannot be assumed without careful validation. Continued interdisciplinary collaboration will be crucial in navigating these challenges and harnessing the full potential of AI in enriching our understanding of the human past and its cultural artefacts.</p>
<hr>
<p><em>Note: A <code>bibliography.bib</code> file with the following (or similar) entries would be required for the citations to render correctly:</em> <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{Samek2017, title={Explainable artificial intelligence: Understanding, visualizing and interpreting deep learning models}, author={Samek, Wojciech and Wiegand, Thomas and M{"u}ller, Klaus-Robert}, journal={ITU Journal: ICT Discoveries}, volume={1}, number={1}, pages={39–57}, year={2017} } <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{Lapuschkin2019, author = {Lapuschkin, Sebastian and W{"a}ldchen, Stephan and Binder, Alexander and Montavon, Gr{'e}goire and Samek, Wojciech and M{"u}ller, Klaus-Robert}, title = {Unmasking Clever Hans predictors and assessing what machines really learn}, journal = {Nature Communications}, volume = {10}, number = {1}, pages = {1096}, year = {2019}, doi = {10.1038/s41467-019-08987-4} } <span class="citation" data-cites="misc">(<a href="#ref-misc" role="doc-biblioref"><strong>misc?</strong></a>)</span>{MondalWebb2024, author = {Mondal, ShB and Webb, N and others}, title = {Multi-step planning mistakes of LLMs}, year = {2024}, eprint = {arXiv:xxxx.xxxxx}, archiveprefix = {arXiv} } <span class="citation" data-cites="inproceedings">(<a href="#ref-inproceedings" role="doc-biblioref"><strong>inproceedings?</strong></a>)</span>{Jafari2024, title={MambaLRP: Long-Range Positive Explanations for Mamba Models}, author={Jafari, Ali and others}, booktitle={Advances in Neural Information Processing Systems (NeurIPS)}, year={2024} } <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{Schnake2022, author = {Schnake, Thomas and Eberle, Oliver and Sch{"u}tt, Kristof T. and M{"u}ller, Klaus-Robert and Samek, Wojciech}, title = {Higher-Order Explanations of Graph Neural Networks via Relevant Walks}, journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}, volume = {45}, number = {5}, pages = {5995–6007}, year = {2022}, doi = {10.1109/TPAMI.2022.3202015} } <span class="citation" data-cites="book">(<a href="#ref-book" role="doc-biblioref"><strong>book?</strong></a>)</span>{Valleriani2019, editor = {Valleriani, Matteo}, title = {The Sphaera Corpus: A Collection of Texts Written in the Context of the Medieval Study of the Sphere}, publisher = {Max Planck Institute for the History of Science}, year = {2019}, series = {Edition Open Access} } <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{ElHajjEberle2023, author = {El-Hajj, Hiba and Eberle, Oliver and others}, title = {Explainability and transparency in the realm of DH}, journal = {International Journal of Digital Humanities}, year = {2023}, doi = {10.1007/s42803-023-00069-0} } <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{Eberle2024Sacrobosco, author = {Eberle, Oliver and others}, title = {The Sacrobosco Table Corpus (1472-1650)}, year = {2024}, note = {Details to be confirmed} } <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{Eberle2024SciAdv, author = {Eberle, Oliver and Valleriani, Matteo and B{"u}ttner, Jochen and others}, title = {Historical insights at scale: Automated analysis of early modern astronomical tables with explainable AI}, journal = {Science Advances}, year = {2024}, doi = {10.1126/sciadv.adk1000} } <span class="citation" data-cites="article">(<a href="#ref-article" role="doc-biblioref"><strong>article?</strong></a>)</span>{Eberle2022TPAMI, author = {Eberle, Oliver and others}, title = {Learning Semantic Similarity for Numerical Tables}, journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)}, year = {2022}, doi = {10.1109/TPAMI.2022.xxxxxxx} }</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ai-nepi_006_chapter.html" class="pagination-link" aria-label="Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./ai-nepi_008_chapter.html" class="pagination-link" aria-label="Modeling Science: LLM for the History, Philosophy and Sociology of Science">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>