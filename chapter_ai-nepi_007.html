<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oliver Eberle">
<meta name="dcterms.date" content="2025-01-01">

<title>7&nbsp; Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities. – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_008.html" rel="next">
<link href="./chapter_ai-nepi_006.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_007.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals, ActDisease Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG in HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#presentation-structure-and-research-focus" id="toc-presentation-structure-and-research-focus" class="nav-link" data-scroll-target="#presentation-structure-and-research-focus"><span class="header-section-number">7.1</span> Presentation Structure and Research Focus</a></li>
  <li><a href="#introduction-to-explainable-ai-xai-1.0" id="toc-introduction-to-explainable-ai-xai-1.0" class="nav-link" data-scroll-target="#introduction-to-explainable-ai-xai-1.0"><span class="header-section-number">7.2</span> Introduction to Explainable AI (XAI) 1.0</a></li>
  <li><a href="#post-hoc-explainability-and-its-rationale" id="toc-post-hoc-explainability-and-its-rationale" class="nav-link" data-scroll-target="#post-hoc-explainability-and-its-rationale"><span class="header-section-number">7.3</span> Post-Hoc Explainability and its Rationale</a></li>
  <li><a href="#transition-to-generative-ai-and-foundation-models" id="toc-transition-to-generative-ai-and-foundation-models" class="nav-link" data-scroll-target="#transition-to-generative-ai-and-foundation-models"><span class="header-section-number">7.4</span> Transition to Generative AI and Foundation Models</a></li>
  <li><a href="#illustrative-model-mistakes-and-limitations" id="toc-illustrative-model-mistakes-and-limitations" class="nav-link" data-scroll-target="#illustrative-model-mistakes-and-limitations"><span class="header-section-number">7.5</span> Illustrative Model Mistakes and Limitations</a></li>
  <li><a href="#xai-2.0-structured-interpretability-and-first-order-attributions" id="toc-xai-2.0-structured-interpretability-and-first-order-attributions" class="nav-link" data-scroll-target="#xai-2.0-structured-interpretability-and-first-order-attributions"><span class="header-section-number">7.6</span> XAI 2.0: Structured Interpretability and First-Order Attributions</a></li>
  <li><a href="#second-order-explanations-pairwise-relationships-and-similarity" id="toc-second-order-explanations-pairwise-relationships-and-similarity" class="nav-link" data-scroll-target="#second-order-explanations-pairwise-relationships-and-similarity"><span class="header-section-number">7.7</span> Second-Order Explanations: Pairwise Relationships and Similarity</a></li>
  <li><a href="#higher-order-explanations-graph-structures-and-contextual-bias" id="toc-higher-order-explanations-graph-structures-and-contextual-bias" class="nav-link" data-scroll-target="#higher-order-explanations-graph-structures-and-contextual-bias"><span class="header-section-number">7.8</span> Higher-Order Explanations: Graph Structures and Contextual Bias</a></li>
  <li><a href="#first-order-attributions-in-llms-biased-sentiment-predictions" id="toc-first-order-attributions-in-llms-biased-sentiment-predictions" class="nav-link" data-scroll-target="#first-order-attributions-in-llms-biased-sentiment-predictions"><span class="header-section-number">7.9</span> First-Order Attributions in LLMs: Biased Sentiment Predictions</a></li>
  <li><a href="#first-order-attributions-for-long-range-dependencies-in-llms" id="toc-first-order-attributions-for-long-range-dependencies-in-llms" class="nav-link" data-scroll-target="#first-order-attributions-for-long-range-dependencies-in-llms"><span class="header-section-number">7.10</span> First-Order Attributions for Long-Range Dependencies in LLMs</a></li>
  <li><a href="#explaining-sentence-similarities-and-embeddings" id="toc-explaining-sentence-similarities-and-embeddings" class="nav-link" data-scroll-target="#explaining-sentence-similarities-and-embeddings"><span class="header-section-number">7.11</span> Explaining Sentence Similarities and Embeddings</a></li>
  <li><a href="#graph-neural-networks-for-structured-predictions-and-language-understanding" id="toc-graph-neural-networks-for-structured-predictions-and-language-understanding" class="nav-link" data-scroll-target="#graph-neural-networks-for-structured-predictions-and-language-understanding"><span class="header-section-number">7.12</span> Graph Neural Networks for Structured Predictions and Language Understanding</a></li>
  <li><a href="#extracting-visual-definitions-from-historical-corpora" id="toc-extracting-visual-definitions-from-historical-corpora" class="nav-link" data-scroll-target="#extracting-visual-definitions-from-historical-corpora"><span class="header-section-number">7.13</span> Extracting Visual Definitions from Historical Corpora</a></li>
  <li><a href="#corpus-level-analysis-of-early-modern-astronomical-tables-xai-historian" id="toc-corpus-level-analysis-of-early-modern-astronomical-tables-xai-historian" class="nav-link" data-scroll-target="#corpus-level-analysis-of-early-modern-astronomical-tables-xai-historian"><span class="header-section-number">7.14</span> Corpus-Level Analysis of Early Modern Astronomical Tables (xAI-Historian)</a></li>
  <li><a href="#verifying-modelling-and-features-using-xai-and-historians" id="toc-verifying-modelling-and-features-using-xai-and-historians" class="nav-link" data-scroll-target="#verifying-modelling-and-features-using-xai-and-historians"><span class="header-section-number">7.15</span> Verifying Modelling and Features using XAI and Historians</a></li>
  <li><a href="#cluster-entropy-analysis-to-investigate-innovation-in-print-programmes" id="toc-cluster-entropy-analysis-to-investigate-innovation-in-print-programmes" class="nav-link" data-scroll-target="#cluster-entropy-analysis-to-investigate-innovation-in-print-programmes"><span class="header-section-number">7.16</span> Cluster Entropy Analysis to Investigate Innovation in Print Programmes</a></li>
  <li><a href="#conclusion-ai-based-methods-for-the-humanities" id="toc-conclusion-ai-based-methods-for-the-humanities" class="nav-link" data-scroll-target="#conclusion-ai-based-methods-for-the-humanities"><span class="header-section-number">7.17</span> Conclusion: AI-based Methods for the Humanities</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Oliver Eberle <a href="mailto:oliver.eberle@tu-berlin.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            BIFOLD / TU Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter explores the interpretability of Large Language Models (<em>LLMs</em>) and their application within the humanities, emphasising transparency and scientific insight. The discussion unfolds in two principal areas: first, the development of methods for understanding complex <em>AI</em> models, particularly explainable <em>AI</em> (<em>XAI</em>); second, the utilisation of <em>AI</em> to generate scientific insights within the humanities. The team has progressed from early <em>XAI</em> 1.0 techniques, such as feature attributions and heatmaps, to more sophisticated <em>XAI</em> 2.0 approaches, which encompass structured interpretability, feature interactions, and mechanistic perspectives. These advanced methods address the challenges posed by generative <em>AI</em> models, which function as multi-task and world models.</p>
<p>Eberle and his colleagues highlight critical issues such as model biases, long-range dependency limitations in summarisation tasks, and the simplistic strategies models often employ for tasks like sentence similarity. To overcome these, the team has developed novel techniques, including second-order explanations for token interactions and higher-order explanations for graph structures, which reveal complex language hierarchies.</p>
<p>Within the humanities, the project demonstrates <em>AI</em>’s capacity to extract visual definitions from historical corpora, exemplified by the classification of mathematical instruments. A significant initiative, the <em>xAI-Historian</em> project, focuses on corpus-level analysis of early modern astronomical tables, specifically the <em>Sacrobosco Corpus</em> (1472-1650), comprising 76,000 pages of university textbooks. This endeavour addresses the heterogeneity and limited annotations characteristic of historical data, where conventional <em>OCR</em> and foundation models often fail. The team developed a statistical model capable of detecting bigram representations within these tables, enabling the automated matching of similar semantics at scale. This methodology facilitates data-driven hypothesis generation and the discovery of historical anomalies, such as the politically controlled print programme in Wittenberg. The project ultimately aims to scale humanities research and foster novel research directions by integrating machine learning and explainable <em>AI</em>, whilst acknowledging the persistent challenges of low-resource and out-of-domain data.</p>
</section>
<section id="presentation-structure-and-research-focus" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="presentation-structure-and-research-focus"><span class="header-section-number">7.1</span> Presentation Structure and Research Focus</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Oliver Eberle, a Senior Researcher at the Berlin Institute for Learning and Data (BIFOLD) at TU Berlin, presented this work. Eberle’s background in machine learning has naturally led him into the digital humanities through collaborations with historians. This chapter systematically divides into two principal parts. The initial section explores explainable <em>AI</em> (<em>XAI</em>) and the development of methods and approaches to comprehend the internal workings of highly complex models, particularly Large Language Models. The subsequent part then demonstrates how researchers leverage <em>AI</em> to derive scientific insights, specifically within humanities applications. The overarching themes encompass the interpretability of <em>LLMs</em>, fostering transparency, exploring practical applications, and generating scientific insights.</p>
</section>
<section id="introduction-to-explainable-ai-xai-1.0" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="introduction-to-explainable-ai-xai-1.0"><span class="header-section-number">7.2</span> Introduction to Explainable AI (XAI) 1.0</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Explainable <em>AI</em> (<em>XAI</em>) 1.0 primarily focuses on feature attributions. Historically, machine learning research has predominantly centred on visual data, particularly images. However, a significant shift has occurred over the past decade, with the field demonstrating a burgeoning interest in language data. A core challenge in machine learning involves comprehending the operations of “black box” models. In typical classification scenarios, such as image classification, users receive a prediction yet possess no insight into the underlying basis for that classification. This opacity necessitates methods to elucidate model decisions.</p>
</section>
<section id="post-hoc-explainability-and-its-rationale" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="post-hoc-explainability-and-its-rationale"><span class="header-section-number">7.3</span> Post-Hoc Explainability and its Rationale</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>For approximately a decade, the field of explainable <em>AI</em> has dedicated its research to tracing the origins of model predictions. A common explanatory method involves generating heatmaps, which delineate the specific pixels responsible for an image classification. For instance, a heatmap might highlight the rooster’s head, indicating its significance in the model’s recognition of a rooster.</p>
<p>Beyond specific examples, the broader rationale for explainability encompasses several critical objectives. Firstly, it enables the verification of predictions, ensuring that models operate reasonably. Secondly, it facilitates the identification of flaws and biases, allowing researchers to correct errors and comprehend how models make mistakes. Thirdly, explainability offers insights into the underlying problem, as models frequently uncover surprising solutions. Finally, and increasingly importantly, it ensures compliance with evolving legislation, such as the European <em>AI</em> Act. This post-hoc explainability represented the standard <em>XAI</em> scenario until approximately five years ago, as Samek and colleagues (2017) documented.</p>
</section>
<section id="transition-to-generative-ai-and-foundation-models" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="transition-to-generative-ai-and-foundation-models"><span class="header-section-number">7.4</span> Transition to Generative AI and Foundation Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The current era is defined by generative <em>AI</em>, where models exhibit extensive multi-task capabilities. These systems can perform classification, identify similar images, generate novel images, and answer diverse questions across various topics. This expanded functionality necessitates a move beyond conventional heatmap representations towards more sophisticated interpretability methods. Eberle and his colleagues now consider feature interactions and adopt more mechanistic perspectives to understand these complex models. Today’s foundation models function not merely as multi-task systems but also as “world models,” offering profound insights into societal structures, the evolution of text over time, and specific features inherent in textual data.</p>
</section>
<section id="illustrative-model-mistakes-and-limitations" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="illustrative-model-mistakes-and-limitations"><span class="header-section-number">7.5</span> Illustrative Model Mistakes and Limitations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Models frequently exhibit surprising and significant errors. One well-known example in object detection involves a standard classifier predicting a “boat” based on the surrounding water, rather than the vessel itself. The model identifies water as a correlated feature with an easily detectable texture, leading to this misattribution, as Lapuschkin and colleagues (2019) documented in <em>Nature Communications</em>.</p>
<p>A more recent illustration of multi-step planning mistakes in Large Language Models (<em>LLMs</em>) emerges from the Tower of Hanoi puzzle. When tasked with moving disks from a left peg to a right peg, the <em>LLM</em> immediately errs by attempting to move the largest, inaccessible disk directly to the final peg. This demonstrates a fundamental failure to comprehend the physical constraints inherent in the problem, a finding Mondal and Webb (2024) highlighted.</p>
</section>
<section id="xai-2.0-structured-interpretability-and-first-order-attributions" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="xai-2.0-structured-interpretability-and-first-order-attributions"><span class="header-section-number">7.6</span> XAI 2.0: Structured Interpretability and First-Order Attributions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The evolution of explainable <em>AI</em> has led to <em>XAI</em> 2.0, which prioritises structured interpretability and seeks to move beyond the limitations of simple heatmap visualisations. First-order explanations, which attribute predictions to individual features, prove particularly useful for elucidating classifier decisions. For instance, in a project involving historical data, Eberle and his team trained a classifier to distinguish subgroups within historical tables, such as numerical tables. To verify the model’s efficacy, they employed heatmaps, which confirmed that the classifier accurately focused on the numerical content, thereby correctly identifying numerical tables. This demonstrated the model’s reliance on meaningful features for its predictions.</p>
</section>
<section id="second-order-explanations-pairwise-relationships-and-similarity" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="second-order-explanations-pairwise-relationships-and-similarity"><span class="header-section-number">7.7</span> Second-Order Explanations: Pairwise Relationships and Similarity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Beyond individual feature attributions, the authors have explored second-order features, specifically focusing on pairwise relationships. This approach proves crucial for explaining similarity scores derived from embeddings. When computing a dot product to ascertain the similarity between two inputs, such as images or textual segments, interaction scores between their constituent features provide the explanation. For example, by analysing interactions between digits in historical tables, the team could verify that their model correctly identified identical tables, confirming its intended operation.</p>
</section>
<section id="higher-order-explanations-graph-structures-and-contextual-bias" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="higher-order-explanations-graph-structures-and-contextual-bias"><span class="header-section-number">7.8</span> Higher-Order Explanations: Graph Structures and Contextual Bias</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>In more recent work, Eberle and his colleagues have investigated higher-order interactions within graph structures, finding them particularly meaningful for interpretability. This approach applies to various networks, such as citation graphs or networks of books and entities, especially when models are trained on classification tasks. A significant observation emerged: models predominantly focus on the later parts of the context, prioritising information presented more recently in the input. Conversely, they are considerably less likely to extract information from the very beginning of the context, a trend evident on a log scale of counts. This finding carries crucial implications for <em>LLM</em> summarisation; models are unlikely to produce balanced summaries of entire texts, instead tending to concentrate on data presented closer to the user’s prompt.</p>
</section>
<section id="first-order-attributions-in-llms-biased-sentiment-predictions" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="first-order-attributions-in-llms-biased-sentiment-predictions"><span class="header-section-number">7.9</span> First-Order Attributions in LLMs: Biased Sentiment Predictions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>Ali and colleagues have applied first-order attributions to Large Language Models (<em>LLMs</em>) to understand feature importance, particularly in the context of biased sentiment predictions. This involves analysing which names exert the most or least influence in shifting a review’s sentiment towards either a positive or negative classification. Examples illustrate this phenomenon: phrases such as “malcolm d.&nbsp;lee,” “the sally jesse raphael atmosphere,” “some sort of martha stewart decorating program run am ok,” and “of cuban leader fidel castro” demonstrate negative relevance. Conversely, “dave barry’s,” “the coe n brothers,” and “a jackie chan movie” exhibit positive relevance. Ali and colleagues (2022) published this investigation into biased sentiment predictions in <em>Transformer LLMs</em> at <em>ICML</em>.</p>
</section>
<section id="first-order-attributions-for-long-range-dependencies-in-llms" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="first-order-attributions-for-long-range-dependencies-in-llms"><span class="header-section-number">7.10</span> First-Order Attributions for Long-Range Dependencies in LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>Jafari and colleagues investigated first-order attributions to understand long-range dependencies within Large Language Models (<em>LLMs</em>), specifically when generating text summaries from extensive inputs, up to an 8,000-token context window. The central question concerned the extent of token dependencies. Their analysis revealed that models predominantly focus on the later sections of the context, prioritising information presented more recently. Conversely, they are significantly less likely to extract information from the very beginning of the context, a pattern evident on a log scale of counts. This finding implies that <em>LLMs</em> may not produce balanced summaries; instead, they tend to concentrate on data positioned closer to the user’s prompt. Jafari and colleagues (2024) published this work in <em>MambaLRP</em> at <em>NeurIPS</em>.</p>
</section>
<section id="explaining-sentence-similarities-and-embeddings" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="explaining-sentence-similarities-and-embeddings"><span class="header-section-number">7.11</span> Explaining Sentence Similarities and Embeddings</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>A significant challenge involves elucidating the rationale behind specific sentence similarity scores. Eberle and his team address this through unsupervised analysis of representations extracted from a pretrained foundation model, employing dot-products. This process begins with a forward prediction or encoder, where a pair of sentences, such as “A cat I really like.” and “It is a great cat!”, undergo processing through multiple layers to yield embeddings, culminating in a similarity score (e.g., 0.92).</p>
<p>To explain this score, their method progresses to token interactions. Second-order explanations generate interaction scores between individual tokens, revealing the specific elements contributing to high similarity. In toy examples, their findings consistently indicate reliance on noun matching strategies, including synonyms and identical noun tokens, alongside some noun-verb interactions and separator/other token interactions. This suggests that models, compelled to compress vast amounts of information, often resort to surprisingly simplistic strategies.</p>
<p>Further analysis extends to corpus-level interaction patterns, visualised through a triangular matrix that illustrates the interaction strength between various part-of-speech tags. Ultimately, this research highlights that the features models utilise to assign high similarity scores can be remarkably simple. Eberle and colleagues (2022) published this work in <em>TPAMI</em>, with further contributions by Vasileiou and Eberle (2024) at <em>NAACL</em>.</p>
</section>
<section id="graph-neural-networks-for-structured-predictions-and-language-understanding" class="level2" data-number="7.12">
<h2 data-number="7.12" class="anchored" data-anchor-id="graph-neural-networks-for-structured-predictions-and-language-understanding"><span class="header-section-number">7.12</span> Graph Neural Networks for Structured Predictions and Language Understanding</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Schnake and colleagues have explored Graph Neural Networks (<em>GNNs</em>) for structured predictions, where attributions manifest as “walks” that represent feature interactions. A crucial insight reveals that <em>GNNs</em>, which inherently encode structural information, can be conceptualised as Large Language Models (<em>LLMs</em>), given that attention networks in <em>LLMs</em> essentially facilitate token message passing akin to graph structures.</p>
<p>Applying this framework to language understanding, the team identified a limitation with first-order attributions: they often fail to capture the intricate complexity of natural language, particularly negations. For instance, in the sentence “First I didn’t like the boring pictures…”, a first-order attribution might incorrectly assign a high score to “boring pictures” due to the presence of “boring.” However, by employing higher-order interaction methods, their system accurately reflects the hierarchical structure of natural language. In the same example, the entire negative first sentence receives a negative score, whilst the subsequent positive part of the sentence is correctly weighted, demonstrating a more nuanced understanding. Schnake and colleagues (2022) published this work on higher-order explanations for <em>GNNs</em> in <em>TPAMI</em>.</p>
</section>
<section id="extracting-visual-definitions-from-historical-corpora" class="level2" data-number="7.13">
<h2 data-number="7.13" class="anchored" data-anchor-id="extracting-visual-definitions-from-historical-corpora"><span class="header-section-number">7.13</span> Extracting Visual Definitions from Historical Corpora</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>In their initial foray into the humanities, El-Hajj and Eberle, amongst others, applied heatmap-based approaches to extract visual definitions from historical corpora. They focused on a corpus of mathematical instruments, comprising historical illustrations, with the objective of classifying these instruments into categories such as “machine” or “mathematical instrument.” This endeavour involved close collaboration with historians, including Matteo Valleriani and Jochen Büttner, to develop objective criteria for these visual definitions. Through rigorous verification with domain experts, the team ensured the meaningfulness of the definitions. A key finding revealed that the fine-grained scales present on mathematical instruments were highly relevant features for the model’s classification decisions. El-Hajj and Eberle, amongst others, published this research on explainability and transparency in digital humanities in the <em>International Journal of Digital Humanities</em> (2023).</p>
</section>
<section id="corpus-level-analysis-of-early-modern-astronomical-tables-xai-historian" class="level2" data-number="7.14">
<h2 data-number="7.14" class="anchored" data-anchor-id="corpus-level-analysis-of-early-modern-astronomical-tables-xai-historian"><span class="header-section-number">7.14</span> Corpus-Level Analysis of Early Modern Astronomical Tables (xAI-Historian)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The largest collaborative project undertaken involved a corpus-level analysis of early modern astronomical tables. This initiative focused on numerical tables from the <em>Sphera Corpus</em>, a collection of early modern texts spanning from 1472 to 1650. Specifically, the <em>Sacrobosco Table Corpus</em>, comprising 76,000 pages of university textbooks from the same period, formed the core dataset. Historians approached the team seeking an automated method for matching tables with similar semantics, a task previously unfeasible at scale.</p>
<p>The machine learning challenge proved substantial due to the data’s extreme heterogeneity, the scarcity of annotations, and the inadequacy of conventional <em>OCR</em> and foundation models. In response, Eberle and his colleagues developed a bespoke workflow designed to empower historians with insights at scale. This led to the concept of the <em>xAI-Historian</em>, an academic who leverages <em>AI</em> and explainable <em>AI</em> to facilitate data-driven hypothesis generation and the discovery of specific case studies. This significant work draws upon the <em>Sphera Corpus</em> (Valleriani and colleagues, 2019) and the <em>Sacrobosco Table Corpus</em> (Eberle and colleagues, 2024).</p>
</section>
<section id="verifying-modelling-and-features-using-xai-and-historians" class="level2" data-number="7.15">
<h2 data-number="7.15" class="anchored" data-anchor-id="verifying-modelling-and-features-using-xai-and-historians"><span class="header-section-number">7.15</span> Verifying Modelling and Features using XAI and Historians</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>This project fundamentally considers historical tables as crucial carriers of scientific knowledge processes, particularly mathematisation. Rather than attempting to process entire tables with generic foundation models—which prove ineffective for this out-of-domain data—Eberle and his team crafted a specialised statistical model. This bespoke model detects bigram representations, such as ‘01’ or ‘21’, within the tables. Given the limited annotations available, their approach combines a learned feature extractor with a hard-coded structure.</p>
<p>Verification of the model’s efficacy involves confirming that it consistently detects identical bigrams across different inputs, for example, identifying ‘38’ on two distinct tables. This rigorous validation ensures the model operates as intended and its decisions can be trusted. The overall workflow encompasses three key steps:</p>
<ul>
<li><p>data collection from images of old books;</p></li>
<li><p>an atomisation-recomposition phase involving input tables, bigram maps, and histograms;</p></li>
<li><p>a corpus-level analysis that generates historical table embeddings and assesses data similarity.</p></li>
</ul>
<p>Eberle and colleagues (2022) detailed this methodology in <em>TPAMI</em>, with further insights in <em>Science Advances</em> (Eberle and colleagues, 2024).</p>
</section>
<section id="cluster-entropy-analysis-to-investigate-innovation-in-print-programmes" class="level2" data-number="7.16">
<h2 data-number="7.16" class="anchored" data-anchor-id="cluster-entropy-analysis-to-investigate-innovation-in-print-programmes"><span class="header-section-number">7.16</span> Cluster Entropy Analysis to Investigate Innovation in Print Programmes</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>Eberle and his team employed cluster entropy analysis, specifically measuring the difference between observed cluster entropy H(p) and maximum attainable entropy H(p_max), to investigate the diffusion of innovation across Europe. This method analysed the print output of various cities, each serving as a publishing location. The process involved utilising representations derived from the bigram model, followed by distance-based clustering to ascertain the number of distinct content clusters each city produced. Entropy then quantified the diversity of these print programmes: a low entropy score indicated a consistent reproduction of the same content, whilst a higher score signified a more diverse programme.</p>
<p>This analysis yielded two compelling case studies. Frankfurt/Main exhibited one of the lowest entropy scores, confirming its historical reputation as a major centre for reprinting editions. More notably, Wittenberg also registered a very low score, revealing a historical anomaly. Here, the political control exerted by Protestant reformers, particularly Melanchthon, actively restricted the curriculum and, consequently, the print programme. This finding not only detected a previously unquantified historical anomaly but also corroborated existing historical intuition and supporting evidence. This work is documented in <em>Sphera</em> publication EPISD-626 and by Eberle and colleagues (2024) in <em>Science Advances</em>.</p>
</section>
<section id="conclusion-ai-based-methods-for-the-humanities" class="level2" data-number="7.17">
<h2 data-number="7.17" class="anchored" data-anchor-id="conclusion-ai-based-methods-for-the-humanities"><span class="header-section-number">7.17</span> Conclusion: AI-based Methods for the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>In conclusion, whilst humanities and digital humanities scholars have largely concentrated on the digitisation of source material, the automated analysis of these corpora presents significant challenges due to their inherent heterogeneity and scarcity of labels. Nevertheless, the integration of machine learning (<em>ML</em>) and explainable <em>AI</em> (<em>XAI</em>) offers substantial potential to scale humanities research and foster novel research directions.</p>
<p>Foundation Models and Large Language Models (<em>LLMs</em>) can effectively assist with intermediate tasks such as labelling, data curation, and error correction. However, their utility remains limited when addressing more complex research questions. Significant roadblocks persist, including the challenges posed by low-resource data for machine learning, particularly concerning scaling laws. Furthermore, out-of-domain transfer, especially for historical and small-scale datasets, demands rigorous evaluation, as current <em>LLMs</em> are primarily trained and aligned for natural language processing and code generation, not historical data.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_008.html" class="pagination-link" aria-label="Modeling Science">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>