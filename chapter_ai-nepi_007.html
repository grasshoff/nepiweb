<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oliver Eberle">
<meta name="dcterms.date" content="2025-06-21">

<title>7&nbsp; Explainable AI and AI-based Scientific Insights in the Humanities â€“ AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_008.html" rel="next">
<link href="./chapter_ai-nepi_006.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_007.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#a-dual-focus-explainable-ai-and-ai-in-the-humanities" id="toc-a-dual-focus-explainable-ai-and-ai-in-the-humanities" class="nav-link" data-scroll-target="#a-dual-focus-explainable-ai-and-ai-in-the-humanities"><span class="header-section-number">7.1</span> A Dual Focus: Explainable AI and AI in the Humanities</a></li>
  <li><a href="#introducing-explainable-ai-the-first-wave" id="toc-introducing-explainable-ai-the-first-wave" class="nav-link" data-scroll-target="#introducing-explainable-ai-the-first-wave"><span class="header-section-number">7.2</span> Introducing Explainable AI: The First Wave</a></li>
  <li><a href="#the-black-box-problem-and-the-need-for-explainability" id="toc-the-black-box-problem-and-the-need-for-explainability" class="nav-link" data-scroll-target="#the-black-box-problem-and-the-need-for-explainability"><span class="header-section-number">7.3</span> The Black Box Problem and the Need for Explainability</a></li>
  <li><a href="#post-hoc-explainability-and-its-motivations" id="toc-post-hoc-explainability-and-its-motivations" class="nav-link" data-scroll-target="#post-hoc-explainability-and-its-motivations"><span class="header-section-number">7.4</span> Post-Hoc Explainability and Its Motivations</a></li>
  <li><a href="#generative-ai-and-new-interpretability-challenges" id="toc-generative-ai-and-new-interpretability-challenges" class="nav-link" data-scroll-target="#generative-ai-and-new-interpretability-challenges"><span class="header-section-number">7.5</span> Generative AI and New Interpretability Challenges</a></li>
  <li><a href="#illustrative-model-failures" id="toc-illustrative-model-failures" class="nav-link" data-scroll-target="#illustrative-model-failures"><span class="header-section-number">7.6</span> Illustrative Model Failures</a></li>
  <li><a href="#xai-2.0-towards-structured-interpretability" id="toc-xai-2.0-towards-structured-interpretability" class="nav-link" data-scroll-target="#xai-2.0-towards-structured-interpretability"><span class="header-section-number">7.7</span> XAI 2.0: Towards Structured Interpretability</a></li>
  <li><a href="#first-order-explanations-for-verification" id="toc-first-order-explanations-for-verification" class="nav-link" data-scroll-target="#first-order-explanations-for-verification"><span class="header-section-number">7.8</span> First-Order Explanations for Verification</a></li>
  <li><a href="#features-and-pairwise-interactions" id="toc-features-and-pairwise-interactions" class="nav-link" data-scroll-target="#features-and-pairwise-interactions"><span class="header-section-number">7.9</span> Features and Pairwise Interactions</a></li>
  <li><a href="#higher-order-interactions-and-circuit-level-understanding" id="toc-higher-order-interactions-and-circuit-level-understanding" class="nav-link" data-scroll-target="#higher-order-interactions-and-circuit-level-understanding"><span class="header-section-number">7.10</span> Higher-Order Interactions and Circuit-Level Understanding</a></li>
  <li><a href="#first-order-attributions-in-large-language-models" id="toc-first-order-attributions-in-large-language-models" class="nav-link" data-scroll-target="#first-order-attributions-in-large-language-models"><span class="header-section-number">7.11</span> First-Order Attributions in Large Language Models</a></li>
  <li><a href="#biased-sentiment-predictions-in-transformer-models" id="toc-biased-sentiment-predictions-in-transformer-models" class="nav-link" data-scroll-target="#biased-sentiment-predictions-in-transformer-models"><span class="header-section-number">7.12</span> Biased Sentiment Predictions in Transformer Models</a></li>
  <li><a href="#long-range-dependencies-in-llms" id="toc-long-range-dependencies-in-llms" class="nav-link" data-scroll-target="#long-range-dependencies-in-llms"><span class="header-section-number">7.13</span> Long-Range Dependencies in LLMs</a></li>
  <li><a href="#limitations-in-long-range-summarisation" id="toc-limitations-in-long-range-summarisation" class="nav-link" data-scroll-target="#limitations-in-long-range-summarisation"><span class="header-section-number">7.14</span> Limitations in Long-Range Summarisation</a></li>
  <li><a href="#higher-order-interactions-in-text" id="toc-higher-order-interactions-in-text" class="nav-link" data-scroll-target="#higher-order-interactions-in-text"><span class="header-section-number">7.15</span> Higher-Order Interactions in Text</a></li>
  <li><a href="#explaining-sentence-similarity-with-bilrp" id="toc-explaining-sentence-similarity-with-bilrp" class="nav-link" data-scroll-target="#explaining-sentence-similarity-with-bilrp"><span class="header-section-number">7.16</span> Explaining Sentence Similarity with <em>BiLRP</em></a></li>
  <li><a href="#graph-neural-networks-for-structured-data" id="toc-graph-neural-networks-for-structured-data" class="nav-link" data-scroll-target="#graph-neural-networks-for-structured-data"><span class="header-section-number">7.17</span> Graph Neural Networks for Structured Data</a></li>
  <li><a href="#explaining-predictions-with-walks" id="toc-explaining-predictions-with-walks" class="nav-link" data-scroll-target="#explaining-predictions-with-walks"><span class="header-section-number">7.18</span> Explaining Predictions with Walks</a></li>
  <li><a href="#limitations-of-standard-explanations" id="toc-limitations-of-standard-explanations" class="nav-link" data-scroll-target="#limitations-of-standard-explanations"><span class="header-section-number">7.19</span> Limitations of Standard Explanations</a></li>
  <li><a href="#higher-order-explanations-for-nuanced-sentiment" id="toc-higher-order-explanations-for-nuanced-sentiment" class="nav-link" data-scroll-target="#higher-order-explanations-for-nuanced-sentiment"><span class="header-section-number">7.20</span> Higher-Order Explanations for Nuanced Sentiment</a></li>
  <li><a href="#ai-for-scientific-insight-in-the-humanities" id="toc-ai-for-scientific-insight-in-the-humanities" class="nav-link" data-scroll-target="#ai-for-scientific-insight-in-the-humanities"><span class="header-section-number">7.21</span> AI for Scientific Insight in the Humanities</a></li>
  <li><a href="#extracting-visual-definitions-from-corpora" id="toc-extracting-visual-definitions-from-corpora" class="nav-link" data-scroll-target="#extracting-visual-definitions-from-corpora"><span class="header-section-number">7.22</span> Extracting Visual Definitions from Corpora</a></li>
  <li><a href="#analysing-early-modern-astronomical-tables" id="toc-analysing-early-modern-astronomical-tables" class="nav-link" data-scroll-target="#analysing-early-modern-astronomical-tables"><span class="header-section-number">7.23</span> Analysing Early Modern Astronomical Tables</a></li>
  <li><a href="#xai-historian-a-workflow-for-scalable-insight" id="toc-xai-historian-a-workflow-for-scalable-insight" class="nav-link" data-scroll-target="#xai-historian-a-workflow-for-scalable-insight"><span class="header-section-number">7.24</span> <em>xAI-Historian</em>: A Workflow for Scalable Insight</a></li>
  <li><a href="#verifying-features-with-xai-and-historians" id="toc-verifying-features-with-xai-and-historians" class="nav-link" data-scroll-target="#verifying-features-with-xai-and-historians"><span class="header-section-number">7.25</span> Verifying Features with XAI and Historians</a></li>
  <li><a href="#analysing-innovation-spread-with-cluster-entropy" id="toc-analysing-innovation-spread-with-cluster-entropy" class="nav-link" data-scroll-target="#analysing-innovation-spread-with-cluster-entropy"><span class="header-section-number">7.26</span> Analysing Innovation Spread with Cluster Entropy</a></li>
  <li><a href="#entropy-and-historical-publishing-programmes" id="toc-entropy-and-historical-publishing-programmes" class="nav-link" data-scroll-target="#entropy-and-historical-publishing-programmes"><span class="header-section-number">7.27</span> Entropy and Historical Publishing Programmes</a></li>
  <li><a href="#conclusion-ai-methods-in-the-humanities" id="toc-conclusion-ai-methods-in-the-humanities" class="nav-link" data-scroll-target="#conclusion-ai-methods-in-the-humanities"><span class="header-section-number">7.28</span> Conclusion: AI Methods in the Humanities</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Oliver Eberle <a href="mailto:oliver.eberle@tu-berlin.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            BIFOLD / TU Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Dr Oliver Eberle, a postdoctoral senior researcher at the Berlin Institute for Learning and Data, offers a comprehensive overview of his work at the intersection of machine learning and the digital humanities. Drawing from his deep background in machine learning, he has forged a path into the humanities through vital collaborations with historians. His research centres on the interpretability of Large Language Models (LLMs) and the broader field of Explainable Artificial Intelligence (XAI).</p>
<p>The presentation systematically addresses two principal areas. Firstly, it establishes a foundational understanding of AI, particularly LLMs, and explores the imperative for their transparency and comprehensibility. Secondly, it demonstrates the practical application of AI methodologies to generate novel scientific insights within humanities disciplines, revealing how such tools can uncover new patterns, connections, and interpretations in fields like history and literature.</p>
</section>
<section id="a-dual-focus-explainable-ai-and-ai-in-the-humanities" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="a-dual-focus-explainable-ai-and-ai-in-the-humanities"><span class="header-section-number">7.1</span> A Dual Focus: Explainable AI and AI in the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>This work establishes a dual focus, addressing two principal areas in a systematic fashion. The first area of inquiry delves into Explainable Artificial Intelligence (XAI) and the critical need to understand Large Language Models (LLMs). This segment explores the interpretability, functionality, and transparency of AI systems, specifically tackling the challenge of comprehending the reasoning and decision-making mechanisms within these complex models.</p>
<p>The discussion then shifts to the generation of AI-based scientific insights within the humanities. Here, the focus is on applying artificial intelligence methodologies to produce novel research findings. The aim is to uncover new patterns, connections, and interpretations within disciplines such as history, literature, and philosophy, thereby making a significant contribution to scholarly understanding in these fields.</p>
</section>
<section id="introducing-explainable-ai-the-first-wave" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="introducing-explainable-ai-the-first-wave"><span class="header-section-number">7.2</span> Introducing Explainable AI: The First Wave</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The discourse transitions to an introduction of Explainable AI 1.0, with a specific focus on feature attributions. This foundational concept in XAI involves determining the importance or contribution of individual input features to a modelâ€™s prediction. By doing so, it enhances the transparency of the modelâ€™s decision-making process. Dr Eberle provides a concise overview, defining XAI from the perspective of the machine learning community.</p>
</section>
<section id="the-black-box-problem-and-the-need-for-explainability" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="the-black-box-problem-and-the-need-for-explainability"><span class="header-section-number">7.3</span> The Black Box Problem and the Need for Explainability</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Historically, machine learning concentrated primarily on visual data; a significant shift towards language-based applications has only emerged in the last decade. To address the inherent opacity of these â€˜black boxâ€™ models, the machine learning community developed Explainable Artificial Intelligence (XAI). For instance, whilst a model might accurately identify a rooster from an image, users typically lack insight into the basis of this prediction. Consequently, a decade of XAI research has been dedicated to understanding and tracing the origins of such predictions.</p>
<p>A common XAI technique involves generating heatmaps, which visually indicate the specific pixels responsible for a classification, thereby clarifying why a model recognised the rooster. Beyond mere technical transparency, the motivations for XAI are multifaceted. As Samek and colleagues (2017) outline, these include:</p>
<ul>
<li><p>Verifying that predictions are reasonable.</p></li>
<li><p>Facilitating the correction of errors by illuminating how they occur.</p></li>
<li><p>Aiding the understanding of the underlying problem, as models can uncover surprising solutions.</p></li>
<li><p>Ensuring compliance with evolving regulations, such as the European AI Act.</p></li>
</ul>
</section>
<section id="post-hoc-explainability-and-its-motivations" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="post-hoc-explainability-and-its-motivations"><span class="header-section-number">7.4</span> Post-Hoc Explainability and Its Motivations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Post-hoc explainability concentrates on interpreting AI decisions after they have been generated. This process typically involves feeding an input, such as an image of a rooster, into a black box AI system, which in turn yields a prediction. To elucidate this prediction, specific explanation methods interact with the system to produce a heatmap.</p>
<p>When overlaid onto the original input, this heatmap visually highlights the pixels most influential in the AIâ€™s decisionâ€”for instance, concentrating on the roosterâ€™s head. This methodology, consistent with the framework of Samek et al.&nbsp;(2017), provides crucial insights into the AIâ€™s reasoning. The imperative for such explainability stems from the need to verify predictions, identify flaws and biases, learn more about the underlying problem, and ensure compliance with legislation.</p>
</section>
<section id="generative-ai-and-new-interpretability-challenges" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="generative-ai-and-new-interpretability-challenges"><span class="header-section-number">7.5</span> Generative AI and New Interpretability Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The field of artificial intelligence has undergone a significant paradigm shift, moving from traditional classification models to the era of Generative AI. Whilst older systems primarily performed discrete tasks such as classifying an input image, contemporary generative models exhibit a far broader range of capabilities. These advanced systems can classify, identify similar images, generate novel content, and engage in comprehensive question-and-answer interactions across diverse topics.</p>
<p>Consequently, grounding a prediction or an answer from a Large Language Model (LLM) in its specific input has become considerably more challenging. The field now requires interpretability methods that extend beyond simple heatmap representations, focusing instead on intricate feature interactions and a more mechanistic understanding of the modelsâ€™ internal workings. Todayâ€™s foundation models function not merely as specialised classifiers but as multi-task â€˜world modelsâ€™, offering profound insights into societal evolution, textual dynamics, and the inherent features of language itself. This evolution necessitates advanced techniques to fully comprehend their complex outputs.</p>
</section>
<section id="illustrative-model-failures" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="illustrative-model-failures"><span class="header-section-number">7.6</span> Illustrative Model Failures</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>AI models, including advanced LLMs, demonstrably make surprising mistakes. In object detection, for example, Lapuschkin and colleagues (<em>Nat Commun</em> â€™19) showed that a standard classifier might erroneously base its prediction of a boat on the surrounding water rather than the vessel itself, simply because water presents a correlated and texturally simpler feature to detect.</p>
<p>In multi-step planning, contemporary LLMs also exhibit significant limitations. Mondal, Webb, and colleagues (arxiv â€™24) tasked a <em>Llama 3.x</em> model with solving the Tower of Hanoi puzzle. The model immediately erred by attempting to move the largest, physically inaccessible disk directly to the final peg. This failure highlights the modelâ€™s inability to comprehend the problemâ€™s fundamental physical constraints, underscoring the ongoing challenges in developing truly robust AI systems.</p>
</section>
<section id="xai-2.0-towards-structured-interpretability" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="xai-2.0-towards-structured-interpretability"><span class="header-section-number">7.7</span> XAI 2.0: Towards Structured Interpretability</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>The discussion now pivots to Explainable AI (XAI) 2.0, which focuses on structured interpretability. This advanced approach aims to transcend the limitations of conventional heatmap representations. It seeks to provide more organised, systematic, and hierarchical explanations for AI model behaviour, with the subsequent sections detailing methodologies that achieve this deeper level of insight.</p>
</section>
<section id="first-order-explanations-for-verification" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="first-order-explanations-for-verification"><span class="header-section-number">7.8</span> First-Order Explanations for Verification</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The exploration of â€˜first-order explanationsâ€™ provides a methodology for elucidating the behaviour of classifiers, typically by generating heatmaps over classification outputs. A pertinent case study involved a classifier trained on historical table data, where the objective was to distinguish between specific subgroups of these tables. To verify that the classifier was operating meaningfully, heatmaps were employed to ensure the modelâ€™s decisions were grounded in relevant features.</p>
</section>
<section id="features-and-pairwise-interactions" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="features-and-pairwise-interactions"><span class="header-section-number">7.9</span> Features and Pairwise Interactions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>To enhance model interpretability, the analysis of relevant features and their interactions is paramount. In a first-order analysis of classifier predictions, a model designed to classify historical tables correctly prioritised numerical content. This focus on numerical data served as an effective proxy for identifying such tables, with heatmaps visually confirming the relevance of these individual features.</p>
<p>Moving to a second-order analysis, the emphasis shifts to pairwise relationships. Here, investigating similarity proved crucial. By computing a dot product between the embeddings of two images, the project team discovered that feature interactions provided an appropriate representation for explaining similarity predictions. This method revealed, for instance, specific interactions between digits that confirmed the identity of two historical tables, thereby verifying the modelâ€™s intended functionality.</p>
</section>
<section id="higher-order-interactions-and-circuit-level-understanding" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="higher-order-interactions-and-circuit-level-understanding"><span class="header-section-number">7.10</span> Higher-Order Interactions and Circuit-Level Understanding</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>More recent scholarship has turned to graph structures, discovering that higher-order interactions offer more meaningful insights into model behaviour. When applied to contexts such as citation networks or networks of books and entities, this approach reveals that feature subgraphs or â€˜feature walksâ€™â€”defined as sets of features that collectively become relevantâ€”are particularly significant. Identifying these complex interactions facilitates a deeper, â€˜circuit-levelâ€™ comprehension of a modelâ€™s internal mechanisms.</p>
</section>
<section id="first-order-attributions-in-large-language-models" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="first-order-attributions-in-large-language-models"><span class="header-section-number">7.11</span> First-Order Attributions in Large Language Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The presentation now transitions to a focused examination of first-order attributions within Large Language Models (LLMs). Through concrete examples drawn from language and the humanities, this segment explores the direct causal links between inputs and outputs in LLMs, elucidating the fundamental mechanisms that underpin their interpretability.</p>
</section>
<section id="biased-sentiment-predictions-in-transformer-models" class="level2" data-number="7.12">
<h2 data-number="7.12" class="anchored" data-anchor-id="biased-sentiment-predictions-in-transformer-models"><span class="header-section-number">7.12</span> Biased Sentiment Predictions in Transformer Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>In a study presented at ICML in 2022, Ali and colleagues investigated biased sentiment predictions within <em>Transformer</em> LLMs. Employing first-order attributions in a standard movie review sentiment analysis scenario, their methodology analysed how certain names influenced sentiment predictions. Using heatmaps generated by a novel method for <em>Transformers</em>, they observed a distinct bias: positive sentiment was more frequently associated with male Western names such as Lee, Barry, or Raphael.</p>
<p>Conversely, negative sentiment scores were more probable when names such as Saddam, Castro, or Chan were present. This study clearly identified fine-grained biases, a phenomenon increasingly recognised within the AI community. The work underscores how XAI can prove invaluable for detecting these subtle, yet significant, model biases.</p>
</section>
<section id="long-range-dependencies-in-llms" class="level2" data-number="7.13">
<h2 data-number="7.13" class="anchored" data-anchor-id="long-range-dependencies-in-llms"><span class="header-section-number">7.13</span> Long-Range Dependencies in LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>In a paper for <em>NeurIPS</em> 2024, Jafari and colleagues investigated first-order attributions to understand long-range dependencies in LLMs. They tasked models with generating summaries from extensive inputs, specifically Wikipedia articles, within an 8,000-token context window. The core inquiry was whether models could effectively utilise information from distant parts of the context.</p>
<p>By analysing the source of the generated text, the team observed that a token such as â€˜1972â€™ was accurately attributed to information located 5,775 tokens earlier in the context. This information originated from passages referencing â€˜Breadâ€™s 1972 album <em>Guitar Man</em>â€™ and a â€˜List of number-one adult contemporary singles of 1972 (U.S.)â€™. This example compellingly demonstrates an LLMâ€™s capacity to leverage long-range dependencies for precise text generation.</p>
</section>
<section id="limitations-in-long-range-summarisation" class="level2" data-number="7.14">
<h2 data-number="7.14" class="anchored" data-anchor-id="limitations-in-long-range-summarisation"><span class="header-section-number">7.14</span> Limitations in Long-Range Summarisation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>The work of Jafari and colleagues (<em>NeurIPS</em> â€™24) also revealed a crucial operational characteristic of LLMs. Whilst models can draw information from the entire 8,000-token context window, they predominantly prioritise data located in the later parts of the input. A histogram illustrating this tendency shows that although mid-range and long-range dependencies are observed, their frequency diminishes significantly compared to short-range interactions.</p>
<p>Consequently, users employing LLMs for text summarisation should anticipate an unbalanced output. The model is more likely to concentrate on information presented closer to the prompt rather than providing a comprehensive, evenly distributed summary of the entire input text, a key consideration for practical applications.</p>
</section>
<section id="higher-order-interactions-in-text" class="level2" data-number="7.15">
<h2 data-number="7.15" class="anchored" data-anchor-id="higher-order-interactions-in-text"><span class="header-section-number">7.15</span> Higher-Order Interactions in Text</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>Building upon prior discussions of embeddings, the presentation now advances to a detailed examination of second and higher-order interactions within textual data. This segment explores complex relationships that extend beyond simple, direct connections, delving into the intricate patterns, contextual dependencies, and emergent properties inherent in language. The methodologies discussed aim to uncover these sophisticated interactions, offering a more nuanced understanding of textual structures.</p>
</section>
<section id="explaining-sentence-similarity-with-bilrp" class="level2" data-number="7.16">
<h2 data-number="7.16" class="anchored" data-anchor-id="explaining-sentence-similarity-with-bilrp"><span class="header-section-number">7.16</span> Explaining Sentence Similarity with <em>BiLRP</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>To explain sentence similarities, Eberle and colleagues (<em>TPAMI</em> 2022) conducted an unsupervised analysis of representations from a pretrained foundation model, using dot products as the similarity metric. Whilst a model might yield a high similarity score for sentences like â€˜A cat I really likeâ€™ and â€˜It is a great cat!â€™, the underlying reasons often remain opaque.</p>
<p>To address this, the team developed the <em>Bilinear Layer-wise Relevance Propagation</em> (<em>BiLRP</em>) method. This technique, formalised by the equation <code>BiLRP(y, x, x') = Î£_{m=1}^{h} LRP([Ï•_L â—¦ ... â—¦ Ï•_1]_m, x) âŠ— LRP([Ï•_L â—¦ ... â—¦ Ï•_1]_m, x')</code>, decomposes the similarity score into contributions from individual tokens or token pairs. The resulting interaction scores clarify the modelâ€™s reasoning.</p>
<p>Analysis of these token interactions frequently reveals surprisingly simplistic strategies. These include noun matching (both synonyms and identical tokens) and some noun-verb interactions, suggesting that models often rely on a â€˜bag of token typesâ€™ approach. This finding is crucial for practitioners, as it indicates that the features driving high similarity scores in embeddings may be remarkably simple.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_18.png" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
</section>
<section id="graph-neural-networks-for-structured-data" class="level2" data-number="7.17">
<h2 data-number="7.17" class="anchored" data-anchor-id="graph-neural-networks-for-structured-data"><span class="header-section-number">7.17</span> Graph Neural Networks for Structured Data</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_19.png" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>The exploration of <em>Graph Neural Networks</em> (<em>GNNs</em>) offers a powerful approach for structured predictions. These models are designed to process graph-structured data, such as complex networks of interconnected nodes and edges. The operational flow of a <em>GNN</em> involves feeding an input graph into a processing pipeline, where an iterative â€˜interactionâ€™ phase refines information across the graph through recurrent message-passing.</p>
<p>This process updates node features based on their neighbours, culminating in a final hidden state that yields the modelâ€™s prediction. Crucially for interpretability, <em>GNNs</em> enable the derivation of attributions in terms of â€˜walksâ€™, which represent specific interactions of features within the graph structure.</p>
</section>
<section id="explaining-predictions-with-walks" class="level2" data-number="7.18">
<h2 data-number="7.18" class="anchored" data-anchor-id="explaining-predictions-with-walks"><span class="header-section-number">7.18</span> Explaining Predictions with Walks</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_20.png" class="img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
<p>Schnake and colleagues (<em>TPAMI</em> 2022) developed a conceptual framework for explaining <em>GNN</em> and LLM predictions by leveraging â€˜walksâ€™. In their method, a walk-based relevance analysis identifies influential sequences of connected nodes and edges, progressively simplifying the explanation from a full graph to a subgraph of only the most relevant components.</p>
<p>A key insight from their work is that <em>GNNs</em>, which inherently encode structural information, can be framed as LLMs. The attention network within an LLM effectively determines which tokens can engage in â€˜message passingâ€™, a process analogous to node interactions in a <em>GNN</em>. This conceptual alignment enables the application of walk-based interpretability methods to language models, offering a powerful tool for understanding their complex behaviours.</p>
</section>
<section id="limitations-of-standard-explanations" class="level2" data-number="7.19">
<h2 data-number="7.19" class="anchored" data-anchor-id="limitations-of-standard-explanations"><span class="header-section-number">7.19</span> Limitations of Standard Explanations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_21.png" class="img-fluid figure-img"></p>
<figcaption>Slide 21</figcaption>
</figure>
</div>
<p>In an illustrative example, Schnake and colleagues (<em>TPAMI</em> 2022) demonstrated how node interactions facilitate the learning of complex language structures. Their premise is that the hierarchical nature of language is well-suited for graph representations, enabling models to be trained on sentiment tasks to extract meaningful â€˜walksâ€™ or linguistic patterns.</p>
<p>However, standard explanation methods like the Bag-of-Words (BoW) approach prove inadequate. For the sentence, â€˜First I didnâ€™t like the boring pictures, but it is certainly one of the best movies I have ever seenâ€™, a first-order, BoW-like explanation might incorrectly assign a high positive score to the initial negative clause due to the word â€˜likeâ€™, failing to interpret the negation. This highlights the critical need for higher-order interaction methods to achieve a more nuanced understanding.</p>
</section>
<section id="higher-order-explanations-for-nuanced-sentiment" class="level2" data-number="7.20">
<h2 data-number="7.20" class="anchored" data-anchor-id="higher-order-explanations-for-nuanced-sentiment"><span class="header-section-number">7.20</span> Higher-Order Explanations for Nuanced Sentiment</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_22.png" class="img-fluid figure-img"></p>
<figcaption>Slide 22</figcaption>
</figure>
</div>
<p>Employing their more complex, higher-order explanation methods, Schnake and colleagues demonstrated a significantly improved capacity to interpret nuanced language. For the same example sentence, their advanced techniques accurately assigned a negative score to the entire initial clause, correctly identifying its negative sentiment. Conversely, the second part of the sentence received a positive score, reflecting its true meaning.</p>
<p>This result illustrates how higher-order methods can precisely capture the hierarchical and often contradictory elements within complex linguistic expressions. The presentation now transitions to its second major section, focusing on AI-based scientific insights within the humanities.</p>
</section>
<section id="ai-for-scientific-insight-in-the-humanities" class="level2" data-number="7.21">
<h2 data-number="7.21" class="anchored" data-anchor-id="ai-for-scientific-insight-in-the-humanities"><span class="header-section-number">7.21</span> AI for Scientific Insight in the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_23.png" class="img-fluid figure-img"></p>
<figcaption>Slide 23</figcaption>
</figure>
</div>
<p>The second major section of the presentation focuses on generating AI-based scientific insights within the humanities. Initial explorations in this domain commenced with heatmap-based approaches, specifically applied to a corpus of historical mathematical instruments. This part of the discussion details how artificial intelligence can be leveraged to produce novel scientific understanding, bridging computational methodologies with traditional humanistic inquiry.</p>
</section>
<section id="extracting-visual-definitions-from-corpora" class="level2" data-number="7.22">
<h2 data-number="7.22" class="anchored" data-anchor-id="extracting-visual-definitions-from-corpora"><span class="header-section-number">7.22</span> Extracting Visual Definitions from Corpora</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_24.png" class="img-fluid figure-img"></p>
<figcaption>Slide 24</figcaption>
</figure>
</div>
<p>In a study for the <em>International Journal of Digital Humanities</em> (2023), El-Hajj, Eberle, and their collaborators explored the extraction of visual definitions from historical corpora. They applied computational methods to illustrations of mathematical instruments, developing a classifier to categorise images into classes such as â€˜machineâ€™ or â€˜mathematical instrumentâ€™. This was achieved through class-specific heatmap explanations, which highlighted the visual features most salient for a particular classification.</p>
<p>This endeavour necessitated close collaboration with historians, including Matteo Valeriani and Jochen BÃ¼ttner, to verify the objectivity of these computationally derived definitions. A key finding revealed that the fine-grained scales on mathematical instruments were highly relevant features for the model. This approach demonstrates how computational techniques can derive and visualise the â€˜visual definitionsâ€™ a model learns, enhancing transparency in digital humanities research.</p>
</section>
<section id="analysing-early-modern-astronomical-tables" class="level2" data-number="7.23">
<h2 data-number="7.23" class="anchored" data-anchor-id="analysing-early-modern-astronomical-tables"><span class="header-section-number">7.23</span> Analysing Early Modern Astronomical Tables</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_25.png" class="img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
<p>In a major cooperative project, Dr Eberleâ€™s team undertook a corpus-level analysis of early modern astronomical tables, focusing on numerical data from the <em>Sphaera Corpus</em> (1472â€“1650). Historians Matteo Valeriani and Jochen BÃ¼ttner initiated this collaboration, seeking an automated method for matching tables with similar semanticsâ€”a task previously unfeasible at scale.</p>
<p>The corpus comprises diverse examples, from <em>TABVLA SINVVM RECTORVM</em> (tables of sines) to <em>TABVLA CLIMA TVM SECVNDVM PARTItionem ueterum</em> (tables of climates). The work draws from both the <em>Sphaera Corpus</em> (Valleriani et al., 2019) and the <em>Sacrobosco Table Corpus</em> (Eberle et al., 2024).</p>
</section>
<section id="xai-historian-a-workflow-for-scalable-insight" class="level2" data-number="7.24">
<h2 data-number="7.24" class="anchored" data-anchor-id="xai-historian-a-workflow-for-scalable-insight"><span class="header-section-number">7.24</span> <em>xAI-Historian</em>: A Workflow for Scalable Insight</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_26.png" class="img-fluid figure-img"></p>
<figcaption>Slide 26</figcaption>
</figure>
</div>
<p>The <em>xAI-Historian</em> project, published by Eberle and colleagues in <em>Science Advances</em> (2024), pioneers a workflow to provide historians with insights at scale. Recognising historical tables as crucial carriers of scientific knowledge, this initiative leverages the <em>Sacrobosco Corpus</em>, an extensive dataset of university textbooks. The project addresses significant machine learning challenges, including heterogeneous data and limited annotations.</p>
<p>The system operates through a three-stage workflow:</p>
<ul>
<li><p>Data Collections involves sourcing diverse historical books.</p></li>
<li><p>Atomization-Recomposition transforms raw tables into structured formats by generating â€˜bigram mapsâ€™ and then â€˜histogramsâ€™ (Î¦(x)) as statistical embeddings.</p></li>
<li><p>Corpus-Level Analysis embeds these processed tables into a shared space, where proximity signifies similarity, quantified by the dot product <code>y(x, x') = âŸ¨Î¦(x), Î¦(x')âŸ©</code>.</p></li>
</ul>
<p>Rather than using general-purpose foundation models, the team developed a custom statistical model for bigram detection. This bespoke approach empowers historians to engage in data-driven hypothesis generation and discover novel case studies.</p>
</section>
<section id="verifying-features-with-xai-and-historians" class="level2" data-number="7.25">
<h2 data-number="7.25" class="anchored" data-anchor-id="verifying-features-with-xai-and-historians"><span class="header-section-number">7.25</span> Verifying Features with XAI and Historians</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_27.png" class="img-fluid figure-img"></p>
<figcaption>Slide 27</figcaption>
</figure>
</div>
<p>The verification of modelling and features in the historical table analysis relies on a collaborative approach involving XAI and historians. As documented by Eberle and colleagues (<em>TPAMI</em> â€˜22; <em>Sci Adv</em> â€™24), historical tables are represented using a â€™bag of bigramsâ€™, such as patterns like â€˜01â€™ or â€˜21â€™. This method employs a learned feature extractor with a hard-coded structure, operating effectively despite limited annotations.</p>
<p>Empirical results underscore the efficacy of this approach. An expert ground truth analysis reveals a direct relationship between table density and model performance: higher densities yield superior correlation coefficients. In cluster classification, the bigram model achieved the highest purity (â‰ˆ0.9), significantly outperforming unigram models (â‰ˆ0.75) and <em>VGG-16</em> (â‰ˆ0.65), demonstrating its superior performance.</p>
</section>
<section id="analysing-innovation-spread-with-cluster-entropy" class="level2" data-number="7.26">
<h2 data-number="7.26" class="anchored" data-anchor-id="analysing-innovation-spread-with-cluster-entropy"><span class="header-section-number">7.26</span> Analysing Innovation Spread with Cluster Entropy</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_28.png" class="img-fluid figure-img"></p>
<figcaption>Slide 28</figcaption>
</figure>
</div>
<p>To investigate the historical spread of innovation, Eberle and colleagues (<em>Science Advances</em>, 2024) employed cluster entropy analysis. Their methodology involved calculating the â€˜difference between the observed cluster entropy H(p) and the maximum attainable entropy at each print locationâ€™. This metric quantitatively assesses the concentration or dispersion of innovative activities.</p>
<p>Historically, the diverse â€˜programmes of typesâ€™ produced by various publishing cities could not be analysed at scale. To overcome this, the team devised a novel clustering approach using robust representations from their bespoke bigram model. This method allowed them to quantify innovation diversity across numerous European cities, including London, Paris, Venice, and Wittenberg, providing unprecedented insights into historical intellectual networks.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_29.png" class="img-fluid figure-img"></p>
<figcaption>Slide 29</figcaption>
</figure>
</div>
</section>
<section id="entropy-and-historical-publishing-programmes" class="level2" data-number="7.27">
<h2 data-number="7.27" class="anchored" data-anchor-id="entropy-and-historical-publishing-programmes"><span class="header-section-number">7.27</span> Entropy and Historical Publishing Programmes</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_31.png" class="img-fluid figure-img"></p>
<figcaption>Slide 31</figcaption>
</figure>
</div>
<p>Continuing their cluster entropy analysis, Eberle and colleagues used a distance-based clustering approach to quantify the diversity of â€˜programmes of typesâ€™ from each city. A low entropy score indicated that a city consistently reproduced identical content, signifying a less diverse print programme. Conversely, a higher entropy score denoted a more varied publishing output.</p>
<p>This analysis revealed two particularly interesting cases: Frankfurt/Main and Wittenberg, both exhibiting the lowest entropy scores. Frankfurt/Main was confirmed as a recognised centre for reprinting editions. More notably, Wittenberg emerged as a historical anomaly, where political control by Protestant reformers actively limited the print programme. This finding, which matched existing historical intuition, underscores the methodâ€™s capacity to detect nuanced historical patterns.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_32.png" class="img-fluid figure-img"></p>
<figcaption>Slide 32</figcaption>
</figure>
</div>
</section>
<section id="conclusion-ai-methods-in-the-humanities" class="level2" data-number="7.28">
<h2 data-number="7.28" class="anchored" data-anchor-id="conclusion-ai-methods-in-the-humanities"><span class="header-section-number">7.28</span> Conclusion: AI Methods in the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_33.png" class="img-fluid figure-img"></p>
<figcaption>Slide 33</figcaption>
</figure>
</div>
<p>The presentation concludes by summarising the landscape of AI-based methods in the humanities. Whilst humanities and Digital Humanities (DH) scholars have largely concentrated on digitising source material, the automated analysis of these corpora presents non-trivial challenges, primarily due to data heterogeneity and the scarcity of labelled data.</p>
<p>Multimodality emerges as a significant aspect, underscoring the necessity for AI methods capable of handling diverse data types beyond conventional text. The integration of Machine Learning (ML) with Explainable AI (XAI) holds substantial promise, potentially enabling the scaling of humanities research and fostering novel research directions.</p>
<p>However, the role of Foundation Models and LLMs requires a nuanced understanding. Whilst prompting can facilitate intermediate tasks like labelling and data curation, these models remain limited when addressing more complex scholarly questions. Furthermore, the challenges of low-resource data, exacerbated by â€˜scaling lawsâ€™ that demand extensive datasets, represent a significant roadblock.</p>
<p>Finally, the issue of out-of-domain transfer is particularly pertinent for historical and small-scale data. This necessitates thorough evaluation, given that current LLMs are primarily trained for natural language and code generation, which may not align with the specific requirements of humanities data.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="The VERITRACE Project">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_008.html" class="pagination-link" aria-label="Validation is All You Need">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>