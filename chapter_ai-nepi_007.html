<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oliver Eberle">
<meta name="dcterms.date" content="2025-01-01">

<title>7&nbsp; Explainable AI and AI-based Scientific Insights in the Humanities – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_008.html" rel="next">
<link href="./chapter_ai-nepi_006.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-85125aaa381e97e617f4eb7319a810c2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_007.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: A Primer and Critical Reflections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Philosophy at Scale: Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification in Historical Patient Organisation Periodicals: A Methodological Report</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE Traces de la Vérité: The reappropriation of ancient wisdom in early modern natural philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Possible applications of RAG systems in philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#explainable-ai-and-ai-based-scientific-insights-in-the-humanities" id="toc-explainable-ai-and-ai-based-scientific-insights-in-the-humanities" class="nav-link" data-scroll-target="#explainable-ai-and-ai-based-scientific-insights-in-the-humanities"><span class="header-section-number">7.1</span> Explainable AI and AI-based Scientific Insights in the Humanities</a></li>
  <li><a href="#explainable-ai-xai-1.0-feature-attributions" id="toc-explainable-ai-xai-1.0-feature-attributions" class="nav-link" data-scroll-target="#explainable-ai-xai-1.0-feature-attributions"><span class="header-section-number">7.2</span> Explainable AI (XAI) 1.0 Feature Attributions</a></li>
  <li><a href="#explainable-ai" id="toc-explainable-ai" class="nav-link" data-scroll-target="#explainable-ai"><span class="header-section-number">7.3</span> Explainable AI</a></li>
  <li><a href="#post-hoc-explainability" id="toc-post-hoc-explainability" class="nav-link" data-scroll-target="#post-hoc-explainability"><span class="header-section-number">7.4</span> Post-Hoc Explainability</a></li>
  <li><a href="#the-advent-of-generative-ai" id="toc-the-advent-of-generative-ai" class="nav-link" data-scroll-target="#the-advent-of-generative-ai"><span class="header-section-number">7.5</span> The Advent of Generative AI</a></li>
  <li><a href="#model-limitations-and-unexpected-errors" id="toc-model-limitations-and-unexpected-errors" class="nav-link" data-scroll-target="#model-limitations-and-unexpected-errors"><span class="header-section-number">7.6</span> Model Limitations and Unexpected Errors</a></li>
  <li><a href="#xai-2.0-structured-interpretability" id="toc-xai-2.0-structured-interpretability" class="nav-link" data-scroll-target="#xai-2.0-structured-interpretability"><span class="header-section-number">7.7</span> XAI 2.0 Structured Interpretability</a></li>
  <li><a href="#first-order-explanations-and-classifier-behaviour" id="toc-first-order-explanations-and-classifier-behaviour" class="nav-link" data-scroll-target="#first-order-explanations-and-classifier-behaviour"><span class="header-section-number">7.8</span> First-Order Explanations and Classifier Behaviour</a></li>
  <li><a href="#second-order-features-pairwise-relationships" id="toc-second-order-features-pairwise-relationships" class="nav-link" data-scroll-target="#second-order-features-pairwise-relationships"><span class="header-section-number">7.9</span> Second-Order Features: Pairwise Relationships</a></li>
  <li><a href="#higher-order-interactions-and-graph-structures" id="toc-higher-order-interactions-and-graph-structures" class="nav-link" data-scroll-target="#higher-order-interactions-and-graph-structures"><span class="header-section-number">7.10</span> Higher-Order Interactions and Graph Structures</a></li>
  <li><a href="#first-order-attributions-in-llms" id="toc-first-order-attributions-in-llms" class="nav-link" data-scroll-target="#first-order-attributions-in-llms"><span class="header-section-number">7.11</span> First-Order Attributions in LLMs</a></li>
  <li><a href="#biased-sentiment-predictions-in-transformer-llms" id="toc-biased-sentiment-predictions-in-transformer-llms" class="nav-link" data-scroll-target="#biased-sentiment-predictions-in-transformer-llms"><span class="header-section-number">7.12</span> Biased Sentiment Predictions in <em>Transformer</em> LLMs</a></li>
  <li><a href="#first-order-attributions-for-long-range-dependencies-in-llms" id="toc-first-order-attributions-for-long-range-dependencies-in-llms" class="nav-link" data-scroll-target="#first-order-attributions-for-long-range-dependencies-in-llms"><span class="header-section-number">7.13</span> First-Order Attributions for Long-Range Dependencies in LLMs</a></li>
  <li><a href="#second-higher-order-interactions-in-text" id="toc-second-higher-order-interactions-in-text" class="nav-link" data-scroll-target="#second-higher-order-interactions-in-text"><span class="header-section-number">7.14</span> Second &amp; Higher-Order Interactions in Text</a></li>
  <li><a href="#graph-neural-networks-for-structured-predictions" id="toc-graph-neural-networks-for-structured-predictions" class="nav-link" data-scroll-target="#graph-neural-networks-for-structured-predictions"><span class="header-section-number">7.15</span> Graph Neural Networks for Structured Predictions</a></li>
  <li><a href="#interaction-of-nodes-and-complex-language-structure" id="toc-interaction-of-nodes-and-complex-language-structure" class="nav-link" data-scroll-target="#interaction-of-nodes-and-complex-language-structure"><span class="header-section-number">7.16</span> Interaction of Nodes and Complex Language Structure</a></li>
  <li><a href="#ai-based-scientific-insights-in-the-humanities" id="toc-ai-based-scientific-insights-in-the-humanities" class="nav-link" data-scroll-target="#ai-based-scientific-insights-in-the-humanities"><span class="header-section-number">7.17</span> AI-based Scientific Insights in the Humanities</a></li>
  <li><a href="#extracting-visual-definitions-from-corpora" id="toc-extracting-visual-definitions-from-corpora" class="nav-link" data-scroll-target="#extracting-visual-definitions-from-corpora"><span class="header-section-number">7.18</span> Extracting Visual Definitions from Corpora</a></li>
  <li><a href="#corpus-level-analysis-of-early-modern-astronomical-tables" id="toc-corpus-level-analysis-of-early-modern-astronomical-tables" class="nav-link" data-scroll-target="#corpus-level-analysis-of-early-modern-astronomical-tables"><span class="header-section-number">7.19</span> Corpus-Level Analysis of Early Modern Astronomical Tables</a></li>
  <li><a href="#the-xai-historian-enabling-historical-insights-at-scale" id="toc-the-xai-historian-enabling-historical-insights-at-scale" class="nav-link" data-scroll-target="#the-xai-historian-enabling-historical-insights-at-scale"><span class="header-section-number">7.20</span> The XAI-Historian: Enabling Historical Insights at Scale</a></li>
  <li><a href="#verifying-models-and-features-with-xai-and-historians" id="toc-verifying-models-and-features-with-xai-and-historians" class="nav-link" data-scroll-target="#verifying-models-and-features-with-xai-and-historians"><span class="header-section-number">7.21</span> Verifying Models and Features with XAI and Historians</a></li>
  <li><a href="#cluster-entropy-analysis-for-innovation-diffusion" id="toc-cluster-entropy-analysis-for-innovation-diffusion" class="nav-link" data-scroll-target="#cluster-entropy-analysis-for-innovation-diffusion"><span class="header-section-number">7.22</span> Cluster Entropy Analysis for Innovation Diffusion</a></li>
  <li><a href="#insights-from-cluster-entropy-frankfurt-and-wittenberg" id="toc-insights-from-cluster-entropy-frankfurt-and-wittenberg" class="nav-link" data-scroll-target="#insights-from-cluster-entropy-frankfurt-and-wittenberg"><span class="header-section-number">7.23</span> Insights from Cluster Entropy: Frankfurt and Wittenberg</a></li>
  <li><a href="#conclusion-ai-based-methods-for-the-humanities" id="toc-conclusion-ai-based-methods-for-the-humanities" class="nav-link" data-scroll-target="#conclusion-ai-based-methods-for-the-humanities"><span class="header-section-number">7.24</span> Conclusion: AI-based Methods for the Humanities</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></h1>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Oliver Eberle <a href="mailto:oliver.eberle@tu-berlin.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            BIFOLD / TU Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This presentation elucidates the dual application of Artificial Intelligence: firstly, in enhancing the interpretability of complex models through Explainable AI (XAI); and secondly, in generating novel scientific insights within the humanities. The authors initially delineate XAI 1.0, focusing on feature attributions via heatmaps for classification models, whilst underscoring the imperative to verify predictions, identify biases, and ensure regulatory compliance. The discussion then transitions to XAI 2.0, which addresses the complexities of <em>Generative AI</em> and <em>Large Language Models</em> (LLMs) by exploring structured interpretability, feature interactions, and mechanistic views.</p>
<p>The work demonstrates that models can exhibit surprising errors, such as misclassifying objects based on correlated features or failing at multi-step planning tasks. To overcome the limitations of first-order explanations, the research introduces second-order (pairwise relationships) and higher-order (graph structures, feature walks) attributions. These reveal more intricate model behaviours and expose simplistic underlying strategies in embedding models. Specific examples illustrate how XAI uncovers biases in sentiment prediction and reveals LLMs’ tendency to prioritise recent information in long-context summarisation.</p>
<p>Within the humanities, the presentation showcases AI’s utility through several compelling case studies. The research team employed heatmap-based approaches to extract visual definitions from corpora of mathematical instruments, identifying fine-grained scales as crucial features. A significant project involved corpus-level analysis of early modern astronomical tables, such as the <em>Sphaera</em> and <em>Sacrobosco Corpora</em>. Here, a bespoke statistical model generating bigram representations proved remarkably effective where conventional <em>Foundation Models</em> failed, primarily due to heterogeneous, out-of-domain historical data. This innovation led to the concept of the “XAI-Historian,” enabling data-driven hypothesis generation at scale. Crucially, cluster entropy analysis, applied to publishing locations, revealed distinct patterns of innovation and control, identifying Frankfurt as a prominent reprinting hub and Wittenberg as a centre where political influence actively shaped the print programme. The presentation concludes by acknowledging the challenges of low-resource data and out-of-domain transfer for LLMs in humanities research, whilst affirming the transformative potential of <em>Machine Learning</em> (ML) and XAI for scaling scholarly inquiry and fostering new research directions.</p>
</section>
<section id="explainable-ai-and-ai-based-scientific-insights-in-the-humanities" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="explainable-ai-and-ai-based-scientific-insights-in-the-humanities"><span class="header-section-number">7.1</span> Explainable AI and AI-based Scientific Insights in the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>This presentation delineates two principal areas of inquiry. Initially, it explores Explainable Artificial Intelligence (XAI), focusing on developing methodologies to comprehend the intricate operations of complex <em>Large Language Models</em> (LLMs). Subsequently, the discussion shifts to the application of AI for generating scientific insights, particularly within the humanities.</p>
</section>
<section id="explainable-ai-xai-1.0-feature-attributions" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="explainable-ai-xai-1.0-feature-attributions"><span class="header-section-number">7.2</span> Explainable AI (XAI) 1.0 Feature Attributions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>This section provides a concise introduction to Explainable Artificial Intelligence (XAI), outlining the core concepts that the <em>machine learning</em> community defines as ‘explanation’.</p>
</section>
<section id="explainable-ai" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="explainable-ai"><span class="header-section-number">7.3</span> Explainable AI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Historically, <em>machine learning</em> predominantly focused on visual data, with a more recent surge of interest in language emerging over the past decade. To comprehend the internal workings of ‘black box’ <em>machine learning</em> models, Samek and colleagues (2017) typically examined classification tasks. For instance, an input image, such as a rooster, would yield a prediction like “Rooster”; however, users generally possessed no insight into the underlying basis for this classification.</p>
</section>
<section id="post-hoc-explainability" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="post-hoc-explainability"><span class="header-section-number">7.4</span> Post-Hoc Explainability</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The field of explainable AI has dedicated approximately a decade to tracing the origins of model predictions. Typically, this endeavour yields outputs such as heatmaps, which delineate the specific input features—for example, pixels—responsible for a given prediction, such as the recognition of a rooster.</p>
<p>Beyond merely elucidating model behaviour, explainability serves several crucial purposes. It enables the verification of predictions, ensuring that models operate reasonably, and facilitates the identification and correction of errors by illuminating how mistakes occur. Furthermore, explainability offers profound insights into the underlying problem domain, as models frequently uncover surprising solutions. Increasingly, it also ensures compliance with evolving regulatory frameworks, such as the European AI Act.</p>
</section>
<section id="the-advent-of-generative-ai" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="the-advent-of-generative-ai"><span class="header-section-number">7.5</span> The Advent of Generative AI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The scenario of classification models, prevalent until approximately five years ago, has now given way to the era of <em>Generative AI</em>. Contemporary models exhibit remarkable versatility, performing diverse functions such as classification, identifying similar images, generating novel images, and answering a broad spectrum of questions. This expanded capability, however, significantly complicates the task of grounding predictions or answers from <em>Large Language Models</em> (LLMs) to their specific inputs.</p>
<p>Consequently, the field necessitates moving beyond conventional heatmap representations, exploring feature interactions and adopting more mechanistic perspectives to achieve deeper understanding. Crucially, today’s <em>foundation models</em> function as both multi-task and ‘world models’, offering profound insights into societal dynamics and the evolution of textual features over time.</p>
</section>
<section id="model-limitations-and-unexpected-errors" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="model-limitations-and-unexpected-errors"><span class="header-section-number">7.6</span> Model Limitations and Unexpected Errors</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Models frequently exhibit surprising errors, as evidenced by two prominent examples. In object detection, Lapuschkin and colleagues (2019) demonstrated how a standard classifier incorrectly identifies a boat by focusing on the surrounding water—a correlated and texturally simpler feature—rather than the boat itself. Furthermore, <em>Large Language Models</em> (LLMs) can falter in multi-step planning tasks. For instance, when presented with the Tower of Hanoi puzzle, Mondal, Webb, and their team (2024) observed that an LLM might immediately attempt to move the largest, inaccessible disc, thereby failing to comprehend the inherent physical constraints of the problem.</p>
</section>
<section id="xai-2.0-structured-interpretability" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="xai-2.0-structured-interpretability"><span class="header-section-number">7.7</span> XAI 2.0 Structured Interpretability</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Whilst more recent reasoning models may exhibit improved performance, the aforementioned Tower of Hanoi example originated from a standard <em>Llama 3.x</em> model. This section now shifts focus to structured interpretability, exploring methodologies that extend beyond conventional heatmap visualisations.</p>
</section>
<section id="first-order-explanations-and-classifier-behaviour" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="first-order-explanations-and-classifier-behaviour"><span class="header-section-number">7.8</span> First-Order Explanations and Classifier Behaviour</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>First-order explanations, often visualised as heatmaps, prove particularly useful for elucidating classifier behaviour. For instance, the authors employed a table classifier on historical documents, aiming to distinguish specific subgroups of historical tables. After training the classifier, they verified its predictions using heatmaps, confirming that the model accurately focused on numerical content. This numerical focus served as an effective proxy for identifying numerical tables within the corpus.</p>
</section>
<section id="second-order-features-pairwise-relationships" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="second-order-features-pairwise-relationships"><span class="header-section-number">7.9</span> Second-Order Features: Pairwise Relationships</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The team also investigated second-order features, specifically focusing on pairwise relationships such as similarity. Their method involved computing a dot product or similarity score between the embeddings of two entities, for example, two images. To explain these similarity predictions, they found that representing the interaction between features proved highly effective. This approach revealed interactions between specific digits, indicating identical tables and thereby verifying the model’s intended functionality.</p>
</section>
<section id="higher-order-interactions-and-graph-structures" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="higher-order-interactions-and-graph-structures"><span class="header-section-number">7.10</span> Higher-Order Interactions and Graph Structures</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>In more recent investigations, the authors have explored graph structures, discovering that higher-order interactions offer more meaningful insights. This approach applies to various networks, such as citation networks or networks of books and entities, typically trained on classification tasks. Here, relevant features emerge as feature subgraphs or feature walks, representing sets of features that become significant collectively. This methodology aims to yield more complex insights into models, ultimately progressing towards a circuit-level understanding of their operations.</p>
</section>
<section id="first-order-attributions-in-llms" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="first-order-attributions-in-llms"><span class="header-section-number">7.11</span> First-Order Attributions in LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>This section presents illustrative examples drawn from the domains of language and the humanities.</p>
</section>
<section id="biased-sentiment-predictions-in-transformer-llms" class="level2" data-number="7.12">
<h2 data-number="7.12" class="anchored" data-anchor-id="biased-sentiment-predictions-in-transformer-llms"><span class="header-section-number">7.12</span> Biased Sentiment Predictions in <em>Transformer</em> LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>Ali and colleagues (2022) investigated biased sentiment predictions within <em>Transformer Large Language Models</em> (LLMs) by analysing the feature importance of names in movie reviews. Employing a standard sentiment prediction scenario, common within the language community, they ranked sentences and computed heatmaps using a novel method specifically designed for <em>transformers</em>. Their findings revealed a notable bias: positive sentiment predictions correlated with male Western names such as Lee, Barry, Raphael, or the Cohen Brothers, whilst negative scores were more likely associated with foreign-sounding names like Saddam, Castro, or Chan. This study underscores the utility of Explainable AI in detecting such fine-grained biases within models.</p>
</section>
<section id="first-order-attributions-for-long-range-dependencies-in-llms" class="level2" data-number="7.13">
<h2 data-number="7.13" class="anchored" data-anchor-id="first-order-attributions-for-long-range-dependencies-in-llms"><span class="header-section-number">7.13</span> First-Order Attributions for Long-Range Dependencies in LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>Jafari and colleagues (2024) explored first-order attributions for long-range dependencies in <em>Large Language Models</em> (LLMs), specifically examining text summarisation for extensive inputs, up to an 8,000-token context window. In a typical LLM scenario, users provide long texts, such as Wikipedia articles, and request a summary, which the model then generates as free text. Their investigation sought to determine the extent to which token dependencies spanned the input and whether models effectively utilised long-range information.</p>
<p>Findings indicated that models predominantly focus on the later sections of the context, prioritising information presented closer to the prompt. Although models can draw upon information from the very beginning of the context, this occurs significantly less frequently, as evidenced by a log scale of counts. Consequently, summaries generated by LLMs may not offer a balanced representation of the entire input text, a crucial consideration for users.</p>
</section>
<section id="second-higher-order-interactions-in-text" class="level2" data-number="7.14">
<h2 data-number="7.14" class="anchored" data-anchor-id="second-higher-order-interactions-in-text"><span class="header-section-number">7.14</span> Second &amp; Higher-Order Interactions in Text</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The authors investigated second and higher-order interactions within textual data, employing a standard embedding scenario involving sentence pairs, such as “a cat I really like, it is a great cat.” Utilising models like the <em>Bird model</em> or a sentence <em>Bird model</em>, they observed that whilst a similarity score was produced, the underlying reasons for its specific value remained opaque.</p>
<p>The solution emerged through second-order explanations, which yielded interaction scores between individual tokens. These scores revealed that models primarily relied on simplistic strategies, such as noun matching (including synonyms and identical noun tokens), and to a lesser extent, noun-verb interactions, alongside separator and other token interactions. This reliance on basic strategies stems from the models’ inherent need to compress vast amounts of information. Understanding these mechanisms proves crucial when embedding data and subsequently computing rankings between them.</p>
</section>
<section id="graph-neural-networks-for-structured-predictions" class="level2" data-number="7.15">
<h2 data-number="7.15" class="anchored" data-anchor-id="graph-neural-networks-for-structured-predictions"><span class="header-section-number">7.15</span> Graph Neural Networks for Structured Predictions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p><em>Graph Neural Networks</em> (GNNs) offer a powerful mechanism for structured predictions, providing attributions in terms of ‘walks’ that represent interactions between features. Notably, GNNs, which inherently encode structural information, can be conceptualised as <em>Large Language Models</em> (LLMs) because the attention network within LLMs dictates which tokens can engage in message passing. This conceptual framework facilitates the analysis of language structures.</p>
</section>
<section id="interaction-of-nodes-and-complex-language-structure" class="level2" data-number="7.16">
<h2 data-number="7.16" class="anchored" data-anchor-id="interaction-of-nodes-and-complex-language-structure"><span class="header-section-number">7.16</span> Interaction of Nodes and Complex Language Structure</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Schnake and colleagues (2022) demonstrated how the interaction of nodes in graph structures enables the learning of complex language structures, particularly in sentiment analysis. Recognising that the hierarchical nature of natural language aligns well with graph structures, they trained a <em>Graph Neural Network</em> (or an LLM) on a movie review sentiment task and extracted ‘walks’ to understand its decision-making.</p>
<p>For instance, in the sentence “First I didn’t like the boring pictures, but it is certainly one of the best movies I have ever seen,” a first-order explanation would fail to capture the complexity, potentially assigning a high score to “like” despite its negation. Conversely, a higher-order explanation accurately assigns a negative score to the initial negative clause and correctly identifies the positive sentiment and hierarchical structure in the latter part of the sentence. This work highlights the superior interpretability offered by higher-order methods.</p>
</section>
<section id="ai-based-scientific-insights-in-the-humanities" class="level2" data-number="7.17">
<h2 data-number="7.17" class="anchored" data-anchor-id="ai-based-scientific-insights-in-the-humanities"><span class="header-section-number">7.17</span> AI-based Scientific Insights in the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The discussion now transitions to the second principal area of inquiry: the generation of AI-based scientific insights within the humanities.</p>
</section>
<section id="extracting-visual-definitions-from-corpora" class="level2" data-number="7.18">
<h2 data-number="7.18" class="anchored" data-anchor-id="extracting-visual-definitions-from-corpora"><span class="header-section-number">7.18</span> Extracting Visual Definitions from Corpora</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>El-Hajj, Eberle, and their colleagues (2023) initially explored heatmap-based methods for extracting visual definitions from corpora, focusing on a collection of mathematical instruments. Their objective involved classifying these instruments into categories such as ‘machine’ or ‘mathematical instrument’. Collaborating closely with historians, including Matteo Valeriani and Jochen Büttner, the team meticulously verified the visual definitions, underscoring the critical role of domain experts in ensuring the meaningfulness of such classifications. A key finding revealed that fine-grained scales present on the mathematical instruments were highly relevant for the model’s decision-making processes.</p>
</section>
<section id="corpus-level-analysis-of-early-modern-astronomical-tables" class="level2" data-number="7.19">
<h2 data-number="7.19" class="anchored" data-anchor-id="corpus-level-analysis-of-early-modern-astronomical-tables"><span class="header-section-number">7.19</span> Corpus-Level Analysis of Early Modern Astronomical Tables</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>In their most extensive collaborative project, the authors undertook a corpus-level analysis of early modern astronomical tables, specifically focusing on numerical data. They utilised the <em>Sphaera Corpus</em>, an early modern text collection spanning 1472 to 1650, and the <em>Sacrobosco Table Corpus</em> (1472-1650). Historians expressed keen interest in developing an automated method for matching tables with similar semantics, a task previously unfeasible at scale. This significant endeavour is detailed in works by Valeriani and colleagues (2019) for the <em>Sphaera Corpus</em> and Eberle and colleagues (2024) for the <em>Sacrobosco Table Corpus</em>.</p>
</section>
<section id="the-xai-historian-enabling-historical-insights-at-scale" class="level2" data-number="7.20">
<h2 data-number="7.20" class="anchored" data-anchor-id="the-xai-historian-enabling-historical-insights-at-scale"><span class="header-section-number">7.20</span> The XAI-Historian: Enabling Historical Insights at Scale</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Collaborating with historians, Eberle and colleagues (2024) developed a sophisticated workflow to facilitate historical insights at scale, coining the term “XAI-Historian” to describe a historian leveraging AI and Explainable AI. This approach aims to uncover novel case studies and enable data-driven hypothesis generation.</p>
<p>The project focused on historical tables, which serve as crucial carriers of scientific knowledge processes, such as mathematisation, within the <em>Sacrobosco Corpus</em>—a collection of 76,000 pages of university textbooks from 1472 to 1650. A significant <em>machine learning</em> challenge arose from the data’s extreme heterogeneity, limited annotations, and the failure of conventional <em>Optical Character Recognition</em> (OCR) and <em>Foundation Models</em> (FMs).</p>
<p>The devised workflow encompassed three key stages: initially, data collection from book images; subsequently, atomisation and recomposition, involving input tables, bigram maps, and histograms; and finally, corpus-level analysis, which included embedding historical tables and assessing data similarity.</p>
</section>
<section id="verifying-models-and-features-with-xai-and-historians" class="level2" data-number="7.21">
<h2 data-number="7.21" class="anchored" data-anchor-id="verifying-models-and-features-with-xai-and-historians"><span class="header-section-number">7.21</span> Verifying Models and Features with XAI and Historians</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Eberle and colleagues (2022, 2024) crafted a statistical model specifically designed to generate bigram representations of historical tables, addressing the challenge posed by <em>foundation models’</em> inability to process such out-of-domain data effectively. This bespoke model underwent rigorous verification: by detecting identical bigrams—for example, ‘38’ on two distinct inputs—the team confirmed its reliable operation, thereby establishing trust in its decisions.</p>
<p>The methodology involved representing tables as a bag of bigrams, such as ‘01’ or ‘21’, and, given the limited annotations, employed a combination of a learned feature extractor and a hard-coded structure.</p>
</section>
<section id="cluster-entropy-analysis-for-innovation-diffusion" class="level2" data-number="7.22">
<h2 data-number="7.22" class="anchored" data-anchor-id="cluster-entropy-analysis-for-innovation-diffusion"><span class="header-section-number">7.22</span> Cluster Entropy Analysis for Innovation Diffusion</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>In a compelling case study, the authors applied cluster entropy analysis to investigate the diffusion of innovation across early modern Europe. Their focus centred on the publishing output of specific cities, each producing distinct “programmes” of textual types. Some cities exhibited diverse print programmes, whilst others concentrated on reprinting existing works; critically, this phenomenon had previously defied analysis at scale. The methodology involved calculating the difference between the observed cluster entropy H(p) and the maximum attainable entropy for each print location, drawing upon data from the <em>Sphaera</em> publication EPISD-626.</p>
</section>
<section id="insights-from-cluster-entropy-frankfurt-and-wittenberg" class="level2" data-number="7.23">
<h2 data-number="7.23" class="anchored" data-anchor-id="insights-from-cluster-entropy-frankfurt-and-wittenberg"><span class="header-section-number">7.23</span> Insights from Cluster Entropy: Frankfurt and Wittenberg</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>The team devised a clustering approach, leveraging the model’s representations to compute a distance-based clustering and subsequently assess the diversity of print programmes produced by individual cities. They employed entropy as a metric: low entropy indicated a consistent reproduction of identical content, whilst higher entropy signified a more diverse print programme.</p>
<p>This analysis identified two particularly compelling cases with the lowest entropy scores: Frankfurt am Main and Wittenberg. Frankfurt am Main was already recognised as a major centre for reprinting editions. More notably, Wittenberg presented a historical anomaly where the political control exerted by Protestant reformers, particularly Melanchthon, actively restricted the print programme, dictating the curriculum to be published. This finding, detailed by Eberle and colleagues (2024), not only revealed a previously unquantifiable historical pattern but also corroborated existing historical intuition and scholarly support.</p>
</section>
<section id="conclusion-ai-based-methods-for-the-humanities" class="level2" data-number="7.24">
<h2 data-number="7.24" class="anchored" data-anchor-id="conclusion-ai-based-methods-for-the-humanities"><span class="header-section-number">7.24</span> Conclusion: AI-based Methods for the Humanities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>Concluding the discussion, the presenter highlighted several key points regarding AI-based methods in the humanities. Whilst humanities and <em>Digital Humanities</em> (DH) researchers have primarily concentrated on the digitisation of source material, the automated analysis of these corpora presents significant challenges due to data heterogeneity and a scarcity of labels. Multimodality also emerges as a crucial consideration.</p>
<p>Nevertheless, the integration of <em>Machine Learning</em> (ML) and Explainable AI (XAI) holds substantial promise for scaling humanities research and fostering novel research directions. <em>Foundation Models</em> and <em>Large Language Models</em> (LLMs), coupled with prompting techniques, can effectively support intermediate tasks such as labelling, data curation, and error correction. However, their utility for addressing more complex research questions remains limited.</p>
<p>Significant challenges persist, notably the issue of low-resource data for ML, which impacts scaling laws. Furthermore, out-of-domain transfer, particularly for historical and small-scale datasets, necessitates rigorous evaluation, as current LLMs are predominantly trained and aligned for natural language tasks and code generation.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="VERITRACE Traces de la Vérité: The reappropriation of ancient wisdom in early modern natural philosophy">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE Traces de la Vérité: The reappropriation of ancient wisdom in early modern natural philosophy</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_008.html" class="pagination-link" aria-label="Modeling Science">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>