<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Paul Näger">
<meta name="dcterms.date" content="2025-01-01">

<title>12&nbsp; RAG Systems in Philosophy and HPSS – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_015.html" rel="next">
<link href="./chapter_ai-nepi_011.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_012.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#rag-systems-in-philosophy-and-hpss" id="toc-rag-systems-in-philosophy-and-hpss" class="nav-link active" data-scroll-target="#rag-systems-in-philosophy-and-hpss"><span class="header-section-number">13</span> RAG Systems in Philosophy and HPSS</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">13.1</span> Overview</a></li>
  <li><a href="#introduction-to-rag-systems" id="toc-introduction-to-rag-systems" class="nav-link" data-scroll-target="#introduction-to-rag-systems"><span class="header-section-number">13.2</span> Introduction to RAG Systems</a></li>
  <li><a href="#rag-system-architecture-and-problem-solving" id="toc-rag-system-architecture-and-problem-solving" class="nav-link" data-scroll-target="#rag-system-architecture-and-problem-solving"><span class="header-section-number">13.3</span> RAG System Architecture and Problem Solving</a></li>
  <li><a href="#applications-in-philosophy" id="toc-applications-in-philosophy" class="nav-link" data-scroll-target="#applications-in-philosophy"><span class="header-section-number">13.4</span> Applications in Philosophy</a></li>
  <li><a href="#example-stanford-encyclopedia-of-philosophy-rag-system" id="toc-example-stanford-encyclopedia-of-philosophy-rag-system" class="nav-link" data-scroll-target="#example-stanford-encyclopedia-of-philosophy-rag-system"><span class="header-section-number">13.5</span> Example: Stanford Encyclopedia of Philosophy RAG System</a></li>
  <li><a href="#sep-rag-system-implementation" id="toc-sep-rag-system-implementation" class="nav-link" data-scroll-target="#sep-rag-system-implementation"><span class="header-section-number">13.6</span> SEP RAG System Implementation</a></li>
  <li><a href="#hyperparameter-tuning-chunk-size" id="toc-hyperparameter-tuning-chunk-size" class="nav-link" data-scroll-target="#hyperparameter-tuning-chunk-size"><span class="header-section-number">13.7</span> Hyperparameter Tuning: Chunk Size</a></li>
  <li><a href="#results-discussion-and-challenges" id="toc-results-discussion-and-challenges" class="nav-link" data-scroll-target="#results-discussion-and-challenges"><span class="header-section-number">13.8</span> Results, Discussion, and Challenges</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Paul Näger <a href="mailto:paul.naeger@cis.lmu.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            LMU München
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>The presentation details the application of Retrieval Augmented Generation (RAG) systems to philosophical research and teaching, specifically within the Humanities, Politics, and Social Sciences (HPSS) domain. The core objective is to address limitations of standard Large Language Models (LLMs) when applied to disciplines requiring high linguistic and semantic accuracy and deep engagement with specific textual corpora. Standard LLMs face problems with access to full texts (despite potenti…</p>
  </div>
</div>


</header>


<section id="rag-systems-in-philosophy-and-hpss" class="level1" data-number="13">
<h1 data-number="13"><span class="header-section-number">13</span> RAG Systems in Philosophy and HPSS</h1>
<section id="overview" class="level2" data-number="13.1">
<h2 data-number="13.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">13.1</span> Overview</h2>
<p>The presentation details the application of Retrieval Augmented Generation (RAG) systems to philosophical research and teaching, specifically within the Humanities, Politics, and Social Sciences (HPSS) domain. The core objective is to address limitations of standard Large Language Models (LLMs) when applied to disciplines requiring high linguistic and semantic accuracy and deep engagement with specific textual corpora.</p>
<p>Standard LLMs face problems with access to full texts (despite potential inclusion in training data), limited context windows, and attribution of information. RAG systems are proposed as a solution by providing explicit access to domain-specific data sources, augmenting prompts with retrieved relevant text chunks, and enabling source citation.</p>
<p>The presentation outlines typical philosophical research questions that require detailed textual analysis. It describes the standard LLM query process and contrasts it with the RAG workflow.</p>
<p>The RAG workflow involves a retrieval query to data sources (such as vector databases or APIs), retrieval of relevant text chunks (typically via semantic search, potentially hybrid or classic search), and augmentation of the LLM prompt with these chunks before generation. This process directly addresses the problems of access, limited context window, and attribution.</p>
<p>Potential applications in philosophy include didactic use (chatting with philosophical corpora for instructive questioning) and research use (looking up facts in handbooks, exploring unexamined corpora, finding passages for close reading, and directly finding detailed answers to research questions).</p>
<p>An example RAG system is presented using the <em>Stanford Encyclopedia of Philosophy</em> (SEP) as the data source. The system was developed through a qualitative study involving theoretically grounded trial and error to optimize performance for philosophical queries.</p>
<p>Key aspects of this study included model choices (generative LLM, embedding model), tuning hyperparameters (number of documents to retrieve (top-k), max input/output token length, chunk size and overlap), and addressing methodological challenges like retrieval semantic mismatch through reranking. Evaluation of results, particularly for complex, unstructured philosophical answers, is identified as crucial and requiring domain expertise.</p>
<p>The implemented SEP RAG system features a frontend with configuration options for generative model (e.g., <em>gpt-4o-mini</em>), prompt token limits, number of texts to retrieve, and persona. It includes a comparative setup displaying answers from the LLM alone versus the RAG system for qualitative evaluation and benchmarking.</p>
<p>The output also lists retrieved texts, their source files, section headings, distance metrics, token lengths, and inclusion status based on prompt limits.</p>
<p>A specific hyperparameter tuning example, chunk size, is discussed. Options explored included fixed word counts, paragraphs, and sections.</p>
<p>The study found that chunking into main sections yielded the best results for the SEP corpus, despite section lengths often exceeding the embedding model’s cutoff. This outcome is attributed to the highly systematic structure of the SEP, where section beginnings effectively summarize content. This highlights that effective chunking is corpus- and question-dependent.</p>
<p>Results indicate that RAG systems offer advantages in integrating verbatim corpora and domain knowledge, leading to more detailed answers and a dramatic reduction in hallucinations compared to standard LLMs. They also enable the citation of relevant documents supporting the generated answer. Overall, the RAG setup is identified as being very well suited for assisting in a wide range of scientific tasks.</p>
<p>However, several cautionary points are raised. RAG systems fundamentally require tweaking; appropriate settings for hyperparameters and methods are highly dependent on the specific corpus and the nature of the questions being asked. Evaluation is crucial and necessitates domain experts to define representative questions and expected answers. A key challenge is the decrease in answer quality when no relevant documents are found, requiring prompt adjustment.</p>
<p>Counterintuitively, RAG systems often provide worse results for widely discussed overview questions, such as inquiries about the central arguments against scientific realism, compared to more specific factual queries. A hypothesis for this phenomenon is that RAGs tend to focus on the local information present in the retrieved chunks. The prompt directs the model to answer based on this local information, which can inadvertently distract from a broader perspective. This suggests a need for prompt adjustments for different question types.</p>
<p>Ultimately, there is a need for more flexible systems, potentially agentic RAG systems, that can discern between different kinds of questions and adapt their strategy accordingly.</p>
<p>The discussion further explores challenges related to philosophical contentiousness and how RAG systems might represent diverse viewpoints, the potential for using LLMs as judges for evaluation, and the specific ways domain expertise influences RAG design, particularly in chunking and defining relevant arguments.</p>
</section>
<section id="introduction-to-rag-systems" class="level2" data-number="13.2">
<h2 data-number="13.2" class="anchored" data-anchor-id="introduction-to-rag-systems"><span class="header-section-number">13.2</span> Introduction to RAG Systems</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>The presentation is delivered from the perspective of a philosopher of science who has engaged with the technical details of Large Language Model (LLM) systems. The focus is on applying these systems, specifically Retrieval Augmented Generation (RAG), within the domain of philosophy and the broader Humanities, Politics, and Social Sciences (HPSS).</p>
<p>A core requirement in philosophical research is a high degree of linguistic and semantic accuracy, demanding deep engagement with specific textual corpora.</p>
<p>Typical research questions in philosophy include inquiries such as “What is Aristotle’s theory of matter in the <em>Physics</em>?” or “Does Einstein’s idea of locality develop from his earlier to his later works?”, referencing specific periods and texts like his relativity works and the 1948 paper on <em>Quantenmechanik und Wirklichkeit</em>. While standard LLMs like <em>ChatGPT</em> can provide decent, differentiated answers to such questions at a general level, they present several problems for rigorous philosophical research.</p>
<p>Standard LLMs lack direct access to the full text of source corpora. Although texts may have been included in their training data, the models cannot explicitly retrieve or quote them accurately. This often leads to hallucination when specific quotes are requested.</p>
<p>While online search features can sometimes provide access, they are subject to limitations such as copyright restrictions, as encountered with papers like the EPR paper. The training mechanism of LLMs is designed to prevent verbatim learning, focusing instead on generalizable statistical rules of text production, which is counter to the philosophical need for direct engagement with original text sources and their fine-grained formulations.</p>
<p>Furthermore, standard LLMs have a limited context window, such as the 128,000 tokens available in <em>ChatGPT-4</em>, which is insufficient for processing large philosophical corpora. Finally, there is a significant attribution problem, as standard LLMs do not provide sources or citations for the claims made in their answers. RAG systems are presented as a suitable setup to address these specific problems.</p>
</section>
<section id="rag-system-architecture-and-problem-solving" class="level2" data-number="13.3">
<h2 data-number="13.3" class="anchored" data-anchor-id="rag-system-architecture-and-problem-solving"><span class="header-section-number">13.3</span> RAG System Architecture and Problem Solving</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The RAG system architecture is described as a setup capable of solving the identified problems with standard LLMs in philosophical contexts. The process begins with a user initiating a query through an application (APP).</p>
<p>The APP then sends a retrieval query to designated data sources. These data sources contain the appropriate corpus, such as Aristotle’s corpus or Einstein’s corpus, and can be implemented using technologies like vector databases or APIs. The retrieval mechanism typically employs semantic search to find relevant text chunks, although hybrid or classic search methods are also viable options.</p>
<p>The data sources return the retrieved chunks of text to the APP. The APP then augments the original LLM query by incorporating these retrieved chunks into the prompt.</p>
<p>This augmented query is sent to the LLM, which performs text generation based on the provided information. The LLM returns the generated answer to the APP, which finally delivers the answer to the user.</p>
<p>This RAG setup directly addresses the problems faced by standard LLMs. It solves the problem of access by providing explicit access to specific texts within the defined corpus, ensuring that the LLM works with the actual source material.</p>
<p>It mitigates the problem of the limited context window by providing only the most relevant text chunks to the LLM, effectively managing the input size within the model’s capacity. Furthermore, the RAG system solves the attribution problem by enabling the citation of sources for the provided text chunks, allowing users to verify the basis of the generated claims.</p>
</section>
<section id="applications-in-philosophy" class="level2" data-number="13.4">
<h2 data-number="13.4" class="anchored" data-anchor-id="applications-in-philosophy"><span class="header-section-number">13.4</span> Applications in Philosophy</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The general idea behind applying RAG systems in philosophy is to enable users to chat with philosophical corpora. This interaction style is similar to using <em>ChatGPT</em> but provides significantly more detailed domain knowledge and is grounded in a verbatim text basis from the specified corpus.</p>
<p>Didactic applications are a key area. RAG systems are useful for students approaching complex philosophical texts, such as Locke’s <em>Essay Concerning Human Understanding</em>.</p>
<p>They allow for repeated questioning, enabling students to start with general ideas and progressively delve deeper into specific details, like Locke’s epistemology or his theory of matter. This interactive process provides an instructive method for students to gain a deeper understanding of the texts.</p>
<p>Research applications are also emphasized. RAG systems are expected to be important for looking up facts in handbooks, serving functions previously performed by manually consulting books for orientation, remarks, or footnote information.</p>
<p>This addresses the unreliability of factual information obtained solely from standard LLMs and necessitates the development of high-quality RAG systems for reliable factual retrieval. Other research uses include exploring corpora that have not been extensively studied, efficiently finding specific passages for close reading, and potentially, in the future, directly finding detailed answers to complex research questions.</p>
</section>
<section id="example-stanford-encyclopedia-of-philosophy-rag-system" class="level2" data-number="13.5">
<h2 data-number="13.5" class="anchored" data-anchor-id="example-stanford-encyclopedia-of-philosophy-rag-system"><span class="header-section-number">13.5</span> Example: Stanford Encyclopedia of Philosophy RAG System</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>An example RAG system was developed using the <em>Stanford Encyclopedia of Philosophy</em> (SEP) as the data source. The content of the SEP was prepared by scraping it into markdown format. The initial aim of this project was to create a useful tool for the philosophical community.</p>
<p>The development process evolved into a qualitative study employing theoretically grounded trial and error. An observation during the initial setup was that a standard RAG configuration, based on typical textbook descriptions involving only retrieval and generation components, produced poor answers.</p>
<p>These answers were found to be worse than those obtained by querying a standard LLM like <em>ChatGPT</em> directly without retrieval augmentation.</p>
<p>This led to an iterative improvement process involving significant tweaking and optimization. This included tweaking the choice of models, specifically selecting the appropriate generative LLM and embedding model.</p>
<p>Hyperparameters were also tuned, including the number of documents to retrieve (top-k), the maximum input and output token lengths, and the chunk size and overlap used for text processing. Furthermore, methodological complexities were added, such as implementing reranking mechanisms to address issues of retrieval semantic mismatch, where initially retrieved chunks might not be the most relevant.</p>
<p>The method for evaluating these improvements was theoretically grounded trial and error, assessing by which measures the answers improved. Sound evaluation standards were identified as crucial.</p>
<p>A key challenge in evaluating philosophical RAG systems is that the desired answers are typically free, unstructured text rather than simple atomic facts (like asking for Wittgenstein’s last place of living, which yields a city name). Evaluating complex propositions for their factual accuracy is not straightforward and requires significant domain expertise.</p>
</section>
<section id="sep-rag-system-implementation" class="level2" data-number="13.6">
<h2 data-number="13.6" class="anchored" data-anchor-id="sep-rag-system-implementation"><span class="header-section-number">13.6</span> SEP RAG System Implementation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>The implemented SEP RAG system consists of a frontend and a backend, which is written in Python code. The frontend provides a web interface with several configurable options.</p>
<p>Users can select the Generative Model to be used, such as <em>gpt-4o-mini</em>. There are settings for the Prompt Token Limit, including the maximum limit supported by the chosen model (e.g., 128000) and a configurable limit for the current session (e.g., 15000). The number of texts to retrieve, corresponding to the top-k value, is also configurable (e.g., 15). A Persona text area allows defining the desired behavior for the LLM, for instance, instructing it to act as “an expert philosopher” who answers “meticulously and precisely.”</p>
<p>The frontend includes an input field for the Philosophical Question, where users enter their query (e.g., “What is priority monism?”). A “Generate answer” button triggers the RAG process.</p>
<p>The output section is designed for qualitative evaluation, featuring a comparative setup. It displays the “Answer with LLM alone” as a benchmark on one side and the “Answer with RAG” on the other. The RAG answer includes source citation indicators, such as “[Text 0]”, linking parts of the answer to the retrieved texts. A “Benchmark” button is available for comparative evaluation.</p>
<p>Below the answers, a “Retrieved Texts Overview” table lists the texts found during the retrieval phase. This table includes columns for file names, section headings, distance metrics, token lengths (length_token for the chunk, total_token for the full section/file), and a flag indicating whether the text was included in the final prompt based on token limits. This table shows the article names and specific section headings that were retrieved and indicates which ones were utilized in the prompt and which were excluded due to prompt length constraints. The backend functionality is implemented in Python code, described as comprising a few thousand lines.</p>
</section>
<section id="hyperparameter-tuning-chunk-size" class="level2" data-number="13.7">
<h2 data-number="13.7" class="anchored" data-anchor-id="hyperparameter-tuning-chunk-size"><span class="header-section-number">13.7</span> Hyperparameter Tuning: Chunk Size</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_15.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>Chunk size is identified as a key hyperparameter requiring optimization in RAG system development. Several options exist for defining text chunks.</p>
<p>One approach is using a fixed number of words, such as 500 tokens or words. This provides a clean criterion but disregards the inherent structure of the document, such as headings or sections. Alternative methods involve chunking by semantic units like paragraphs or sections, potentially considering different hierarchical levels of sections.</p>
<p>For the specific case of the SEP corpus, the optimization process revealed a surprising result: the best performance was achieved by chunking the text into its main sections, including their headings.</p>
<p>This finding was unexpected because the average length of SEP sections (approximately 3000 words) significantly exceeded the typical cutoff length of the embedding model used (512 words). Despite this discrepancy, chunking by main sections yielded superior results compared to smaller, fixed-size chunks or paragraphs.</p>
<p>A hypothesis for this surprising outcome is that the SEP documents are highly systematically ordered. The initial parts of each section often effectively summarize the main theme and key ideas. These crucial introductory segments likely fall within the effective context window of the embedding model, even if the entire section is much longer.</p>
<p>This suggests that the structure and organization of the corpus play a significant role in determining the optimal chunking strategy, and this approach might not be as effective for less structured or heterogeneous texts.</p>
<p>Future work is planned to explore the use of embedding models with longer context windows, such as <em>Cohere Embed 3</em>, to see if they further improve performance with larger chunks.</p>
<p>The key lesson derived from this optimization process is that effective chunking is not a one-size-fits-all solution; it highly depends on the specific characteristics of the corpus being used and the nature of the questions being posed.</p>
</section>
<section id="results-discussion-and-challenges" class="level2" data-number="13.8">
<h2 data-number="13.8" class="anchored" data-anchor-id="results-discussion-and-challenges"><span class="header-section-number">13.8</span> Results, Discussion, and Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_18.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
<p>The results and discussion highlight several advantages of RAG systems. They effectively integrate verbatim corpora and domain-specific or special knowledge, leading to more detailed answers and a dramatic reduction in hallucinations compared to standard LLMs.</p>
<p>RAG systems also enable the citation of relevant documents supporting the generated answer. Overall, the RAG setup is identified as being very well suited for assisting in a wide range of scientific tasks.</p>
<p>However, several cautionary points are raised. RAG systems fundamentally require tweaking; appropriate settings for hyperparameters and methods are highly dependent on the specific corpus and the nature of the questions being asked.</p>
<p>The evaluation of RAG systems is crucial and necessitates a representative set of questions along with expected answers. This process essentially requires domain experts, such as philosophers in this context, for both evaluation and initial setup, as the optimal configuration is specific to the domain, the type of corpus, and the kind of questions. A challenge remains regarding how to effectively evaluate RAG performance when dealing with unexplored corpora.</p>
<p>Several challenges are also identified. A decrease in answer quality occurs if no relevant documents are found during retrieval, indicating a need to adjust the prompt in such cases.</p>
<p>Counterintuitively, RAG systems often provide worse results for widely discussed overview questions, such as inquiries about the central arguments against scientific realism, compared to more specific factual queries. A hypothesis for this phenomenon is that RAGs tend to focus on the local information present in the retrieved chunks. The prompt directs the model to answer based on this local information, which can inadvertently distract from a broader perspective. This suggests a need for prompt adjustments for different question types.</p>
<p>Ultimately, there is a need for more flexible systems, potentially agentic RAG systems, that can discern between different kinds of questions and adapt their strategy accordingly.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_011.html" class="pagination-link" aria-label="Chatting with Papers">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Plural pursuit across scales">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>