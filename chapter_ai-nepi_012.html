<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Paul Näger">
<meta name="dcterms.date" content="2025-01-01">

<title>12&nbsp; RAG in HPSS – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_015.html" rel="next">
<link href="./chapter_ai-nepi_011.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_012.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG in HPSS</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals, ActDisease Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Computational Epistemology and Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG in HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#addressing-llm-limitations-in-philosophical-inquiry" id="toc-addressing-llm-limitations-in-philosophical-inquiry" class="nav-link" data-scroll-target="#addressing-llm-limitations-in-philosophical-inquiry"><span class="header-section-number">12.1</span> Addressing <em>LLM</em> Limitations in Philosophical Inquiry</a></li>
  <li><a href="#core-rag-system-architecture" id="toc-core-rag-system-architecture" class="nav-link" data-scroll-target="#core-rag-system-architecture"><span class="header-section-number">12.2</span> Core RAG System Architecture</a></li>
  <li><a href="#document-retrieval-and-prompt-augmentation" id="toc-document-retrieval-and-prompt-augmentation" class="nav-link" data-scroll-target="#document-retrieval-and-prompt-augmentation"><span class="header-section-number">12.3</span> Document Retrieval and Prompt Augmentation</a></li>
  <li><a href="#addressing-the-problem-of-access-and-llm-training-limitations" id="toc-addressing-the-problem-of-access-and-llm-training-limitations" class="nav-link" data-scroll-target="#addressing-the-problem-of-access-and-llm-training-limitations"><span class="header-section-number">12.4</span> Addressing the Problem of Access and <em>LLM</em> Training Limitations</a></li>
  <li><a href="#context-window-limitations-and-philosophical-research-needs" id="toc-context-window-limitations-and-philosophical-research-needs" class="nav-link" data-scroll-target="#context-window-limitations-and-philosophical-research-needs"><span class="header-section-number">12.5</span> Context Window Limitations and Philosophical Research Needs</a></li>
  <li><a href="#solving-the-attribution-problem-and-general-applications" id="toc-solving-the-attribution-problem-and-general-applications" class="nav-link" data-scroll-target="#solving-the-attribution-problem-and-general-applications"><span class="header-section-number">12.6</span> Solving the Attribution Problem and General Applications</a></li>
  <li><a href="#didactic-applications-of-rag-systems" id="toc-didactic-applications-of-rag-systems" class="nav-link" data-scroll-target="#didactic-applications-of-rag-systems"><span class="header-section-number">12.7</span> Didactic Applications of RAG Systems</a></li>
  <li><a href="#research-applications-factual-lookups" id="toc-research-applications-factual-lookups" class="nav-link" data-scroll-target="#research-applications-factual-lookups"><span class="header-section-number">12.8</span> Research Applications: Factual Lookups</a></li>
  <li><a href="#advanced-research-applications-and-future-vision" id="toc-advanced-research-applications-and-future-vision" class="nav-link" data-scroll-target="#advanced-research-applications-and-future-vision"><span class="header-section-number">12.9</span> Advanced Research Applications and Future Vision</a></li>
  <li><a href="#the-stanford-encyclopedia-of-philosophy-rag-example" id="toc-the-stanford-encyclopedia-of-philosophy-rag-example" class="nav-link" data-scroll-target="#the-stanford-encyclopedia-of-philosophy-rag-example"><span class="header-section-number">12.10</span> The Stanford Encyclopedia of Philosophy RAG Example</a></li>
  <li><a href="#project-aims-and-initial-findings" id="toc-project-aims-and-initial-findings" class="nav-link" data-scroll-target="#project-aims-and-initial-findings"><span class="header-section-number">12.11</span> Project Aims and Initial Findings</a></li>
  <li><a href="#optimisation-strategies-and-evaluation-challenges" id="toc-optimisation-strategies-and-evaluation-challenges" class="nav-link" data-scroll-target="#optimisation-strategies-and-evaluation-challenges"><span class="header-section-number">12.12</span> Optimisation Strategies and Evaluation Challenges</a></li>
  <li><a href="#the-crucial-role-of-sound-evaluation" id="toc-the-crucial-role-of-sound-evaluation" class="nav-link" data-scroll-target="#the-crucial-role-of-sound-evaluation"><span class="header-section-number">12.13</span> The Crucial Role of Sound Evaluation</a></li>
  <li><a href="#sep-rag-system-frontend-and-configuration" id="toc-sep-rag-system-frontend-and-configuration" class="nav-link" data-scroll-target="#sep-rag-system-frontend-and-configuration"><span class="header-section-number">12.14</span> <em>SEP</em> RAG System Frontend and Configuration</a></li>
  <li><a href="#comparative-output-display" id="toc-comparative-output-display" class="nav-link" data-scroll-target="#comparative-output-display"><span class="header-section-number">12.15</span> Comparative Output Display</a></li>
  <li><a href="#retrieved-texts-overview" id="toc-retrieved-texts-overview" class="nav-link" data-scroll-target="#retrieved-texts-overview"><span class="header-section-number">12.16</span> Retrieved Texts Overview</a></li>
  <li><a href="#optimising-chunk-size-for-philosophical-texts" id="toc-optimising-chunk-size-for-philosophical-texts" class="nav-link" data-scroll-target="#optimising-chunk-size-for-philosophical-texts"><span class="header-section-number">12.17</span> Optimising Chunk Size for Philosophical Texts</a></li>
  <li><a href="#reranking-for-enhanced-relevance" id="toc-reranking-for-enhanced-relevance" class="nav-link" data-scroll-target="#reranking-for-enhanced-relevance"><span class="header-section-number">12.18</span> Reranking for Enhanced Relevance</a></li>
  <li><a href="#results-and-discussion-overview" id="toc-results-and-discussion-overview" class="nav-link" data-scroll-target="#results-and-discussion-overview"><span class="header-section-number">12.19</span> Results and Discussion Overview</a></li>
  <li><a href="#advantages-cautions-and-challenges-of-rag-systems" id="toc-advantages-cautions-and-challenges-of-rag-systems" class="nav-link" data-scroll-target="#advantages-cautions-and-challenges-of-rag-systems"><span class="header-section-number">12.20</span> Advantages, Cautions, and Challenges of RAG Systems</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG in HPSS</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Paul Näger <a href="mailto:paul.naeger@cis.lmu.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            LMU München
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This presentation explores the application and optimisation of Retrieval-Augmented Generation (RAG) systems within the humanities, particularly philosophy. The project team developed a RAG system to address the inherent limitations of Large Language Models (<em>LLMs</em>), such as their inability to access full texts, their tendency to hallucinate, and their restricted context windows. The system aims to provide accurate, detailed, and attributable answers to complex philosophical research questions by integrating verbatim corpora and specialised domain knowledge.</p>
<p>The core RAG architecture establishes a dedicated data source for document retrieval. This setup requires the integration of a pertinent corpus, such as the complete works of Aristotle or Einstein, to serve as the foundational knowledge base for the system.</p>
<p>The retrieval process involves identifying relevant documents from this source using semantic, hybrid, or classic search methods. These retrieved text chunks then augment the <em>LLM</em>’s prompts, enabling more precise and contextually rich responses. A key innovation lies in the system’s capacity to cite original sources, thereby resolving the attribution problem crucial for academic rigour.</p>
<p>A practical implementation, the Stanford Encyclopedia of Philosophy (<em>SEP</em>) RAG system, serves as a compelling case study. Initial development revealed that a basic RAG configuration yielded suboptimal results, necessitating extensive qualitative study and iterative refinement. This optimisation process involved careful selection of generative <em>LLMs</em> and embedding models, alongside meticulous tuning of hyperparameters such as the number of retrieved documents (top-k), token limits, generation temperature, and chunk size. Notably, chunking by main sections, despite exceeding the embedding model’s typical cutoff, proved most effective for philosophical texts owing to their highly systematised structure.</p>
<p>Further enhancements included a reranking mechanism, where a generative <em>LLM</em> evaluates the relevance of retrieved texts to mitigate false positives, albeit at increased computational cost. The system’s frontend provides a comparative interface, displaying answers from both a standalone <em>LLM</em> and the RAG system, alongside a detailed overview of the retrieved texts.</p>
<p>Whilst RAG systems offer significant advantages—including reduced hallucinations, enhanced detail, and source citation—they present distinct challenges. Their performance is highly dependent on domain-specific refinement and robust evaluation, which necessitates representative question sets and the indispensable involvement of domain experts. Furthermore, RAGs can paradoxically underperform on broad overview questions, as their focus on local information may obscure wider perspectives. This highlights a future need for more flexible, potentially agentic, RAG systems capable of discerning question types and adapting their retrieval strategies accordingly.</p>
</section>
<section id="addressing-llm-limitations-in-philosophical-inquiry" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="addressing-llm-limitations-in-philosophical-inquiry"><span class="header-section-number">12.1</span> Addressing <em>LLM</em> Limitations in Philosophical Inquiry</h2>
<p>Philosophers frequently pose complex research questions demanding high linguistic and semantic accuracy. For instance, inquiries might concern Aristotle’s theory of matter as presented in his <em>Physics</em>, or the evolution of Einstein’s concept of locality from his early works on relativity through to his 1948 paper, <em>Quantenmechanik und Wirklichkeit</em>. Whilst Large Language Models (<em>LLMs</em>) like <em>ChatGPT</em> can offer reasonably differentiated answers to such queries, they exhibit inherent limitations. Retrieval-Augmented Generation (RAG) systems offer a compelling architectural solution, precisely engineered to surmount these challenges.</p>
</section>
<section id="core-rag-system-architecture" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="core-rag-system-architecture"><span class="header-section-number">12.2</span> Core RAG System Architecture</h2>
<p>The fundamental RAG architecture establishes a dedicated data source from which documents are retrieved. This setup requires the integration of a pertinent corpus, such as the complete works of Aristotle or Einstein, to serve as the foundational knowledge base for the system.</p>
</section>
<section id="document-retrieval-and-prompt-augmentation" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="document-retrieval-and-prompt-augmentation"><span class="header-section-number">12.3</span> Document Retrieval and Prompt Augmentation</h2>
<p>Document retrieval within the RAG framework typically utilises semantic search, though hybrid or classic search methods also present viable alternatives. Crucially, the system augments the <em>LLM</em>’s prompts with the most relevant text chunks identified during this retrieval phase. This process ensures the language model receives highly pertinent contextual information for generating its responses.</p>
</section>
<section id="addressing-the-problem-of-access-and-llm-training-limitations" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="addressing-the-problem-of-access-and-llm-training-limitations"><span class="header-section-number">12.4</span> Addressing the Problem of Access and <em>LLM</em> Training Limitations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>RAG systems primarily address the <em>LLM</em>’s limited access to full texts. Whilst extensive corpora may inform an <em>LLM</em>’s training data, the model cannot directly access or reliably quote specific chapters or papers during inference. This limitation frequently results in hallucination, wherein the model fabricates information. Although online search functionalities can sometimes enable quoting, copyright restrictions, as encountered with the <em>EPR</em> paper, often impede direct reproduction. Fundamentally, <em>LLM</em> training mechanisms are engineered to acquire generalisable statistical rules for text production, not to memorise texts verbatim. Indeed, explicit mechanisms within their design actively preclude these systems from verbatim reproduction.</p>
</section>
<section id="context-window-limitations-and-philosophical-research-needs" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="context-window-limitations-and-philosophical-research-needs"><span class="header-section-number">12.5</span> Context Window Limitations and Philosophical Research Needs</h2>
<p>Philosophical research inherently necessitates direct engagement with original text sources, requiring deep analysis of their most fine-grained formulations. This necessity directly challenges the issue of <em>LLMs</em>’ limited context windows. RAG systems provide a vital solution by furnishing the language model with only the most relevant text chunks, thereby circumventing context window constraints whilst ensuring access to the precise textual evidence required for rigorous philosophical inquiry.</p>
</section>
<section id="solving-the-attribution-problem-and-general-applications" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="solving-the-attribution-problem-and-general-applications"><span class="header-section-number">12.6</span> Solving the Attribution Problem and General Applications</h2>
<p>RAG systems efficaciously resolve the attribution problem by citing the sources of all provided text chunks. This capability forms the basis for a broader application: enabling users to “chat” with philosophical corpora, such as Locke’s complete works. Their objective is to facilitate interactions yielding significantly more detailed domain knowledge and a verifiable verbatim text basis, thereby surpassing the capabilities of standard <em>LLMs</em> like <em>ChatGPT</em>.</p>
</section>
<section id="didactic-applications-of-rag-systems" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="didactic-applications-of-rag-systems"><span class="header-section-number">12.7</span> Didactic Applications of RAG Systems</h2>
<p>RAG systems present substantial didactic utility, furnishing an instructive methodology for students to engage deeply with complex texts. For instance, students approaching Locke’s <em>Essay Concerning Human Understanding</em> may commence their study by querying the system for Locke’s general ideas, then progressively delve into more specific topics such as his epistemology or theory of matter. This iterative questioning cultivates a structured and efficacious learning progression, guiding students into profound textual engagement.</p>
</section>
<section id="research-applications-factual-lookups" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="research-applications-factual-lookups"><span class="header-section-number">12.8</span> Research Applications: Factual Lookups</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Beyond didactic uses, RAG systems possess considerable significance for academic research, particularly for factual lookups within handbooks. This functionality directly supplants the traditional method of manually consulting physical books to find relevant pages for orientation, remarks, or footnotes. Crucially, RAG systems surmount the inherent unreliability of standalone <em>LLMs</em> for such precise factual lookups, ensuring the information retrieved is both accurate and verifiable.</p>
</section>
<section id="advanced-research-applications-and-future-vision" class="level2" data-number="12.9">
<h2 data-number="12.9" class="anchored" data-anchor-id="advanced-research-applications-and-future-vision"><span class="header-section-number">12.9</span> Advanced Research Applications and Future Vision</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>RAG systems broaden their research utility to encompass the exploration of previously unexamined corpora, though this first requires digitisation of the texts. Furthermore, they enable the identification of specific passages for close reading, directly pertinent to a researcher’s inquiry. Ultimately, these systems possess the potential to furnish detailed answers to at least portions of complex research questions. This comprehensive vision aims to elucidate the transformative capabilities RAG systems could bring to future philosophical research.</p>
</section>
<section id="the-stanford-encyclopedia-of-philosophy-rag-example" class="level2" data-number="12.10">
<h2 data-number="12.10" class="anchored" data-anchor-id="the-stanford-encyclopedia-of-philosophy-rag-example"><span class="header-section-number">12.10</span> The Stanford Encyclopedia of Philosophy RAG Example</h2>
<p>The project team has developed an exemplary RAG system employing the Stanford Encyclopedia of Philosophy (<em>SEP</em>) as its primary data source. The <em>SEP</em>, a widely recognised online philosophical handbook, furnishes a robust and authoritative corpus for this application.</p>
</section>
<section id="project-aims-and-initial-findings" class="level2" data-number="12.11">
<h2 data-number="12.11" class="anchored" data-anchor-id="project-aims-and-initial-findings"><span class="header-section-number">12.11</span> Project Aims and Initial Findings</h2>
<p>The project team commenced by scraping the Stanford Encyclopedia’s content into Markdown format, with the initial objective of crafting a practical tool for the philosophical community. However, early trials uncovered a critical insight: a conventional RAG setup, as described in standard textbooks (comprising only retrieval and generation components), yielded answers inferior to those generated by a standalone <em>ChatGPT</em>. This unexpected outcome necessitated a revision of the project’s focus, pivoting towards a qualitative study dedicated to optimising RAG system configurations specifically for philosophical applications.</p>
</section>
<section id="optimisation-strategies-and-evaluation-challenges" class="level2" data-number="12.12">
<h2 data-number="12.12" class="anchored" data-anchor-id="optimisation-strategies-and-evaluation-challenges"><span class="header-section-number">12.12</span> Optimisation Strategies and Evaluation Challenges</h2>
<p>Improving RAG system performance demands a multifaceted approach, encompassing meticulous refinement and the integration of algorithmic sophistication. Key areas for adjustment involve selecting appropriate generative <em>LLMs</em> and embedding models, alongside fine-tuning various hyperparameters. These parameters include the number of documents retrieved (top-k), the maximum input and output token lengths, the temperature or top-p settings for generation, and the chunk size and overlap. Furthermore, addressing methodological challenges such as retrieval semantic mismatch frequently necessitates more intricate algorithms, including reranking.</p>
<p>The overarching methodological approach entails a theoretically grounded iterative process, systematically assessing which measures enhance answer quality. This process is particularly challenging in philosophy, where answers typically manifest as complex, unstructured text rather than atomic facts, such as “Wittgenstein’s last place of living.” Consequently, the authors must rigorously assess whether the generated propositions accurately reflect the underlying facts, a task requiring sophisticated evaluation criteria.</p>
</section>
<section id="the-crucial-role-of-sound-evaluation" class="level2" data-number="12.13">
<h2 data-number="12.13" class="anchored" data-anchor-id="the-crucial-role-of-sound-evaluation"><span class="header-section-number">12.13</span> The Crucial Role of Sound Evaluation</h2>
<p>Sound evaluation is paramount for the effective deployment of RAG systems. Nevertheless, assessing the accuracy and quality of complex philosophical propositions poses a considerable challenge, necessitating robust and nuanced evaluation methodologies.</p>
</section>
<section id="sep-rag-system-frontend-and-configuration" class="level2" data-number="12.14">
<h2 data-number="12.14" class="anchored" data-anchor-id="sep-rag-system-frontend-and-configuration"><span class="header-section-number">12.14</span> <em>SEP</em> RAG System Frontend and Configuration</h2>
<p>The <em>SEP</em> RAG system integrates a user-friendly frontend with a Python-based backend. The frontend features a ‘Configuration’ section, complete with an ‘Initialize’ button, alongside an ‘Options’ section. Within these options, users can select a generative model, with <em>gpt-4o-mini</em> being the default choice, and configure prompt token limits (e.g., model limit of 128,000, system limit of 15,000). A ‘Persona’ setting, which defines the <em>LLM</em> as “an expert philosopher” who answers “meticulously and precisely,” guides the generation process. Users further specify the number of texts to retrieve, typically set at 15. A dedicated ‘Philosophical Question’ text box enables users to input queries, such as “What is priority monism?”, before initiating the answer generation process with a ‘Generate answer’ button.</p>
</section>
<section id="comparative-output-display" class="level2" data-number="12.15">
<h2 data-number="12.15" class="anchored" data-anchor-id="comparative-output-display"><span class="header-section-number">12.15</span> Comparative Output Display</h2>
<p>The system features a comparative output display for generated answers. The left side, serving as the benchmark, presents the answer produced by a standalone <em>LLM</em>, such as <em>ChatGPT</em>. Conversely, the right side showcases the answer generated by the RAG system. This side-by-side presentation considerably facilitates the comparison of answer quality between the two approaches.</p>
</section>
<section id="retrieved-texts-overview" class="level2" data-number="12.16">
<h2 data-number="12.16" class="anchored" data-anchor-id="retrieved-texts-overview"><span class="header-section-number">12.16</span> Retrieved Texts Overview</h2>
<p>The system’s output includes a crucial component: a comprehensive list of all retrieved texts. For each text, the system furnishes detailed information, encompassing article names, relevant section headings, the text’s length in tokens, the total token count, and its inclusion status—indicating whether the text was fully incorporated into the prompt or truncated owing to prompt limitations.</p>
</section>
<section id="optimising-chunk-size-for-philosophical-texts" class="level2" data-number="12.17">
<h2 data-number="12.17" class="anchored" data-anchor-id="optimising-chunk-size-for-philosophical-texts"><span class="header-section-number">12.17</span> Optimising Chunk Size for Philosophical Texts</h2>
<p>Optimising chunk size constitutes a critical hyperparameter tuning step. Initially, three primary chunking options emerged: a fixed number of words (e.g., 500 tokens or words), paragraphs, or sections (at various hierarchical levels). Surprisingly, chunking the content into main sections, inclusive of their headings, consistently produced the most favourable outcomes. This outcome accords with the nature of philosophical facts, which seldom manifest as brief, isolated statements; instead, they often require substantial textual space for comprehensive presentation, thereby favouring longer semantic units.</p>
<p>A significant observation emerged from this optimisation: the average length of these optimal sections, approximately 3,000 words, substantially exceeded the embedding model’s typical cutoff of 512 words. This counter-intuitive success likely derives from the highly systematised structure of the Stanford Encyclopedia of Philosophy. Within such meticulously organised documents, the initial 500 words of a section frequently encapsulate its central themes and main ideas. However, this specific chunking strategy may not prove efficacious for more heterogeneous or less rigorously structured texts.</p>
</section>
<section id="reranking-for-enhanced-relevance" class="level2" data-number="12.18">
<h2 data-number="12.18" class="anchored" data-anchor-id="reranking-for-enhanced-relevance"><span class="header-section-number">12.18</span> Reranking for Enhanced Relevance</h2>
<p>Reranking represents an additional, pivotal step within the retrieval process. This technique mitigates the issue of false positives, where not all initially retrieved texts prove pertinent to the user’s query. Reranking’s primary objective is to reorder documents according to their genuine relevance. A generative <em>LLM</em> (<em>gLLM</em>) conducts this evaluation, furnishing a more advanced semantic differentiation capability than the initial embedding model. The <em>gLLM</em> evaluates texts based on scoring categories such as informativeness and the length of relevant passages, subsequently calculating a total score for each document. Whilst this method yields highly favourable results in terms of relevance, it substantially increases computational expenditure.</p>
</section>
<section id="results-and-discussion-overview" class="level2" data-number="12.19">
<h2 data-number="12.19" class="anchored" data-anchor-id="results-and-discussion-overview"><span class="header-section-number">12.19</span> Results and Discussion Overview</h2>
<p>This section offers a comprehensive overview of the results and discussion concerning RAG systems, with a particular focus on their distinct advantages.</p>
</section>
<section id="advantages-cautions-and-challenges-of-rag-systems" class="level2" data-number="12.20">
<h2 data-number="12.20" class="anchored" data-anchor-id="advantages-cautions-and-challenges-of-rag-systems"><span class="header-section-number">12.20</span> Advantages, Cautions, and Challenges of RAG Systems</h2>
<p>RAG systems present compelling advantages for academic inquiry. They seamlessly integrate verbatim corpora with specialised domain knowledge, consequently yielding more detailed answers whilst significantly reducing the incidence of hallucinations. Furthermore, these systems enable the citation of pertinent documents, a critical feature for academic integrity. Collectively, these capabilities render RAG configurations exceptionally well-suited for assisting across a broad spectrum of scientific tasks.</p>
<p>Nevertheless, several caveats warrant consideration. RAG systems inherently necessitate extensive refinement; optimal configurations vary considerably depending on the specific corpus and the nature of the questions posed. Crucially, robust evaluation remains paramount, demanding a representative set of questions and their corresponding expected answers. This process highlights the indispensable role of domain experts, particularly when engaging with unexplored corpora.</p>
<p>Significant challenges also persist. Should the system fail to retrieve pertinent documents, the quality of the generated answer demonstrably diminishes, thereby necessitating prompt adjustment. Paradoxically, RAG systems often yield suboptimal results for widely discussed overview questions, such as “What are the central arguments against scientific realism?” This phenomenon arises because RAGs tend to concentrate on the local information they retrieve, which can inadvertently obscure the broader perspective essential for comprehensive overview responses. Addressing this limitation necessitates the development of more adaptable systems, including agentic RAG systems, capable of discerning distinct question types and adjusting their retrieval and generation strategies accordingly.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_011.html" class="pagination-link" aria-label="Science dynamics and AI">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Quantum Gravity and Plural Pursuit in Science">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>