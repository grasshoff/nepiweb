---
title: "Towards Interpretable Models: Bridging Traditional and Deep Learning Methods for Tracing Linguistic Change in English Scientific Writing"
author:
- name: "Sofía Aguilar & Stefania Degaetano-Ortlieb"
  affiliation: "AI-NEPI Conference Participant"
date: '2025-07-31'
bibliography: bibliography.bib
---
## Overview {.unnumbered}

This research programme investigates the interplay between different forms of context in shaping language variation and semantic change. It operates within the *Cascade* project, a Marie Curie Doctoral Network dedicated to the computational analysis of semantic change across diverse environments. As a pilot study, the project examines the chemical revolution—a pivotal paradigm shift from the phlogiston theory to modern oxygen theory—using the Royal Society Corpus as its primary data source.

To understand how language adapts to scientific evolution, the investigation integrates principles from linguistics and information theory, including language variation, register theory, and rational communication. The team employs a multi-faceted computational toolkit to dissect this process. Previous work demonstrated the utility of Kullback-Leibler divergence for detecting periods of significant linguistic change, and cascade models, based on Hawkes processes, for identifying key innovators like Priestley and influential spreaders like Pearson.

Furthermore, the authors used *word2vec* to visualise the displacement of the 'phlogiston' semantic space by 'oxygen' terminology. They also applied the concept of surprisal to model the cognitive effort associated with new terms, demonstrating how structural compression fosters more efficient terminology as concepts become established. Building on this foundation, the current project, led by PhD student Sofía Aguilar, aims to synthesise these approaches. Aguilar proposes a novel framework combining *BERT* embeddings with a *Transformer-Graph Convolutional Network* (*GCN*) to model the latent interactions between semantic content and contextual metadata, thereby creating a more holistic understanding of conceptual change.

## A Framework for Scientific Discourse

![Slide 19](images/ai-nepi_019_slide_19.png)

The authors have developed a robust theoretical framework to analyse transformations in scientific discourse, situating their work within the *Cascade* project. Their central objective is to model how different forms of context interact to drive semantic change. For this purpose, the project uses the chemical revolution as a pilot case study, drawing on texts from the Royal Society Corpus.

The investigation rests upon two key linguistic principles. First, language variation and register theory posit that situational context fundamentally shapes language use. This theory also explains how the linguistic system’s inherent flexibility permits various encodings for a concept, such as the evolution from 'dephlogisticated air' to the term 'oxygen'.

Second, the framework incorporates principles of rational communication and information theory. These principles suggest that such variation is not arbitrary; instead, it serves as a mechanism for modulating information content. This allows speakers and writers to achieve efficient communication whilst keeping cognitive effort at a reasonable level.

## Detecting Change with KL Divergence

To pinpoint moments of linguistic transformation, the team employs Kullback-Leibler (KL) divergence, a method that moves beyond the static comparisons of predefined periods common in traditional corpus linguistics. Instead, the authors model change as a continuous process. Their underlying assumption is that linguistic divergence increases with temporal distance; language from periods far apart should differ more than language from adjacent periods.

In practice, the team creates a continuous timeline of language use by calculating KL divergence repeatedly within sliding temporal bins. This dynamic process yields a diachronic comparison that highlights moments of significant transformation, visualised as peaks of divergence, and periods of stability, represented by troughs of convergence.

## Tracking Lexical and Grammatical Evolution

The team’s analysis of linguistic evolution extends across both lexical and grammatical levels to construct a comprehensive picture of change. At the lexical level, their diachronic comparison reveals that peaks in divergence are primarily driven by the emergence of new terminology. During the chemical revolution, for instance, scientists first wrote about experimenting with 'air' that was 'dephlogisticated' long before the concept and term 'oxygen' became established.

Simultaneously, the authors track grammatical shifts by retaining function words that are often discarded in such analyses. By analysing part-of-speech (POS) trigrams, they identify grammatical patterns that co-occur with and support lexical innovation. These structures, such as adjectival patterns like 'dephlogisticated air' or nominal phrases like 'oxide of iron', also generate divergence peaks, which demonstrates that grammar plays an active role in expressing new scientific concepts.

## Visualising Paradigmatic Shifts

To visualise the profound conceptual shifts occurring during the chemical revolution, the authors modelled the semantic space using the *word2vec* method. This approach maps the relationships between terms, offering a visual representation of the paradigmatic context.

The results of this analysis proved decisive. Their model showed how the established 'phlogiston' semantic space was systematically replaced by terminology associated with the new oxygen theory. Over time, the term 'phlogiston' and its related concepts occupied a progressively smaller area within the semantic map, eventually disappearing from the dominant scientific discourse.

## Identifying Innovators and Spreaders

Beyond tracking *what* changes, the authors sought to identify *who* drives these transformations. To determine the key actors leading and disseminating new scientific terminology, the team employed cascade models, a methodology derived from Hawkes processes. This technique, originating in fields like seismology and now applied to social media analysis, models how events trigger subsequent events in a network.

By applying these models to the usage of chemical terms in the Royal Society Corpus, the authors could distinguish innovators from their followers. Their analysis identified distinct roles within the scientific community: Priestley emerged as a central innovator, who in turn heavily influenced George Pearson, a critical early adopter and spreader responsible for disseminating the new terminology. The models also successfully categorised other figures, such as late adopters, providing a clear map of the innovation's diffusion.

## Surprisal, Effort, and Terminological Change

To understand the underlying rationale for terminological evolution, the team's analysis adopts a communicative perspective centred on the concept of surprisal. Surprisal quantifies the predictability of a word in a given context and is proportional to the cognitive effort required to process it; a highly surprising word is informative but difficult to process. The first mention of 'oxygen' by Priestley, for example, carried a high surprisal value for its contemporary readers.

The authors observed a distinct evolutionary pattern they term structural compression. Initially, a new technical term exhibits high surprisal. As it gains traction within the community, its usage becomes more common and its surprisal value steadily declines, eventually reaching a saturation point. This reduction in collective cognitive effort paves the way for a more compact and efficient linguistic form to emerge. Crucially, the authors note that this mechanism appears to be a specific feature of terminological development, as it does not apply to the evolution of general-purpose phrases.

## A Unified Framework for Contextual Interactions

Building on this foundation, a new project led by Sofía Aguilar aims to create a unified framework for modelling the interaction between diverse contextual factors. Her multi-stage methodology seeks to provide a more holistic view of conceptual change. The process begins with data sampling, where Aguilar uses Kullback-Leibler divergence to identify the key terms and historical periods that define the phlogiston-oxygen debate.

Next, during network construction, she represents the interactions that fostered the new concept. She uses *BERT* to create term embeddings and combines them with contextual metadata—such as authors and journals—into comprehensive node feature matrices for every 20-year period. To manage the high computational cost of this dense graph, Aguilar's framework proposes using community detection to simplify the network structure.

The third stage focuses on predicting latent relationships, for which Aguilar employs a hybrid *Transformer-Graph Convolutional Network* (*GCN*). The *GCN* learns structural patterns from the node profiles to predict new links, whilst the *Transformer's* attention mechanism identifies the most influential nodes driving interactions.

Finally, for validation, her framework performs entity alignment. This step assesses whether the predicted relationships are meaningful by searching for isomorphic graphs or recurring network motifs over time. By identifying stable structures, Aguilar can confirm the persistence and significance of the discovered interaction patterns.

## Limitations and Future Perspectives

The authors conclude by outlining several critical limitations and forward-looking questions that define the future of computational conceptual history. A primary challenge is distinguishing genuine epistemic shifts from mere linguistic drift; can models truly trace the evolution of thought itself? Another open question concerns the role of context: how exactly do language models incorporate metadata, and should it be treated as a core signal of meaning or as external noise? This project proceeds on the assumption that context is a core signal.

Furthermore, the team continues to explore the fundamental unit of language change. Are shifts best observed at the level of words, concepts, grammar, or broader discourse patterns? This leads to the question of whether it is possible to identify recurring linguistic pathways for the emergence of new concepts across different domains. Finally, as the models used to investigate these phenomena grow in complexity, the limits of their interpretability become a central concern, demanding new methods for understanding and validating their outputs.