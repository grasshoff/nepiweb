<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jochen Büttner">
<meta name="dcterms.date" content="2025-06-21">

<title>15&nbsp; Time-aware large language models towards a novel architecture for historical analysis – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_018.html" rel="next">
<link href="./chapter_ai-nepi_016.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_017.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models: Architecture, Adaptation, and Applications in HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#limitations-of-current-llms-and-the-need-for-temporal-awareness" id="toc-limitations-of-current-llms-and-the-need-for-temporal-awareness" class="nav-link" data-scroll-target="#limitations-of-current-llms-and-the-need-for-temporal-awareness"><span class="header-section-number">15.1</span> Limitations of Current <em>LLMs</em> and the Need for Temporal Awareness</a></li>
  <li><a href="#formalising-temporal-dependence-in-llms" id="toc-formalising-temporal-dependence-in-llms" class="nav-link" data-scroll-target="#formalising-temporal-dependence-in-llms"><span class="header-section-number">15.2</span> Formalising Temporal Dependence in <em>LLMs</em></a></li>
  <li><a href="#addressing-temporal-drift-in-llm-training" id="toc-addressing-temporal-drift-in-llm-training" class="nav-link" data-scroll-target="#addressing-temporal-drift-in-llm-training"><span class="header-section-number">15.3</span> Addressing Temporal Drift in <em>LLM</em> Training</a></li>
  <li><a href="#the-time-transformer-concept-and-data-acquisition" id="toc-the-time-transformer-concept-and-data-acquisition" class="nav-link" data-scroll-target="#the-time-transformer-concept-and-data-acquisition"><span class="header-section-number">15.4</span> The Time Transformer Concept and Data Acquisition</a></li>
  <li><a href="#weather-report-dataset-processing" id="toc-weather-report-dataset-processing" class="nav-link" data-scroll-target="#weather-report-dataset-processing"><span class="header-section-number">15.5</span> Weather Report Dataset Processing</a></li>
  <li><a href="#vanilla-transformer-model-architecture-and-training" id="toc-vanilla-transformer-model-architecture-and-training" class="nav-link" data-scroll-target="#vanilla-transformer-model-architecture-and-training"><span class="header-section-number">15.6</span> Vanilla Transformer Model Architecture and Training</a></li>
  <li><a href="#integrating-time-into-the-transformer-architecture" id="toc-integrating-time-into-the-transformer-architecture" class="nav-link" data-scroll-target="#integrating-time-into-the-transformer-architecture"><span class="header-section-number">15.7</span> Integrating Time into the Transformer Architecture</a></li>
  <li><a href="#dataset-characteristics-and-tokenisation-for-time-aware-models" id="toc-dataset-characteristics-and-tokenisation-for-time-aware-models" class="nav-link" data-scroll-target="#dataset-characteristics-and-tokenisation-for-time-aware-models"><span class="header-section-number">15.8</span> Dataset Characteristics and Tokenisation for Time-Aware Models</a></li>
  <li><a href="#comparative-architecture-of-vanilla-and-time-transformers" id="toc-comparative-architecture-of-vanilla-and-time-transformers" class="nav-link" data-scroll-target="#comparative-architecture-of-vanilla-and-time-transformers"><span class="header-section-number">15.9</span> Comparative Architecture of Vanilla and Time Transformers</a></li>
  <li><a href="#experiment-1---efficient-learning-of-temporal-drift-synonymic-succession" id="toc-experiment-1---efficient-learning-of-temporal-drift-synonymic-succession" class="nav-link" data-scroll-target="#experiment-1---efficient-learning-of-temporal-drift-synonymic-succession"><span class="header-section-number">15.10</span> Experiment 1 - Efficient Learning of Temporal Drift (Synonymic Succession)</a></li>
  <li><a href="#experiment-2---changing-weather-patterns-and-collocation-fixation" id="toc-experiment-2---changing-weather-patterns-and-collocation-fixation" class="nav-link" data-scroll-target="#experiment-2---changing-weather-patterns-and-collocation-fixation"><span class="header-section-number">15.11</span> Experiment 2 - Changing Weather Patterns and Collocation Fixation</a></li>
  <li><a href="#proof-of-concept-applications-next-steps-and-challenges" id="toc-proof-of-concept-applications-next-steps-and-challenges" class="nav-link" data-scroll-target="#proof-of-concept-applications-next-steps-and-challenges"><span class="header-section-number">15.12</span> Proof of Concept, Applications, Next Steps, and Challenges</a></li>
  <li><a href="#supplementary-resource" id="toc-supplementary-resource" class="nav-link" data-scroll-target="#supplementary-resource"><span class="header-section-number">15.13</span> Supplementary Resource</a></li>
  <li><a href="#additional-visual-materials" id="toc-additional-visual-materials" class="nav-link" data-scroll-target="#additional-visual-materials"><span class="header-section-number">15.14</span> Additional Visual Materials</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Jochen Büttner <a href="mailto:buettner@gea.mpg.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Max Planck Institute of Geoanthropology
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The presentation introduces a novel architectural approach for Large Language Models (<em>LLMs</em>), termed the “Time Transformer”, designed to imbue them with explicit temporal awareness. This innovation directly addresses the inherent limitation of current <em>LLMs</em>, which derive only an implicit understanding of time from statistical patterns within their training data. The speaker highlights that whilst existing models demonstrate remarkable capabilities, their lack of explicit temporal conditioning can lead to inconsistencies when processing information that evolves over time, such as historical data. The proposed “Time Transformer” integrates a dedicated temporal dimension directly into the token embeddings, thereby enabling the model to learn and reproduce changing linguistic patterns as a function of time. The authors validated this concept using a small generative <em>LLM</em> trained on a highly constrained dataset of Met Office weather reports, demonstrating its ability to efficiently capture and reproduce time-dependent linguistic shifts. The presentation explores the theoretical underpinnings of this approach, details the model architecture and data preparation, and presents two experiments demonstrating its efficacy in learning synthetic temporal drifts. Furthermore, it outlines potential applications, including historical analysis and instruction-tuned models, whilst acknowledging challenges related to fine-tuning and data curation.</p>
</section>
<section id="limitations-of-current-llms-and-the-need-for-temporal-awareness" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="limitations-of-current-llms-and-the-need-for-temporal-awareness"><span class="header-section-number">15.1</span> Limitations of Current <em>LLMs</em> and the Need for Temporal Awareness</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>Current Large Language Models (<em>LLMs</em>) inherently possess only an implicit understanding of time, which they derive statistically from the vast textual corpora used for their training. Whilst these models exhibit a profound grasp of temporal concepts, their comprehension stems from subtle cues embedded within the data rather than explicit temporal conditioning. Explicit time awareness, however, would demonstrably enhance their utility, particularly within historical analysis and, indeed, across a broader spectrum of applications.</p>
<p>Consider, for instance, two sentences that differ solely in their temporal context, such as ‘The primary architecture for processing text through Neural Networks is <em>LSTM</em>’ and ‘The primary architecture for processing text through Neural Networks is <em>Transformer</em>.’ Without explicit temporal information, these statements, representing different states of affairs in 2017 and 2025 respectively, directly contradict one another within the <em>LLM</em>’s training data. The model then struggles to perfectly fulfil its objective, as it must arbitrarily favour one, inevitably making an error regarding the other. Furthermore, a discernible recency bias often influences <em>LLM</em> predictions, favouring more contemporary information. Current methods, such as prompt engineering, merely attempt to exploit the model’s implicit temporal understanding, akin to ‘fishing in the dark’ for desired outcomes.</p>
<p>To overcome these limitations, the authors propose integrating time directly into the token embeddings of <em>Transformer</em>-based <em>LLMs</em>. This architectural modification aims to render <em>LLMs</em> explicitly time-aware, enabling them to precisely learn and reproduce the evolving patterns within their training data as a direct function of time. A proof of concept, utilising a small generative <em>LLM</em>, has already been developed to validate this innovative approach.</p>
</section>
<section id="formalising-temporal-dependence-in-llms" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="formalising-temporal-dependence-in-llms"><span class="header-section-number">15.2</span> Formalising Temporal Dependence in <em>LLMs</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>Fundamentally, Large Language Models operate by estimating the probability distribution over their vocabulary for the next token, conditioned on a given sequence of preceding tokens. This process is mathematically represented as p(x_n | x_1, …, x_{n-1}). However, in real-world scenarios, the likelihood of a token appearing within a specific context is not static; rather, it is intrinsically dependent on time, thus becoming p(x_n | x_1, …, x_{n-1}, t).</p>
<p>Extending this principle, the joint probability for an entire sequence of tokens uttered at a particular time t is expressed as the product of conditional probabilities: p(x_1, …, x_n | t) = product p(x_k | x_1, …, x_{k-1}, t). Despite this inherent temporal variability, current <em>LLM</em> training processes frequently treat these probability distributions as static. Consequently, during inference, these models can only reflect temporal drift in the underlying token sequences through in-context learning, a mechanism that relies on the immediate context provided rather than an explicit, integrated understanding of time.</p>
</section>
<section id="addressing-temporal-drift-in-llm-training" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="addressing-temporal-drift-in-llm-training"><span class="header-section-number">15.3</span> Addressing Temporal Drift in <em>LLM</em> Training</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>A significant challenge in current Large Language Model (<em>LLM</em>) training lies in their tendency to treat inherently time-dependent probability distributions as static. This simplification means that whilst the real-world likelihood of a token given its preceding context is a direct function of time—for instance, the probability of ‘transformer’ completing a sentence was effectively zero in 2017—<em>LLMs</em> primarily reflect such temporal drift only through in-context learning during inference.</p>
<p>To improve upon this, the authors must develop more effective methods for modelling these dynamic, time-dependent probability distributions. Existing strategies, such as ‘time slicing’—where distinct models are trained for specific temporal segments, assuming static distributions within those slices—prove remarkably data inefficient. A more streamlined and integrated approach is therefore imperative.</p>
</section>
<section id="the-time-transformer-concept-and-data-acquisition" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="the-time-transformer-concept-and-data-acquisition"><span class="header-section-number">15.4</span> The Time Transformer Concept and Data Acquisition</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>To overcome the limitations of implicit temporal understanding, the authors propose an innovative solution termed the ‘Time Transformer’. This concept centres on a remarkably simple yet profound architectural adjustment: reserving a single dimension within the token embedding space specifically for time. This dedicated dimension explicitly conveys the utterance date for each token sequence, thereby providing direct temporal context.</p>
<p>The initial implementation employs a non-trainable, min-max normalised ‘day of the year’ as the time embedding. This particular choice strategically exploits natural seasonal variations inherent in the chosen dataset, such as the prevalence of snow in winter or heat in summer. However, the framework readily accommodates alternative time embeddings as required.</p>
<p>For the proof of concept, the research team selected Met Office weather reports as the primary dataset. This text corpus is characterised by its limited vocabulary and simple, repetitive language, making it an ideal candidate for initial validation. The UK’s national meteorological service issues these daily reports, and historical data remains accessible through their digital archive. Additionally, the ‘TinyStories’ dataset was identified as another potentially suitable resource for similar investigations.</p>
</section>
<section id="weather-report-dataset-processing" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="weather-report-dataset-processing"><span class="header-section-number">15.5</span> Weather Report Dataset Processing</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The research team systematically acquired the dataset by scraping daily weather reports from Met Office <em>PDFs</em> spanning the years 2018 to 2024. This process yielded approximately 2,500 reports, each comprising between 150 and 200 words. For text processing, the team employed <em>tf.keras.layers.TextVectorization</em>, standardising the input by converting text to lowercase and stripping punctuation. Crucially, the tokenisation process avoided sub-word segmentation and deliberately neglected case and interpunctuation, reflecting the inherently simple nature of the language. This straightforward approach resulted in a remarkably concise vocabulary of just 3,395 unique words across the entire seven-year corpus. An illustrative example, the Daily Weather Summary for Sunday 04 August 2019, details showery rain and mist, whilst the Daily Extremes table highlights a highest maximum temperature of 27.5°C recorded in Writtle, Essex, and a lowest maximum of 14.1°C in Fair Isle, Shetland.</p>
</section>
<section id="vanilla-transformer-model-architecture-and-training" class="level2" data-number="15.6">
<h2 data-number="15.6" class="anchored" data-anchor-id="vanilla-transformer-model-architecture-and-training"><span class="header-section-number">15.6</span> Vanilla Transformer Model Architecture and Training</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The authors constructed a modest-sized, decoder-only <em>Transformer</em> architecture, termed the ‘<em>Vanilla model</em>’, to establish a baseline for language pattern learning within the weather report dataset. This architecture processes input through an Embedding Layer with a d_model of 512, followed by Positional Encoding and a Dropout layer set at a 0.1 rate. Subsequently, the processed input traverses a stack of four Multi-Head Attention Decoder Blocks. Each decoder layer comprises a Multi-Head Attention mechanism with eight heads and a key_dim of 512, succeeded by an Add &amp; Norm operation, then a Feed Forward Network (dff=2048), and another Add &amp; Norm. The final output from these layers feeds into a Dense Layer, sized to the vocabulary, which ultimately produces the model’s output.</p>
<p>This compact model contains 39 million parameters, equating to approximately 150 <em>MB</em>, a stark contrast to models such as <em>GPT-4</em>, which commands 1.8 trillion parameters across 120 layers. Despite its modest scale, the model trains with remarkable efficiency on an <em>HPC</em> cluster in Munich, utilising two <em>A100 GPUs</em>, completing each epoch in merely 11 seconds—a speed attributable to both the small dataset and the model’s compact size. The associated code, available on <em>GitHub</em>, was primarily developed for foundational understanding rather than production use. During training, the model’s accuracy steadily improved, with training accuracy reaching approximately 0.47 and validation accuracy stabilising around 0.38, demonstrating its capacity to perfectly reproduce the language patterns observed in the weather reports.</p>
</section>
<section id="integrating-time-into-the-transformer-architecture" class="level2" data-number="15.7">
<h2 data-number="15.7" class="anchored" data-anchor-id="integrating-time-into-the-transformer-architecture"><span class="header-section-number">15.7</span> Integrating Time into the Transformer Architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>The established ‘<em>Vanilla model</em>’ demonstrates a robust capacity to perfectly reproduce the language of weather reports. For instance, when provided with a seed sequence such as ‘During the night, a band…’, the model autoregressively generates coherent and contextually relevant text, closely mimicking actual weather forecasts.</p>
<p>The transition to a ‘Time Transformer’ involves a remarkably minimal architectural adjustment. Instead of solely embedding all information within a 512-dimensional latent semantic space, the authors propose reserving one dimension specifically for temporal data. This dedicated dimension explicitly informs each token about the precise date on which its sequence was uttered. The current implementation employs a non-trainable, min-max normalised ‘day of the year’ as this time embedding, a choice driven by the desire to leverage natural seasonal variations inherent in weather data, such as the distinct patterns of snow in winter and heat in summer. Crucially, this design allows for the integration of various other time embedding approaches as required by different datasets or research objectives.</p>
</section>
<section id="dataset-characteristics-and-tokenisation-for-time-aware-models" class="level2" data-number="15.8">
<h2 data-number="15.8" class="anchored" data-anchor-id="dataset-characteristics-and-tokenisation-for-time-aware-models"><span class="header-section-number">15.8</span> Dataset Characteristics and Tokenisation for Time-Aware Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>To rigorously test their proposed time-aware model, the authors sought a dataset characterised by restricted, repetitive language and a small vocabulary, thereby simplifying the task of pattern learning. The <em>UK</em> Met Office weather reports proved an ideal choice, readily accessible online from the national meteorological service. The ‘Tiny Stories’ dataset was also identified as a potential alternative for future investigations.</p>
<p>The data, originally presented as monthly <em>PDFs</em> containing daily reports, was systematically scraped for the period spanning 2018 to 2024. This yielded approximately 2,500 reports, each comprising between 150 and 200 words. The tokenisation process remained intentionally simple, eschewing sub-word segmentation and deliberately neglecting both case and interpunctuation. This streamlined approach underscored the inherent simplicity of the language, resulting in a remarkably compact vocabulary of just 3,400 words across the entire seven-year corpus.</p>
</section>
<section id="comparative-architecture-of-vanilla-and-time-transformers" class="level2" data-number="15.9">
<h2 data-number="15.9" class="anchored" data-anchor-id="comparative-architecture-of-vanilla-and-time-transformers"><span class="header-section-number">15.9</span> Comparative Architecture of Vanilla and Time Transformers</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>The ‘Time Transformer’ represents a minimal yet impactful architectural adjustment to the standard <em>Transformer</em> decoder. In a conventional <em>Vanilla Transformer</em>, the input directly flows into an Embedding Layer, typically with a d_model of 512, followed by Positional Encoding, a Dropout layer, and then a series of four Decoder Layers before culminating in a Final Dense Layer and the ultimate output.</p>
<p>Conversely, the ‘Time Transformer’ introduces two distinct inputs: textual data and temporal data. The textual input undergoes embedding into a d_model of 511, whilst the temporal data is embedded into a dedicated d_model of 1. These two embedded streams are then concatenated, maintaining the overall embedding dimension, before proceeding through the familiar sequence of Positional Encoding, Dropout, and the identical stack of four Decoder Layers. The time dimension itself is implemented as a non-trainable, min-max normalised ‘day of the year’, calculated using the formula (day of year - 1) / (365 - 1). This explicit integration directly addresses the fundamental challenge that whilst Large Language Models estimate token probabilities based on preceding sequences, real-world token likelihoods are inherently time-dependent, a dynamic often overlooked by training processes that treat distributions as static. Consequently, without this explicit temporal conditioning, current models can only reflect temporal drift through less efficient in-context learning during inference.</p>
</section>
<section id="experiment-1---efficient-learning-of-temporal-drift-synonymic-succession" class="level2" data-number="15.10">
<h2 data-number="15.10" class="anchored" data-anchor-id="experiment-1---efficient-learning-of-temporal-drift-synonymic-succession"><span class="header-section-number">15.10</span> Experiment 1 - Efficient Learning of Temporal Drift (Synonymic Succession)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>To assess the ‘Time Transformer’s’ capacity for efficiently learning temporal drift, the authors conducted a ‘synonymic succession’ experiment. This involved injecting a synthetic, time-dependent drift directly into the training data: the word ‘rain’ was progressively replaced by ‘liquid sunshine’ throughout the year. The objective was to ascertain whether the model could reproduce this engineered temporal dependence within its predicted token sequences for each day of the year.</p>
<p>The probability of this replacement followed an S-shaped curve, commencing near zero in January and gradually ascending to approach 1.00 by the year’s end. Analysis of monthly occurrences in the generated sequences clearly demonstrated the model’s successful capture of this drift: ‘Rain’ occurrences predominated in the earlier months, whilst ‘Liquidsunshine’ became significantly more frequent and eventually dominant in the latter half of the year, particularly from August through December.</p>
</section>
<section id="experiment-2---changing-weather-patterns-and-collocation-fixation" class="level2" data-number="15.11">
<h2 data-number="15.11" class="anchored" data-anchor-id="experiment-2---changing-weather-patterns-and-collocation-fixation"><span class="header-section-number">15.11</span> Experiment 2 - Changing Weather Patterns and Collocation Fixation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>A second experiment, termed ‘changing a weather pattern’ or ‘fixation of a collocation’, further investigated the model’s ability to capture temporal shifts. This involved injecting a synthetic, time-dependent change in co-occurrence: the pattern ‘rain’ followed by any word other than ‘and’ was progressively altered to ‘rain and snow’. Linguistically, this simulates the ‘fixation of a collocation’, akin to the established phrase ‘bread and butter’.</p>
<p>The results, visualised through monthly comparisons, clearly demonstrated the injected temporal shift. ‘Rain Only’ occurrences were notably higher in the first half of the year, whilst ‘Rain and Snow’ occurrences became significantly more frequent in the latter half, peaking around October and November. Furthermore, an analysis of attention weights revealed that the token ‘snow’ consistently exhibited the highest attention on ‘rain’, followed by ‘heavy’ and ‘and’ (specifically in Head 5), indicating that the model successfully learned this evolving co-occurrence pattern. Example sentences from Day 1 and Day 363 illustrate this learned association, consistently featuring ‘heavy rain and snow’ as the year progresses.</p>
</section>
<section id="proof-of-concept-applications-next-steps-and-challenges" class="level2" data-number="15.12">
<h2 data-number="15.12" class="anchored" data-anchor-id="proof-of-concept-applications-next-steps-and-challenges"><span class="header-section-number">15.12</span> Proof of Concept, Applications, Next Steps, and Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>The conducted research establishes a clear proof of concept: <em>Transformer</em>-based Large Language Models can be efficiently rendered time-aware through the integration of a dedicated temporal dimension within their token embeddings. This innovation opens several compelling applications. A foundational ‘Time Transformer’, for instance, could provide an exceptional basis for a myriad of downstream tasks involving historical data. Moreover, an instruction-tuned variant would empower users to ‘talk to a specific time’, potentially yielding superior results even in common usage scenarios where interaction with the present is desired. Beyond temporal dynamics, the methodology readily extends to modelling dependencies on other contextual or metadata dimensions, such as country or genre.</p>
<p>Future research endeavours include benchmarking this approach against explicit time-token methods and rigorously testing for potential increases in training efficiency. Nevertheless, challenges persist towards broader application. Uncertainty surrounds the feasibility and efficiency of fine-tuning due to the architectural modifications. Furthermore, the approach necessitates a departure from the simplicity of metadata-free self-supervised learning, plunging the authors into the intricate complexities of data curation. Fundamental questions also arise, such as determining the generation time of a given token sequence and exploring the utility of a more modest, targeted encoder model.</p>
</section>
<section id="supplementary-resource" class="level2" data-number="15.13">
<h2 data-number="15.13" class="anchored" data-anchor-id="supplementary-resource"><span class="header-section-number">15.13</span> Supplementary Resource</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>A supplementary resource, specifically a <em>ChatGPT</em> conversation, is available for further exploration. This resource can be accessed directly via the provided <em>URL</em>: https://chatgpt.com/c/67b8237a-2a48-8012-9862-80af84830a17.</p>
</section>
<section id="additional-visual-materials" class="level2" data-number="15.14">
<h2 data-number="15.14" class="anchored" data-anchor-id="additional-visual-materials"><span class="header-section-number">15.14</span> Additional Visual Materials</h2>
<p>The following slides provide supplementary visual information relevant to the presentation:</p>
<p><img src="images/ai-nepi_017_slide_12.png" class="img-fluid" alt="Slide 12"> <em>Failed to analyse slide</em></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_016.html" class="pagination-link" aria-label="Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_018.html" class="pagination-link" aria-label="Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>