<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jochen Büttner">
<meta name="dcterms.date" content="2025-01-01">

<title>15&nbsp; Time-Aware Language Models – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_018.html" rel="next">
<link href="./chapter_ai-nepi_016.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_017.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Transformer’s Legacy: Understanding Large Language Models and their Application in HPSS Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Workflow and Utility of OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Beyond Traditional Views of Science Funding</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#the-temporal-deficit-in-current-language-models" id="toc-the-temporal-deficit-in-current-language-models" class="nav-link" data-scroll-target="#the-temporal-deficit-in-current-language-models"><span class="header-section-number">15.1</span> The Temporal Deficit in Current Language Models</a></li>
  <li><a href="#architecting-time-awareness-the-time-transformer" id="toc-architecting-time-awareness-the-time-transformer" class="nav-link" data-scroll-target="#architecting-time-awareness-the-time-transformer"><span class="header-section-number">15.2</span> Architecting Time-Awareness: The Time Transformer</a></li>
  <li><a href="#empirical-validation-experimental-design-and-implementation" id="toc-empirical-validation-experimental-design-and-implementation" class="nav-link" data-scroll-target="#empirical-validation-experimental-design-and-implementation"><span class="header-section-number">15.3</span> Empirical Validation: Experimental Design and Implementation</a></li>
  <li><a href="#learning-temporal-dynamics-experimental-outcomes" id="toc-learning-temporal-dynamics-experimental-outcomes" class="nav-link" data-scroll-target="#learning-temporal-dynamics-experimental-outcomes"><span class="header-section-number">15.4</span> Learning Temporal Dynamics: Experimental Outcomes</a></li>
  <li><a href="#broader-implications-and-future-trajectories" id="toc-broader-implications-and-future-trajectories" class="nav-link" data-scroll-target="#broader-implications-and-future-trajectories"><span class="header-section-number">15.5</span> Broader Implications and Future Trajectories</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Jochen Büttner <a href="mailto:buettner@gea.mpg.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Max Planck Institute of Geoanthropology
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Researchers at the Max Planck Institute of Geoanthropology propose a novel architecture, termed the “<em>Time Transformer</em>”, designed to imbue <em>Large Language Models</em> (<em>LLMs</em>) with explicit time-awareness. This work addresses a critical limitation: current <em>LLMs</em> possess only an implicit, statistically derived understanding of time, hindering their capacity to accurately process temporally evolving information, particularly for historical analysis. The core innovation involves augmenting standard <em>Transformer</em> models by incorporating a dedicated temporal dimension into token embeddings, thereby explicitly encoding the utterance time for each token.</p>
<p>A proof-of-concept study utilised a small generative <em>LLM</em>, trained on a corpus of Met Office weather reports spanning 2018 to 2024. For this experiment, the temporal dimension represented the min-max normalised day of the year. The <em>Time Transformer</em> demonstrated its capability to learn and reproduce both synthetically introduced temporal drifts in language patterns—such as synonym replacement and alterations in word co-occurrence—and naturally occurring seasonal variations within the weather data. Key components of this investigation comprised the baseline vanilla <em>Transformer</em> model, its <em>Time Transformer</em> modification, and the curated dataset of weather reports. Development and training relied on standard <em>LLM</em> frameworks and an <em>HPC</em> cluster equipped with <em>NVIDIA A100 GPUs</em>. Potential applications extend beyond historical analysis to include the creation of foundation models for diverse time-sensitive tasks, enabling interactions with specific temporal contexts, and possibly modelling other contextual metadata dimensions like geography or genre. Nevertheless, this approach necessitates training models from scratch, presents challenges in curating temporal metadata, and raises questions regarding the feasibility of fine-tuning existing models.</p>
</section>
<section id="the-temporal-deficit-in-current-language-models" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="the-temporal-deficit-in-current-language-models"><span class="header-section-number">15.1</span> The Temporal Deficit in Current Language Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Jochen Büttner, from the Max Planck Institute of Geoanthropology, introduced a foundational concept aimed at enhancing language models. His presentation formalised an idea with potential applications in historical analysis (<em>HPSS</em>), though the speaker acknowledged its basic nature and solicited information regarding any pre-existing similar work.</p>
<p>Researchers argued that current <em>Large Language Models</em> operate with merely an implicit comprehension of time, a comprehension statistically distilled from the vast quantities of text encountered during training. Whilst these models demonstrate a considerable, albeit indirect, grasp of temporal concepts, explicit time-awareness promises significant benefits, particularly for historical analysis and potentially broader applications. Consider, for instance, two statements: “The primary architectures for processing text through NNs are <em>LSTMs</em>,” accurate around 2017, and “The primary architectures for processing text through NNs are <em>Transformers</em>,” pertinent circa 2025. Humans effortlessly resolve the apparent contradiction by understanding the different temporal contexts. However, within an <em>LLM</em>’s training data, which lacks explicit temporal markers, these statements directly compete, compelling the model towards an unavoidable error in at least one instance.</p>
<p>Consequently, during inference, an <em>LLM</em> prompted with “The primary architectures for processing text through NNs are” will likely predict “<em>Transformers</em>,” influenced by an inherent recency bias from its training. Eliciting an older truth, such as “<em>LSTMs</em>,” often necessitates careful prompt engineering—perhaps by adding “In 2017” or altering verb tenses—a process researchers describe as somewhat haphazard. The central objective, therefore, involves engineering explicitly time-aware <em>LLMs</em>, empowering them to learn and reproduce evolving patterns within training data as a direct function of time.</p>
<p>Formally, standard <em>LLMs</em> estimate the probability of a subsequent token given a sequence of preceding tokens, denoted p(xn | x1, …, xn-1). In reality, this probability remains non-static; it dynamically changes with time, correctly represented as p(xn | x1, …, xn-1, t). For instance, the likelihood of “<em>Transformers</em>” completing the aforementioned sentence in 2017 was effectively zero. One can express the probability of an entire token sequence uttered at a specific time <em>t</em> as the product of these conditional probabilities: p(x1, x2, …, xn | t) = Πk=1 to n p(xk | x1, …, xk-1, t). Current models can only mirror temporal shifts in these underlying distributions through in-context learning during inference, a less direct mechanism.</p>
</section>
<section id="architecting-time-awareness-the-time-transformer" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="architecting-time-awareness-the-time-transformer"><span class="header-section-number">15.2</span> Architecting Time-Awareness: The Time Transformer</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Addressing the challenge of modelling the time-dependent probability distribution p(xn | x1, …, xn-1, t) necessitated a novel approach. One existing strategy, time slicing, involves training distinct models for separate temporal segments, assuming distributions remain relatively static within each slice. However, this technique proves exceptionally data-inefficient.</p>
<p>Consequently, researchers conceived the “<em>Time Transformer</em>”, an architecture distinguished by its elegant simplicity. Standard Natural Language Processing tasks commence by transforming words or tokens into vectorial representations—embeddings—which models refine during training. The <em>Time Transformer</em> innovates by appending an additional dimension to these latent semantic token features, specifically encoding the token’s origin time. Thus, every token in a sequence, uttered at a particular time, receives this explicit temporal information. For instance, the representation for “cat” would subtly differ in this dimension depending on whether it was uttered recently or several years prior.</p>
<p>One can formalise this time-aware embedding as E(x, t) = {e1(x), e2(x), …, ed-1(x), φ(t)}, where φ(t) represents the encoded time. The <em>Transformer</em> model then processes a sequence of these augmented embeddings, [E(x1, t), E(x2, t), …, E(xn-1, t)], to predict the time-conditioned probability pθ(xn | x1, …, xn-1, t). The training objective remains the minimisation of the negative log likelihood across the dataset: minθ - Σi=1 to N Σk=1 to n(i) log pθ(xk(i) | x1(i), …, xk-1(i), t(i)). Through this mechanism, temporal information directly ‘injects’ into every token’s representation, enabling the model to learn precisely how significantly the time dimension influences each individual token.</p>
</section>
<section id="empirical-validation-experimental-design-and-implementation" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="empirical-validation-experimental-design-and-implementation"><span class="header-section-number">15.3</span> Empirical Validation: Experimental Design and Implementation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>To validate the <em>Time Transformer</em> concept, researchers required a dataset characterised by a limited vocabulary and simple, repetitive language, thereby facilitating the training of a small generative <em>LLM</em>. Met Office weather reports from the UK’s National Meteorological Service, accessible via their digital archive (https://digital.nmla.metoffice.gov.uk/), fulfilled these criteria admirably. Researchers scraped data spanning 2018 to 2024, yielding approximately 2,500 reports, each comprising around 150-200 words. They also noted an alternative dataset, <em>TinyStories</em>. Preprocessing involved extracting daily reports from monthly PDFs and applying a straightforward tokenisation strategy: no sub-word units, and a disregard for case and interpunctuation. This yielded a modest vocabulary of 3,395 unique words.</p>
<p>Researchers first constructed a baseline ‘vanilla’ <em>Transformer</em> model. This decoder-only architecture comprised an embedding layer, positional encoding, and dropout, followed by four decoder blocks—each containing multi-head attention (with eight heads), residual connections with layer normalisation, and a feed-forward network—culminating in a final dense layer for output probability distribution. This relatively small model, with 39 million parameters (150MB), contrasts sharply with models such as <em>GPT-4</em> (1.8 trillion parameters). Training occurred on an <em>HPC</em> cluster in Munich, utilising two <em>NVIDIA A100 GPUs</em>, achieving a rapid 11 seconds per epoch owing to the dataset’s and model’s compactness. The associated code is available on <em>GitHub</em> (j-buettner/time_transformer), though primarily serving as a learning tool. This vanilla model demonstrated proficiency in replicating the language of the weather reports.</p>
<p>Transitioning to the <em>Time Transformer</em> involved a minimal architectural adjustment. Instead of a standard embedding, researchers incorporated time data by reserving one dimension within the, for example, 512-dimensional latent semantic space for a temporal signal. They concatenated this time value with the token’s semantic embedding before positional encoding. Specifically, a non-trainable, min-max normalised day of the year (calculated as (day of year - 1) / 364) served as the time embedding, a choice made to exploit natural seasonal variations in weather patterns. Researchers acknowledged that alternative methods for encoding time could also be employed.</p>
</section>
<section id="learning-temporal-dynamics-experimental-outcomes" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="learning-temporal-dynamics-experimental-outcomes"><span class="header-section-number">15.4</span> Learning Temporal Dynamics: Experimental Outcomes</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_16.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The primary inquiry guiding these experiments sought to determine whether the <em>Time Transformer</em> could efficiently learn temporal drift within the underlying data distribution. A first experiment, termed “synonymic succession,” involved injecting a synthetic temporal drift. Researchers implemented a time-dependent replacement of the word “rain” with “liquid sunshine,” where the probability of replacement followed a sigmoid function across the days of the year—commencing at zero and culminating at one by year’s end. By generating a weather prediction for each day and analysing the monthly frequencies of these terms, they found the model accurately reproduced this injected pattern: “rain” predominated early in the year, whilst “liquid sunshine” emerged towards the end, with a clear mid-year transition, all subject to expected statistical fluctuations.</p>
<p>Beyond synthetic changes, the model also captured naturally occurring seasonal patterns, such as the increased frequency of terms like “snow” and “sleet” in winter months, and “hot” or “warm” in summer. However, researchers viewed these as simpler instances of temporal influence, primarily affecting word frequencies. To explore a more complex scenario, a second experiment focused on altering a co-occurrence pattern, which they described as the “fixation of a collocation.” Here, they synthetically replaced instances of “rain” not immediately followed by “and” with “rain and snow” in a time-dependent manner. This aimed to render “rain and snow” an obligatory pairing by the year’s end, akin to how “bread and butter” functions as a fixed phrase. Again, analysis of daily predictions across the year confirmed the model’s success: towards the year’s end, predictions almost exclusively featured “rain and snow,” whilst earlier in the year, “rain” could appear alone—though “rain and snow” also occurred, reflecting genuine meteorological conditions for periods like January.</p>
<p>Investigations into the model’s internal workings, specifically its attention mechanisms (using techniques alluded to as ‘excite’), revealed that certain attention heads had specialised in capturing these temporal dependencies. For instance, the attention paid from “snow” back to “rain” (when generating “rain and snow”) varied appropriately with the time of year. Furthermore, early-year co-occurrences of “rain and snow” often correctly conditioned on contextual cues like “cold system,” underscoring the model’s ability to learn nuanced patterns. These findings collectively provided a proof of concept: <em>Transformer</em>-based <em>LLMs</em> can indeed be rendered efficiently time-aware through the simple addition of a temporal dimension to their token embeddings.</p>
</section>
<section id="broader-implications-and-future-trajectories" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="broader-implications-and-future-trajectories"><span class="header-section-number">15.5</span> Broader Implications and Future Trajectories</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_017_slide_21.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 21</figcaption>
</figure>
</div>
<p>The successful proof of concept for the <em>Time Transformer</em> opens several avenues for application and further research. A foundational <em>Time Transformer</em> could provide a robust basis for numerous downstream tasks reliant on historical data. Furthermore, an instruction-tuned version might enable users to interact with information as it existed at a specific point in time, potentially even enhancing present-focused interactions by providing a richer temporal context. This architectural principle could, moreover, extend to model dependencies on other metadata dimensions, such as geographical origin or textual genre.</p>
<p>Regarding future work, researchers identified several promising directions. Benchmarking the <em>Time Transformer</em> against approaches that treat time as an explicit token within the input sequence would prove valuable. Another important investigation involves testing whether the inclusion of an explicit temporal dimension enhances training efficiency; the hypothesis posits that it could aid the model in more readily deciphering complex temporal patterns that are otherwise only implicitly cued.</p>
<p>Nevertheless, translating this concept into widespread practical application faces notable challenges. The architectural modification—the addition of a temporal dimension to embeddings—raises questions about the feasibility and efficiency of fine-tuning existing pre-trained models; indeed, it may necessitate training new models from scratch. This, in turn, implies significant computational costs for any application beyond the small-scale demonstration. A crucial shift from current practices involves the loss of metadata-free self-supervised learning; the <em>Time Transformer</em> requires meticulous data curation to assign a temporal marker to every token sequence. For historians, accurately determining the ‘generation date’ of textual material can prove complex, involving considerations of original utterance, reprints, and publication lags.</p>
<p>As a concluding reflection, the presenter suggested that a more modest, targeted encoder model, akin to <em>BERT</em>, built upon the same time-aware principle, might offer a pragmatic path for specific tasks that do not require full generative capabilities. Such a model could focus on learning relevant temporal patterns without the overhead of modelling all linguistic intricacies. Collaboration on exploring these targeted applications is welcomed.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_016.html" class="pagination-link" aria-label="Titles, Abstracts, or Full-Texts? A Comparative Study of *LDA* and *BERTopic* Performance across Text Levels">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_018.html" class="pagination-link" aria-label="Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>