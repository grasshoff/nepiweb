<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst">
<meta name="dcterms.date" content="2025-06-21">

<title>11&nbsp; AI Solutions for Academic Information Retrieval: The Ghostwriter and EverythingData Approach – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_012.html" rel="next">
<link href="./chapter_ai-nepi_010.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_011.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Solutions for Academic Information Retrieval: The Ghostwriter and EverythingData Approach</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Solutions for Academic Information Retrieval: The Ghostwriter and EverythingData Approach</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">A Comparative Study of LDA and BERTopic Performance Across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#science-dynamics-and-ai" id="toc-science-dynamics-and-ai" class="nav-link" data-scroll-target="#science-dynamics-and-ai"><span class="header-section-number">11.1</span> Science Dynamics and AI</a></li>
  <li><a href="#presentation-outline-and-research-question" id="toc-presentation-outline-and-research-question" class="nav-link" data-scroll-target="#presentation-outline-and-research-question"><span class="header-section-number">11.2</span> Presentation Outline and Research Question</a></li>
  <li><a href="#the-ghostwriter-approach-a-new-ir-interface" id="toc-the-ghostwriter-approach-a-new-ir-interface" class="nav-link" data-scroll-target="#the-ghostwriter-approach-a-new-ir-interface"><span class="header-section-number">11.3</span> The <em>Ghostwriter</em> Approach: A New IR Interface</a></li>
  <li><a href="#ghostwriter-and-everythingdata-core-components" id="toc-ghostwriter-and-everythingdata-core-components" class="nav-link" data-scroll-target="#ghostwriter-and-everythingdata-core-components"><span class="header-section-number">11.4</span> <em>Ghostwriter</em> and <em>EverythingData</em>: Core Components</a></li>
  <li><a href="#vector-versus-graph-databases-for-rag" id="toc-vector-versus-graph-databases-for-rag" class="nav-link" data-scroll-target="#vector-versus-graph-databases-for-rag"><span class="header-section-number">11.5</span> Vector versus Graph Databases for RAG</a></li>
  <li><a href="#system-architecture" id="toc-system-architecture" class="nav-link" data-scroll-target="#system-architecture"><span class="header-section-number">11.6</span> System Architecture</a></li>
  <li><a href="#ghostwriter-content-indexing" id="toc-ghostwriter-content-indexing" class="nav-link" data-scroll-target="#ghostwriter-content-indexing"><span class="header-section-number">11.7</span> <em>Ghostwriter</em>: Content Indexing</a></li>
  <li><a href="#interactive-queries-and-source-transparency" id="toc-interactive-queries-and-source-transparency" class="nav-link" data-scroll-target="#interactive-queries-and-source-transparency"><span class="header-section-number">11.8</span> Interactive Queries and Source Transparency</a></li>
  <li><a href="#iterative-refinement-and-verifiability" id="toc-iterative-refinement-and-verifiability" class="nav-link" data-scroll-target="#iterative-refinement-and-verifiability"><span class="header-section-number">11.9</span> Iterative Refinement and Verifiability</a></li>
  <li><a href="#entity-extraction-and-multilingual-support" id="toc-entity-extraction-and-multilingual-support" class="nav-link" data-scroll-target="#entity-extraction-and-multilingual-support"><span class="header-section-number">11.10</span> Entity Extraction and Multilingual Support</a></li>
  <li><a href="#query-mapping-to-graph-representations" id="toc-query-mapping-to-graph-representations" class="nav-link" data-scroll-target="#query-mapping-to-graph-representations"><span class="header-section-number">11.11</span> Query Mapping to Graph Representations</a></li>
  <li><a href="#entity-linking-with-wikidata" id="toc-entity-linking-with-wikidata" class="nav-link" data-scroll-target="#entity-linking-with-wikidata"><span class="header-section-number">11.12</span> Entity Linking with Wikidata</a></li>
  <li><a href="#conceptual-translation-with-gemma3" id="toc-conceptual-translation-with-gemma3" class="nav-link" data-scroll-target="#conceptual-translation-with-gemma3"><span class="header-section-number">11.13</span> Conceptual Translation with <em>Gemma3</em></a></li>
  <li><a href="#system-functionality-and-benefits" id="toc-system-functionality-and-benefits" class="nav-link" data-scroll-target="#system-functionality-and-benefits"><span class="header-section-number">11.14</span> System Functionality and Benefits</a></li>
  <li><a href="#future-directions" id="toc-future-directions" class="nav-link" data-scroll-target="#future-directions"><span class="header-section-number">11.15</span> Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Solutions for Academic Information Retrieval: The Ghostwriter and EverythingData Approach</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst <a href="mailto:philipp.mayr@gesis.org" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This presentation introduces a novel AI-driven solution, comprising <em>Ghostwriter</em> and <em>EverythingData</em>, which a collaborative team from Dans (Data Archiving and Networked Services) and GESIS (Leibniz Institute for the Social Sciences) has meticulously crafted. Their work addresses the burgeoning challenge of information overload within scientific disciplines. The system facilitates knowledge production by enabling users to ‘chat with papers’, directly engaging with the core research question: is it feasible to construct an AI solution for conversational interaction with specific collections of academic literature?</p>
<p>The system architecture integrates Retrieval-Augmented Generation (RAG) with a hybrid of vector and graph database methodologies. <em>EverythingData</em> constitutes the backend, processing raw document collections—such as full-text articles from the <em>method-data-analysis (mda) journal</em>—into a structured knowledge base. This process involves comprehensive term extraction, the generation of embeddings using various Machine Learning algorithms and Large Language Models (LLMs), and subsequent enrichment through external knowledge graphs like Wikidata.</p>
<p>For implementation, the team employs a vector store, specifically <em>Q-drant</em>, for content embeddings and a graph database for metadata, formally expressed using the Croissant ML standard. This hybrid ‘GraphRAG’ model combines the semantic understanding afforded by vector spaces with the relational insights provided by knowledge graphs. It fosters a ‘locally’ implemented Distributed AI where the LLM functions dually as an intuitive interface and a powerful reasoning engine.</p>
<p><em>Ghostwriter</em> operates as the user-facing interface, facilitating natural language queries. It dynamically generates both a list of relevant documents and an explanatory text, crucially providing transparent sourcing to prevent hallucinations. The system’s iterative approach empowers users to refine their questions. Its entity extraction pipeline meticulously maps query terms to controlled vocabularies and links them to broader knowledge graph representations, thereby supporting immediate multilinguality. This robust architecture ensures that responses are rigorously grounded in the specific collection, offering a controlled search space for ‘close reading’ and enabling the discovery of associations that extend beyond explicit text or metadata.</p>
<p>Future developments include expanding the pilot to incorporate bibliometric questions by integrating metadata harvesting. The team also plans to apply the methodology to large-scale official statistical data, such as CBS data via the ODISSEI Portal and the SSHOC.nl project, and to extend its application to specialised cultural heritage datasets, as in the MuseIT case. Key challenges ahead involve rigorously evaluating the workflow’s efficacy and developing advanced visualisation techniques to represent the spatial and temporal evolution of research topics. The project champions a sustainable, local AI approach, reducing reliance on large industry models and fostering collaborative development within the academic community.</p>
</section>
<section id="science-dynamics-and-ai" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="science-dynamics-and-ai"><span class="header-section-number">11.1</span> Science Dynamics and AI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The evolution of scientific disciplines consistently demonstrates both growth and increasing differentiation, leading to an overwhelming volume of information. This expansion presents a significant practical challenge: the imperative to efficiently review, evaluate, and select pertinent content. Fundamentally, the creation of new knowledge, whether within individual minds or across broader academia, relies upon the ability to locate and comprehend existing information.</p>
<p>Whilst machines, particularly recent advancements in Artificial Intelligence, have undeniably fostered this growth, a critical question arises: can they also actively support the knowledge production process itself? This inquiry forms a core challenge within the domain of Information Retrieval. At Dans, senior research engineer Slava Tikhonov has pioneered extensive experimentation, meticulously building complex data pipelines. His intricate work, though challenging to unravel, has inspired the current endeavour. The primary objective involves applying these AI-driven methodologies to manage the burgeoning flood of information, thereby addressing fundamental information retrieval challenges.</p>
</section>
<section id="presentation-outline-and-research-question" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="presentation-outline-and-research-question"><span class="header-section-number">11.2</span> Presentation Outline and Research Question</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>This presentation addresses the central research question: can an AI solution be developed to facilitate conversational interaction with academic papers? The introductory segment will delve into foundational concepts, encompassing information retrieval principles, the dynamics of human-machine interaction, and the sophisticated techniques of Retrieval-Augmented Generation (RAG) within generative AI.</p>
<p>A concrete use case focuses on the <em>method-data-analysis (mda) journal</em>, providing a specific domain for application. The discussion will then introduce the bespoke workflow underpinning this ‘local’ or tailored AI solution, highlighting two principal components: <em>Ghostwriter</em>, which functions as the user interface, and <em>EverythingData</em>, a comprehensive term encapsulating the entire backend infrastructure. The talk will subsequently provide illustrations of both front-end and back-end operations, culminating in a summary and an outlook on future directions. Specifically, the AI solution aims to enable users to chat with papers derived from a carefully curated selection.</p>
</section>
<section id="the-ghostwriter-approach-a-new-ir-interface" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="the-ghostwriter-approach-a-new-ir-interface"><span class="header-section-number">11.3</span> The <em>Ghostwriter</em> Approach: A New IR Interface</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The initial challenge in effective information retrieval centres upon formulating the precise question, identifying the most appropriate information source, and accurately interpreting the resultant findings. The project team proposes the <em>Ghostwriter</em> approach as a novel interface to address these complexities, contrasting it with existing query interaction models.</p>
<p>Traditionally, information retrieval (IR) involves a query interacting with a single database representation. This necessitates the user’s explicit knowledge of the schema and its typical values to obtain results—a scenario likened to ‘Me and a database’. A more advanced model, exemplified by Google Features and schema.org, involves a query interacting with a data collection underpinned by connected structured databases or graphs. This is akin to ‘Me and a librarian’, where the system offers suggestions for similar or improved queries based on schema connections.</p>
<p>The advent of Large Language Models (LLMs) introduced a paradigm where a query interacts directly with an LLM, resembling ‘Me and a library’ or ‘Me and a round of experts’. Here, the system interprets natural language input and suggests results, also expressed in natural language.</p>
<p>The <em>Ghostwriter</em> approach, however, represents a significant advancement. It involves a query interacting with a <em>local</em> LLM, a specific target data collection, and a network of additional data interpretation sources accessed via APIs. The authors describe this sophisticated interaction metaphorically as ‘Me chatting with experts and librarians at the same time’. <em>Ghostwriter</em> dynamically creates a family of terms related to the query, identifies pertinent structured information, and returns a comprehensive list of results. Its iterative application empowers users to reformulate their questions, fostering a deeper understanding of what they genuinely seek to ask and what the available data space can realistically provide.</p>
</section>
<section id="ghostwriter-and-everythingdata-core-components" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="ghostwriter-and-everythingdata-core-components"><span class="header-section-number">11.4</span> <em>Ghostwriter</em> and <em>EverythingData</em>: Core Components</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Scientifically, the <em>Ghostwriter</em> and <em>EverythingData</em> system aligns with the broader discourse surrounding Retrieval Augmented Generation (RAG). This approach integrates two primary ingredients: a vector space and a graph. The team meticulously constructs the vector space from the content of data files, where information is encoded into embeddings that capture inherent properties and their attributes. These embeddings are computed using diverse Machine Learning algorithms and can leverage various Large Language Models.</p>
<p>Conversely, the graph constitutes a metadata layer, seamlessly integrated with a range of ontologies and controlled vocabularies, including those pertinent to responsible AI. The authors formally express this graph structure using the Croissant ML standard. The overarching vision for this system proposes combining both graph and vector representations into a singular model, termed ‘GraphRAG’. This innovative approach aims for a locally implemented Distributed AI, where the LLM functions dually as an intuitive interface between human users and the AI, and as a powerful reasoning engine.</p>
<p>In terms of implementation, the LLM is robustly connected to a RAG library, which effectively embodies the knowledge graph. This connection enables the LLM to navigate through extensive datasets and consume embeddings as contextual input for its operations. The conceptual design, which draws inspiration from seminal works such as ‘The GraphRAG Manifesto’ by Phipa Rathie, illustrates the progressive evolution of AI systems, moving from basic LLMs to a complex, interconnected graph structure that symbolises a fully realised knowledge-augmented system.</p>
</section>
<section id="vector-versus-graph-databases-for-rag" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="vector-versus-graph-databases-for-rag"><span class="header-section-number">11.5</span> Vector versus Graph Databases for RAG</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>A comparative analysis, drawing upon insights from TheAiEdge.io, elucidates the distinct paradigms of Vector and Graph Databases for Retrieval Augmented Generation (RAG). The Vector Database approach systematically processes information by first partitioning data into discrete chunks. Subsequently, these chunks are encoded into numerical vectors using an LLM, then indexed and stored. For retrieval, a posed question is similarly transformed into an embedding, and the system identifies the nearest neighbours—semantically similar chunks—to provide as context for an LLM-generated response.</p>
<p>In contrast, the Graph Database approach commences with an LLM extracting relational information between entities from raw data, such as ‘MACHINE LEARNING’ and ‘FUN’ linked by ‘IS’. This process forms a structured knowledge representation organised as a network of interconnected entities and relationships, which is then stored in a Graph database. When a question concerning a specific entity arises, retrieval involves extracting a relevant subgraph from the database to pass as context to an LLM.</p>
<p>Further insights into vector space models reveal a document-term matrix structure, enriched by LLMs identifying semantically similar words and by knowledge graphs capturing deeper meaning. This yields a vector space founded upon distinct ‘classes’ of words, which in turn determine weights and facilitate a more sophisticated understanding of document similarity.</p>
</section>
<section id="system-architecture" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="system-architecture"><span class="header-section-number">11.6</span> System Architecture</h2>
<p>The <em>Ghostwriter</em> and <em>EverythingData</em> system architecture systematically transforms raw textual data into a structured, queryable knowledge base. The process commences with a collection of full-text articles, exemplified by the <em>MDA Journal</em>, serving as the primary data source.</p>
<p>This full text undergoes comprehensive processing within the <em>EverythingData</em> backend. Information is initially stored in a Vector Store, <em>Q-drant</em>, which houses all data. From this store, the system executes several critical operations: it extracts key terms, converts text segments into numerical vector representations (embeddings), and adds further contextual information through enrichments. Crucially, selected terms are then expressed as structured data within a graph, subsequently enriched with external knowledge from Wikidata. This structured and enriched data then feeds into a Vector space RAG-Graph.</p>
<p>Users interact with the system via the <em>Ghostwriter</em> interface, posing natural language queries such as ‘Explain male breadwinner model to me?’. The system processes this query through the Vector space RAG-Graph, producing two distinct outputs: a list of relevant documents and a concise explanatory text. The authors clarify that whilst the system begins with <em>MDA Journal</em> articles, any document collection could serve as input. Coupling this process with knowledge graphs enhances the value of the embeddings, ultimately feeding into a unified system that delivers both document lists and summarised responses.</p>
</section>
<section id="ghostwriter-content-indexing" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="ghostwriter-content-indexing"><span class="header-section-number">11.7</span> <em>Ghostwriter</em>: Content Indexing</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p><em>Ghostwriter</em> functions as a dedicated tool for content indexing, enabling the ingestion of documents and webpages into a queryable collection. The <em>mda methods, data, analyses</em> journal website serves as a primary content source. The <em>Ghostwriter</em> tool itself, residing on the <em>gesis Leibniz-Institut Sozialwissenschaften</em> platform, presents distinct sections for ‘Ask Questions’ and ‘Add Page’.</p>
<p>Within the ‘Add Page’ section, users can input a webpage URL or RSS feed, with the system supporting various source types. The interface also displays available collections and management capabilities. The current scope involves a test collection of 100 articles, acquired through web scraping, with the tool accessible at <code>https://gesis.now.museum</code>.</p>
<p>The speaker, whilst initially cautious about Large Language Models, systematically deconstructed the training process to identify specific applications. This work, though demonstrated for academic papers, is versatile enough for any web content. Crucially, the system prevents hallucinations by exclusively relying on the ingested source material; if information is unavailable, it explicitly states, ‘I don’t know’. The system achieves complex query responses by combining a relatively simple LLM with sophisticated knowledge graphs, ensuring a curated collection is built by adding papers incrementally.</p>
</section>
<section id="interactive-queries-and-source-transparency" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="interactive-queries-and-source-transparency"><span class="header-section-number">11.8</span> Interactive Queries and Source Transparency</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> system facilitates interactive engagement with academic literature. When a user poses a question, such as ‘explain male breadwinner model to me’, the system provides a detailed explanation within its ‘Answer’ section. A ‘Sources’ section transparently lists the academic papers that informed the answer, complete with relevance scores.</p>
<p>For instance, the response to the male breadwinner model query cites ‘The Past, Present and Future of Factorial Survey Experiments’ by Treischl and ‘Gender and Survey Participation’ by Becker, both from the <em>MDA GESIS</em> journal. The system’s output comprises both an explanation and a list of documents, notably including those that may not explicitly contain the query terms, thereby indicating a sophisticated semantic search. The tool operates on <em>MDA</em> papers and is accessible at <code>https://gesis.now.museum</code>.</p>
<p>The speaker emphasises that, unlike some generative AI models, this implementation provides precise references and demonstrably avoids hallucination because it accurately identifies the information’s origin. The underlying mechanism involves splitting each paper into small, uniquely identified blocks. The LLM technique then intelligently connects and retrieves these blocks, applying weights and leveraging knowledge graphs to predict which text segments will most effectively respond to a given question.</p>
</section>
<section id="iterative-refinement-and-verifiability" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="iterative-refinement-and-verifiability"><span class="header-section-number">11.9</span> Iterative Refinement and Verifiability</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> system employs an iterative approach to ensure accurate, verifiable answers. This is exemplified by its query refinement capability: an initial broad query, such as ‘Explain the male Breadwinner model to me?’, can be refined into a more specific follow-up, like ‘Explain how data were collected on male breadwinner model?’.</p>
<p>For such refined queries, the system transparently states if direct information is unavailable. Nevertheless, it provides valuable contextual information, noting, for example, that a study utilised German data and employed a mixed-methods research strategy. The ‘Sources’ section lists relevant academic papers, such as Treischl’s ‘The Past, Present and Future of Factorial Survey Experiments’, complete with relevance scores and direct download URLs. An interactive ‘Chat’ column allows users to pose follow-up questions directly related to specific documents. The speaker underscores that if the system lacks information, it explicitly states this limitation, whilst users retain the ability to add missing articles, thereby enhancing the knowledge base for future queries.</p>
</section>
<section id="entity-extraction-and-multilingual-support" class="level2" data-number="11.10">
<h2 data-number="11.10" class="anchored" data-anchor-id="entity-extraction-and-multilingual-support"><span class="header-section-number">11.10</span> Entity Extraction and Multilingual Support</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Behind the operational facade lies a sophisticated entity extraction pipeline. This pipeline meticulously annotates terms with semantic meaning by mapping them to controlled vocabularies, effectively transforming raw data from a numerical vector space representation into a structured knowledge graph. Furthermore, the system extends this process by linking extracted entities to broader knowledge graph representations, with Wikidata serving as a prominent example. This comprehensive linking establishes a ‘ground truth’ against which the accuracy of LLM-generated answers can be rigorously assessed.</p>
<p>A key capability of the system is its immediate multilinguality. This is particularly critical when processing papers in languages such as Chinese or German and expecting reliable answers in English. The underlying processes, including entity extraction and linking, inherently support multiple languages. Ultimately, an LLM completes the feedback loop by synthesising the insights derived from the knowledge graph operations into concise, human-readable ‘explanatory text’ summaries.</p>
</section>
<section id="query-mapping-to-graph-representations" class="level2" data-number="11.11">
<h2 data-number="11.11" class="anchored" data-anchor-id="query-mapping-to-graph-representations"><span class="header-section-number">11.11</span> Query Mapping to Graph Representations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The system meticulously processes user queries by mapping them to a graph representation, whilst simultaneously annotating the query strings with ‘facts’. For instance, the input query ‘explain male breadwinner model to me’ undergoes an initial fact extraction phase, where semantic triples and relationships are identified. These facts often reference ontological relationships, such as ‘gender roles societal expectations(owl:partOf) male breadwinner model’, indicating that societal expectations related to gender roles constitute a component of the male breadwinner model.</p>
<p>Following this extraction, a comprehensive graph representation is constructed, comprising an array of structured objects. Each object precisely defines a relationship between two concepts; for example, one entry explicitly states <code>concept1: 'gender roles'</code>, <code>concept2: 'male breadwinner model'</code>, and <code>relationship: 'owl:partOf'</code>. The speaker elaborates that this fact extraction process systematically splits the question into smaller, manageable pieces, leveraging a knowledge organisation system that can iteratively generate new levels of terms.</p>
</section>
<section id="entity-linking-with-wikidata" class="level2" data-number="11.12">
<h2 data-number="11.12" class="anchored" data-anchor-id="entity-linking-with-wikidata"><span class="header-section-number">11.12</span> Entity Linking with Wikidata</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>The system meticulously links entities to the Wikidata ontology, exemplified by the disambiguation and mapping of the term ‘male’ to structured knowledge. Various examples illustrate the polysemy of this term, each associated with a Wikidata entity, its label, a description, a Concept URI, and a similarity score derived from LLM embeddings.</p>
<p>The highest similarity score is attributed to ‘male given name’, indicating a strong LLM association. Other significant associations include ‘male’ as human sex or gender and ‘male organism’. The system also identifies technical usages, such as ‘male connector’, and distinguishes homographs like ‘Malé’, the capital of the Maldives. The speaker clarifies that this process involves linking all entities to Wikidata, thereby obtaining identifiers rather than free strings. These identifiers are inherently linked to multilingual translations, providing access to all properties and enabling queries in diverse languages.</p>
</section>
<section id="conceptual-translation-with-gemma3" class="level2" data-number="11.13">
<h2 data-number="11.13" class="anchored" data-anchor-id="conceptual-translation-with-gemma3"><span class="header-section-number">11.13</span> Conceptual Translation with <em>Gemma3</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>The system demonstrates robust multilingual support by treating the core of a query, such as ‘bread winner model’, as a distinct conceptual entity. A Large Language Model, specifically <em>Gemma3</em>, then produces comprehensive translations for this concept. The underlying mechanism employs a structured data representation, akin to RDF/Turtle, to define and translate the concept of a ‘male breadwinner model’.</p>
<p>This involves defining the central concept with a unique URI and associating it with an extensive list of languages, from Czech to Ukrainian. For each language, a precise translation is provided; for example, the Chinese translation is ‘男性主導收入模式’. The frequent inclusion of gendered terms in many translations underscores the specific nature of the concept. The speaker confirms that this process enables the question to be translated into hundreds of languages, with all such translations serving as queries to the LLM.</p>
</section>
<section id="system-functionality-and-benefits" class="level2" data-number="11.14">
<h2 data-number="11.14" class="anchored" data-anchor-id="system-functionality-and-benefits"><span class="header-section-number">11.14</span> System Functionality and Benefits</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>This system offers a robust pipeline that functions effectively for any collection, systematically creating a semantic index and a local chatbot. The capability for ‘local chatting with papers’ significantly supports human ‘close reading’, offering an interactive tool for in-depth textual analysis.</p>
<p>Furthermore, the system effectively ‘contains the search space’ by integrating the user’s question and the specific collection into a particular area within the networked space of scientific knowledge. Crucially, it enables users to gain information extending beyond what is explicitly expressed in the text or annotated in the metadata. This is achieved by forging associations at both the natural language and the Knowledge Organisation Systems level, uncovering implicit knowledge and connections. The <em>Ghostwriter</em> interface, built upon the <em>EverythingData</em> workflow, enables users to find related documents and to refine their queries.</p>
<p>The speaker elaborates on the concept of ‘ground truth’, explaining that knowledge has been decoupled from questions and papers, allowing it to be stored independently of the model. This separation permits the use of entirely different models to produce the same list of identifiers, thereby enabling the creation of benchmarks for future generations of scientists.</p>
</section>
<section id="future-directions" class="level2" data-number="11.15">
<h2 data-number="11.15" class="anchored" data-anchor-id="future-directions"><span class="header-section-number">11.15</span> Future Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The ‘MDA case’ currently serves as a pilot, yet future developments aim to incorporate bibliometric questions, necessitating the integration of metadata harvesting. This progression distinguishes between ‘chatting-with-papers’ and ‘chatting-about-ensemble of papers’. The project intends to expand its application to other significant use cases, including CBS (Dutch Statistical Office) data, which is intrinsically linked to the ODISSEI Portal and the SSHOC.nl project. Furthermore, the scope will extend to specialised Dataverse instances concerning performing arts and inclusion, exemplified by the MuseIT case.</p>
<p>Critical methodological questions for the future revolve around rigorously evaluating the workflow and developing advanced visualisation techniques to display new findings effectively. An API facilitates an automatic mode for agentic architectures, enabling the collection of results and the identification of novel knowledge within papers. The speaker underscored the inherent value of this local approach, highlighting its benefits over reliance on large, less controllable, and often costly external machines. This ‘chatting with papers’ is conceptualised as engaging with an ‘invisible college’, not merely for definitive facts, but primarily to provoke and support the human thought process in formulating precise research questions.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_012.html" class="pagination-link" aria-label="RAG systems solve central problems of LLMs">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>