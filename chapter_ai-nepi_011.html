<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst">
<meta name="dcterms.date" content="2025-01-01">

<title>11&nbsp; Science Dynamics and AI – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_012.html" rel="next">
<link href="./chapter_ai-nepi_010.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_011.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Transformer’s Legacy: Understanding Large Language Models and their Application in HPSS Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Workflow and Utility of OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Beyond Traditional Views of Science Funding</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#context-science-dynamics-information-overload-and-ai" id="toc-context-science-dynamics-information-overload-and-ai" class="nav-link" data-scroll-target="#context-science-dynamics-information-overload-and-ai"><span class="header-section-number">11.1</span> Context: Science Dynamics, Information Overload, and AI</a></li>
  <li><a href="#research-objectives-and-system-introduction-ghostwriter-and-everythingdata" id="toc-research-objectives-and-system-introduction-ghostwriter-and-everythingdata" class="nav-link" data-scroll-target="#research-objectives-and-system-introduction-ghostwriter-and-everythingdata"><span class="header-section-number">11.2</span> Research Objectives and System Introduction: Ghostwriter and EverythingData</a></li>
  <li><a href="#the-ghostwriter-interface-a-novel-information-retrieval-approach" id="toc-the-ghostwriter-interface-a-novel-information-retrieval-approach" class="nav-link" data-scroll-target="#the-ghostwriter-interface-a-novel-information-retrieval-approach"><span class="header-section-number">11.3</span> The Ghostwriter Interface: A Novel Information Retrieval Approach</a></li>
  <li><a href="#theoretical-framework-retrieval-augmented-generation-rag-with-graphrag" id="toc-theoretical-framework-retrieval-augmented-generation-rag-with-graphrag" class="nav-link" data-scroll-target="#theoretical-framework-retrieval-augmented-generation-rag-with-graphrag"><span class="header-section-number">11.4</span> Theoretical Framework: Retrieval Augmented Generation (RAG) with GraphRAG</a></li>
  <li><a href="#system-workflow-from-document-ingestion-to-query-response" id="toc-system-workflow-from-document-ingestion-to-query-response" class="nav-link" data-scroll-target="#system-workflow-from-document-ingestion-to-query-response"><span class="header-section-number">11.5</span> System Workflow: From Document Ingestion to Query Response</a></li>
  <li><a href="#implementation-and-use-case-interacting-with-mda-journal-articles" id="toc-implementation-and-use-case-interacting-with-mda-journal-articles" class="nav-link" data-scroll-target="#implementation-and-use-case-interacting-with-mda-journal-articles"><span class="header-section-number">11.6</span> Implementation and Use Case: Interacting with MDA Journal Articles</a></li>
  <li><a href="#core-functionality-factual-chat-referencing-and-iterative-refinement" id="toc-core-functionality-factual-chat-referencing-and-iterative-refinement" class="nav-link" data-scroll-target="#core-functionality-factual-chat-referencing-and-iterative-refinement"><span class="header-section-number">11.7</span> Core Functionality: Factual Chat, Referencing, and Iterative Refinement</a></li>
  <li><a href="#advanced-backend-mechanisms-entity-management-and-multilingual-capabilities" id="toc-advanced-backend-mechanisms-entity-management-and-multilingual-capabilities" class="nav-link" data-scroll-target="#advanced-backend-mechanisms-entity-management-and-multilingual-capabilities"><span class="header-section-number">11.8</span> Advanced Backend Mechanisms: Entity Management and Multilingual Capabilities</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst <a href="mailto:philipp.mayr@gesis.org" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Researchers at DANS, the data archive of the Royal Netherlands Academy of Arts and Science, and GESIS, a prominent research institute, have pioneered an innovative AI-driven solution. This system directly addresses the pervasive challenge of information overload within scientific research. Their primary objective centred on crafting a system that enables users to ‘chat with papers’ from a carefully curated collection, specifically focusing on articles from the <em>method-data-analysis</em> (<em>mda</em>) journal.</p>
<p>This ambitious endeavour harnesses sophisticated data processing pipelines, collectively termed <em>EverythingData</em>. These pipelines encompass meticulous term extraction, precise embedding generation, and the efficient utilisation of a <em>Qdrant</em> vector store. Central to this architecture is the <em>Ghostwriter</em> interface, which elegantly facilitates natural language interaction with the processed documents. The underlying methodology draws heavily upon Retrieval Augmented Generation (RAG), seamlessly integrating vector spaces with knowledge graphs, notably <em>Wikidata</em>, to significantly enhance contextual understanding and factual accuracy. This approach, inspired by concepts such as <em>GraphRAG</em>, employs a local, one-billion-parameter Large Language Model (LLM) as both a reasoning engine and an intuitive interface; <em>Gemma3</em> specifically handles translation tasks.</p>
<p>The system’s architecture meticulously splits papers into identifiable blocks, links entities to knowledge graphs for robust grounding, and inherently supports multilingual queries. Initial tests, conducted on a collection of 100 <em>mda</em> articles, compellingly demonstrate the system’s capacity to deliver factual, referenced answers. Crucially, it explicitly states when information is absent, thereby preventing hallucinations, and readily permits iterative query refinement. Moreover, this work proposes a novel methodology for creating LLM benchmarks by decoupling knowledge into <em>Wikidata</em> identifiers, thus paving the way for more sustainable and verifiable AI in scientific knowledge production.</p>
</section>
<section id="context-science-dynamics-information-overload-and-ai" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="context-science-dynamics-information-overload-and-ai"><span class="header-section-number">11.1</span> Context: Science Dynamics, Information Overload, and AI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>This exploration into AI’s pivotal role in science dynamics stems from a collaborative endeavour between DANS, the data archive of the Royal Netherlands Academy of Arts and Science, and GESIS, a research-active archive. Whilst DANS primarily focuses on data archiving, GESIS also conducts extensive research. The initiative originated from the profound experimentation of Slava Tikhonov, a senior research engineer at DANS, who has meticulously developed intricate data processing pipelines—complex systems aptly characterised by Arno Simons as a ‘tangle of interwoven components’.</p>
<p>Modern sciences evolve with remarkable rapidity and increasing differentiation. This trajectory, however, poses a significant challenge: how can researchers effectively review, evaluate, and select pertinent information from an ever-expanding corpus? Consequently, scholars confront a veritable ‘flood of information’. The ability to locate and comprehend existing knowledge forms a fundamental precondition for creating new insights, whether by individuals or broader academic communities. A central question thus emerges: can machines, particularly the latest AI technologies that have paradoxically contributed to this information proliferation, also assist in the knowledge production process itself? This chapter investigates this crucial question through the lens of Information Retrieval, aiming to elucidate complex AI solutions comprehensively via a practical use case.</p>
</section>
<section id="research-objectives-and-system-introduction-ghostwriter-and-everythingdata" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="research-objectives-and-system-introduction-ghostwriter-and-everythingdata"><span class="header-section-number">11.2</span> Research Objectives and System Introduction: Ghostwriter and EverythingData</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>Investigators pursued a specific research question: could they construct an AI solution enabling users to interact conversationally with a selected collection of academic papers? To address this, they developed a system comprising two primary components, internally designated <em>Ghostwriter</em> and <em>EverythingData</em>. <em>Ghostwriter</em> functions as the user-facing interface, whilst <em>EverythingData</em> encompasses the intricate array of backend processes.</p>
<p>This chapter introduces foundational concepts such as Information Retrieval, human-machine interaction, and the Retrieval-Augmented Generation (RAG) technique in generative AI. Subsequently, it details the compelling use case involving the <em>method-data-analysis</em> (<em>mda</em>) journal. A core segment elucidates the workflow underpinning this ‘local’ or ‘tailored’ AI solution, providing illustrations of both front-end and back-end operations, before concluding with a summary and outlook.</p>
</section>
<section id="the-ghostwriter-interface-a-novel-information-retrieval-approach" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="the-ghostwriter-interface-a-novel-information-retrieval-approach"><span class="header-section-number">11.3</span> The Ghostwriter Interface: A Novel Information Retrieval Approach</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>Researchers conceptualise the <em>Ghostwriter</em> system as a novel interface for Information Retrieval. Its design philosophy draws inspiration from Slava Tikhonov’s insightful metaphors, which distinguish between two modes of interaction: ‘talking to the librarian’ and ‘talking to the expert’. The ‘librarian’ symbolises engagement with structured data, knowledge organisation systems, and pre-existing classifications. Conversely, the ‘expert’ represents interaction through natural language.</p>
<p>Crucially, the <em>Ghostwriter</em> interface enables users to converse with both these symbolic entities simultaneously. This capability rests upon a local Large Language Model (LLM) operating on a target data collection, which is further embedded within a network of supplementary data interpretation sources accessible via APIs. This innovative approach seeks to overcome the classic Information Retrieval challenge, where users often require prior knowledge of a database’s schema and typical values to formulate effective queries and obtain optimal results.</p>
</section>
<section id="theoretical-framework-retrieval-augmented-generation-rag-with-graphrag" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="theoretical-framework-retrieval-augmented-generation-rag-with-graphrag"><span class="header-section-number">11.4</span> Theoretical Framework: Retrieval Augmented Generation (RAG) with GraphRAG</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The system’s development firmly situates itself within the broader scientific discourse of Retrieval Augmented Generation (RAG). For a comprehensive introduction to this topic, particularly the integration of knowledge graphs, readers are highly encouraged to consult Philip Rattliff’s seminal paper, ‘<em>GenAI Knowledge Graph The GraphRAG Manifesto: Adding Knowledge to GenAI</em>’ (Neo4j, 11 July 2024). Arno Simons also merits acknowledgement for his significant contributions in this domain, particularly concerning the RAG ‘tool box’.</p>
<p>This RAG approach fundamentally comprises three main ingredients. Firstly, researchers construct a vector space from the content of data files, encoding them as embeddings that meticulously capture properties and their attributes; various Machine Learning algorithms and diverse LLMs compute these embeddings. Secondly, a graph forms a metadata layer, seamlessly integrating with diverse ontologies and controlled vocabularies, including those pertinent to responsible AI, and is expressed using the <em>Croissant ML</em> standard. The overarching vision, termed <em>GraphRAG</em>, aims to unify these graph and vector components within a single model. Developers plan to implement this ‘locally’, conceptualising it as a form of Distributed AI where the LLM serves as both an ‘interface’ between human and AI and a ‘reasoning engine’. In practice, the LLM connects to a ‘RAG library’ (representing the graph), navigates datasets, and consumes embeddings (the vectors) to provide essential context for its operations.</p>
</section>
<section id="system-workflow-from-document-ingestion-to-query-response" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="system-workflow-from-document-ingestion-to-query-response"><span class="header-section-number">11.5</span> System Workflow: From Document Ingestion to Query Response</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_05.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The system processes information through a clearly defined workflow, commencing with a collection of input documents. For demonstration purposes, researchers utilised articles from the <em>mda</em> journal, scraping a small number, though any document collection can serve as input. These documents first enter the <em>EverythingData</em> backend, where a series of sophisticated operations transform them. Initially, the system ingests information into a vector store, employing <em>Qdrant</em> for this purpose. Subsequent operations include meticulous term extraction, the construction of precise embeddings, and various enrichments. Notably, selected terms become structured data within a graph, further enriched by linking to external resources such as <em>Wikidata</em>. This coupling with knowledge graphs proves crucial, as it significantly enhances the value of words, phrases, and embeddings by adding layers of contextualisation.</p>
<p>All processed data then populates a ‘vector space RAG-Graph’, which forms the core reasoning substrate. When a user poses a question in natural language via the <em>Ghostwriter</em> interface, this query directly interacts with the vector space RAG-Graph. In response, the system delivers not only a list of relevant documents, typical of conventional information retrieval systems, but also a generated summary or explanatory text that the underlying ‘machinery’ deems pertinent to the user’s question. An accompanying diagram from <em>TheAidedge.io</em> compellingly illustrates the comparative roles of vector and graph databases within RAG architectures.</p>
</section>
<section id="implementation-and-use-case-interacting-with-mda-journal-articles" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="implementation-and-use-case-interacting-with-mda-journal-articles"><span class="header-section-number">11.6</span> Implementation and Use Case: Interacting with MDA Journal Articles</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>Slava Tikhonov, a senior research engineer at DANS, meticulously detailed the system’s implementation, drawing upon his early engagement with Large Language Models (LLMs) since testing <em>GPT-2</em> in 2020. His methodology involves deconstructing the LLM training process into smaller, adaptable components. This approach yields a versatile system applicable not only to academic papers but also to diverse web content; for instance, it can interact with spreadsheets, enabling users to query specific values and receive factual, non-hallucinated responses derived exclusively from the spreadsheet’s data. For complex queries, the system employs a one-billion-parameter LLM, significantly enhanced by integrated knowledge graphs.</p>
<p>The primary use case centres on the ‘<em>mda methods, data, analyses</em>’ journal, a GESIS publication. Engineers ingested papers from this journal into the <em>Ghostwriter</em> tool, thereby creating a distinct collection. A core design principle dictates that the system must not rely on any general knowledge pre-loaded into the LLM; instead, it must answer questions using only factual information present within the specified papers. If the requested information is absent, the system transparently states ‘I don’t know’, thereby avoiding speculation. For testing, developers utilised a collection of 100 articles scraped from the <em>mda</em> website. The <em>Ghostwriter</em> instance for these <em>mda</em> papers remains accessible at https://gesis.now.museum. The GESIS ‘Ask Questions’ interface, presented as part of the broader ecosystem, allows users to add new content collections via various means, including single webpages, website crawlers, or RSS feeds.</p>
</section>
<section id="core-functionality-factual-chat-referencing-and-iterative-refinement" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="core-functionality-factual-chat-referencing-and-iterative-refinement"><span class="header-section-number">11.7</span> Core Functionality: Factual Chat, Referencing, and Iterative Refinement</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> system compellingly demonstrates its core functionalities through practical examples. When a user queries, for instance, ‘explain male breadwinner model to me’, the system furnishes a detailed explanation and, crucially, provides precise references to the source documents. This implementation actively prevents hallucination by meticulously locating information within the ingested texts. Engineers achieve this accuracy by splitting each paper into small, identifiable blocks, each assigned a unique identifier. LLM-based techniques then intelligently connect and retrieve these blocks, whilst weights and other methods further refine the process. Furthermore, knowledge graphs assist in predicting which specific text segments are most likely to provide a relevant answer to a given question.</p>
<p>Should a query be refined—for instance, to ‘explain how data was collected on male breadwinner model’—and the information proves absent from the current corpus, the system responds transparently: ‘According to the provided text, there is no direct information about how data was collected on the male breadwinner model.’ This honesty represents a key feature. The system also supports iterative improvement; an ‘add paper’ button enables users to integrate new documents they discover externally. Subsequently, if the same question is posed, the system can readily utilise this newly incorporated information. For all queries, the interface displays source papers, including their titles, direct links (e.g., to <em>mda.gesis.org</em>), and relevance scores, although not all listed documents may contain the exact query terms in their full text.</p>
</section>
<section id="advanced-backend-mechanisms-entity-management-and-multilingual-capabilities" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="advanced-backend-mechanisms-entity-management-and-multilingual-capabilities"><span class="header-section-number">11.8</span> Advanced Backend Mechanisms: Entity Management and Multilingual Capabilities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_11.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Several advanced backend mechanisms empower the <em>Ghostwriter</em> system, particularly in entity management and multilingual support. An entity extraction pipeline annotates terms with semantic meaning by mapping them to controlled vocabularies, thereby effectively bridging vector spaces and knowledge graphs. These entities then link to richer knowledge graph representations, with <em>Wikidata</em> serving as a prime example; this linkage proves vital for establishing ground truth. The system also offers immediate multilinguality, enabling seamless interaction even when query and document languages differ. Finally, the LLM processes the retrieved, relevant text pieces to generate a coherent summary or ‘explanatory text’.</p>
<p>Delving deeper into fact extraction, a user’s query undergoes mapping to a graph representation, and its constituent strings are meticulously annotated with ‘facts’. For instance, terms such as ‘gender roles’ or ‘male breadwinner model’ connect to concepts like ‘societal expectations’ or ‘economic systems’. This process relies on a Knowledge Organisation System (KOS) that can be iteratively applied to reveal progressively deeper semantic layers beneath a term. Instead of relying on free-text strings, the system links entities to <em>Wikidata</em>, thereby obtaining unique identifiers. These identifiers intrinsically connect to multilingual translations and a wealth of properties, allowing, for example, the term ‘male’ to resolve to its specific <em>Wikidata</em> entry (e.g., Q12308941), with LLM embeddings providing similarity scores for disambiguation.</p>
<p>Multilingual capability is robustly implemented. The system identifies the core concept of a query, such as ‘male breadwinner model’ (represented as ‘bread winner mo’). An LLM, specifically <em>Gemma3</em>, then generates translations of this core concept into a multitude of languages, including Czech, Danish, German, and Japanese, amongst others. These translations effectively broaden the search parameters for the primary LLM.</p>
<p>This sophisticated approach underpins a broader vision for Knowledge Organisation Systems. By converting concepts into <em>Wikidata</em> identifiers, knowledge becomes decoupled from the specifics of individual questions or papers. Such abstracted knowledge can be stored independently of any single LLM, thereby fostering model agnosticism. This decoupling also facilitates a novel benchmarking methodology: different LLMs, even those yet to be developed, can be evaluated by their ability to return the same set of identifiers for identical conceptual queries. Any deviations would signal potential issues with a model’s suitability for certain tasks. Collaborations with industry leaders like <em>Google</em> and <em>Meta</em> aim to establish this KOS-centric methodology as a sustainable and foundational element for future scientific endeavours, positioning KOS as a cornerstone of future knowledge management.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Large Language Models for Footnote Parsing in Law and Humanities Scholarship">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_012.html" class="pagination-link" aria-label="Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>