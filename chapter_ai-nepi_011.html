<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst">
<meta name="dcterms.date" content="2025-01-01">

<title>11&nbsp; Science dynamics and AI – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_012.html" rel="next">
<link href="./chapter_ai-nepi_010.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_011.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models: Architecture, Adaptation, and Applications in HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#presentation-objectives-and-core-research-question" id="toc-presentation-objectives-and-core-research-question" class="nav-link" data-scroll-target="#presentation-objectives-and-core-research-question"><span class="header-section-number">11.1</span> Presentation Objectives and Core Research Question</a></li>
  <li><a href="#the-ghostwriter-interface-a-new-paradigm-for-information-retrieval" id="toc-the-ghostwriter-interface-a-new-paradigm-for-information-retrieval" class="nav-link" data-scroll-target="#the-ghostwriter-interface-a-new-paradigm-for-information-retrieval"><span class="header-section-number">11.2</span> The Ghostwriter Interface: A New Paradigm for Information Retrieval</a></li>
  <li><a href="#retrieval-augmented-generation-rag-and-graphrag-architecture" id="toc-retrieval-augmented-generation-rag-and-graphrag-architecture" class="nav-link" data-scroll-target="#retrieval-augmented-generation-rag-and-graphrag-architecture"><span class="header-section-number">11.3</span> Retrieval Augmented Generation (RAG) and GraphRAG Architecture</a></li>
  <li><a href="#ghostwriter-and-everythingdata-workflow" id="toc-ghostwriter-and-everythingdata-workflow" class="nav-link" data-scroll-target="#ghostwriter-and-everythingdata-workflow"><span class="header-section-number">11.4</span> Ghostwriter and EverythingData Workflow</a></li>
  <li><a href="#ghostwriter-document-indexing-and-collection-management" id="toc-ghostwriter-document-indexing-and-collection-management" class="nav-link" data-scroll-target="#ghostwriter-document-indexing-and-collection-management"><span class="header-section-number">11.5</span> Ghostwriter: Document Indexing and Collection Management</a></li>
  <li><a href="#ghostwriter-chatting-with-papers-and-hallucination-prevention" id="toc-ghostwriter-chatting-with-papers-and-hallucination-prevention" class="nav-link" data-scroll-target="#ghostwriter-chatting-with-papers-and-hallucination-prevention"><span class="header-section-number">11.6</span> Ghostwriter: Chatting with Papers and Hallucination Prevention</a></li>
  <li><a href="#iterative-query-refinement-and-content-addition" id="toc-iterative-query-refinement-and-content-addition" class="nav-link" data-scroll-target="#iterative-query-refinement-and-content-addition"><span class="header-section-number">11.7</span> Iterative Query Refinement and Content Addition</a></li>
  <li><a href="#behind-the-screens-entity-extraction-and-multilinguality" id="toc-behind-the-screens-entity-extraction-and-multilinguality" class="nav-link" data-scroll-target="#behind-the-screens-entity-extraction-and-multilinguality"><span class="header-section-number">11.8</span> Behind the Screens: Entity Extraction and Multilinguality</a></li>
  <li><a href="#fact-extraction-and-knowledge-organisation-systems" id="toc-fact-extraction-and-knowledge-organisation-systems" class="nav-link" data-scroll-target="#fact-extraction-and-knowledge-organisation-systems"><span class="header-section-number">11.9</span> Fact Extraction and Knowledge Organisation Systems</a></li>
  <li><a href="#linking-entities-to-wikidata-for-multilingual-support" id="toc-linking-entities-to-wikidata-for-multilingual-support" class="nav-link" data-scroll-target="#linking-entities-to-wikidata-for-multilingual-support"><span class="header-section-number">11.10</span> Linking Entities to Wikidata for Multilingual Support</a></li>
  <li><a href="#multilingual-query-translation" id="toc-multilingual-query-translation" class="nav-link" data-scroll-target="#multilingual-query-translation"><span class="header-section-number">11.11</span> Multilingual Query Translation</a></li>
  <li><a href="#summary-of-pipeline-capabilities-and-future-vision" id="toc-summary-of-pipeline-capabilities-and-future-vision" class="nav-link" data-scroll-target="#summary-of-pipeline-capabilities-and-future-vision"><span class="header-section-number">11.12</span> Summary of Pipeline Capabilities and Future Vision</a></li>
  <li><a href="#live-demonstration-querying-and-multilingual-capabilities" id="toc-live-demonstration-querying-and-multilingual-capabilities" class="nav-link" data-scroll-target="#live-demonstration-querying-and-multilingual-capabilities"><span class="header-section-number">11.13</span> Live Demonstration: Querying and Multilingual Capabilities</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst <a href="mailto:philipp.mayr@gesis.org" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<pre><code>  This presentation details the development of an AI solution designed to facilitate interaction with scholarly papers, addressing the increasing volume of scientific information. Researchers from DANS, the data archive of the Royal Netherlands Academy of Arts and Sciences, and GESIS, an archive also engaged in research, collaborated on this project. Their primary objective involved constructing an AI system that enables users to "chat" with selected academic texts, thereby enhancing information retrieval processes.

  The solution comprises two principal components: Ghostwriter, serving as the user interface, and EverythingData, which manages the underlying backend workflow. Ghostwriter functions as a novel information retrieval interface, allowing simultaneous interaction with both structured data (metaphorically, a "librarian" representing knowledge organisation systems) and natural language content (an "expert"). This approach aligns with the broader scientific discourse surrounding Retrieval Augmented Generation (RAG), specifically advocating for a GraphRAG methodology.

  The system's core ingredients include a vector space, constructed from data file content encoded as embeddings via various machine learning algorithms and Large Language Models (LLMs), and a graph, which represents a metadata layer integrated with diverse ontologies and controlled vocabularies, including those for responsible AI, expressed using the Croissant ML standard. The vision centres on unifying these graph and vector representations within a single model, creating a local, distributed AI where the LLM acts as both an interface and a reasoning engine. This engine connects to a "RAG library" (the graph), navigates datasets, and consumes embeddings (vectors) as contextual information.

  Implementation begins with ingesting a collection of articles, such as those from the *methods, data, analyses* (MDA) journal. EverythingData processes these articles, storing information in a vector store (Qdrant) and performing operations like term extraction, embedding construction, and enrichment. Crucially, the system couples these processes with knowledge graphs, thereby contextualising embeddings and enhancing their value. Users formulate natural language queries within the Ghostwriter interface, prompting the system to return a list of relevant documents and an explanatory summary.

  To prevent hallucinations, the system explicitly states when information is not directly available within the provided text, offering users the option to add new papers. Backend operations involve an entity extraction pipeline that annotates terms with semantic meaning by mapping them to controlled vocabularies, transitioning from vector space to the knowledge graph. Entities are further linked to the Wikidata ontology, providing immediate multilingual support by enabling queries in various languages. The LLM then synthesises these extracted text pieces to produce the final explanatory output.

  The pipeline demonstrates versatility, functioning with any collection, including webpages, RSS feeds, and trusted data repositories like Dataverse instances. This capability enables localised interaction with papers, supporting close reading and containing the search space by situating questions within specific areas of scientific knowledge. The system extracts information beyond explicit text and metadata, forging associations at both natural language and Knowledge Organisation System levels. The Ghostwriter interface specifically facilitates the identification of related documents and the refinement of queries.

  A key innovation lies in decoupling knowledge from questions and papers, storing this knowledge externally (e.g., as Wikidata identifiers). This separation allows for benchmarking different models against established Knowledge Organisation Systems, fostering future advancements in scientific inquiry. The project actively collaborates with industry partners, including Google and Meta, to ensure the sustainability of this KOS-based approach. During a live demonstration, the Ghostwriter interface successfully processed queries regarding "rational choice theory" and "utility in rational choice theory," providing accurate summaries and references, whilst showcasing its multilingual capabilities by processing a German-language paper. The system employs a 1 billion parameter LLM (Llama), capable of local execution, and segments papers into small, identifiable blocks, leveraging LLM techniques and knowledge graphs to predict relevant text segments. This local processing capability offers greater control and cost-effectiveness compared to reliance on large, external models, ultimately supporting human thought processes in formulating research questions rather than providing definitive answers. The system has already demonstrated scalability, handling approximately 300,000 documents for Harvard University.</code></pre>
</section>
<section id="presentation-objectives-and-core-research-question" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="presentation-objectives-and-core-research-question"><span class="header-section-number">11.1</span> Presentation Objectives and Core Research Question</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<pre><code>    This presentation addresses a pivotal research question: whether an AI solution can be effectively constructed to facilitate interactive "chatting" with a curated selection of academic papers. The discussion commences by introducing fundamental concepts in information retrieval, exploring the intricate dynamics of human-machine interaction, and detailing the principles of Retrieval-Augmented Generation (RAG) within generative AI.

    A specific use case, drawing upon articles from the *methods, data, analyses* (MDA) journal, illustrates the practical application of the developed system. The presentation then introduces the underlying workflow of a "local" or "tailored AI solution," which comprises two key components: Ghostwriter, serving as the interface, and EverythingData, encompassing the comprehensive backend operations. Subsequent sections provide detailed illustrations of both front-end and back-end functionalities, culminating in a summary and an outlook on future developments.

    The broader context for this endeavour stems from the pervasive challenge of managing the overwhelming flood of information in contemporary science. This initiative represents a collaborative effort between DANS, the data archive of the Royal Netherlands Academy of Arts and Sciences, and GESIS, an institution that combines archiving with active research.
  </code></pre>
</section>
<section id="the-ghostwriter-interface-a-new-paradigm-for-information-retrieval" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="the-ghostwriter-interface-a-new-paradigm-for-information-retrieval"><span class="header-section-number">11.2</span> The Ghostwriter Interface: A New Paradigm for Information Retrieval</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<pre><code>    The Ghostwriter approach introduces a novel interface for information retrieval, fundamentally altering how users interact with data. This system conceptualises information access through a series of evolving metaphors, each representing increasing sophistication in interaction. Initially, querying a single database, akin to "Me and a database," necessitates explicit knowledge of the schema and its typical values to yield results, embodying a classic information retrieval challenge.

    Progressing beyond this, the interaction with "Me and a librarian" signifies engagement with a single data collection or space, where connected structured databases or graphs operate in the background. This "librarian" metaphor specifically refers to structured data, encompassing knowledge organisation systems (KOS) and pre-existing classifications. Further still, the advent of Large Language Models (LLMs) transforms the interaction into "Me and a library" or "Me and a round of experts," where natural language becomes the primary mode of engagement.

    Crucially, the Ghostwriter interface claims to enable simultaneous "chatting with experts and librarians." This advanced interaction is facilitated by a local LLM, integrated with a target data collection or space, and embedded within a network of additional data interpretation sources via APIs. This innovative design allows users to leverage both structured knowledge and the nuanced understanding provided by natural language processing in a unified environment.
  </code></pre>
</section>
<section id="retrieval-augmented-generation-rag-and-graphrag-architecture" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="retrieval-augmented-generation-rag-and-graphrag-architecture"><span class="header-section-number">11.3</span> Retrieval Augmented Generation (RAG) and GraphRAG Architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<pre><code>    Scientifically, this project situates itself within the broader discourse of Retrieval Augmented Generation (RAG). A particularly insightful resource on this topic is Philip Rustle's paper from Neo4j, which offers a comprehensive introduction to the field. The system's architecture relies on two main ingredients: a vector space and a graph.

    The vector space is meticulously constructed from the content of data files, with information encoded into embeddings. Various Machine Learning (ML) algorithms and diverse Large Language Models (LLMs) compute these embeddings. Concurrently, a graph component represents a sophisticated metadata layer. This graph integrates seamlessly with a range of ontologies and controlled vocabularies, notably including those pertaining to responsible AI, and adheres to the Croissant ML standard for its expression.

    The overarching vision for this system involves the integration of both graph and vector representations into a singular, cohesive model, termed GraphRAG. This model is designed for implementation as a "local" Distributed AI, where the LLM performs a dual function: serving as the primary interface between human users and the AI, and operating as a robust reasoning engine. In practice, the LLM connects to a "RAG library," which embodies the graph structure. Through this connection, the LLM navigates extensive datasets and consumes embeddings, which represent the vector component, as crucial contextual information.
  </code></pre>
</section>
<section id="ghostwriter-and-everythingdata-workflow" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="ghostwriter-and-everythingdata-workflow"><span class="header-section-number">11.4</span> Ghostwriter and EverythingData Workflow</h2>
<pre><code>    The Ghostwriter and EverythingData workflow commences with a designated collection of articles, exemplified by those from the *methods, data, analyses* (MDA) journal. This system, however, demonstrates versatility, accepting any collection of documents as its input. The "EverythingData" component, representing the upper part of the workflow, orchestrates a series of operations.

    Initially, this component stores information within a vector store, specifically utilising Qdrant. Subsequently, it executes various processes, including term extraction, the construction of embeddings, and further enrichments. A critical aspect involves the integration with knowledge graphs, which couples the processed information to contextualise the embeddings. This integration significantly enhances the value of specific words, phrases, and embeddings by providing a richer context.

    All processed data then converges into a unified vector space, termed the RAG-Graph. The Ghostwriter interface directly interacts with this RAG-Graph vector space, allowing users to formulate queries as natural language questions. In response, the system delivers a list of relevant documents and an explanatory summary, generated by the underlying machinery. A key design principle ensures that the system does not hallucinate; it precisely identifies the source of its information.

    From an implementation perspective, the system meticulously splits each paper into small, manageable blocks, assigning a unique identifier to every block. Leveraging advanced LLM techniques, the system intelligently connects and retrieves these blocks, employing weights in conjunction with knowledge graphs to accurately predict which pieces of text will best respond to a specific question.
  </code></pre>
</section>
<section id="ghostwriter-document-indexing-and-collection-management" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="ghostwriter-document-indexing-and-collection-management"><span class="header-section-number">11.5</span> Ghostwriter: Document Indexing and Collection Management</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<pre><code>    Ghostwriter functions as a sophisticated tool for indexing documents and webpages, enabling their organisation into distinct collections. The system initially ingested articles from the *methods, data, analyses* (MDA) journal, creating a test collection of approximately 100 articles scraped directly from its website. This demonstrates the system's capacity to process and manage specific datasets.

    Crucially, Ghostwriter exhibits considerable input flexibility, capable of ingesting virtually any content from the web, including spreadsheets, individual webpages, entire websites via crawling, and RSS feeds. A core design principle ensures that the system relies exclusively on the ingested source data, thereby preventing hallucinations. Rather than employing large, complex LLMs, the system leverages a more modest 1 billion parameter LLM to address intricate questions, achieving accuracy through its integration with knowledge graphs. The primary objective remains to furnish only factual information present within the paper, explicitly stating "I don't know" if the requested information is unavailable in the source material.

    The user interface, accessible via the "Ask Questions" section on the GESIS website, provides an intuitive input field for queries. Users can readily create new collections, manage available collections (such as the pre-selected "mda" collection), and add new content through options like "Single Webpage," "Website Crawler," or "RSS Feed." The Ghostwriter system, specifically for MDA papers, is accessible online via `https://gesis.now.museum`.
  </code></pre>
</section>
<section id="ghostwriter-chatting-with-papers-and-hallucination-prevention" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="ghostwriter-chatting-with-papers-and-hallucination-prevention"><span class="header-section-number">11.6</span> Ghostwriter: Chatting with Papers and Hallucination Prevention</h2>
<pre><code>    Ghostwriter's core functionality centres on enabling users to "chat" directly with academic papers. For instance, when presented with the query "explain male breadwinner model to me," the system delivers a concise explanation alongside precise references. These references, unlike those often generated by general-purpose LLMs, are accurate and directly traceable to the original sources, such as "The Past, Present and Future of Factorial Survey Experiments" and "Gender and Survey Participation."

    A fundamental design principle ensures that the system does not hallucinate; it maintains an exact awareness of its information sources. This precision is achieved through a meticulous implementation strategy: each paper undergoes a process of segmentation into small, discrete blocks, with a unique identifier assigned to every block. The underlying LLM then employs sophisticated techniques to connect and retrieve these blocks, applying weights in conjunction with knowledge graphs to accurately predict which text segments are most pertinent to a given question. The interface clearly presents the answer, followed by a "Sources" section that lists the contributing papers, complete with a "Chat" button, title, reference URL, and a relevance score.
  </code></pre>
</section>
<section id="iterative-query-refinement-and-content-addition" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="iterative-query-refinement-and-content-addition"><span class="header-section-number">11.7</span> Iterative Query Refinement and Content Addition</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<pre><code>    The Ghostwriter system incorporates an iterative approach to prevent hallucinations, explicitly stating when information is unavailable. For example, if a user poses the question "explain how data was collected on male breadwinner model," and the direct information is not present in the indexed texts, the system will respond by stating, "According to the provided text, there is no direct information about how data was collected on the male breadwinner model," whilst potentially referring to other related articles.

    This design encourages users to actively participate in refining the knowledge base. Should a user locate an article containing the missing information, they can utilise the "Add Paper" button to ingest it into the system. Consequently, upon subsequent queries regarding the same topic, the system will then be able to provide a comprehensive response, drawing upon the newly added content. The sources section continues to list relevant papers, such as "The Past, Present and Future of Factorial Survey Experiments" and "Gender of Interviewer Effects," even when direct answers are not found for specific sub-queries.
  </code></pre>
</section>
<section id="behind-the-screens-entity-extraction-and-multilinguality" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="behind-the-screens-entity-extraction-and-multilinguality"><span class="header-section-number">11.8</span> Behind the Screens: Entity Extraction and Multilinguality</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<pre><code>    Behind the Ghostwriter interface, a sophisticated entity extraction pipeline operates, meticulously annotating terms with semantic meaning. This process involves mapping terms to controlled vocabularies, effectively transitioning data from the vector space into a structured knowledge graph. Crucially, the system links these extracted entities to broader knowledge graph representations, notably leveraging Wikidata. This linking is paramount as it establishes a "ground truth," enabling the validation of LLM-generated answers and ensuring their accuracy.

    Furthermore, the system provides immediate and robust multilinguality support. This capability is critical; it allows users to pose questions in one language, such as English, and receive reliable answers even when the source papers are written in entirely different languages, like Chinese or German. Ultimately, the LLM synthesises these disparate pieces of text to produce a coherent, explanatory summary.
  </code></pre>
</section>
<section id="fact-extraction-and-knowledge-organisation-systems" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="fact-extraction-and-knowledge-organisation-systems"><span class="header-section-number">11.9</span> Fact Extraction and Knowledge Organisation Systems</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<pre><code>    The fact extraction process within Ghostwriter meticulously dissects a user's query into smaller, manageable pieces. The system then maps this query to a comprehensive graph representation, whilst simultaneously annotating the query strings with specific "facts." For instance, a query such as "explain male breadwinner model to me" prompts the extraction of pertinent facts, including "gender roles societal expectations," "male breadwinner model economic systems," and "male breadwinner model social structures," amongst others.

    The resulting graph representation encapsulates key concepts like "gender roles," "male breadwinner model," "economic systems," "patriarchal society," and "feminine role," complete with their interrelationships and assigned importance scores. This entire mechanism operates as a dynamic Knowledge Organisation System (KOS), capable of repeated querying. Each iteration can generate new, deeper levels of detail beneath the initial terms, providing an increasingly granular understanding of the subject matter.
  </code></pre>
</section>
<section id="linking-entities-to-wikidata-for-multilingual-support" class="level2" data-number="11.10">
<h2 data-number="11.10" class="anchored" data-anchor-id="linking-entities-to-wikidata-for-multilingual-support"><span class="header-section-number">11.10</span> Linking Entities to Wikidata for Multilingual Support</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<pre><code>    A crucial step in the Ghostwriter workflow involves linking all extracted entities directly to Wikidata. This process transforms free-form strings into standardised identifiers, which are inherently connected to a wealth of multilingual translations. Consequently, the system gains the profound ability to comprehend questions posed in various languages, ensuring that the underlying knowledge remains accessible regardless of the query's linguistic origin. The similarity measure, which quantifies the relevance of a link, is derived directly from the LLM embeddings. For example, the term "Male" might be linked to the Wikidata entity `Q12308941`, representing a male given name, with an associated similarity score of 0.3429.
  </code></pre>
</section>
<section id="multilingual-query-translation" class="level2" data-number="11.11">
<h2 data-number="11.11" class="anchored" data-anchor-id="multilingual-query-translation"><span class="header-section-number">11.11</span> Multilingual Query Translation</h2>
<pre><code>    The system's robust multilingual support treats the core query, such as "bread winner model," as a conceptual entity rather than a fixed string. An integrated LLM, specifically Gemma3, then generates translations of this concept into hundreds of languages. This comprehensive set of translations subsequently forms the complete query submitted to the LLM. For instance, the concept is translated into Chinese as "男性主要收入模式 (nánxì zhǔyào shōurù móshì)," alongside translations into Czech, Danish, Dutch, English, French, German, Greek, Italian, Japanese, Korean, Norwegian, Polish, Portuguese, Russian, Slovak, Spanish, Swedish, and Ukrainian, ensuring broad linguistic coverage.
  </code></pre>
</section>
<section id="summary-of-pipeline-capabilities-and-future-vision" class="level2" data-number="11.12">
<h2 data-number="11.12" class="anchored" data-anchor-id="summary-of-pipeline-capabilities-and-future-vision"><span class="header-section-number">11.12</span> Summary of Pipeline Capabilities and Future Vision</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<pre><code>    The developed pipeline demonstrates remarkable versatility, functioning effectively with any collection of documents, whether sourced from webpages, websites, RSS feeds, or trusted data repositories such as Dataverse instances. This capability enables the creation of a "semantic index" and a localised chatbot for diverse collections, thereby supporting "close reading" by human researchers.

    The system strategically contains the search space by situating user questions and their associated collections within specific, relevant areas of the networked scientific knowledge domain. Crucially, it facilitates the acquisition of information that extends beyond what is explicitly stated in the text or annotated in the metadata. This is achieved by forging intricate associations at both the natural language level and within Knowledge Organisation Systems (KOS), effectively simulating a dialogue with the "experts" or "invisible colleges" that underpin the scholarly papers.

    The Ghostwriter interface itself offers dual functionalities: it assists users in identifying related documents and provides mechanisms for refining questions or queries. A significant innovation lies in the system's ability to decouple knowledge from specific questions and papers, storing this knowledge externally, for instance, as Wikidata identifiers. This separation establishes a robust "ground truth," allowing researchers to benchmark different models by comparing the identifier lists they produce in response to identical questions. This method readily identifies models unsuitable for particular tasks, whilst simultaneously leveraging KOS for the benefit of future generations of scientists. The project actively collaborates with industry leaders, including Google and Meta, to ensure the long-term sustainability of this KOS-centric approach, which the developers firmly believe represents the future of information management in science.
  </code></pre>
</section>
<section id="live-demonstration-querying-and-multilingual-capabilities" class="level2" data-number="11.13">
<h2 data-number="11.13" class="anchored" data-anchor-id="live-demonstration-querying-and-multilingual-capabilities"><span class="header-section-number">11.13</span> Live Demonstration: Querying and Multilingual Capabilities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<pre><code>    A live demonstration showcased the "Ask Questions" web interface developed by the GESIS Leibniz-Institut für Sozialwissenschaften. The interface displayed the "mda" collection, comprising 37,637 vectors, as the selected dataset.

    When presented with the query "what is the role of utility in the Rational Choice Theory," the system promptly provided a detailed explanation, citing various researchers and studies. The sources section accurately listed the contributing papers, including "The measurement of utility and subjective probability" and "Responding to Socially Desirable and Undesirable Topics," complete with their respective reference URLs and scores. A subsequent query, "explain utility in rational choice theory," yielded different, yet relevant, pieces of information, consistently pointing back to the same source papers.

    The system also offers an API, enabling an automatic mode for building agentic architectures, where results can be collected and new insights from papers identified. Users can contribute new content via an "Add page" button, ensuring the knowledge base remains current. A compelling aspect of the demonstration involved the system's multilingual capability: whilst the query was posed in English, the primary source paper, "Die Messung von Nutzen und subjektiven Wahrscheinlichkeiten," was entirely in German, save for its abstract. The system successfully processed this, demonstrating its linguistic versatility.

    Technically, the system operates efficiently on a local computer, even accommodating paper training processes, utilising a compact 1 billion parameter LLM. This local deployment offers significant advantages in terms of control and cost-effectiveness, particularly for handling private or sensitive information. The system has already proven its scalability, having been developed for Harvard University to manage approximately 300,000 documents. The developers advocate for this local, controlled approach over a full reliance on external models like ChatGPT, emphasising its role in supporting the human thought process and aiding in the formulation of research questions, rather than merely providing definitive answers. The team actively seeks collaborations with external parties who have concrete research questions, offering resources for try-outs and facilitating the handover of the system for further tinkering and refinement.
  </code></pre>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_012.html" class="pagination-link" aria-label="RAG systems solve central problems of LLMs">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>