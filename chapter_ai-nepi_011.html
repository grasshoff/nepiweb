<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst">
<meta name="dcterms.date" content="2025-01-01">

<title>11&nbsp; Science dynamics and AI – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_012.html" rel="next">
<link href="./chapter_ai-nepi_010.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-85125aaa381e97e617f4eb7319a810c2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_011.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: A Primer and Critical Reflections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Philosophy at Scale: Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification in Historical Patient Organisation Periodicals: A Methodological Report</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE Traces de la Vérité: The reappropriation of ancient wisdom in early modern natural philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Assessing Biases in Bibliometric Databases Using Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Possible applications of RAG systems in philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#science-dynamics-and-ai-addressing-information-overload" id="toc-science-dynamics-and-ai-addressing-information-overload" class="nav-link" data-scroll-target="#science-dynamics-and-ai-addressing-information-overload"><span class="header-section-number">11.1</span> Science Dynamics and AI: Addressing Information Overload</a></li>
  <li><a href="#project-objectives-and-system-architecture" id="toc-project-objectives-and-system-architecture" class="nav-link" data-scroll-target="#project-objectives-and-system-architecture"><span class="header-section-number">11.2</span> Project Objectives and System Architecture</a></li>
  <li><a href="#ghostwriter-a-novel-information-retrieval-interface" id="toc-ghostwriter-a-novel-information-retrieval-interface" class="nav-link" data-scroll-target="#ghostwriter-a-novel-information-retrieval-interface"><span class="header-section-number">11.3</span> Ghostwriter: A Novel Information Retrieval Interface</a></li>
  <li><a href="#retrieval-augmented-generation-rag-framework" id="toc-retrieval-augmented-generation-rag-framework" class="nav-link" data-scroll-target="#retrieval-augmented-generation-rag-framework"><span class="header-section-number">11.4</span> Retrieval-Augmented Generation (RAG) Framework</a></li>
  <li><a href="#ghostwriter-and-everythingdata-operational-workflow" id="toc-ghostwriter-and-everythingdata-operational-workflow" class="nav-link" data-scroll-target="#ghostwriter-and-everythingdata-operational-workflow"><span class="header-section-number">11.5</span> Ghostwriter and EverythingData: Operational Workflow</a></li>
  <li><a href="#ghostwriter-indexing-and-factual-retrieval" id="toc-ghostwriter-indexing-and-factual-retrieval" class="nav-link" data-scroll-target="#ghostwriter-indexing-and-factual-retrieval"><span class="header-section-number">11.6</span> Ghostwriter: Indexing and Factual Retrieval</a></li>
  <li><a href="#chatting-with-papers-the-male-breadwinner-model-example" id="toc-chatting-with-papers-the-male-breadwinner-model-example" class="nav-link" data-scroll-target="#chatting-with-papers-the-male-breadwinner-model-example"><span class="header-section-number">11.7</span> Chatting with Papers: The Male Breadwinner Model Example</a></li>
  <li><a href="#iterative-approach-to-query-refinement-and-factual-integrity" id="toc-iterative-approach-to-query-refinement-and-factual-integrity" class="nav-link" data-scroll-target="#iterative-approach-to-query-refinement-and-factual-integrity"><span class="header-section-number">11.8</span> Iterative Approach to Query Refinement and Factual Integrity</a></li>
  <li><a href="#system-mechanics-entity-extraction-knowledge-graphs-and-multilinguality" id="toc-system-mechanics-entity-extraction-knowledge-graphs-and-multilinguality" class="nav-link" data-scroll-target="#system-mechanics-entity-extraction-knowledge-graphs-and-multilinguality"><span class="header-section-number">11.9</span> System Mechanics: Entity Extraction, Knowledge Graphs, and Multilinguality</a></li>
  <li><a href="#fact-extraction-and-wikidata-integration-for-semantic-enrichment" id="toc-fact-extraction-and-wikidata-integration-for-semantic-enrichment" class="nav-link" data-scroll-target="#fact-extraction-and-wikidata-integration-for-semantic-enrichment"><span class="header-section-number">11.10</span> Fact Extraction and Wikidata Integration for Semantic Enrichment</a></li>
  <li><a href="#multilingual-capabilities-and-the-future-of-knowledge-organisation" id="toc-multilingual-capabilities-and-the-future-of-knowledge-organisation" class="nav-link" data-scroll-target="#multilingual-capabilities-and-the-future-of-knowledge-organisation"><span class="header-section-number">11.11</span> Multilingual Capabilities and the Future of Knowledge Organisation</a></li>
  <li><a href="#live-demonstration-and-philosophical-implications" id="toc-live-demonstration-and-philosophical-implications" class="nav-link" data-scroll-target="#live-demonstration-and-philosophical-implications"><span class="header-section-number">11.12</span> Live Demonstration and Philosophical Implications</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></h1>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst <a href="mailto:philipp.mayr@gesis.org" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter elucidates the development of an innovative AI-driven solution, meticulously crafted to manage the escalating volume of scientific information and to bolster knowledge production. Researchers from DANS (Data Archiving and Networked Services) and GESIS (Leibniz Institute for the Social Sciences) collaborated to confront the pervasive challenge of information overload, which frequently impedes the effective review, evaluation, and selection of scholarly content. Their core objective involved engineering an AI system capable of engaging in a “chat” with papers drawn from specific collections, thereby significantly enhancing information retrieval and human-machine interaction.</p>
<p>The team conceptualised the system as a “local” or “tailored AI solution,” comprising two principal components: <em>Ghostwriter</em>, which serves as the intuitive user interface, and <em>EverythingData</em>, encompassing the intricate back-end processing pipelines. Its foundational methodology employs Retrieval-Augmented Generation (RAG), seamlessly integrating both vector spaces and knowledge graphs. The authors construct vector spaces from data file content, encoding them through embeddings derived from various machine learning algorithms and Large Language Models (LLMs). Concurrently, a graph represents a metadata layer, meticulously integrated with diverse ontologies and controlled vocabularies, including principles of responsible AI, and expressed via the <em>Croissant ML</em> standard.</p>
<p>A key vision for this architecture, termed <em>GraphRAG</em>, seeks to unify graphs and vectors within a singular model, operating as a distributed AI. Within this framework, the LLM functions as both an interface and a sophisticated reasoning engine, connecting to a “RAG library”—essentially the graph—to navigate datasets and consume embeddings (vectors) as contextual information. The system demonstrably prevents hallucinations by strictly adhering to provided source material, offering precise, factual answers with direct references. It supports iterative query refinement and boasts robust multilingual capabilities, enabling queries in one language whilst processing documents in another.</p>
<p>The implementation involves ingesting articles, such as 100 papers from the <em>method-data-analysis</em> (<em>mda</em>) journal, into a vector store (<em>Qdrant</em>) and performing operations like term extraction, embedding construction, and enrichment. Crucially, the team expresses selected terms as structured data within a knowledge graph, often enriched with <em>Wikidata</em>, which contextualises embeddings and serves as a “ground truth” for validating LLM outputs. This decoupling of knowledge from the model facilitates benchmarking and ensures the sustainability of knowledge organisation systems for future scientific endeavours. The project ultimately aims to support human thought processes in formulating research questions, offering a controllable and cost-effective alternative to large, cloud-based LLMs.</p>
</section>
<section id="science-dynamics-and-ai-addressing-information-overload" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="science-dynamics-and-ai-addressing-information-overload"><span class="header-section-number">11.1</span> Science Dynamics and AI: Addressing Information Overload</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_01.png" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>This initiative represents a collaborative endeavour between DANS, the data archive of the Royal Netherlands Academy of Arts and Science, and GESIS, another prominent archive actively engaged in research. The project addresses a fundamental challenge within the evolving landscape of scientific disciplines: the relentless growth and increasing differentiation of knowledge. This expansion invariably complicates the processes of reviewing, evaluating, and selecting pertinent information.</p>
<p>Crucially, the capacity to find and comprehend information remains a prerequisite for any form of knowledge creation, whether within individual cognitive processes or across broader academic communities. Modern machines, particularly the latest advancements in Artificial Intelligence, have undeniably accelerated this growth. Consequently, a pivotal question emerges: can these technologies also support the intricate knowledge production process, specifically within the domain of Information Retrieval?</p>
<p>The impetus for this work stemmed from extensive experimentation conducted by Slava Tikhonov, a senior research engineer at DANS, who pioneered the construction of various data pipelines. Rather than a straightforward pipeline, the system Tikhonov and his team developed is more accurately characterised as a complex “back of things”—a multifaceted architecture challenging to deconstruct and articulate. Ultimately, the project sought to apply and illustrate AI solutions to effectively manage the overwhelming deluge of information that increasingly submerges contemporary researchers.</p>
</section>
<section id="project-objectives-and-system-architecture" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="project-objectives-and-system-architecture"><span class="header-section-number">11.2</span> Project Objectives and System Architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The central research question guiding this project explored the feasibility of constructing an AI solution capable of facilitating interactive dialogue with scholarly papers drawn from a curated selection. This inquiry necessitated an exploration of several interconnected concepts: information retrieval, the dynamics of human-machine interaction, and the burgeoning field of Retrieval-Augmented Generation (RAG) within generative AI.</p>
<p>The researchers selected the <em>method-data-analysis</em> (<em>mda</em>) journal as a specific use case to demonstrate the system’s capabilities. They introduced a workflow underpinning a ‘local’ or ‘tailored AI solution’, distinguishing its primary components with internal project names: <em>Ghostwriter</em>, which functions as the user interface, and <em>EverythingData</em>, a comprehensive term encompassing all underlying back-end processes. The presentation subsequently provided illustrative examples of both front-end and back-end operations, culminating in a summary and outlook on the project’s implications.</p>
</section>
<section id="ghostwriter-a-novel-information-retrieval-interface" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="ghostwriter-a-novel-information-retrieval-interface"><span class="header-section-number">11.3</span> Ghostwriter: A Novel Information Retrieval Interface</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> interface represents a novel approach to information retrieval, designed to facilitate simultaneous interaction with both structured data and natural language inputs. The authors metaphorically describe this dual capability as “chatting with experts and librarians at the same time,” where the “librarian” embodies structured data and knowledge organisation systems, whilst the “expert” represents natural language.</p>
<p>Historically, traditional information retrieval, involving a query against a single database representation, necessitated prior knowledge of the database schema and its typical values to yield results. This scenario, likened to “Me and a database,” presented the classic information retrieval problem of formulating the precise query. More advanced information retrieval systems, operating on connected structured data or graphs, offered improvements. Here, the underlying machinery could suggest similar or superior queries based on schema interconnections, subsequently providing lists of potential results. This advancement, conceptualised as “Me and a librarian,” mirrors features found in <em>Google</em> and <em>schema.org</em>, though typically applied to web-scale interactions rather than local ones.</p>
<p>The advent of Large Language Models (LLMs) introduced another paradigm: a query against an LLM interprets natural language input and suggests results, also expressed in natural language. This interaction is akin to “Me and a library” or “Me and a round of experts.” <em>Ghostwriter</em> synthesises these approaches. It integrates a local LLM with target data collections and a network of additional data interpretation sources, accessible via Application Programming Interfaces (APIs). This sophisticated architecture enables the system to generate families of terms around a given query, identify related structured information, and ultimately return a comprehensive list of results. Crucially, applying this system iteratively empowers users to reformulate their questions, thereby gaining a deeper understanding of their actual query intent and the scope of the available data space.</p>
</section>
<section id="retrieval-augmented-generation-rag-framework" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="retrieval-augmented-generation-rag-framework"><span class="header-section-number">11.4</span> Retrieval-Augmented Generation (RAG) Framework</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Scientifically, this system firmly situates itself within the broader academic discourse surrounding Retrieval-Augmented Generation (RAG). A foundational understanding of this topic is readily available through resources such as Philip Rattliff’s “The <em>GraphRAG</em> Manifesto: Adding Knowledge to GenAI,” published by <em>Neo4j</em>.</p>
<p>The system’s efficacy hinges upon two primary ingredients. Firstly, the authors meticulously construct a vector space from the content of data files. This content undergoes encoding into embeddings, which capture both properties and their associated attributes. Various machine learning algorithms, leveraging different Large Language Models, compute these embeddings. Secondly, a robust graph serves as a comprehensive metadata layer. This graph seamlessly integrates diverse ontologies and controlled vocabularies, notably incorporating principles of responsible AI, and adheres to the <em>Croissant ML</em> standard for its expression.</p>
<p>A key strategic vision, termed <em>GraphRAG</em>, aims to unify both the graph and vector components into a singular, cohesive model. The authors designed this integration for local implementation, thereby fostering a form of Distributed AI. Within this architecture, the LLM assumes a dual role: it acts as the primary interface facilitating human-AI interaction and simultaneously functions as a sophisticated reasoning engine. The practical implementation involves the LLM connecting directly to a “RAG library,” which is essentially the graph, enabling it to navigate through datasets and consume the generated embeddings as contextual information.</p>
</section>
<section id="ghostwriter-and-everythingdata-operational-workflow" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="ghostwriter-and-everythingdata-operational-workflow"><span class="header-section-number">11.5</span> Ghostwriter and EverythingData: Operational Workflow</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The operational workflow commences with an input comprising a collection of articles. Whilst the demonstration specifically utilised a small, scraped collection from the <em>MDA</em> journal, the system readily accommodates any document collection. This input then enters the “<em>EverythingData</em>” component, which orchestrates a series of intricate back-end operations.</p>
<p>Initially, <em>EverythingData</em> stores the processed information within a vector store, specifically employing <em>Qdrant</em>. Subsequently, it executes a range of processes, including term extraction, the construction of embeddings, and various enrichments. A crucial step involves coupling this data with knowledge graphs: the team transforms selected terms into structured data within a graph and further enriches them, notably through integration with <em>Wikidata</em>. This strategic coupling serves to contextualise the embeddings, thereby imbuing them with enhanced semantic value.</p>
<p>All processed data converges into a unified “Vector Space RAG-Graph.” Users then interact with this comprehensive knowledge base via the query interface, formulating their questions in natural language. The system responds by providing two distinct outputs: a list of relevant documents, aligning with conventional information retrieval practices, and a concise explanatory summary text, intelligently generated by the system’s machinery in response to the user’s query. The <em>Ghostwriter</em> interface serves as the primary conduit for this seamless user interaction.</p>
</section>
<section id="ghostwriter-indexing-and-factual-retrieval" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="ghostwriter-indexing-and-factual-retrieval"><span class="header-section-number">11.6</span> Ghostwriter: Indexing and Factual Retrieval</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The developer’s approach to Large Language Models (LLMs) stems from early engagement, commencing with <em>GPT-2</em> testing in 2020. Rather than relying on monolithic models, the strategy involves deconstructing the LLM training process into smaller, more manageable components, enabling their targeted application. This modularity grants the system remarkable flexibility in content processing: whilst demonstrated with scholarly papers, it seamlessly handles any web content and even spreadsheets, facilitating precise queries regarding specific data values.</p>
<p>Crucially, the system rigorously prevents hallucinations. Its responses are strictly factual and non-hallucinatory because it draws exclusively from the provided source material. Should information be unavailable within the designated source, the system transparently indicates “I don’t know.” This commitment to factual integrity is achieved by employing a relatively simple 1 billion parameter LLM, which, when synergistically combined with knowledge graphs, proves highly effective in answering complex questions.</p>
<p>For the presented use case, the researchers ingested 100 articles from the <em>MDA</em> (GESIS journal) website directly into <em>Ghostwriter</em>, establishing a dedicated collection. The system deliberately avoids reliance on any pre-ingested LLM knowledge; instead, it directly queries specific papers to extract factual information. The overarching goal remains to provide responses derived solely from the content present within the paper, without introducing extraneous details. This <em>Ghostwriter</em> instance, operating on <em>MDA</em> papers, is publicly accessible at <code>https://gesis.now.museum</code>.</p>
</section>
<section id="chatting-with-papers-the-male-breadwinner-model-example" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="chatting-with-papers-the-male-breadwinner-model-example"><span class="header-section-number">11.7</span> Chatting with Papers: The Male Breadwinner Model Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>A practical demonstration of the <em>Ghostwriter</em>’s capabilities involved the query: “explain male breadwinner model to me.” In response, the system generated a comprehensive explanation of the Male Breadwinner Ideology, elucidating its societal concept, the expectation for men to serve as primary financial providers, and its observed influence on individual attitudes and entrepreneurial activities within Germany.</p>
<p>Crucially, the system meticulously provides direct references to the original scholarly papers from which the information was extracted, including titles such as “The Past, Present and Future of Factorial Survey Experiments…” and “Gender and Survey Participation…”. This rigorous source referencing ensures transparency and validates the information presented. The system’s design inherently prevents hallucinations, as it precisely identifies and retrieves information directly from the source texts.</p>
<p>Technically, this precision is achieved by segmenting each paper into numerous small blocks, with a unique identifier assigned to every block. The system then employs advanced Large Language Model techniques to intelligently connect and retrieve these blocks, applying specific weights to prioritise their relevance. Furthermore, the integration of knowledge graphs significantly enhances this process by accurately predicting which particular text segments will most effectively address a given question.</p>
</section>
<section id="iterative-approach-to-query-refinement-and-factual-integrity" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="iterative-approach-to-query-refinement-and-factual-integrity"><span class="header-section-number">11.8</span> Iterative Approach to Query Refinement and Factual Integrity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The system’s commitment to factual integrity extends to its handling of information gaps. When presented with a refined query, such as “explain how data was collected on male breadwinner model,” and the direct information is unavailable within its indexed sources, the system explicitly states “there is no direct information.”</p>
<p>For instance, in response to this particular query, the system noted a study that utilised German data and employed a mixed-methods research strategy, including a survey experiment by Hanhmueller et al.&nbsp;(2015). It also referenced another article by Haase et al.&nbsp;(2016) that examined the male breadwinner model, yet it transparently indicated the absence of data collection details for this specific study. Furthermore, the interface incorporates an “Add paper” button, empowering users to contribute new articles to the collection. Crucially, any information added through this feature will subsequently be incorporated into the system’s knowledge base, enriching future query responses.</p>
</section>
<section id="system-mechanics-entity-extraction-knowledge-graphs-and-multilinguality" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="system-mechanics-entity-extraction-knowledge-graphs-and-multilinguality"><span class="header-section-number">11.9</span> System Mechanics: Entity Extraction, Knowledge Graphs, and Multilinguality</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>Underpinning the system’s functionality lies a sophisticated entity extraction pipeline. This pipeline meticulously annotates terms with semantic meaning by mapping them to controlled vocabularies, thereby transforming raw vector space data into a coherent knowledge graph. Beyond this initial transformation, the system actively links these entities to more extensive knowledge graph representations, notably leveraging <em>Wikidata</em>. This integration with <em>Wikidata</em> serves a crucial purpose: it establishes a “ground truth,” providing a reliable benchmark against which the accuracy of LLM-generated answers can be rigorously validated.</p>
<p>A significant feature of the system is its immediate and robust multilinguality. This capability proves indispensable for processing scholarly papers published in diverse languages, such as Chinese or German, whilst enabling users to pose questions and receive answers in English. Ultimately, the Large Language Model orchestrates the synthesis of various text segments, culminating in the production of a concise, explanatory summary.</p>
</section>
<section id="fact-extraction-and-wikidata-integration-for-semantic-enrichment" class="level2" data-number="11.10">
<h2 data-number="11.10" class="anchored" data-anchor-id="fact-extraction-and-wikidata-integration-for-semantic-enrichment"><span class="header-section-number">11.10</span> Fact Extraction and Wikidata Integration for Semantic Enrichment</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>The fact extraction process commences by segmenting user queries into granular pieces. A sophisticated knowledge organisation system then processes these segments, systematically revealing new and deeper levels of associated terms. Crucially, all extracted information undergoes a rigorous linking process with <em>Wikidata</em>, transforming free-form strings into structured, canonical identifiers.</p>
<p>These <em>Wikidata</em> identifiers confer substantial benefits. They inherently enable multilingual translations, providing access to a comprehensive array of associated properties. Consequently, the system can comprehend and process questions posed in various languages. The determination of conceptual similarity for these linkages relies upon the precise measurements derived from Large Language Model embeddings.</p>
</section>
<section id="multilingual-capabilities-and-the-future-of-knowledge-organisation" class="level2" data-number="11.11">
<h2 data-number="11.11" class="anchored" data-anchor-id="multilingual-capabilities-and-the-future-of-knowledge-organisation"><span class="header-section-number">11.11</span> Multilingual Capabilities and the Future of Knowledge Organisation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The system’s robust multilingual capabilities are exemplified by its treatment of core query concepts, such as “bread winner mo,” as abstract entities. The <em>Gemma3</em> Large Language Model then generates translations for these concepts into hundreds of languages. A pivotal innovation involves establishing a “ground truth” by decoupling knowledge from specific questions and papers. This is achieved by storing knowledge as a comprehensive list of <em>Wikidata</em> identifiers, maintained externally to the model itself.</p>
<p>This externalisation of knowledge facilitates rigorous benchmarking. Researchers can test various models, including those not yet fully trained, by posing identical questions and comparing the consistency of their generated identifier lists. This comparative analysis effectively identifies models unsuitable for specific tasks. Furthermore, this methodological approach supports the creation of robust benchmarks and champions the utilisation of knowledge organisation systems for future generations of scientists. Collaborations with prominent industry partners, including <em>Google</em> and <em>Meta</em>, underscore a commitment to ensuring the long-term sustainability of this process. Ultimately, the developers firmly believe that knowledge organisation systems represent the future paradigm for information management.</p>
</section>
<section id="live-demonstration-and-philosophical-implications" class="level2" data-number="11.12">
<h2 data-number="11.12" class="anchored" data-anchor-id="live-demonstration-and-philosophical-implications"><span class="header-section-number">11.12</span> Live Demonstration and Philosophical Implications</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>A live demonstration showcased the system’s capabilities via the GESIS Leibniz-Institut für Sozialwissenschaften website, specifically within its “Ask Questions” section. When queried with “Rational Choice Theory,” the system promptly retrieved pertinent information, synthesised a summary from various papers, and provided direct references to the original sources. A subsequent, more specific query, “explain utility in Rational Choice Theory,” prompted the system to select distinct pieces of information from the indexed papers, yielding varied results whilst consistently referencing the same source documents.</p>
<p>An Application Programming Interface (API) further extends the system’s utility, enabling an automatic mode suitable for agentic architectures. This allows for the construction of sophisticated pipelines, facilitating automated result collection and the identification of novel knowledge. Users also possess the ability to augment the collection by adding new pages or content, either via a webpage URL or an RSS feed, which the system seamlessly incorporates. A compelling demonstration of its multilingual prowess involved posing a question in English and successfully retrieving information from a source paper written entirely in German, save for its abstract.</p>
<p>The developers emphasised the significant benefits of a local system, which affords greater control over data and mitigates the considerable costs and inherent control limitations associated with large, cloud-based Large Language Models. The interaction with scholarly papers is evocatively likened to engaging with an “invisible college.” Crucially, the system’s fundamental purpose transcends merely providing definitive facts or ultimate answers. Instead, it aims to stimulate human thought processes, assist in comprehending complex questions, and support the precise formulation of research questions. Ultimately, these technological possibilities should be perceived as powerful tools designed to augment and support human intellectual activity.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Parsing Footnotes in Law and Humanities Scholarship with Large Language Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_012.html" class="pagination-link" aria-label="Possible applications of RAG systems in philosophy">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Possible applications of RAG systems in philosophy</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>