<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst">
<meta name="dcterms.date" content="2025-01-01">

<title>11&nbsp; Chatting with Papers – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_012.html" rel="next">
<link href="./chapter_ai-nepi_010.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_011.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#chatting-with-papers" id="toc-chatting-with-papers" class="nav-link active" data-scroll-target="#chatting-with-papers"><span class="header-section-number">12</span> Chatting with Papers</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">12.1</span> Overview</a></li>
  <li><a href="#project-overview-and-affiliations" id="toc-project-overview-and-affiliations" class="nav-link" data-scroll-target="#project-overview-and-affiliations"><span class="header-section-number">12.2</span> Project Overview and Affiliations</a></li>
  <li><a href="#science-dynamics-and-information-overload" id="toc-science-dynamics-and-information-overload" class="nav-link" data-scroll-target="#science-dynamics-and-information-overload"><span class="header-section-number">12.3</span> Science Dynamics and Information Overload</a></li>
  <li><a href="#talk-structure-and-system-architecture" id="toc-talk-structure-and-system-architecture" class="nav-link" data-scroll-target="#talk-structure-and-system-architecture"><span class="header-section-number">12.4</span> Talk Structure and System Architecture</a></li>
  <li><a href="#ghostwriter-new-ir-interface-and-query-models" id="toc-ghostwriter-new-ir-interface-and-query-models" class="nav-link" data-scroll-target="#ghostwriter-new-ir-interface-and-query-models"><span class="header-section-number">12.5</span> <em>Ghostwriter</em>: New IR Interface and Query Models</a></li>
  <li><a href="#ghostwriter-and-everythingdata-rag-architecture" id="toc-ghostwriter-and-everythingdata-rag-architecture" class="nav-link" data-scroll-target="#ghostwriter-and-everythingdata-rag-architecture"><span class="header-section-number">12.6</span> <em>Ghostwriter</em> and <em>EverythingData</em>: <em>RAG</em> Architecture</a></li>
  <li><a href="#everythingdata-backend-and-vector-space" id="toc-everythingdata-backend-and-vector-space" class="nav-link" data-scroll-target="#everythingdata-backend-and-vector-space"><span class="header-section-number">12.7</span> <em>EverythingData</em> Backend and Vector Space</a></li>
  <li><a href="#ghostwriter-functionality-and-mechanisms" id="toc-ghostwriter-functionality-and-mechanisms" class="nav-link" data-scroll-target="#ghostwriter-functionality-and-mechanisms"><span class="header-section-number">12.8</span> <em>Ghostwriter</em> Functionality and Mechanisms</a></li>
  <li><a href="#ghostwriter-demonstration" id="toc-ghostwriter-demonstration" class="nav-link" data-scroll-target="#ghostwriter-demonstration"><span class="header-section-number">12.9</span> <em>Ghostwriter</em> Demonstration</a></li>
  <li><a href="#project-benefits-and-philosophy" id="toc-project-benefits-and-philosophy" class="nav-link" data-scroll-target="#project-benefits-and-philosophy"><span class="header-section-number">12.10</span> Project Benefits and Philosophy</a></li>
  <li><a href="#system-performance-and-local-deployment" id="toc-system-performance-and-local-deployment" class="nav-link" data-scroll-target="#system-performance-and-local-deployment"><span class="header-section-number">12.11</span> System Performance and Local Deployment</a></li>
  <li><a href="#from-development-to-production" id="toc-from-development-to-production" class="nav-link" data-scroll-target="#from-development-to-production"><span class="header-section-number">12.12</span> From Development to Production</a></li>
  <li><a href="#validation-and-community-engagement" id="toc-validation-and-community-engagement" class="nav-link" data-scroll-target="#validation-and-community-engagement"><span class="header-section-number">12.13</span> Validation and Community Engagement</a></li>
  <li><a href="#data-ingestion-and-collections" id="toc-data-ingestion-and-collections" class="nav-link" data-scroll-target="#data-ingestion-and-collections"><span class="header-section-number">12.14</span> Data Ingestion and Collections</a></li>
  <li><a href="#project-goals-and-collaboration" id="toc-project-goals-and-collaboration" class="nav-link" data-scroll-target="#project-goals-and-collaboration"><span class="header-section-number">12.15</span> Project Goals and Collaboration</a></li>
  <li><a href="#recency-bias-mitigation" id="toc-recency-bias-mitigation" class="nav-link" data-scroll-target="#recency-bias-mitigation"><span class="header-section-number">12.16</span> Recency Bias Mitigation</a></li>
  <li><a href="#comparison-to-google-notebook-ml" id="toc-comparison-to-google-notebook-ml" class="nav-link" data-scroll-target="#comparison-to-google-notebook-ml"><span class="header-section-number">12.17</span> Comparison to <em>Google Notebook ML</em></a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst <a href="mailto:philipp.mayr@gesis.org" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>The project develops an AI solution for interacting with specific document collections, referred to as “chatting with papers.” The primary objective is to address the problem of information overload in science dynamics by improving information retrieval and knowledge production processes using AI. The system utilizes a mixed approach combining Large Language Models (LLMs) and semantic artifacts, specifically structured data represented as knowledge graphs and vector spaces derived from do…</p>
  </div>
</div>


</header>


<section id="chatting-with-papers" class="level1" data-number="12">
<h1 data-number="12"><span class="header-section-number">12</span> Chatting with Papers</h1>
<section id="overview" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">12.1</span> Overview</h2>
<p>The project develops an <em>AI</em> solution for interacting with specific document collections, referred to as “chatting with papers.” Its primary objective is to address the problem of information overload in science dynamics by improving information retrieval and knowledge production processes using <em>AI</em>.</p>
<p>The system utilizes a mixed approach, combining <em>Large Language Models</em> (<em>LLMs</em>) with semantic artifacts. These artifacts include structured data represented as knowledge graphs and vector spaces derived from document content. The core components are codenamed <em>Ghostwriter</em> (the interface) and <em>EverythingData</em> (the backend processing pipeline).</p>
<p>The approach is based on <em>Retrieval-Augmented Generation</em> (<em>RAG</em>), integrating vector embeddings of document content with a metadata layer. This metadata layer is represented as a knowledge graph, which incorporates ontologies and controlled vocabularies, including aspects of responsible <em>AI</em>. The graph is expressed using the <em>Croissant ML</em> standard.</p>
<p>The system aims for a “local” or “tailored” <em>AI</em> solution, functioning as a distributed <em>AI</em>. In this architecture, the <em>LLM</em> acts as an interface and reasoning engine, connected to the <em>RAG</em> library (graph) and consuming embeddings (vectors) as context. A key feature is the use of entity extraction pipelines that link terms to knowledge graphs, specifically <em>Wikidata</em>. This linkage provides ground truth, supports multilinguality, and enables validation of <em>LLM</em> responses against structured identifiers.</p>
<p>The system splits papers into small blocks, each with a unique identifier. It employs <em>LLM</em> techniques to connect and retrieve these blocks, applying weights and knowledge graph information to predict relevant text pieces. It provides summaries and references to original sources, avoids hallucination by relying solely on the ingested data, and indicates when information is not found.</p>
<p>The interface allows users to ask natural language questions, receive summaries and document lists, and add missing information. The system supports multilingual queries by linking terms to <em>Wikidata</em> identifiers, which have multilingual translations. This approach is seen as a way to support the user’s thought process and help find relevant research questions rather than providing definitive answers.</p>
<p>The system is being considered for open-source release under the <em>Linux Foundation</em>. It is also being explored for integration with various data sources, including <em>GitHub</em> content, manuals, and guidelines, with potential applications in building research infrastructure portals. Validation against other systems like <em>Neo4j Graph Builder</em> or <em>Microsoft Graph</em> is being considered. The approach of using knowledge organization systems linked to identifiers is proposed as a method for benchmarking future generations of <em>AI</em> models and ensuring sustainability. The system uses downscaled <em>LLMs</em> (e.g., 1 billion parameters) capable of running locally. Recency bias in results is acknowledged, with a proposed solution involving storing facts with timestamps in the knowledge graph to allow for processing linked to specific dates. The approach is considered similar to <em>Google Notebook ML</em> due to reliance on similar ideas and collaboration with the same teams.</p>
</section>
<section id="project-overview-and-affiliations" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="project-overview-and-affiliations"><span class="header-section-number">12.2</span> Project Overview and Affiliations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>The project is titled “<em>Chatting with Papers</em>,” with the subtitle “the mixed use of <em>LLM’s</em> and semantic artifacts to support the understanding of science dynamics - and beyond.” The authors involved are Slava Tykhonov, Philipp Mayr, Jetze Touber, and Andrea Scharnhorst.</p>
<p>Their affiliations are <em>GESIS</em>, Cologne, Germany for Philipp Mayr, and <em>DANS-KNAW</em>, The Hague, The Netherlands for Slava Tykhonov, Jetze Touber, and Andrea Scharnhorst. The presentation includes the logos for <em>GESIS</em> and <em>DANS</em>. The text “<em>LLM 4 HPSS</em>” is also present, indicating the context within which this work is situated.</p>
</section>
<section id="science-dynamics-and-information-overload" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="science-dynamics-and-information-overload"><span class="header-section-number">12.3</span> Science Dynamics and Information Overload</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>The evolution of sciences exhibits growth and increasing differentiation, presenting the challenge of reviewing, evaluating, and selecting relevant information. A fundamental precondition for creating new knowledge, whether in individual researchers or across academia, is the ability to find and understand existing information. Machines, particularly recent advancements in <em>AI</em>, have contributed to this growth in information volume.</p>
<p>The project investigates whether <em>AI</em> can also support the knowledge production process itself, framing this as a problem within the domain of <em>Information Retrieval</em>. The motivation stems from the need to manage the overwhelming volume of information researchers face.</p>
<p>The work is based on extensive experimentation by senior research engineer Slava Tykhonov at <em>DANS</em> across various projects, involving the construction of complex technical pipelines, characterized as a “back of things you can hardly unravel.” The project aims to apply and illustrate this technical structure using a specific use case, making it understandable to a broader audience.</p>
</section>
<section id="talk-structure-and-system-architecture" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="talk-structure-and-system-architecture"><span class="header-section-number">12.4</span> Talk Structure and System Architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The talk addresses the research question: Can an <em>AI</em> solution be constructed to facilitate interaction, or “chatting,” with papers from a specific, selected collection? The introduction covers foundational concepts including information retrieval, the dynamics of human-machine interaction, and <em>Retrieval-augmented generation</em> (<em>RAG</em>) within the context of <em>generative AI</em>.</p>
<p>A specific use case involving papers from the <em>method-data-analysis</em> (<em>mda</em>) journal is presented. The workflow introduces a “local” or “tailored <em>AI</em> solution” architecture, comprising two main components known by the pet names <em>Ghostwriter</em> and <em>EverythingData</em>. <em>Ghostwriter</em> serves as the user interface, while <em>EverythingData</em> encompasses the entire backend processing pipeline. The presentation includes illustrations of both front end and back end operations, concluding with a summary and outlook on future directions.</p>
</section>
<section id="ghostwriter-new-ir-interface-and-query-models" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="ghostwriter-new-ir-interface-and-query-models"><span class="header-section-number">12.5</span> <em>Ghostwriter</em>: New IR Interface and Query Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> approach introduces a new interface for information retrieval. A primary challenge in this domain involves formulating the correct question, identifying the appropriate person or information source, and accurately interpreting the results. This is fundamentally linked to the classic <em>information retrieval</em> (<em>IR</em>) problem of finding the right query. The approach explores different models of query interaction, illustrated through comparisons.</p>
<p>Interacting with a database requires explicit knowledge of its schema and typical values to obtain results, representing the classic <em>IR</em> problem. A model involving querying connected structured data, such as databases or graphs, is likened to interacting with a <em>librarian</em>. The system suggests similar or improved queries based on schema connections and provides lists of potential results for different query variations. This is exemplified by features like <em>Google’s schema.org</em> integration, which works well on the web but is less suited for local interactions.</p>
<p>Querying a <em>Large Language Model</em> is compared to interacting with a library or a round of <em>experts</em>. The <em>LLM</em> interprets the query as natural language input and provides suggestions for results, also expressed in natural language. The <em>Ghostwriter</em> approach combines a local <em>LLM</em> with a target data collection or space, embedding it within a network of additional data interpretation sources accessible via <em>APIs</em>. This is metaphorically described as chatting simultaneously with <em>experts</em> and <em>librarians</em>.</p>
<p>This combined approach creates a family of terms related to the query, identifies relevant structured information, and returns a list of results. When applied iteratively, this process assists users in reformulating their questions by enhancing their understanding of their actual query intent and the capabilities of the available data space. The metaphors of a “<em>librarian</em>” representing structured data, knowledge organization systems, and existing classifications, and an “<em>expert</em>” representing natural language, are central to describing these interaction models.</p>
</section>
<section id="ghostwriter-and-everythingdata-rag-architecture" class="level2" data-number="12.6">
<h2 data-number="12.6" class="anchored" data-anchor-id="ghostwriter-and-everythingdata-rag-architecture"><span class="header-section-number">12.6</span> <em>Ghostwriter</em> and <em>EverythingData</em>: <em>RAG</em> Architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> and <em>EverythingData</em> architecture is situated within the wider discourse of <em>Retrieval Augmented Generation</em> (<em>RAG</em>). The main ingredients of this system include a vector space and a graph. The vector space is constructed from the content of data files, with content encoded into embeddings that possess properties and attributes. These embeddings are computed using various machine learning algorithms and different <em>Large Language Models</em>.</p>
<p>The graph component represents a metadata layer that is integrated with various ontologies and controlled vocabularies, encompassing considerations for responsible <em>AI</em>. This graph is expressed using the <em>Croissant ML</em> standard. The vision behind this approach is to combine both the graph and vector components into a single model, a concept referred to as <em>GraphRAG</em>.</p>
<p>This is implemented locally as a form of <em>Distributed AI</em>, where the <em>LLM</em> serves as the interface between the human user and the <em>AI</em> system, simultaneously functioning as a reasoning engine. In implementation, the <em>LLM</em> is connected to a “<em>RAG library</em>,” which is the graph component. It navigates through datasets and consumes the embeddings (vectors) as context to inform its responses.</p>
<p>Related concepts and resources mentioned include the <em>GenAI Knowledge Graph</em> and “<em>The GraphRAG Manifesto: Adding Knowledge to GenAI</em>,” authored by <em>Philip Rathle</em>, <em>CTO</em> of <em>Neo4j</em>, with a link provided to the <em>Neo4j</em> blog post. The <em>Wikipedia</em> page for <em>Retrieval-augmented generation</em> is also referenced, along with a reference to <em>Arno Simons’</em> presentation on tool boxes.</p>
</section>
<section id="everythingdata-backend-and-vector-space" class="level2" data-number="12.7">
<h2 data-number="12.7" class="anchored" data-anchor-id="everythingdata-backend-and-vector-space"><span class="header-section-number">12.7</span> <em>EverythingData</em> Backend and Vector Space</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The system’s input data consists of a collection of articles, specifically scraped from the <em>MDA</em> journal, although the system is designed to work with any collection of documents. This input is processed by the backend component, referred to as “<em>tamed EverythingData</em>.” The backend executes various operations, including storing the information in a vector store utilizing <em>Quadrant</em>. Additional processing steps involve term extractions, constructing embeddings, and other related operations.</p>
<p>A crucial aspect of the backend is the integration of knowledge graphs, coupling the processed information to these graphs. This integration enhances the value of words, phrases, and embeddings by providing additional context and adding another layer of value to the existing context. The processed information is structured and fed into a vector space. The user interface interacts with this combined vector space and graph structure. Users formulate queries as natural language questions. The system responds by providing a list of relevant documents, consistent with standard information retrieval outputs, and a summary generated by the machinery based on the user’s question.</p>
</section>
<section id="ghostwriter-functionality-and-mechanisms" class="level2" data-number="12.8">
<h2 data-number="12.8" class="anchored" data-anchor-id="ghostwriter-functionality-and-mechanisms"><span class="header-section-number">12.8</span> <em>Ghostwriter</em> Functionality and Mechanisms</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> system is designed for chatting with papers, but its capabilities extend to interacting with any content from the web or even spreadsheets. When interacting with spreadsheets, the system can recognize specific values and provide responses without hallucinating, as it relies solely on the spreadsheet content as its source. The system utilizes a relatively simple <em>LLM</em> with 1 billion parameters, which is capable of answering complex questions by leveraging knowledge graphs.</p>
<p>By default, the system does not depend on knowledge pre-ingested into the <em>LLM</em>. Its primary goal is to provide answers based <em>only</em> on factual information present in the specific paper or papers that have been ingested. If the required information is not found within the ingested papers, the system explicitly states “I don’t know.” This strict reliance on the source material is the mechanism for avoiding hallucination, as the system has precise knowledge of where to locate information.</p>
<p>The underlying implementation involves splitting each paper into small blocks, with a separate identifier assigned to each block. <em>LLM</em> techniques are employed to intelligently connect and retrieve these blocks. The system applies weights and incorporates information from knowledge graphs to predict which specific pieces of text are most relevant to answer a given question. A user interaction feature includes an “Add paper” button, allowing users to contribute missing information; this added content will then be available for subsequent queries on the same topic.</p>
<p>The backend processing involves an entity extraction pipeline and annotations. Entities are linked to knowledge graphs, which is considered extremely important as it provides a ground truth mechanism for validating the accuracy of the <em>LLM</em>’s responses. Multilinguality support is a critical feature; the system can handle papers written in languages such as Chinese or German and respond to questions posed in English, aiming for reliable answers. The <em>LLM</em>’s final role is to synthesize the retrieved pieces of text to produce the results.</p>
<p>The fact extraction process involves splitting the user’s question into smaller pieces and utilizing a knowledge organization system (<em>KOS</em>). This <em>KOS</em> is a repeatable process that can reveal new levels of related terms underneath the initial query term. A key step is linking everything to <em>Wikidata</em>. This process transforms free-text strings into identifiers that are linked to multilingual translations available in <em>Wikidata</em>. This linking provides access to all associated properties and enables the system to understand and respond to questions asked in various languages. The query construction process involves translating the user’s question into potentially hundreds of languages, and all these translations are used as input to the <em>LLM</em>.</p>
<p>The knowledge graph linking provides a ground truth mechanism by decoupling knowledge from the questions and papers, storing this knowledge externally as a list of identifiers from <em>Wikidata</em>. This allows for a validation mechanism where different models, including those not yet trained, can be tested by asking the same questions and comparing the resulting lists of identifiers. Discrepancies in the identifier lists indicate that a particular model may not be suitable for the task. This approach is proposed as a method for creating benchmarks and supporting future generations of scientists. The project is collaborating with industry partners like <em>Google</em> and <em>Meta</em> to ensure the sustainability of this process, viewing the knowledge organization system as a potential future standard.</p>
</section>
<section id="ghostwriter-demonstration" class="level2" data-number="12.9">
<h2 data-number="12.9" class="anchored" data-anchor-id="ghostwriter-demonstration"><span class="header-section-number">12.9</span> <em>Ghostwriter</em> Demonstration</h2>
<p>A demonstration of the <em>Ghostwriter</em> interface is conducted within a browser environment. The first query example involves asking the system about “rational choice theory.” The system processes this request by thinking and retrieving relevant pieces of information. The output consists of a summary compiled from different papers and includes references pointing directly to the original source papers, confirming that the results originate from the specified sources.</p>
<p>A second query example involves asking the system to “explain utility in Rational Choice Theory.” The system responds by selecting different pieces of information from the ingested papers, presenting different results while still referencing the same source documents. The system provides an <em>API</em> that enables automatic mode operation, facilitating the construction of pipelines within an agentic architecture where the system can be prompted, results collected, and subsequent queries issued. This <em>API</em> can be used to analyze papers to identify new information or knowledge contributions.</p>
<p>The interface includes a feature allowing users to add a page or information if the system does not provide results for a query; this added information is then incorporated and will appear in responses to the same question in the future. A key demonstration of the system’s capability is asking questions in English about a source paper that is written entirely in German, showcasing its multilinguality support.</p>
</section>
<section id="project-benefits-and-philosophy" class="level2" data-number="12.10">
<h2 data-number="12.10" class="anchored" data-anchor-id="project-benefits-and-philosophy"><span class="header-section-number">12.10</span> Project Benefits and Philosophy</h2>
<p>A significant benefit of the project’s approach is the local availability of the system. This provides users with greater control compared to interacting with large, external systems, which can also be costly. The interaction with papers via the system is likened to chatting with an <em>invisible college</em>.</p>
<p>It is recommended that users approach this interaction with the same perspective as engaging with an <em>invisible college</em>, meaning the goal is not necessarily to find ultimate facts or definitive answers. Instead, the primary purpose of the system is to provoke and support the user’s thinking process. The human user retains the role of understanding the question and identifying the appropriate research question. The system’s function is to provide support for the user’s own cognitive process. The recommended perspective is to view these technological possibilities as tools that enhance and support human thinking.</p>
</section>
<section id="system-performance-and-local-deployment" class="level2" data-number="12.11">
<h2 data-number="12.11" class="anchored" data-anchor-id="system-performance-and-local-deployment"><span class="header-section-number">12.11</span> System Performance and Local Deployment</h2>
<p>System performance has been improved by downscaling the <em>Large Language Models</em> used. The implementation transitioned from a complex <em>Llama</em> model with 70 billion parameters to a smaller model with only 1 billion parameters. This current model is capable of running on a local computer. The ability to deploy and run <em>LLMs</em> locally on private or sensitive material is seen as a potential challenge to companies like <em>Nvidia</em> if this capability becomes widely known and adopted.</p>
</section>
<section id="from-development-to-production" class="level2" data-number="12.12">
<h2 data-number="12.12" class="anchored" data-anchor-id="from-development-to-production"><span class="header-section-number">12.12</span> From Development to Production</h2>
<p>The current status of the interface is described as a “playing ground,” used primarily to gain a better understanding of the system’s behavior and capabilities. However, similar underlying machinery is being applied in other, more serious projects intended for production environments. An example of such a production project is the <em>Odyssey</em> project in the Netherlands, which involves building a portal designed to bring together various data sources.</p>
<p>Projects like <em>Odyssey</em> necessitate considerations for long-term sustainability and the handling of diverse data sources, while still applying the same core principles developed in the <em>Ghostwriter</em>/<em>EverythingData</em> work. These aspects are actively discussed at a high level within research infrastructure discussions in the Netherlands.</p>
</section>
<section id="validation-and-community-engagement" class="level2" data-number="12.13">
<h2 data-number="12.13" class="anchored" data-anchor-id="validation-and-community-engagement"><span class="header-section-number">12.13</span> Validation and Community Engagement</h2>
<p>Future validation of the system is envisioned through its development as a community project under the <em>Linux Foundation</em>. The <em>Linux Foundation</em> has approached the project team with interest in publishing the work. The project is expected to be released as an open source project potentially within the current month.</p>
<p>The community is anticipated to play a crucial role in helping to validate and improve the system, reflecting the belief that significant progress is impossible without community involvement. Currently, the team is in an experimental phase regarding validation. The next steps involve engaging in scientific discourse and publishing scientific papers about the work, marking the beginning of the serious academic validation process.</p>
</section>
<section id="data-ingestion-and-collections" class="level2" data-number="12.14">
<h2 data-number="12.14" class="anchored" data-anchor-id="data-ingestion-and-collections"><span class="header-section-number">12.14</span> Data Ingestion and Collections</h2>
<p>Setting up a collection, such as a <em>Nodo</em> collection, is considered not hard. This assessment is based on observations of the system’s capability to perform similar setup processes for information extracted from various other <em>APIs</em>. The system is designed to ingest data from any kind of source, including content from <em>GitHub</em>, manuals, guidelines, and papers.</p>
<p>An example collaboration involves building this system for <em>Harvard University</em>. The system deployed for <em>Harvard</em> currently contains approximately 300,000 documents, and <em>Harvard University</em> has commenced using it. The project team is receiving substantial feedback from users like <em>Harvard</em>. Based on this feedback, there is a strong belief that utilizing local models deployed on personal computers represents a preferable approach compared to being fully dependent on industry-provided solutions such as <em>ChatGPT</em>.</p>
</section>
<section id="project-goals-and-collaboration" class="level2" data-number="12.15">
<h2 data-number="12.15" class="anchored" data-anchor-id="project-goals-and-collaboration"><span class="header-section-number">12.15</span> Project Goals and Collaboration</h2>
<p>The project’s primary goal is not centered on developing or selling software commercially. The preferred model is based on collaborations, typically triggered by individuals or groups who have concrete research questions that the system might help address.</p>
<p>The collaboration process involves seeking resources to conduct a try-out of the system for the specific use case, followed by handing over the system to the collaborating partners. These partners are then expected to tinker with, validate, and polish the system further. The team expresses anticipation for future collaborations.</p>
</section>
<section id="recency-bias-mitigation" class="level2" data-number="12.16">
<h2 data-number="12.16" class="anchored" data-anchor-id="recency-bias-mitigation"><span class="header-section-number">12.16</span> Recency Bias Mitigation</h2>
<p>A potential problem identified is the possibility of recency bias in the system’s results. An example cited is querying a concept like “rational choice,” which originated in the 1930s or 1940s, but potentially receiving results predominantly from the 2000s. This recency bias is acknowledged as true.</p>
<p>The proposed solution involves collecting facts and storing them within the knowledge graph. A key detail of the knowledge graph structure is the ability to store a fact along with a timestamp if one is available. This allows for separate processing based on these timestamps. For queries related to temporal aspects, the system can provide a list of all facts linked to specific dates, rather than a single, potentially biased answer, offering a way to mitigate recency bias.</p>
</section>
<section id="comparison-to-google-notebook-ml" class="level2" data-number="12.17">
<h2 data-number="12.17" class="anchored" data-anchor-id="comparison-to-google-notebook-ml"><span class="header-section-number">12.17</span> Comparison to <em>Google Notebook ML</em></h2>
<p>When compared to <em>Google Notebook ML</em>, the system is assessed as being quite similar. This similarity is attributed to the reliance on the same underlying ideas and collaboration with the same development teams.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Extracting Citation Data from Law and Humanities Scholarship">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_012.html" class="pagination-link" aria-label="RAG Systems in Philosophy and HPSS">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>