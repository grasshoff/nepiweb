<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.13">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst">
<meta name="dcterms.date" content="2025-01-01">

<title>11&nbsp; Science dynamics and AI – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_012.html" rel="next">
<link href="./chapter_ai-nepi_010.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-a126389619fad6dbfb296a5315d49fef.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_011.html"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: A Primer and Critical Reflections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Philosophy at Scale: Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE Traces de la Vérité: The reappropriation of ancient wisdom in early modern natural philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">SDG-Research in Bibliometric DBs - LLMs for HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems for Philosophical Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Unlocking Science’s Hidden Dynamics: A Computational Approach to Archival Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Transforming Biographical Sources into Knowledge Graphs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#navigating-scientific-information-overload" id="toc-navigating-scientific-information-overload" class="nav-link" data-scroll-target="#navigating-scientific-information-overload"><span class="header-section-number">11.1</span> Navigating Scientific Information Overload</a></li>
  <li><a href="#system-architecture-and-core-components" id="toc-system-architecture-and-core-components" class="nav-link" data-scroll-target="#system-architecture-and-core-components"><span class="header-section-number">11.2</span> System Architecture and Core Components</a></li>
  <li><a href="#the-ghostwriter-interface-a-novel-retrieval-paradigm" id="toc-the-ghostwriter-interface-a-novel-retrieval-paradigm" class="nav-link" data-scroll-target="#the-ghostwriter-interface-a-novel-retrieval-paradigm"><span class="header-section-number">11.3</span> The <em>Ghostwriter</em> Interface: A Novel Retrieval Paradigm</a></li>
  <li><a href="#retrieval-augmented-generation-rag-architecture" id="toc-retrieval-augmented-generation-rag-architecture" class="nav-link" data-scroll-target="#retrieval-augmented-generation-rag-architecture"><span class="header-section-number">11.4</span> Retrieval-Augmented Generation (<em>RAG</em>) Architecture</a></li>
  <li><a href="#operational-workflow-data-ingestion-and-processing" id="toc-operational-workflow-data-ingestion-and-processing" class="nav-link" data-scroll-target="#operational-workflow-data-ingestion-and-processing"><span class="header-section-number">11.5</span> Operational Workflow: Data Ingestion and Processing</a></li>
  <li><a href="#ghostwriter-implementation-preventing-hallucinations" id="toc-ghostwriter-implementation-preventing-hallucinations" class="nav-link" data-scroll-target="#ghostwriter-implementation-preventing-hallucinations"><span class="header-section-number">11.6</span> <em>Ghostwriter</em> Implementation: Preventing Hallucinations</a></li>
  <li><a href="#ghostwriter-in-practice-querying-and-refinement" id="toc-ghostwriter-in-practice-querying-and-refinement" class="nav-link" data-scroll-target="#ghostwriter-in-practice-querying-and-refinement"><span class="header-section-number">11.7</span> <em>Ghostwriter</em> in Practice: Querying and Refinement</a></li>
  <li><a href="#underlying-architecture-entity-extraction-and-multilingual-capabilities" id="toc-underlying-architecture-entity-extraction-and-multilingual-capabilities" class="nav-link" data-scroll-target="#underlying-architecture-entity-extraction-and-multilingual-capabilities"><span class="header-section-number">11.8</span> Underlying Architecture: Entity Extraction and Multilingual Capabilities</a></li>
  <li><a href="#live-demonstration-engaging-with-ghostwriter" id="toc-live-demonstration-engaging-with-ghostwriter" class="nav-link" data-scroll-target="#live-demonstration-engaging-with-ghostwriter"><span class="header-section-number">11.9</span> Live Demonstration: Engaging with <em>Ghostwriter</em></a></li>
  <li><a href="#project-vision-and-future-trajectories" id="toc-project-vision-and-future-trajectories" class="nav-link" data-scroll-target="#project-vision-and-future-trajectories"><span class="header-section-number">11.10</span> Project Vision and Future Trajectories</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></h1>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Philipp Mayr, Slava Tykhonov, Jetze Touber &amp; Andrea Scharnhorst <a href="mailto:philipp.mayr@gesis.org" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            GESIS – Leibniz Institute for the Social Sciences
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Researchers at DANS, the data archive of the Royal Netherlands Academy of Arts and Science, in collaboration with GESIS, a research-engaged archive, have pioneered an AI-driven solution to manage the escalating volume of scientific information. This initiative directly addresses the challenges of growth and increasing differentiation within the sciences, which complicate the review, evaluation, and selection of relevant content. A fundamental precondition for creating new knowledge, whether individually or across academia, involves efficiently finding and understanding existing information. Consequently, the project investigates whether contemporary Artificial Intelligence (AI), particularly Large Language Models (LLMs), can support the knowledge production process through advanced information retrieval.</p>
<p>The core research question explores the feasibility of constructing an AI solution capable of facilitating conversational interaction with academic papers from specific collections. Developers have crafted a dual-component system: <em>Ghostwriter</em>, serving as the user interface, and <em>EverythingData</em>, encompassing the comprehensive backend operations. This architecture integrates principles of information retrieval, human-machine interaction, and Retrieval-Augmented Generation (<em>RAG</em>). The project employs the <em>method-data-analysis (mda)</em> journal as a practical use case, demonstrating a ‘local’ and ‘tailored’ AI solution workflow.</p>
<p>The <em>Ghostwriter</em> interface redefines information retrieval by enabling simultaneous interaction with structured data—analogous to a librarian—and natural language—akin to an expert. This approach leverages Knowledge Organisation Systems (KOS) and classification schemes whilst interpreting natural language queries. The underlying technical infrastructure, <em>EverythingData</em>, processes input document collections, such as articles from the <em>mda</em> journal, by ingesting them into a vector store, specifically <em>Qdrant</em>. It performs crucial operations including term extraction, embedding construction, and crucially, coupling these with knowledge graphs. This integration enriches embeddings by contextualising them, thereby adding significant value to the information.</p>
<p>The system prioritises factual accuracy, aiming to prevent hallucinations by relying exclusively on the ingested source material. It segments papers into small, identifiable blocks, employing LLM techniques to intelligently connect and retrieve relevant sections. Knowledge graphs further enhance this process by predicting which text segments will best address specific queries. A key innovation links extracted entities to <em>Wikidata</em>, transforming free strings into multilingual identifiers. This mechanism supports immediate multilinguality, allowing users to query in one language and retrieve information from documents in another. Moreover, decoupling knowledge from the model and storing it as <em>Wikidata</em> identifiers establishes a robust ground truth for benchmarking and validating future AI models. The project envisions this knowledge organisation system as a sustainable future for scientific information management, fostering collaborations with industry leaders like Google and Meta.</p>
</section>
<section id="navigating-scientific-information-overload" class="level2" data-number="11.1">
<h2 data-number="11.1" class="anchored" data-anchor-id="navigating-scientific-information-overload"><span class="header-section-number">11.1</span> Navigating Scientific Information Overload</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>This collaborative endeavour, uniting DANS—the data archive of the Royal Netherlands Academy of Arts and Science—with GESIS, an archive actively engaged in research, addresses a critical challenge within contemporary science. The sciences exhibit continuous growth and increasing differentiation, which consequently complicates the processes of reviewing, evaluating, and selecting pertinent information.</p>
<p>A fundamental precondition for generating new knowledge, whether within individual minds or across broader academic communities, necessitates the capacity to locate and comprehend existing information effectively. Therefore, a central research question explores whether advanced AI systems can genuinely support the knowledge production process, specifically focusing on information retrieval.</p>
<p>The project originated from extensive experimentation conducted by Slava Tikhonov, a senior research engineer at DANS, who meticulously constructs complex data pipelines. Rather than simple linear pipelines, these systems represent intricate “backs of things,” as one colleague aptly described, making them challenging to unravel and explain. Consequently, the project aims to illustrate the application of these AI capabilities in a manner accessible to a broader audience. From a wider perspective, this initiative seeks to harness AI’s potential to manage the overwhelming deluge of information in which researchers increasingly find themselves immersed.</p>
</section>
<section id="system-architecture-and-core-components" class="level2" data-number="11.2">
<h2 data-number="11.2" class="anchored" data-anchor-id="system-architecture-and-core-components"><span class="header-section-number">11.2</span> System Architecture and Core Components</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>A central research question drives this project: can developers construct an AI solution enabling conversational interaction with academic papers drawn from a specific selection? This inquiry integrates several key concepts, including information retrieval, the dynamics of human-machine interaction, and the principles of Retrieval-Augmented Generation (<em>RAG</em>). Researchers have selected the <em>method-data-analysis (mda)</em> journal as a pertinent use case, providing a concrete context for demonstrating the system’s capabilities.</p>
<p>The project introduces a workflow for a ‘local’ or ‘tailored’ AI solution, comprising two primary components. Developers have affectionately named these <em>Ghostwriter</em>, which functions as the user interface, and <em>EverythingData</em>, serving as a comprehensive summary for all underlying backend operations. This chapter will further illustrate both the front-end user experience and the intricate back-end processes, culminating in a summary and outlook on future developments.</p>
</section>
<section id="the-ghostwriter-interface-a-novel-retrieval-paradigm" class="level2" data-number="11.3">
<h2 data-number="11.3" class="anchored" data-anchor-id="the-ghostwriter-interface-a-novel-retrieval-paradigm"><span class="header-section-number">11.3</span> The <em>Ghostwriter</em> Interface: A Novel Retrieval Paradigm</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The <em>Ghostwriter</em> approach introduces a novel paradigm for information retrieval, fundamentally altering how users interact with data. This system conceptualises queries across various levels of complexity and data representation.</p>
<p>Initially, a direct query to a single database representation necessitates prior knowledge of its schema and typical values to yield results, akin to a user interacting solely with a database. Progressing beyond this, a query directed at a data collection or space, underpinned by connected structured databases or graphs, prompts the system to suggest similar or improved queries based on schema interconnections, whilst providing a list of potential results. This interaction mirrors a user consulting a librarian.</p>
<p>Further advancing, a query posed to a Large Language Model (LLM) interprets natural language input and generates results, also expressed in natural language. This scenario evokes the experience of engaging with a library or a panel of experts. Crucially, the <em>Ghostwriter</em> system integrates a local LLM with a target data collection, embedding it within a network of additional data interpretation sources accessible via Application Programming Interfaces (APIs). This sophisticated setup generates a family of terms around the query, identifies related structured information, and ultimately returns a comprehensive list of results. This advanced interaction simulates a user simultaneously chatting with both experts and librarians.</p>
<p>Traditionally, information retrieval has grappled with the challenge of formulating the precise query. Whilst Google features and schema.org enable machines to make informed guesses about user queries, these typically operate within a web-based context, not a local interaction. <em>Ghostwriter</em>, however, through its iterative application, empowers users to reformulate their questions, thereby fostering a deeper understanding of their actual intent and the available data space. This innovative interface, drawing on the metaphors of a “librarian”—representing structured data, Knowledge Organisation Systems (KOS), and historical classifications—and an “expert”—embodying natural language—claims to facilitate simultaneous conversational interaction with both.</p>
</section>
<section id="retrieval-augmented-generation-rag-architecture" class="level2" data-number="11.4">
<h2 data-number="11.4" class="anchored" data-anchor-id="retrieval-augmented-generation-rag-architecture"><span class="header-section-number">11.4</span> Retrieval-Augmented Generation (<em>RAG</em>) Architecture</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Scientifically, this project firmly situates itself within the broader discourse surrounding Retrieval-Augmented Generation (<em>RAG</em>). Philip Rattliff’s paper from Neo4j offers a highly recommended introduction to this intricate topic. [CITATION NEEDED for Rattliff’s paper]. The system’s architecture fundamentally relies upon two main ingredients: a vector space and a knowledge graph. Developers construct the vector space from the content of data files, encoding this information into embeddings. Various Machine Learning (ML) algorithms compute these embeddings, employing diverse Large Language Models (LLMs) in the process.</p>
<p>Conversely, the knowledge graph represents a sophisticated metadata layer. Engineers integrate this layer with a range of ontologies and controlled vocabularies, notably incorporating principles of responsible AI. The <em>Croissant ML standard</em> precisely expresses this graph. The overarching vision for this system involves seamlessly combining both graph and vector representations into a unified model, termed <em>GraphRAG</em>. Developers implement this approach ‘locally’, conceptualising it as a form of Distributed AI. Within this framework, the LLM assumes a dual role, functioning both as an interface between human users and the AI, and as a powerful reasoning engine. Operationally, the LLM connects to a ‘RAG library’—the knowledge graph—enabling it to navigate through datasets and consume embeddings, or vectors, as contextual information.</p>
</section>
<section id="operational-workflow-data-ingestion-and-processing" class="level2" data-number="11.5">
<h2 data-number="11.5" class="anchored" data-anchor-id="operational-workflow-data-ingestion-and-processing"><span class="header-section-number">11.5</span> Operational Workflow: Data Ingestion and Processing</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_05.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The system initiates its operational workflow by ingesting a collection of articles, specifically those sourced from the <em>method-data-analysis (mda)</em> journal. Developers have scraped a limited number of these articles for the current implementation; however, the architecture accommodates any collection of documents as input. This raw information then enters the <em>EverythingData</em> component, which orchestrates a series of sophisticated operations.</p>
<p>Initially, the system stores this information within a vector store, utilising <em>Qdrant</em> for this purpose. Subsequently, it performs crucial processes, including term extraction and the construction of embeddings. A pivotal aspect of this workflow involves coupling the processed information with knowledge graphs. This integration significantly enhances the value of words, phrases, and embeddings by contextualising them, effectively enriching the overall context. All this meticulously processed data then feeds into a unified vector space, forming the <em>RAG-Graph</em>. The <em>Ghostwriter</em> interface interacts directly with this vector space and its integrated graph. Users formulate questions in natural language, and in response, the system provides both a list of relevant documents and a concise summary text, reflecting its understanding of the query.</p>
</section>
<section id="ghostwriter-implementation-preventing-hallucinations" class="level2" data-number="11.6">
<h2 data-number="11.6" class="anchored" data-anchor-id="ghostwriter-implementation-preventing-hallucinations"><span class="header-section-number">11.6</span> <em>Ghostwriter</em> Implementation: Preventing Hallucinations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The developer, whilst having engaged with early iterations of LLMs such as <em>GPT-2</em> in 2020, expresses a nuanced perspective, focusing instead on deconstructing and repurposing their training processes. This work, initially conceived for academic papers, demonstrates remarkable versatility, extending its application to any web content or even spreadsheets, enabling users to query specific values.</p>
<p>A cornerstone of its design lies in its robust mechanism for preventing hallucinations: the system exclusively draws information from the provided source material. Consequently, if a query pertains to information absent from the ingested data, the system transparently responds with “I don’t know.”</p>
<p>Notably, this implementation employs a relatively simple 1 billion parameter LLM, yet it effectively addresses complex questions through the strategic integration of knowledge graphs. For instance, papers from the <em>mda</em>, a GESIS journal, have been ingested into <em>Ghostwriter</em>, forming a distinct collection. A core principle guiding this system dictates that it does not rely on any knowledge pre-ingested into the LLM. Instead, its explicit goal is to furnish only factual information directly present within the specific paper under scrutiny.</p>
</section>
<section id="ghostwriter-in-practice-querying-and-refinement" class="level2" data-number="11.7">
<h2 data-number="11.7" class="anchored" data-anchor-id="ghostwriter-in-practice-querying-and-refinement"><span class="header-section-number">11.7</span> <em>Ghostwriter</em> in Practice: Querying and Refinement</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>Demonstrating its capabilities, the system processes a query such as “explain male breadwinner model to me,” providing a comprehensive explanation of the concept. Crucially, it accompanies this explanation with a detailed list of references, each entry specifying a chat number, article title, direct URL, and a relevance score. This meticulous referencing ensures the system’s output remains grounded in verifiable sources, effectively preventing hallucinations by precisely identifying where information originates.</p>
<p>Internally, the system operates by segmenting each paper into small, distinct blocks, assigning a unique identifier to every block. It then employs sophisticated LLM techniques to intelligently connect and retrieve these blocks, applying weights and leveraging knowledge graphs to predict which text segments will most accurately respond to a given question. This iterative approach is evident when a refined query, for instance, “explain how data was collected on male breadwinner model,” yields a response indicating “no direct information” if the content is not present within the ingested papers. Furthermore, a user-friendly “Add paper” button empowers users to contribute new articles, seamlessly integrating fresh content for subsequent queries.</p>
</section>
<section id="underlying-architecture-entity-extraction-and-multilingual-capabilities" class="level2" data-number="11.8">
<h2 data-number="11.8" class="anchored" data-anchor-id="underlying-architecture-entity-extraction-and-multilingual-capabilities"><span class="header-section-number">11.8</span> Underlying Architecture: Entity Extraction and Multilingual Capabilities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_11.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The system’s robust underlying architecture comprises several interconnected components: entity extraction, knowledge graph linking, multilinguality support, and summary generation. An entity extraction pipeline meticulously annotates terms with semantic meaning, mapping them to controlled vocabularies and thereby transitioning information from the vector space into the knowledge graph. This process extends to linking extracted entities to broader knowledge graph representations, notably <em>Wikidata</em>. Knowledge graphs assume critical importance, serving as a “ground truth” against which the accuracy of LLM-generated answers can be rigorously validated.</p>
<p>Furthermore, the system incorporates immediate multilinguality support, a vital feature enabling it to process papers in diverse languages, such as Chinese or German, whilst responding to queries posed in English. Ultimately, the LLM synthesises these disparate pieces of text to produce the final results, including summary or explanatory content.</p>
<p>The fact extraction process begins by segmenting the user’s query into smaller components, which are then mapped to a Knowledge Organisation System (KOS). This KOS possesses the unique characteristic of iteratively generating new levels of terms, enriching the semantic understanding.</p>
<p>Crucially, the system links these extracted entities to <em>Wikidata</em>, transforming free strings into unique identifiers. These identifiers, in turn, connect to multilingual translations, providing comprehensive properties that facilitate cross-language comprehension. For instance, the core concept of a query, such as “bread winner mo,” can be translated by <em>LLM/Gemma3</em> into hundreds of languages. This mechanism establishes a robust ground truth by decoupling knowledge from both questions and papers, storing it externally as <em>Wikidata</em> identifiers. Consequently, researchers can benchmark different models by testing them against the same list of identifiers, precisely assessing their suitability and identifying any inaccuracies. The project’s proponents envision the Knowledge Organisation System as the future of sustainable information management, actively pursuing collaborations with industry leaders like Google and Meta to realise this vision.</p>
</section>
<section id="live-demonstration-engaging-with-ghostwriter" class="level2" data-number="11.9">
<h2 data-number="11.9" class="anchored" data-anchor-id="live-demonstration-engaging-with-ghostwriter"><span class="header-section-number">11.9</span> Live Demonstration: Engaging with <em>Ghostwriter</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_011_slide_15.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>A live demonstration showcased the <em>Ghostwriter</em> interface, accessible via the GESIS Leibniz-Institut für Sozialwissenschaften website, specifically within its “Ask Questions” section. Users interact with an input field labelled “Enter your question:”, submitting queries via a prominent red “Ask” button. The system also provides collection management functionalities, including an “Add New Collection” dropdown and an “Available Collections” section, where the <em>mda</em> (Methods, Data, Analyses) journal collection was selected, indicating “Vectors 37,637” as its size.</p>
<p>During the demonstration, a query for “Rational Choice Theory” yielded a concise summary compiled from various papers, accompanied by precise references detailing titles, URLs, and relevance scores. A subsequent, more specific query, “explain utility in Rational Choice Theory,” prompted the system to select distinct pieces of information, presenting varied results whilst consistently pointing to the same foundational papers. An available Application Programming Interface (API) further extends the system’s utility, enabling an automatic mode for agentic architectures, which can collect results and identify new knowledge. Users can also expand the system’s knowledge base via an “Add Page” section, allowing the input of webpage URLs or RSS feeds, with options for single webpages, website crawling, or RSS feed integration. Notably, the demonstration highlighted the system’s robust multilingual capabilities: a query posed in English successfully retrieved and processed information from a source paper written entirely in German, save for its abstract.</p>
</section>
<section id="project-vision-and-future-trajectories" class="level2" data-number="11.10">
<h2 data-number="11.10" class="anchored" data-anchor-id="project-vision-and-future-trajectories"><span class="header-section-number">11.10</span> Project Vision and Future Trajectories</h2>
<p>This project champions a key benefit: the provision of local control and cost-effectiveness, contrasting sharply with the reliance on large, external AI models. The interaction with the system is conceptualised as conversing with an “invisible college,” a dynamic exchange designed to provoke human thinking and assist in formulating precise research questions. Crucially, the AI’s role remains one of support for the human thought process; it does not aim to furnish ultimate factual answers or to independently formulate research questions for its users.</p>
<p>From a strategic perspective, the project explicitly avoids a business model centred on developing and selling software. Instead, it prioritises collaborative engagements, particularly with partners who present concrete research questions. The team actively seeks resources to facilitate initial try-outs, intending thereafter to hand over the developed solutions to collaborators. This handover model empowers partners to further tinker with, validate, and polish the systems, fostering a sustainable ecosystem for scientific inquiry. The project’s key contributions lie in demonstrating a practical, localised <em>RAG</em> solution for scientific information management, emphasising factual accuracy, multilingual capabilities, and a robust knowledge organisation framework.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Parsing Footnotes in Law and Humanities Scholarship with Large Language Models">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_012.html" class="pagination-link" aria-label="RAG Systems for Philosophical Research">
        <span class="nav-page-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems for Philosophical Research</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>