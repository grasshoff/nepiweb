<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Sofía Aguilar &amp; Stefania Degaetano-Ortlieb">
<meta name="dcterms.date" content="2025-01-01">

<title>17&nbsp; Interpretable Models for Linguistic Change – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_020.html" rel="next">
<link href="./chapter_ai-nepi_018.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-fe5eeb5af71a333b155c360431d06b9a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e463572c889c87c7eefd27e1777fa793.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="17&nbsp; Interpretable Models for Linguistic Change – AI-NEPI Conference Proceedings - Enhanced Edition">
<meta property="og:description" content="The presentation details a research project focused on modeling context and the interplay between different types of context to trace linguistic change, specifically in English scientific writing. The project utilizes methods from both traditional linguistic analysis and deep learning. The core objective is to develop interpretable models that bridge these approaches to understand how language changes over time and across different contextual dimensions. The research investigates the chem…">
<meta property="og:image" content="images/ai-nepi_019_slide_01.jpg">
<meta property="og:site_name" content="AI-NEPI Conference Proceedings - Enhanced Edition">
<meta name="twitter:title" content="17&nbsp; Interpretable Models for Linguistic Change – AI-NEPI Conference Proceedings - Enhanced Edition">
<meta name="twitter:description" content="The presentation details a research project focused on modeling context and the interplay between different types of context to trace linguistic change, specifically in English scientific writing. The project utilizes methods from both traditional linguistic analysis and deep learning. The core objective is to develop interpretable models that bridge these approaches to understand how language changes over time and across different contextual dimensions. The research investigates the chem…">
<meta name="twitter:image" content="images/ai-nepi_019_slide_01.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_019.html"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">A Primer on Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OpenAlex Mapper: Transdisciplinary Investigations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Computational HPSS: Tracing Ancient Wisdom’s Influence with VERITRACE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and Scientific Insights in Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">17.1</span> Overview</a></li>
  <li><a href="#context-and-theoretical-framework" id="toc-context-and-theoretical-framework" class="nav-link" data-scroll-target="#context-and-theoretical-framework"><span class="header-section-number">17.2</span> Context and Theoretical Framework</a></li>
  <li><a href="#detecting-linguistic-change" id="toc-detecting-linguistic-change" class="nav-link" data-scroll-target="#detecting-linguistic-change"><span class="header-section-number">17.3</span> Detecting Linguistic Change</a></li>
  <li><a href="#paradigmatic-context-and-influence" id="toc-paradigmatic-context-and-influence" class="nav-link" data-scroll-target="#paradigmatic-context-and-influence"><span class="header-section-number">17.4</span> Paradigmatic Context and Influence</a></li>
  <li><a href="#linguistic-realization-and-communicative-perspective" id="toc-linguistic-realization-and-communicative-perspective" class="nav-link" data-scroll-target="#linguistic-realization-and-communicative-perspective"><span class="header-section-number">17.5</span> Linguistic Realization and Communicative Perspective</a></li>
  <li><a href="#framework-for-context-and-language-dynamics" id="toc-framework-for-context-and-language-dynamics" class="nav-link" data-scroll-target="#framework-for-context-and-language-dynamics"><span class="header-section-number">17.6</span> Framework for Context and Language Dynamics</a>
  <ul>
  <li><a href="#stage-i-data-sampling" id="toc-stage-i-data-sampling" class="nav-link" data-scroll-target="#stage-i-data-sampling"><span class="header-section-number">17.6.1</span> Stage I: Data Sampling</a></li>
  <li><a href="#stage-ii-network-construction" id="toc-stage-ii-network-construction" class="nav-link" data-scroll-target="#stage-ii-network-construction"><span class="header-section-number">17.6.2</span> Stage II: Network Construction</a></li>
  <li><a href="#stage-iii-link-prediction" id="toc-stage-iii-link-prediction" class="nav-link" data-scroll-target="#stage-iii-link-prediction"><span class="header-section-number">17.6.3</span> Stage III: Link Prediction</a></li>
  <li><a href="#stage-iv-entity-alignment" id="toc-stage-iv-entity-alignment" class="nav-link" data-scroll-target="#stage-iv-entity-alignment"><span class="header-section-number">17.6.4</span> Stage IV: Entity Alignment</a></li>
  </ul></li>
  <li><a href="#limitations-and-future-work" id="toc-limitations-and-future-work" class="nav-link" data-scroll-target="#limitations-and-future-work"><span class="header-section-number">17.7</span> Limitations and Future Work</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Show code</button></div></div>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Sofía Aguilar &amp; Stefania Degaetano-Ortlieb </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            AI-NEPI Conference Participant
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    The presentation details a research project focused on modeling context and the interplay between different types of context to trace linguistic change, specifically in English scientific writing. The project utilizes methods from both traditional linguistic analysis and deep learning. The core objective is to develop interpretable models that bridge these approaches to understand how language changes over time and across different contextual dimensions. The research investigates the chem…
  </div>
</div>


</header>


<section id="overview" class="level2" data-number="17.1">
<h2 data-number="17.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">17.1</span> Overview</h2>
<p>The presentation details a research project focused on modeling context and the interplay between different types of context to trace linguistic change, specifically in English scientific writing. The project utilizes methods from both traditional linguistic analysis and deep learning. The core objective is to develop interpretable models that bridge these approaches to understand how language changes over time and across different contextual dimensions. The research investigates the chemical revolution period (1760s-1820s) in the Royal Society Corpus (RSC) as a case study, focusing on the shift from the phlogiston theory to the oxygen theory.</p>
<p>Previous work involved modeling context using separate approaches. The current work aims to combine these approaches and analyze their interactions. The theoretical framework draws upon language variation and register theory (Halliday 1985, Biber 1988), which posits that situational context determines language use and linguistic context exhibits variation. It also incorporates principles from rational communication and information theory (Jaeger and Levy 2007, Piantadosi et al.&nbsp;2011), suggesting that linguistic variation modulates information content for efficient communication.</p>
<p>Methods for detecting periods of change include continuous comparison using Kullback-Leibler Divergence (KLD) on probability distributions of linguistic units (words, POS trigrams) over time (Degaetano-Ortlieb and Teich 2018, 2019). This method identifies periods of increased divergence, indicating significant linguistic shifts. Analysis of <em>what</em> changes involves examining the specific lexical items and grammatical patterns contributing to high KLD, revealing “waves of increased expressivity” potentially linked to new concepts. The effects of change are observed across linguistic levels, including lexical items (lemmas) and grammatical units (POS trigrams).</p>
<p>Paradigmatic context and change are analyzed using semantic space models (Fankhauser et al.&nbsp;2017, Bizzoni et al.&nbsp;2019), visualizing semantic similarity and frequency of terms like “phlogiston” and “oxygen” across different time periods. Identifying <em>who</em> leads or spreads change utilizes <em>Cascade models</em> (<em>Hawkes processes</em>) (Bizzoni et al.&nbsp;2021), which model influence spread within a network, identifying innovators (e.g., Priestley) and spreaders (e.g., Pearson).</p>
<p>Investigating <em>how</em> change is realized linguistically and <em>why</em> it occurs from a communicative perspective involves analyzing Surprisal (Shannon 1949), which correlates with cognitive effort (Hale 2001, Levy 2008, Crocker et al.&nbsp;2016). Linguistic structures that reduce surprisal and encoding effort, such as shifts from prepositional phrases (“consumption of oxygen”) to compounds (“oxygen consumption”), are analyzed over time in relation to community adoption (number of authors).</p>
<p>The proposed framework for modeling context for language variation and change addresses limitations of current methods (e.g., static network approaches) by treating context as a central signal. It proposes using <em>Graph Convolutional Networks</em> (<em>GCNs</em>) for modeling complex relational data. A pilot study on the chemical revolution outlines a multi-stage process:</p>
<ul>
<li><p>Data Sampling: Using the RSC, applying tf-idf and KLD to identify keywords in the target period (1760s-1820s).</p></li>
<li><p>Network Construction: Building time-aware networks. This involves creating word- and time-aware feature vectors using <em>BERT</em> for word embeddings and one-hot encoding for categorical metadata (author, journal, period). Node feature matrices are created for 20-year periods. Change in node features is measured using KLD across periods, resulting in a diachronic series of graphs. Network size is managed using community detection algorithms (e.g., Riolo &amp; Newman 2020).</p></li>
<li><p>Link Prediction: Predicting how, when, and by whom words are used. Word profiles are augmented with semantic embeddings (from <em>BERT</em>), contextual metadata (author, journal, period), and grammatical information (POS, syntactic role). A <em>Transformer-GCN</em> model learns patterns in these profiles to predict new links, with <em>GCN</em> capturing structural relationships and <em>Transformer</em> attention highlighting influential contextual features.</p></li>
<li><p>Entity Alignment: Inspecting and interpreting change. This involves identifying Network Motifs (small, overrepresented subgraphs) using the <em>Kavosh algorithm</em>, which groups isomorphic graphs to find motifs across networks. Entity alignment (e.g., using <em>GCNs</em> for tasks like aligning concepts across different datasets or languages) is a future perspective.</p></li>
</ul>
<p>Limitations and perspectives include computationally tracing conceptual versus linguistic change, integrating metadata as a core signal, determining the optimal unit of language change (word, concept, grammar, discourse), identifying recurring linguistic pathways for concept emergence, and ensuring interpretability of complex models. Future work includes expanding to multilingual corpora (e.g., French, German journals) and other text types (letters, monographs) and investigating the expression of attitude (positive/negative) towards concepts within the network structure.</p>
</section>
<section id="context-and-theoretical-framework" class="level2" data-number="17.2">
<h2 data-number="17.2" class="anchored" data-anchor-id="context-and-theoretical-framework"><span class="header-section-number">17.2</span> Context and Theoretical Framework</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_019_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>The research focuses on the computational analysis of semantic change across different environments, specifically modeling context and the interplay between various types of context. A key case study involves the chemical revolution as documented in the Royal Society Corpus (RSC). This historical event centers on the replacement of the 100-year-old phlogiston theory by Lavoisier’s theory of oxygen. Previous research efforts modeled context using separate approaches, while the current work aims to combine these methods to analyze the interactions between different contextual dimensions.</p>
<p>The framework identifies six key types of context: Situational (Where), Temporal (When), Experiential (What), Interpersonal (Who), Textual (How), and Causal (Why). The theoretical foundation draws upon two main areas. Firstly, language variation and register theory, as described by Halliday (1985) and Biber (1988), posits that situational context dictates language use and that linguistic context inherently exhibits variation. Examples of such variation include phrases like “…air which was dephlogisticated…”, “…dephlogisticated air…”, and “…oxygen…”. Secondly, rational communication and information theory, developed within the IDeaL SFB 1102 project and referenced in works by Jaeger and Levy (2007) and Piantadosi et al.&nbsp;(2011), suggests that linguistic variation serves to modulate information content, leading to optimization effects that facilitate efficient communication with reasonable effort.</p>
</section>
<section id="detecting-linguistic-change" class="level2" data-number="17.3">
<h2 data-number="17.3" class="anchored" data-anchor-id="detecting-linguistic-change"><span class="header-section-number">17.3</span> Detecting Linguistic Change</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_019_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The research addresses the problem of detecting periods of change in language use by identifying these periods directly rather than relying on comparisons between predefined time segments. The primary method for detecting change utilizes Kullback-Leibler Divergence (KLD). This approach compares the probability distributions, p(unit|context), of linguistic units over time using a continuous comparison method (Degaetano-Ortlieb and Teich 2018, 2019). The interpretation of KLD values is direct: similar distributions result in low divergence, while differing distributions yield higher divergence. The continuous comparison employs a sliding time window, for instance, comparing a 20-year period designated as “PAST” with the subsequent 20-year period labeled “FUTURE”.</p>
<p>To analyze <em>what</em> changes, the method plots KLD over time for various linguistic items, including both lexical items and POS trigrams. Peaks observed in these KLD plots are interpreted as “waves of increased expressivity,” suggesting the emergence of new concepts or significant shifts in the linguistic treatment of existing ones. The analysis includes a wide range of lexical items such as “electricity”, “electrify”, “’s”, “limb”, “ditto”, “air”, “dephlogisticated experiment”, “nitrous”, “acid”, “gas”, “oxide”, “be”, “hydrogen”, “current”, “urine”, “cell”, “corpuscule”, “glacier”, “tide”, “the”, “of”, “sin”, and “cos”. A specific period of interest, approximately from 1765 to 1805, is highlighted, encompassing terms like “dephlogisticated experiment”, “nitrous”, “acid”, “air”, “gas”, “oxide”, “be”, “hydrogen”, “current”, “urine”, and “cell”. This period aligns with significant historical events like the discovery of hydrogen (inflammable air) by Henry Cavendish in 1766 and the discovery of oxygen (dephlogisticated air) by Joseph Priestley in 1774.</p>
<p>The analysis observes effects across different linguistic levels. KLD is applied to lexical items, using the lemma as the unit of analysis, and also to grammatical units, specifically POS trigrams. The findings indicate that peaks in KLD for lexical items, occurring around 1775-1805, correspond roughly to peaks observed in the KLD analysis of POS trigrams. Examples of POS trigrams analyzed include “NN NN IN (zenith distance of)”, “VBZ JJR IN (is greater than)”, “DT NN IN (the end of)”, “NN NN NN (thunder and lightning)”, “IN JJ NN (of dephlogisticated air)”, “DT NNS IN (the effects of)”, “NN NN DT (oxide of iron)”, “NN NN IN (the quantity/number of)”, “VBZ JJR IN (is greater than)”, “NN NN IN (unite edge of)”, and “IN DT JJ (for the same)”. This suggests that linguistic change during this period manifested across both vocabulary and grammatical structure.</p>
</section>
<section id="paradigmatic-context-and-influence" class="level2" data-number="17.4">
<h2 data-number="17.4" class="anchored" data-anchor-id="paradigmatic-context-and-influence"><span class="header-section-number">17.4</span> Paradigmatic Context and Influence</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_019_slide_06.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The analysis of paradigmatic context and change employs methods described by Fankhauser et al.&nbsp;(2017) and Bizzoni et al.&nbsp;(2019). This technique involves visualizing semantic space at different time periods, such as 1780, 1800, and 1840. Terms are represented as points within this space, where their position indicates semantic similarity. The visualizations provide additional details: the size of the circle representing a term indicates its relative frequency, and color is used to represent clusters of terms. Observing the shifts in term positions and clustering over time reveals semantic change, exemplified by the appearance of “oxygen” and the changing position and frequency of terms like “phlogiston” and “dephlogisticated”. The corpora used for this analysis are available at corpora.ids-mannheim.de.</p>
<p>To identify <em>who</em> is leading or spreading change, the research utilizes <em>Cascade models</em>, specifically <em>Hawkes processes</em>, as detailed by Bizzoni et al.&nbsp;(2021). These models are applied to model the spread of influence or linguistic innovations within a network, such as a network of authors. The models enable the identification of individuals acting as “Innovators,” such as Priestley, and those acting as “Early Adopters” or “Spreaders,” including Pearson and Davy. The results are visualized using a heatmap that shows author influence over time. In this visualization, the color intensity represents the degree of influence, and dashed lines are used to indicate the spread of influence across different time points.</p>
</section>
<section id="linguistic-realization-and-communicative-perspective" class="level2" data-number="17.5">
<h2 data-number="17.5" class="anchored" data-anchor-id="linguistic-realization-and-communicative-perspective"><span class="header-section-number">17.5</span> Linguistic Realization and Communicative Perspective</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_019_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The research investigates how linguistic change is realized and why these changes occur from a communicative perspective. The approach involves analyzing change within the linguistic context using the concept of Surprisal, as introduced by Shannon (1949). The underlying principle is that the surprisal of a linguistic unit is proportional to the cognitive effort required to process it, a relationship supported by work from Hale (2001), Levy (2008), and Crocker et al.&nbsp;(2016). A core hypothesis is that linguistic changes occur to reduce cognitive effort and facilitate more efficient communication.</p>
<p>The analysis tracks the surprisal of different linguistic structures over time. Examples of structures examined include clausal forms like “…the oxygen (which was) consumed”, prepositional phrases such as “…the consumption of oxygen…”, and compound forms like “…the oxygen consumption…”. The observation is that the surprisal of longer, more effortful structures, exemplified by the prepositional phrase “Prepositional consumption of oxygen”, tends to decrease over time. This decrease coincides with the emergence and establishment of shorter, less effortful structures, such as the compound “Compound oxygen consumption”, within the linguistic community. A correlation is observed between the decrease in surprisal for these shorter forms and an increasing number of authors adopting and using them. This process indicates that shorter encoding emerges and becomes established in the community, effectively reducing cognitive effort as reflected by lower surprisal values. This work is related to the MA thesis of Viktoria Lima-Vaz (2025) and a submission by Degaetano-Ortlieb et al.&nbsp;(July 2024).</p>
</section>
<section id="framework-for-context-and-language-dynamics" class="level2" data-number="17.6">
<h2 data-number="17.6" class="anchored" data-anchor-id="framework-for-context-and-language-dynamics"><span class="header-section-number">17.6</span> Framework for Context and Language Dynamics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_019_slide_12.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The proposed framework for modeling context for the analysis of language variation and change is motivated by the understanding that language change is driven by shifts in social context, including evolving goals, social structures, and domain conventions. Current limitations in the field include that existing semantic change studies and KLD applications often track shifts but do not adequately model the interaction between various contextual signals. Furthermore, static network approaches are limited in their ability to capture dynamic interactions over time.</p>
<p>The proposed framework posits that context serves as a central signal for modeling language dynamics. <em>Graph Convolutional Networks</em> (<em>GCNs</em>) are proposed as one possible technological direction due to their powerful capability for modeling complex relational data. A pilot study focusing on the chemical revolution is outlined, utilizing the Royal Society Corpus (RSC) and targeting the period between the 1760s and 1820s.</p>
<section id="stage-i-data-sampling" class="level3" data-number="17.6.1">
<h3 data-number="17.6.1" class="anchored" data-anchor-id="stage-i-data-sampling"><span class="header-section-number">17.6.1</span> Stage I: Data Sampling</h3>
<p>This stage employs methods such as tf-idf and KLD to identify relevant keywords within the target period. KLD is used to define words that are distinct for each period, with words contributing highly to KLD being considered relevant.</p>
</section>
<section id="stage-ii-network-construction" class="level3" data-number="17.6.2">
<h3 data-number="17.6.2" class="anchored" data-anchor-id="stage-ii-network-construction"><span class="header-section-number">17.6.2</span> Stage II: Network Construction</h3>
<p>This stage aims at building word- and time-aware feature vectors. This involves using <em>BERT</em> for generating word vectors and one-hot encoding for categorical metadata such as Author, Journal, and Period. A node feature matrix is created for each 20-year period. Change in these node feature vectors is measured using KLD to assess dissimilarity across periods, resulting in a diachronic series of graphs. To manage network complexity, community detection algorithms, such as those described by Riolo &amp; Newman (2020), are used for network size definition.</p>
</section>
<section id="stage-iii-link-prediction" class="level3" data-number="17.6.3">
<h3 data-number="17.6.3" class="anchored" data-anchor-id="stage-iii-link-prediction"><span class="header-section-number">17.6.3</span> Stage III: Link Prediction</h3>
<p>This stage seeks to predict how, when, and by whom words are used. This involves using word profiles augmented with semantic embeddings (e.g., from <em>BERT</em>), contextual metadata (e.g., author, journal, period), and grammatical information (e.g., part of speech, syntactic role). A <em>Transformer-GCN</em> model is employed, which learns patterns in these augmented profiles and predicts new links. The <em>GCN</em> component captures structural relationships within the network, while the <em>Transformer</em> attention mechanism highlights the most influential contextual features.</p>
</section>
<section id="stage-iv-entity-alignment" class="level3" data-number="17.6.4">
<h3 data-number="17.6.4" class="anchored" data-anchor-id="stage-iv-entity-alignment"><span class="header-section-number">17.6.4</span> Stage IV: Entity Alignment</h3>
<p>This stage is designed to inspect and interpret the observed change. It utilizes Network Motifs, defined as small, overrepresented subgraphs that reflect meaningful interaction structures. The <em>Kavosh algorithm</em> is used, which groups isomorphic graphs to identify these motifs within networks. Entity alignment is also considered as a future application, potentially involving tasks like aligning similar graphs across different time periods (t1, t2).</p>
</section>
</section>
<section id="limitations-and-future-work" class="level2" data-number="17.7">
<h2 data-number="17.7" class="anchored" data-anchor-id="limitations-and-future-work"><span class="header-section-number">17.7</span> Limitations and Future Work</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_019_slide_16.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The research acknowledges several limitations and outlines future perspectives. Key questions include what it truly means to computationally trace conceptual change and whether models can capture deeper epistemic shifts beyond mere linguistic drift. Another challenge is understanding how context becomes integrated into the meaning represented by language models, and whether metadata should be treated as external noise or a core signal. The optimal ‘unit’ of language change remains a question: are shifts best observed at the level of words, concepts, grammar, or discourse patterns? The possibility of identifying recurring linguistic pathways for concept emergence and determining if new ideas follow predictable linguistic trajectories is also explored. Finally, the limits of interpretability in complex models are considered, emphasizing the need to ensure that explanations are meaningful rather than merely plausible.</p>
<p>Future perspectives include expanding the data sources beyond the Royal Society Corpus to include multilingual corpora, such as French and German journals, and incorporating other text types like monographs and letters. A significant area for future work is addressing the expression of attitude or stance in language use, particularly the challenge of differentiating between positive and negative usage of terms like “oxygen” or “dephlogisticated air” within the context of heated historical debates. Potential approaches involve analyzing differences in network structure based on usage context, such as linking terms to critiques or “dispective” adjectives.</p>
<p>Matching linguistic patterns to authors known to advocate for or against specific theories, potentially leveraging external historical knowledge from philosophy of science texts, is another avenue. Furthermore, insights from work on propaganda analysis, such as in the context of the Russian-Ukraine war, could be mapped onto historical texts to identify propagandistic strategies. The method would involve comparing network structures over time, focusing on structural features and identifying which nodes promote more edges.</p>
<p>Applying the developed methods to current era corpora, such as a quantum gravity corpus, is also a future perspective. The goal is to observe community building and changing language in real-time or near real-time. This would require establishing a protocol for structuring the data, potentially in a relational database like SQL, to facilitate its translation into a graph format. Processing the data to leverage categorical values, such as author, journal, and topics, as features within the graph structure would be necessary. Depending on the structure of the dataset, data engineering may be required.</p>
<p>Finally, Entity Alignment is identified as a future perspective, particularly for enabling multilingual or multi-corpus comparisons. This involves tasks such as aligning concepts, for example, the “oxygen” subgraph, across different datasets, such as those from English versus French journals. The method would utilize a <em>graph convolutional network</em> specifically for an entity alignment task, distinct from a link prediction task. The objective is to determine if entities are identified as the same based on their neighboring nodes and overall network structure.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  // Create burger menu button
  const toggleButton = document.createElement('button');
  toggleButton.className = 'sidebar-toggle';
  toggleButton.setAttribute('aria-label', 'Toggle sidebar');
  toggleButton.innerHTML = `
    <div class="burger-icon">
      <span></span>
      <span></span>
      <span></span>
    </div>
  `;
  
  // Create backdrop for mobile
  const backdrop = document.createElement('div');
  backdrop.className = 'sidebar-backdrop';
  
  // Add elements to page
  document.body.appendChild(toggleButton);
  document.body.appendChild(backdrop);
  
  // Get sidebar and main content elements
  const sidebar = document.querySelector('.sidebar') || 
                 document.querySelector('.quarto-sidebar') || 
                 document.querySelector('.sidebar-navigation');
  const mainContent = document.querySelector('main') || 
                     document.querySelector('.main-content') || 
                     document.querySelector('.quarto-container') || 
                     document.body;
  
  // State management
  let sidebarOpen = window.innerWidth > 768; // Start open on desktop, closed on mobile
  
  // Initialize sidebar state
  function initializeSidebar() {
    if (window.innerWidth <= 768) {
      sidebarOpen = false;
    }
    updateSidebarState();
  }
  
  // Update sidebar state and classes
  function updateSidebarState() {
    if (sidebar) {
      if (sidebarOpen) {
        sidebar.classList.remove('collapsed');
        toggleButton.classList.add('sidebar-open');
        mainContent.classList.add('sidebar-open');
        mainContent.classList.remove('sidebar-closed');
        if (window.innerWidth <= 768) {
          backdrop.classList.add('active');
        }
      } else {
        sidebar.classList.add('collapsed');
        toggleButton.classList.remove('sidebar-open');
        mainContent.classList.remove('sidebar-open');
        mainContent.classList.add('sidebar-closed');
        backdrop.classList.remove('active');
      }
    }
    
    // Store state in localStorage
    localStorage.setItem('sidebarOpen', sidebarOpen);
  }
  
  // Toggle sidebar
  function toggleSidebar() {
    sidebarOpen = !sidebarOpen;
    updateSidebarState();
  }
  
  // Close sidebar (for chapter links)
  function closeSidebar() {
    if (window.innerWidth <= 768) { // Only auto-close on mobile
      sidebarOpen = false;
      updateSidebarState();
    }
  }
  
  // Event listeners
  toggleButton.addEventListener('click', toggleSidebar);
  backdrop.addEventListener('click', toggleSidebar);
  
  // Auto-close sidebar when clicking chapter links
  if (sidebar) {
    const chapterLinks = sidebar.querySelectorAll('a[href]');
    chapterLinks.forEach(link => {
      link.addEventListener('click', function(e) {
        // Small delay to allow navigation to start
        setTimeout(closeSidebar, 100);
      });
    });
  }
  
  // Handle window resize
  window.addEventListener('resize', function() {
    if (window.innerWidth > 768 && !sidebarOpen) {
      sidebarOpen = true;
      updateSidebarState();
    } else if (window.innerWidth <= 768 && sidebarOpen) {
      sidebarOpen = false;
      updateSidebarState();
    }
  });
  
  // Handle escape key
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && sidebarOpen && window.innerWidth <= 768) {
      closeSidebar();
    }
  });
  
  // Restore saved state from localStorage
  const savedState = localStorage.getItem('sidebarOpen');
  if (savedState !== null) {
    sidebarOpen = savedState === 'true';
  }
  
  // Initialize
  initializeSidebar();
  
  // Add keyboard navigation support
  toggleButton.addEventListener('keydown', function(e) {
    if (e.key === 'Enter' || e.key === ' ') {
      e.preventDefault();
      toggleSidebar();
    }
  });
  
  // Improve accessibility
  toggleButton.setAttribute('role', 'button');
  toggleButton.setAttribute('tabindex', '0');
  
  // Update aria-expanded attribute
  function updateAriaExpanded() {
    toggleButton.setAttribute('aria-expanded', sidebarOpen);
  }
  
  // Call updateAriaExpanded whenever sidebar state changes
  const originalUpdateSidebarState = updateSidebarState;
  updateSidebarState = function() {
    originalUpdateSidebarState();
    updateAriaExpanded();
  };
  
  updateAriaExpanded();
  
  // Ensure TOC sticky positioning works properly
  function ensureTOCSticky() {
    // Find all possible TOC elements
    const tocSelectors = [
      '#TOC',
      '.table-of-contents',
      '.quarto-sidebar-toc',
      '.toc',
      '.quarto-toc',
      'nav[role="doc-toc"]',
      '.margin-sidebar',
      '.sidebar-right',
      '.quarto-margin-sidebar',
      '.column-margin'
    ];
    
    let toc = null;
    for (const selector of tocSelectors) {
      toc = document.querySelector(selector);
      if (toc) break;
    }
    
    if (toc) {
      console.log('Found TOC element:', toc.className || toc.id);
      
      // Force sticky positioning with important styles
      toc.style.setProperty('position', 'sticky', 'important');
      toc.style.setProperty('top', '1rem', 'important');
      toc.style.setProperty('max-height', 'calc(100vh - 2rem)', 'important');
      toc.style.setProperty('overflow-y', 'auto', 'important');
      toc.style.setProperty('z-index', '100', 'important');
      
      // Ensure parent containers support sticky
      let parent = toc.parentElement;
      while (parent && parent !== document.body) {
        parent.style.setProperty('position', 'relative', 'important');
        parent.style.setProperty('height', 'auto', 'important');
        parent = parent.parentElement;
      }
      
      // Add scroll event listener to maintain visibility
      let lastScrollTop = 0;
      const scrollHandler = function() {
        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
        
        // Ensure TOC remains visible and properly positioned
        if (toc && window.innerWidth > 768) {
          toc.style.setProperty('position', 'sticky', 'important');
          toc.style.setProperty('top', '1rem', 'important');
        }
        
        lastScrollTop = scrollTop;
      };
      
      // Remove existing scroll listeners to avoid duplicates
      window.removeEventListener('scroll', scrollHandler);
      window.addEventListener('scroll', scrollHandler, { passive: true });
      
      // Also apply to any nested TOC elements
      const nestedTocs = toc.querySelectorAll('#TOC, .toc, .table-of-contents');
      nestedTocs.forEach(nestedToc => {
        nestedToc.style.setProperty('position', 'sticky', 'important');
        nestedToc.style.setProperty('top', '0', 'important');
      });
    } else {
      console.log('No TOC element found');
    }
  }
  
  // Initialize TOC sticky behavior
  ensureTOCSticky();
  
  // Re-initialize periodically to ensure it stays sticky
  setInterval(ensureTOCSticky, 2000);
  
  // Re-initialize on window resize
  window.addEventListener('resize', function() {
    setTimeout(ensureTOCSticky, 100);
  });
  
  // Re-initialize if content changes
  const observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      if (mutation.type === 'childList') {
        setTimeout(ensureTOCSticky, 100);
      }
    });
  });
  
  observer.observe(document.body, {
    childList: true,
    subtree: true
  });
  
  // Force re-initialization after page load
  window.addEventListener('load', function() {
    setTimeout(ensureTOCSticky, 500);
  });
});
</script>

<style>
/* Additional styles for better integration */
body {
  overflow-x: hidden;
}

.sidebar-toggle {
  -webkit-tap-highlight-color: transparent;
}

/* Ensure smooth transitions on all relevant elements */
.sidebar,
.sidebar-toggle,
.main-content,
.sidebar-backdrop {
  will-change: transform, opacity, margin;
}

/* Focus styles for accessibility */
.sidebar-toggle:focus {
  outline: 2px solid white;
  outline-offset: 2px;
}

/* Prevent text selection on burger icon */
.burger-icon {
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
</style> 
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_018.html" class="pagination-link" aria-label="LLMs for Chemical Knowledge Analysis">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_020.html" class="pagination-link" aria-label="LLM for HPS Studies: Analyzing the NHGRI Archive">
        <span class="nav-page-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="an">abstract:</span><span class="co"> "\n      The presentation details a research project focused on modeling\</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">  \ context and the interplay between different types of context to trace linguistic\</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co">  \ change, specifically in English scientific writing. The project utilizes methods\</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co">  \ from both traditional linguistic analysis and deep learning. The core objective\</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">  \ is to develop interpretable models that bridge these approaches to understand\</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">  \ how language changes over time and across different contextual dimensions. The\</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">  \ research investigates the chem..."</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="an">author:</span></span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co">- affiliation: AI-NEPI Conference Participant</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co">  name: Sofía Aguilar &amp; Stefania Degaetano-Ortlieb</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="an">bibliography:</span><span class="co"> bibliography.bib</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="an">date:</span><span class="co"> '2025'</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">---</span></span>
<span id="cb1-16"><a href="#cb1-16"></a></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="fu"># Interpretable Models for Linguistic Change</span></span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="fu">## Overview</span></span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a>The presentation details a research project focused on modeling context and the interplay between different types of context to trace linguistic change, specifically in English scientific writing. The project utilizes methods from both traditional linguistic analysis and deep learning. The core objective is to develop interpretable models that bridge these approaches to understand how language changes over time and across different contextual dimensions. The research investigates the chemical revolution period (1760s-1820s) in the Royal Society Corpus (RSC) as a case study, focusing on the shift from the phlogiston theory to the oxygen theory.</span>
<span id="cb1-22"><a href="#cb1-22"></a></span>
<span id="cb1-23"><a href="#cb1-23"></a>Previous work involved modeling context using separate approaches. The current work aims to combine these approaches and analyze their interactions. The theoretical framework draws upon language variation and register theory (Halliday 1985, Biber 1988), which posits that situational context determines language use and linguistic context exhibits variation. It also incorporates principles from rational communication and information theory (Jaeger and Levy 2007, Piantadosi et al. 2011), suggesting that linguistic variation modulates information content for efficient communication.</span>
<span id="cb1-24"><a href="#cb1-24"></a></span>
<span id="cb1-25"><a href="#cb1-25"></a>Methods for detecting periods of change include continuous comparison using Kullback-Leibler Divergence (KLD) on probability distributions of linguistic units (words, POS trigrams) over time (Degaetano-Ortlieb and Teich 2018, 2019). This method identifies periods of increased divergence, indicating significant linguistic shifts. Analysis of *what* changes involves examining the specific lexical items and grammatical patterns contributing to high KLD, revealing "waves of increased expressivity" potentially linked to new concepts. The effects of change are observed across linguistic levels, including lexical items (lemmas) and grammatical units (POS trigrams).</span>
<span id="cb1-26"><a href="#cb1-26"></a></span>
<span id="cb1-27"><a href="#cb1-27"></a>Paradigmatic context and change are analyzed using semantic space models (Fankhauser et al. 2017, Bizzoni et al. 2019), visualizing semantic similarity and frequency of terms like "phlogiston" and "oxygen" across different time periods. Identifying *who* leads or spreads change utilizes *Cascade models* (*Hawkes processes*) (Bizzoni et al. 2021), which model influence spread within a network, identifying innovators (e.g., Priestley) and spreaders (e.g., Pearson).</span>
<span id="cb1-28"><a href="#cb1-28"></a></span>
<span id="cb1-29"><a href="#cb1-29"></a>Investigating *how* change is realized linguistically and *why* it occurs from a communicative perspective involves analyzing Surprisal (Shannon 1949), which correlates with cognitive effort (Hale 2001, Levy 2008, Crocker et al. 2016). Linguistic structures that reduce surprisal and encoding effort, such as shifts from prepositional phrases ("consumption of oxygen") to compounds ("oxygen consumption"), are analyzed over time in relation to community adoption (number of authors).</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a>The proposed framework for modeling context for language variation and change addresses limitations of current methods (e.g., static network approaches) by treating context as a central signal. It proposes using *Graph Convolutional Networks* (*GCNs*) for modeling complex relational data. A pilot study on the chemical revolution outlines a multi-stage process:</span>
<span id="cb1-32"><a href="#cb1-32"></a></span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="ss">- </span>Data Sampling: Using the RSC, applying tf-idf and KLD to identify keywords in the target period (1760s-1820s).</span>
<span id="cb1-34"><a href="#cb1-34"></a></span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="ss">- </span>Network Construction: Building time-aware networks. This involves creating word- and time-aware feature vectors using *BERT* for word embeddings and one-hot encoding for categorical metadata (author, journal, period). Node feature matrices are created for 20-year periods. Change in node features is measured using KLD across periods, resulting in a diachronic series of graphs. Network size is managed using community detection algorithms (e.g., Riolo &amp; Newman 2020).</span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a><span class="ss">- </span>Link Prediction: Predicting how, when, and by whom words are used. Word profiles are augmented with semantic embeddings (from *BERT*), contextual metadata (author, journal, period), and grammatical information (POS, syntactic role). A *Transformer-GCN* model learns patterns in these profiles to predict new links, with *GCN* capturing structural relationships and *Transformer* attention highlighting influential contextual features.</span>
<span id="cb1-38"><a href="#cb1-38"></a></span>
<span id="cb1-39"><a href="#cb1-39"></a><span class="ss">- </span>Entity Alignment: Inspecting and interpreting change. This involves identifying Network Motifs (small, overrepresented subgraphs) using the *Kavosh algorithm*, which groups isomorphic graphs to find motifs across networks. Entity alignment (e.g., using *GCNs* for tasks like aligning concepts across different datasets or languages) is a future perspective.</span>
<span id="cb1-40"><a href="#cb1-40"></a></span>
<span id="cb1-41"><a href="#cb1-41"></a>Limitations and perspectives include computationally tracing conceptual versus linguistic change, integrating metadata as a core signal, determining the optimal unit of language change (word, concept, grammar, discourse), identifying recurring linguistic pathways for concept emergence, and ensuring interpretability of complex models. Future work includes expanding to multilingual corpora (e.g., French, German journals) and other text types (letters, monographs) and investigating the expression of attitude (positive/negative) towards concepts within the network structure.</span>
<span id="cb1-42"><a href="#cb1-42"></a></span>
<span id="cb1-43"><a href="#cb1-43"></a><span class="fu">## Context and Theoretical Framework</span></span>
<span id="cb1-44"><a href="#cb1-44"></a></span>
<span id="cb1-45"><a href="#cb1-45"></a><span class="al">![Slide 01](images/ai-nepi_019_slide_01.jpg)</span></span>
<span id="cb1-46"><a href="#cb1-46"></a></span>
<span id="cb1-47"><a href="#cb1-47"></a>The research focuses on the computational analysis of semantic change across different environments, specifically modeling context and the interplay between various types of context. A key case study involves the chemical revolution as documented in the Royal Society Corpus (RSC). This historical event centers on the replacement of the 100-year-old phlogiston theory by Lavoisier's theory of oxygen. Previous research efforts modeled context using separate approaches, while the current work aims to combine these methods to analyze the interactions between different contextual dimensions.</span>
<span id="cb1-48"><a href="#cb1-48"></a></span>
<span id="cb1-49"><a href="#cb1-49"></a>The framework identifies six key types of context: Situational (Where), Temporal (When), Experiential (What), Interpersonal (Who), Textual (How), and Causal (Why). The theoretical foundation draws upon two main areas. Firstly, language variation and register theory, as described by Halliday (1985) and Biber (1988), posits that situational context dictates language use and that linguistic context inherently exhibits variation. Examples of such variation include phrases like "...air which was dephlogisticated...", "...dephlogisticated air...", and "...oxygen...". Secondly, rational communication and information theory, developed within the IDeaL SFB 1102 project and referenced in works by Jaeger and Levy (2007) and Piantadosi et al. (2011), suggests that linguistic variation serves to modulate information content, leading to optimization effects that facilitate efficient communication with reasonable effort.</span>
<span id="cb1-50"><a href="#cb1-50"></a></span>
<span id="cb1-51"><a href="#cb1-51"></a><span class="fu">## Detecting Linguistic Change</span></span>
<span id="cb1-52"><a href="#cb1-52"></a></span>
<span id="cb1-53"><a href="#cb1-53"></a><span class="al">![Slide 03](images/ai-nepi_019_slide_03.jpg)</span></span>
<span id="cb1-54"><a href="#cb1-54"></a></span>
<span id="cb1-55"><a href="#cb1-55"></a>The research addresses the problem of detecting periods of change in language use by identifying these periods directly rather than relying on comparisons between predefined time segments. The primary method for detecting change utilizes Kullback-Leibler Divergence (KLD). This approach compares the probability distributions, p(unit|context), of linguistic units over time using a continuous comparison method (Degaetano-Ortlieb and Teich 2018, 2019). The interpretation of KLD values is direct: similar distributions result in low divergence, while differing distributions yield higher divergence. The continuous comparison employs a sliding time window, for instance, comparing a 20-year period designated as "PAST" with the subsequent 20-year period labeled "FUTURE".</span>
<span id="cb1-56"><a href="#cb1-56"></a></span>
<span id="cb1-57"><a href="#cb1-57"></a>To analyze *what* changes, the method plots KLD over time for various linguistic items, including both lexical items and POS trigrams. Peaks observed in these KLD plots are interpreted as "waves of increased expressivity," suggesting the emergence of new concepts or significant shifts in the linguistic treatment of existing ones. The analysis includes a wide range of lexical items such as "electricity", "electrify", "'s", "limb", "ditto", "air", "dephlogisticated experiment", "nitrous", "acid", "gas", "oxide", "be", "hydrogen", "current", "urine", "cell", "corpuscule", "glacier", "tide", "the", "of", "sin", and "cos". A specific period of interest, approximately from 1765 to 1805, is highlighted, encompassing terms like "dephlogisticated experiment", "nitrous", "acid", "air", "gas", "oxide", "be", "hydrogen", "current", "urine", and "cell". This period aligns with significant historical events like the discovery of hydrogen (inflammable air) by Henry Cavendish in 1766 and the discovery of oxygen (dephlogisticated air) by Joseph Priestley in 1774.</span>
<span id="cb1-58"><a href="#cb1-58"></a></span>
<span id="cb1-59"><a href="#cb1-59"></a>The analysis observes effects across different linguistic levels. KLD is applied to lexical items, using the lemma as the unit of analysis, and also to grammatical units, specifically POS trigrams. The findings indicate that peaks in KLD for lexical items, occurring around 1775-1805, correspond roughly to peaks observed in the KLD analysis of POS trigrams. Examples of POS trigrams analyzed include "NN NN IN (zenith distance of)", "VBZ JJR IN (is greater than)", "DT NN IN (the end of)", "NN NN NN (thunder and lightning)", "IN JJ NN (of dephlogisticated air)", "DT NNS IN (the effects of)", "NN NN DT (oxide of iron)", "NN NN IN (the quantity/number of)", "VBZ JJR IN (is greater than)", "NN NN IN (unite edge of)", and "IN DT JJ (for the same)". This suggests that linguistic change during this period manifested across both vocabulary and grammatical structure.</span>
<span id="cb1-60"><a href="#cb1-60"></a></span>
<span id="cb1-61"><a href="#cb1-61"></a><span class="fu">## Paradigmatic Context and Influence</span></span>
<span id="cb1-62"><a href="#cb1-62"></a></span>
<span id="cb1-63"><a href="#cb1-63"></a><span class="al">![Slide 06](images/ai-nepi_019_slide_06.jpg)</span></span>
<span id="cb1-64"><a href="#cb1-64"></a></span>
<span id="cb1-65"><a href="#cb1-65"></a>The analysis of paradigmatic context and change employs methods described by Fankhauser et al. (2017) and Bizzoni et al. (2019). This technique involves visualizing semantic space at different time periods, such as 1780, 1800, and 1840. Terms are represented as points within this space, where their position indicates semantic similarity. The visualizations provide additional details: the size of the circle representing a term indicates its relative frequency, and color is used to represent clusters of terms. Observing the shifts in term positions and clustering over time reveals semantic change, exemplified by the appearance of "oxygen" and the changing position and frequency of terms like "phlogiston" and "dephlogisticated". The corpora used for this analysis are available at corpora.ids-mannheim.de.</span>
<span id="cb1-66"><a href="#cb1-66"></a></span>
<span id="cb1-67"><a href="#cb1-67"></a>To identify *who* is leading or spreading change, the research utilizes *Cascade models*, specifically *Hawkes processes*, as detailed by Bizzoni et al. (2021). These models are applied to model the spread of influence or linguistic innovations within a network, such as a network of authors. The models enable the identification of individuals acting as "Innovators," such as Priestley, and those acting as "Early Adopters" or "Spreaders," including Pearson and Davy. The results are visualized using a heatmap that shows author influence over time. In this visualization, the color intensity represents the degree of influence, and dashed lines are used to indicate the spread of influence across different time points.</span>
<span id="cb1-68"><a href="#cb1-68"></a></span>
<span id="cb1-69"><a href="#cb1-69"></a><span class="fu">## Linguistic Realization and Communicative Perspective</span></span>
<span id="cb1-70"><a href="#cb1-70"></a></span>
<span id="cb1-71"><a href="#cb1-71"></a><span class="al">![Slide 09](images/ai-nepi_019_slide_09.jpg)</span></span>
<span id="cb1-72"><a href="#cb1-72"></a></span>
<span id="cb1-73"><a href="#cb1-73"></a>The research investigates how linguistic change is realized and why these changes occur from a communicative perspective. The approach involves analyzing change within the linguistic context using the concept of Surprisal, as introduced by Shannon (1949). The underlying principle is that the surprisal of a linguistic unit is proportional to the cognitive effort required to process it, a relationship supported by work from Hale (2001), Levy (2008), and Crocker et al. (2016). A core hypothesis is that linguistic changes occur to reduce cognitive effort and facilitate more efficient communication.</span>
<span id="cb1-74"><a href="#cb1-74"></a></span>
<span id="cb1-75"><a href="#cb1-75"></a>The analysis tracks the surprisal of different linguistic structures over time. Examples of structures examined include clausal forms like "...the oxygen (which was) consumed", prepositional phrases such as "...the consumption of oxygen...", and compound forms like "...the oxygen consumption...". The observation is that the surprisal of longer, more effortful structures, exemplified by the prepositional phrase "Prepositional consumption of oxygen", tends to decrease over time. This decrease coincides with the emergence and establishment of shorter, less effortful structures, such as the compound "Compound oxygen consumption", within the linguistic community. A correlation is observed between the decrease in surprisal for these shorter forms and an increasing number of authors adopting and using them. This process indicates that shorter encoding emerges and becomes established in the community, effectively reducing cognitive effort as reflected by lower surprisal values. This work is related to the MA thesis of Viktoria Lima-Vaz (2025) and a submission by Degaetano-Ortlieb et al. (July 2024).</span>
<span id="cb1-76"><a href="#cb1-76"></a></span>
<span id="cb1-77"><a href="#cb1-77"></a><span class="fu">## Framework for Context and Language Dynamics</span></span>
<span id="cb1-78"><a href="#cb1-78"></a></span>
<span id="cb1-79"><a href="#cb1-79"></a><span class="al">![Slide 12](images/ai-nepi_019_slide_12.jpg)</span></span>
<span id="cb1-80"><a href="#cb1-80"></a></span>
<span id="cb1-81"><a href="#cb1-81"></a>The proposed framework for modeling context for the analysis of language variation and change is motivated by the understanding that language change is driven by shifts in social context, including evolving goals, social structures, and domain conventions. Current limitations in the field include that existing semantic change studies and KLD applications often track shifts but do not adequately model the interaction between various contextual signals. Furthermore, static network approaches are limited in their ability to capture dynamic interactions over time.</span>
<span id="cb1-82"><a href="#cb1-82"></a></span>
<span id="cb1-83"><a href="#cb1-83"></a>The proposed framework posits that context serves as a central signal for modeling language dynamics. *Graph Convolutional Networks* (*GCNs*) are proposed as one possible technological direction due to their powerful capability for modeling complex relational data. A pilot study focusing on the chemical revolution is outlined, utilizing the Royal Society Corpus (RSC) and targeting the period between the 1760s and 1820s.</span>
<span id="cb1-84"><a href="#cb1-84"></a></span>
<span id="cb1-85"><a href="#cb1-85"></a><span class="fu">### Stage I: Data Sampling</span></span>
<span id="cb1-86"><a href="#cb1-86"></a></span>
<span id="cb1-87"><a href="#cb1-87"></a>This stage employs methods such as tf-idf and KLD to identify relevant keywords within the target period. KLD is used to define words that are distinct for each period, with words contributing highly to KLD being considered relevant.</span>
<span id="cb1-88"><a href="#cb1-88"></a></span>
<span id="cb1-89"><a href="#cb1-89"></a><span class="fu">### Stage II: Network Construction</span></span>
<span id="cb1-90"><a href="#cb1-90"></a></span>
<span id="cb1-91"><a href="#cb1-91"></a>This stage aims at building word- and time-aware feature vectors. This involves using *BERT* for generating word vectors and one-hot encoding for categorical metadata such as Author, Journal, and Period. A node feature matrix is created for each 20-year period. Change in these node feature vectors is measured using KLD to assess dissimilarity across periods, resulting in a diachronic series of graphs. To manage network complexity, community detection algorithms, such as those described by Riolo &amp; Newman (2020), are used for network size definition.</span>
<span id="cb1-92"><a href="#cb1-92"></a></span>
<span id="cb1-93"><a href="#cb1-93"></a><span class="fu">### Stage III: Link Prediction</span></span>
<span id="cb1-94"><a href="#cb1-94"></a></span>
<span id="cb1-95"><a href="#cb1-95"></a>This stage seeks to predict how, when, and by whom words are used. This involves using word profiles augmented with semantic embeddings (e.g., from *BERT*), contextual metadata (e.g., author, journal, period), and grammatical information (e.g., part of speech, syntactic role). A *Transformer-GCN* model is employed, which learns patterns in these augmented profiles and predicts new links. The *GCN* component captures structural relationships within the network, while the *Transformer* attention mechanism highlights the most influential contextual features.</span>
<span id="cb1-96"><a href="#cb1-96"></a></span>
<span id="cb1-97"><a href="#cb1-97"></a><span class="fu">### Stage IV: Entity Alignment</span></span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a>This stage is designed to inspect and interpret the observed change. It utilizes Network Motifs, defined as small, overrepresented subgraphs that reflect meaningful interaction structures. The *Kavosh algorithm* is used, which groups isomorphic graphs to identify these motifs within networks. Entity alignment is also considered as a future application, potentially involving tasks like aligning similar graphs across different time periods (t1, t2).</span>
<span id="cb1-100"><a href="#cb1-100"></a></span>
<span id="cb1-101"><a href="#cb1-101"></a><span class="fu">## Limitations and Future Work</span></span>
<span id="cb1-102"><a href="#cb1-102"></a></span>
<span id="cb1-103"><a href="#cb1-103"></a><span class="al">![Slide 16](images/ai-nepi_019_slide_16.jpg)</span></span>
<span id="cb1-104"><a href="#cb1-104"></a></span>
<span id="cb1-105"><a href="#cb1-105"></a>The research acknowledges several limitations and outlines future perspectives. Key questions include what it truly means to computationally trace conceptual change and whether models can capture deeper epistemic shifts beyond mere linguistic drift. Another challenge is understanding how context becomes integrated into the meaning represented by language models, and whether metadata should be treated as external noise or a core signal. The optimal 'unit' of language change remains a question: are shifts best observed at the level of words, concepts, grammar, or discourse patterns? The possibility of identifying recurring linguistic pathways for concept emergence and determining if new ideas follow predictable linguistic trajectories is also explored. Finally, the limits of interpretability in complex models are considered, emphasizing the need to ensure that explanations are meaningful rather than merely plausible.</span>
<span id="cb1-106"><a href="#cb1-106"></a></span>
<span id="cb1-107"><a href="#cb1-107"></a>Future perspectives include expanding the data sources beyond the Royal Society Corpus to include multilingual corpora, such as French and German journals, and incorporating other text types like monographs and letters. A significant area for future work is addressing the expression of attitude or stance in language use, particularly the challenge of differentiating between positive and negative usage of terms like "oxygen" or "dephlogisticated air" within the context of heated historical debates. Potential approaches involve analyzing differences in network structure based on usage context, such as linking terms to critiques or "dispective" adjectives.</span>
<span id="cb1-108"><a href="#cb1-108"></a></span>
<span id="cb1-109"><a href="#cb1-109"></a>Matching linguistic patterns to authors known to advocate for or against specific theories, potentially leveraging external historical knowledge from philosophy of science texts, is another avenue. Furthermore, insights from work on propaganda analysis, such as in the context of the Russian-Ukraine war, could be mapped onto historical texts to identify propagandistic strategies. The method would involve comparing network structures over time, focusing on structural features and identifying which nodes promote more edges.</span>
<span id="cb1-110"><a href="#cb1-110"></a></span>
<span id="cb1-111"><a href="#cb1-111"></a>Applying the developed methods to current era corpora, such as a quantum gravity corpus, is also a future perspective. The goal is to observe community building and changing language in real-time or near real-time. This would require establishing a protocol for structuring the data, potentially in a relational database like SQL, to facilitate its translation into a graph format. Processing the data to leverage categorical values, such as author, journal, and topics, as features within the graph structure would be necessary. Depending on the structure of the dataset, data engineering may be required.</span>
<span id="cb1-112"><a href="#cb1-112"></a></span>
<span id="cb1-113"><a href="#cb1-113"></a>Finally, Entity Alignment is identified as a future perspective, particularly for enabling multilingual or multi-corpus comparisons. This involves tasks such as aligning concepts, for example, the "oxygen" subgraph, across different datasets, such as those from English versus French journals. The method would utilize a *graph convolutional network* specifically for an entity alignment task, distinct from a link prediction task. The objective is to determine if entities are identified as the same based on their neighboring nodes and overall network structure.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>