<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.17">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Oliver Eberle">
<meta name="dcterms.date" content="2025-06-21">

<title>7&nbsp; Interpretability for LLMs: Scientific Insights, Transparency, and Applications in the Humanities – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_008.html" rel="next">
<link href="./chapter_ai-nepi_006.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-c2d8198b7f72dec16de60f0cb3fab69f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a0afd4a9b901cc50d8ed64d4ec5e2aec.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_007.html"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Scientific Insights, Transparency, and Applications in the Humanities</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Large Language Models for History, Philosophy and Sociology of Science - Workshop Proceedings</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI-assisted Methods for History and Philosophy of Science: Workshop Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Investigating the transdiciplinary application of model templates through projective methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Scientific Insights, Transparency, and Applications in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Scientific Reasoning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers - the mixed use of LLM’s and semantic artifacts to support the understanding of science dynamics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Applying Retrieval-Augmented Generation to Philosophical Research: A Case Study and Methodological Insights</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural Pursuit: The Case of Quantum Gravity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Making Transformer-Based LLMs Time-Aware: A Proof of Concept</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Towards Interpretable Models: Bridging Traditional and Deep Learning Methods for Tracing Linguistic Change in English Scientific Writing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">From Source to Structure – Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#presentation-structure" id="toc-presentation-structure" class="nav-link" data-scroll-target="#presentation-structure"><span class="header-section-number">7.1</span> Presentation Structure</a></li>
  <li><a href="#foundations-of-explainable-ai" id="toc-foundations-of-explainable-ai" class="nav-link" data-scroll-target="#foundations-of-explainable-ai"><span class="header-section-number">7.2</span> Foundations of Explainable AI</a></li>
  <li><a href="#the-black-box-problem" id="toc-the-black-box-problem" class="nav-link" data-scroll-target="#the-black-box-problem"><span class="header-section-number">7.3</span> The ‘Black Box’ Problem</a></li>
  <li><a href="#the-advent-of-generative-ai" id="toc-the-advent-of-generative-ai" class="nav-link" data-scroll-target="#the-advent-of-generative-ai"><span class="header-section-number">7.4</span> The Advent of Generative AI</a></li>
  <li><a href="#illustrative-model-failures" id="toc-illustrative-model-failures" class="nav-link" data-scroll-target="#illustrative-model-failures"><span class="header-section-number">7.5</span> Illustrative Model Failures</a></li>
  <li><a href="#a-new-paradigm-structured-interpretability" id="toc-a-new-paradigm-structured-interpretability" class="nav-link" data-scroll-target="#a-new-paradigm-structured-interpretability"><span class="header-section-number">7.6</span> A New Paradigm: Structured Interpretability</a></li>
  <li><a href="#first-and-second-order-explanations" id="toc-first-and-second-order-explanations" class="nav-link" data-scroll-target="#first-and-second-order-explanations"><span class="header-section-number">7.7</span> First and Second-Order Explanations</a></li>
  <li><a href="#higher-order-interactions-in-graphs" id="toc-higher-order-interactions-in-graphs" class="nav-link" data-scroll-target="#higher-order-interactions-in-graphs"><span class="header-section-number">7.8</span> Higher-Order Interactions in Graphs</a></li>
  <li><a href="#detecting-bias-in-language-models" id="toc-detecting-bias-in-language-models" class="nav-link" data-scroll-target="#detecting-bias-in-language-models"><span class="header-section-number">7.9</span> Detecting Bias in Language Models</a></li>
  <li><a href="#long-range-dependencies-in-summarisation" id="toc-long-range-dependencies-in-summarisation" class="nav-link" data-scroll-target="#long-range-dependencies-in-summarisation"><span class="header-section-number">7.10</span> Long-Range Dependencies in Summarisation</a></li>
  <li><a href="#explaining-sentence-similarity" id="toc-explaining-sentence-similarity" class="nav-link" data-scroll-target="#explaining-sentence-similarity"><span class="header-section-number">7.11</span> Explaining Sentence Similarity</a></li>
  <li><a href="#modelling-complex-language" id="toc-modelling-complex-language" class="nav-link" data-scroll-target="#modelling-complex-language"><span class="header-section-number">7.12</span> Modelling Complex Language</a></li>
  <li><a href="#case-study-defining-historical-instruments" id="toc-case-study-defining-historical-instruments" class="nav-link" data-scroll-target="#case-study-defining-historical-instruments"><span class="header-section-number">7.13</span> Case Study: Defining Historical Instruments</a></li>
  <li><a href="#case-study-the-sphera-corpus" id="toc-case-study-the-sphera-corpus" class="nav-link" data-scroll-target="#case-study-the-sphera-corpus"><span class="header-section-number">7.14</span> Case Study: The Sphera Corpus</a></li>
  <li><a href="#the-xai-historian-workflow" id="toc-the-xai-historian-workflow" class="nav-link" data-scroll-target="#the-xai-historian-workflow"><span class="header-section-number">7.15</span> The ‘XAI-Historian’ Workflow</a></li>
  <li><a href="#case-study-print-diversity-and-innovation" id="toc-case-study-print-diversity-and-innovation" class="nav-link" data-scroll-target="#case-study-print-diversity-and-innovation"><span class="header-section-number">7.16</span> Case Study: Print Diversity and Innovation</a></li>
  <li><a href="#conclusion" id="toc-conclusion" class="nav-link" data-scroll-target="#conclusion"><span class="header-section-number">7.17</span> Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Scientific Insights, Transparency, and Applications in the Humanities</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Oliver Eberle <a href="mailto:oliver.eberle@tu-berlin.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            BIFOLD / TU Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter presents a dual-pronged investigation into artificial intelligence. The authors first explore the evolution of explainable AI (XAI), before demonstrating its application in generating novel scientific insights within the humanities.</p>
<p>The initial part charts the progression from first-generation XAI, which relied upon heatmap-based feature attributions for simple classification models, towards a more sophisticated paradigm the authors term ‘XAI 2.0’. This advanced approach focuses on structured interpretability, analysing second-order (pairwise) and higher-order (graph-based) feature interactions. Such methods are essential for understanding the complex mechanisms of modern foundation models, including Large Language Models (LLMs). The authors demonstrate how these techniques can uncover biases in sentiment prediction, analyse how LLMs handle long-range dependencies, and reveal the surprisingly simple heuristics, such as noun matching, that models employ for tasks like sentence similarity.</p>
<p>The second part transitions to a series of case studies applying these AI techniques to historical research. One project involves classifying a corpus of early modern mathematical instruments, using heatmaps to derive visual definitions based on features like fine-grained scales. A more extensive project, the ‘XAI-Historian’, analyses the Sphera corpus of numerical tables from 1472–1650. By developing a specialised model for bigram detection and using XAI to verify its logic, the team could analyse historical publishing patterns at scale. A key finding emerged from a cluster entropy analysis, which identified Wittenberg as a centre of low print diversity—a data-driven discovery that corroborated historical knowledge about the political control exerted over its publishing curriculum by Protestant reformers.</p>
</section>
<section id="presentation-structure" class="level2" data-number="7.1">
<h2 data-number="7.1" class="anchored" data-anchor-id="presentation-structure"><span class="header-section-number">7.1</span> Presentation Structure</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>The discourse is structured into two principal sections. The first part addresses the field of Explainable AI and its role in understanding the inner workings of Large Language Models. Subsequently, the second part demonstrates how these AI-driven methods can yield new scientific insights within the humanities.</p>
</section>
<section id="foundations-of-explainable-ai" class="level2" data-number="7.2">
<h2 data-number="7.2" class="anchored" data-anchor-id="foundations-of-explainable-ai"><span class="header-section-number">7.2</span> Foundations of Explainable AI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The initial exploration into explainable AI, which may be termed XAI 1.0, centres on the concept of feature attribution. This approach seeks to establish a clear definition of what constitutes a model explanation within the machine learning community, providing a foundation for the more complex methods of interpretability that followed.</p>
</section>
<section id="the-black-box-problem" class="level2" data-number="7.3">
<h2 data-number="7.3" class="anchored" data-anchor-id="the-black-box-problem"><span class="header-section-number">7.3</span> The ‘Black Box’ Problem</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>Historically, machine learning research focused predominantly on visual data, creating powerful but opaque ‘black box’ systems. These models could, for instance, correctly classify an object in an image but offered no insight into the basis for their decision. The field of explainable AI emerged to address this opacity, dedicating a decade of research to methods that trace a model’s predictions back to its inputs. A foundational technique is the heatmap, which visually highlights the input pixels most influential in a classification, thereby showing <em>why</em> a model recognised a rooster.</p>
<p>The imperative for such explainability is fourfold. It enables scholars and engineers to:</p>
<ul>
<li><p>Verify that a model is functioning reasonably.</p></li>
<li><p>Diagnose and correct its errors.</p></li>
<li><p>Learn from the surprising or novel solutions that models can uncover.</p></li>
<li><p>Ensure compliance with emerging regulatory frameworks, including the European AI Act.</p></li>
</ul>
</section>
<section id="the-advent-of-generative-ai" class="level2" data-number="7.4">
<h2 data-number="7.4" class="anchored" data-anchor-id="the-advent-of-generative-ai"><span class="header-section-number">7.4</span> The Advent of Generative AI</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The landscape of AI has shifted dramatically from the standard classification models prevalent five years ago to the current era of Generative AI. Unlike their predecessors, today’s foundation models are multi-task systems. They can classify content, retrieve similar images, generate entirely new images, and answer questions across a vast range of topics.</p>
<p>This expanded capability introduces a significant challenge: grounding a model’s output, such as a generated answer, in specific input data becomes far more complex. Consequently, research must now advance beyond simple heatmap representations. The focus is shifting towards analysing feature interactions and adopting more mechanistic perspectives to understand these models, which effectively act as ‘world models’ that encode societal knowledge and patterns of textual evolution.</p>
</section>
<section id="illustrative-model-failures" class="level2" data-number="7.5">
<h2 data-number="7.5" class="anchored" data-anchor-id="illustrative-model-failures"><span class="header-section-number">7.5</span> Illustrative Model Failures</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>AI models are prone to making surprising and revealing errors. One well-known example involves an object classifier that incorrectly bases its identification of a boat on the surrounding water; the model learns this correlation because the water’s texture is a simpler feature to detect than the boat itself.</p>
<p>Another example highlights failures in multi-step planning. When a standard LLM, such as a <em>Llama 3</em> model, is prompted to solve the Tower of Hanoi puzzle, it immediately violates the game’s rules by attempting to move the largest, inaccessible disk. This demonstrates a fundamental misunderstanding of the problem’s physical constraints.</p>
</section>
<section id="a-new-paradigm-structured-interpretability" class="level2" data-number="7.6">
<h2 data-number="7.6" class="anchored" data-anchor-id="a-new-paradigm-structured-interpretability"><span class="header-section-number">7.6</span> A New Paradigm: Structured Interpretability</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>To address the limitations of earlier methods, the authors’ work introduces a new paradigm termed ‘XAI 2.0’, which champions the concept of structured interpretability. This approach aims to move beyond simple heatmap visualisations to uncover more complex, relational patterns within a model’s decision-making process. The need for such methods is underscored by failures in standard models, like the <em>Llama 3</em> variant that struggled with the Tower of Hanoi, although more recent reasoning models may show improvement.</p>
</section>
<section id="first-and-second-order-explanations" class="level2" data-number="7.7">
<h2 data-number="7.7" class="anchored" data-anchor-id="first-and-second-order-explanations"><span class="header-section-number">7.7</span> First and Second-Order Explanations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>Structured interpretability distinguishes between different orders of explanation. First-order explanations, akin to heatmaps, are useful for simple classifiers. For instance, when the authors trained a model to classify historical tables, these explanations verified that the model correctly focused on numerical content to make its predictions.</p>
<p>Second-order explanations, however, analyse pairwise relationships between features. This becomes crucial for understanding tasks like similarity measurement. When explaining the similarity score between two images, an interaction-based method reveals the specific features that correspond. In an example with two identical tables, this approach correctly highlights the interactions between matching digits, confirming the model’s logic.</p>
</section>
<section id="higher-order-interactions-in-graphs" class="level2" data-number="7.8">
<h2 data-number="7.8" class="anchored" data-anchor-id="higher-order-interactions-in-graphs"><span class="header-section-number">7.8</span> Higher-Order Interactions in Graphs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>More recent work by the team extends this analysis to graph structures, such as citation networks or relationships between entities like books. In these contexts, higher-order interactions provide more meaningful explanations than simpler methods.</p>
<p>For models trained on graph classification tasks, explanations manifest as ‘feature walks’ or subgraphs—sets of interconnected features that become relevant only when considered collectively. The ultimate goal of this research is to derive more complex insights into model behaviour and progress towards a circuit-level understanding of their internal mechanisms.</p>
</section>
<section id="detecting-bias-in-language-models" class="level2" data-number="7.9">
<h2 data-number="7.9" class="anchored" data-anchor-id="detecting-bias-in-language-models"><span class="header-section-number">7.9</span> Detecting Bias in Language Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Applying first-order attributions to language models reveals their underlying biases. In a standard sentiment prediction task using a movie review dataset, the authors employed a heatmap-style method adapted for <em>Transformers</em>. The analysis showed that the model’s predictions were skewed by the names present in the text.</p>
<p>A review was more likely to receive a positive classification if it contained male, Western names like ‘Lee’ or ‘Raphael’. Conversely, the presence of foreign-sounding names like ‘Saddam’ or ‘Chan’ correlated with a negative score. This work demonstrates that explainable AI is a powerful tool for detecting such fine-grained, and often unintended, biases within language models.</p>
</section>
<section id="long-range-dependencies-in-summarisation" class="level2" data-number="7.10">
<h2 data-number="7.10" class="anchored" data-anchor-id="long-range-dependencies-in-summarisation"><span class="header-section-number">7.10</span> Long-Range Dependencies in Summarisation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>The authors investigated how LLMs handle long-range dependencies when summarising extensive texts, such as Wikipedia articles, within an 8,000-token context window. By tracing the generated summary back to its sources in the input, they sought to determine if the models effectively use information from the entire document.</p>
<p>Their analysis revealed a strong recency bias: the model predominantly focuses on information from the latter parts of the context. Although it can access information from the beginning of the text, it is significantly less likely to do so, as shown by a logarithmic scale of attribution counts. This finding implies that LLM-generated summaries are not balanced representations of the source material but are skewed towards content presented closer to the end of the prompt.</p>
</section>
<section id="explaining-sentence-similarity" class="level2" data-number="7.11">
<h2 data-number="7.11" class="anchored" data-anchor-id="explaining-sentence-similarity"><span class="header-section-number">7.11</span> Explaining Sentence Similarity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>To understand how models compute sentence similarity, the team applied second-order explanations to a standard pretrained model like <em>Sentence-BERT</em>. Given two sentences, the method generates interaction scores between their tokens to reveal the basis for the calculated similarity score.</p>
<p>The analysis of a toy example (‘A cat I really like’ and ‘It is a great cat’) and other pairs revealed that the models do not employ complex semantic reasoning. Instead, they rely on surprisingly simplistic heuristics, operating like a ‘bag-of-tokens’ system. The primary strategy is simple noun matching, supplemented by noun-verb pairings and interactions with separator tokens. This suggests that in the process of compressing vast amounts of information, these models default to simple, and perhaps not immediately obvious, decision-making strategies.</p>
</section>
<section id="modelling-complex-language" class="level2" data-number="7.12">
<h2 data-number="7.12" class="anchored" data-anchor-id="modelling-complex-language"><span class="header-section-number">7.12</span> Modelling Complex Language</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_19.png" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>Graph Neural Networks (GNNs) can be conceptually framed as LLMs, as their message-passing mechanism is analogous to an LLM’s attention network. This perspective allows for the application of higher-order explanation methods to complex language phenomena.</p>
<p>Standard first-order, or bag-of-words, explanations often fail in this regard. For instance, in the sentence ‘First, I didn’t like the boring pictures’, such a method would incorrectly assign a positive sentiment due to the word ‘like’, completely missing the negation. In contrast, a higher-order explanation method successfully captures the complex structure. It correctly assigns a negative value to the entire negated phrase and properly interprets the sentence’s overall sentiment hierarchy, demonstrating a more nuanced understanding of language.</p>
</section>
<section id="case-study-defining-historical-instruments" class="level2" data-number="7.13">
<h2 data-number="7.13" class="anchored" data-anchor-id="case-study-defining-historical-instruments"><span class="header-section-number">7.13</span> Case Study: Defining Historical Instruments</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_24.png" class="img-fluid figure-img"></p>
<figcaption>Slide 24</figcaption>
</figure>
</div>
<p>In a collaborative project with historians Matteo Valeriani and Jochen Büttner, the authors applied AI to a corpus of historical mathematical instruments. Their goal was to build a classifier that could distinguish between categories such as ‘machine’ and ‘mathematical instrument’.</p>
<p>By employing heatmap-based explanations, the team sought to extract objective ‘visual definitions’ that the model used for its classifications. This process necessitated close interaction with the domain experts to validate the meaningfulness of the AI-derived criteria. A key finding was that the model correctly identified fine-grained scales as a highly relevant and defining feature for the ‘mathematical instrument’ class.</p>
</section>
<section id="case-study-the-sphera-corpus" class="level2" data-number="7.14">
<h2 data-number="7.14" class="anchored" data-anchor-id="case-study-the-sphera-corpus"><span class="header-section-number">7.14</span> Case Study: The Sphera Corpus</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_25.png" class="img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
<p>The team’s largest collaborative project with historians from the Bifold institute involved the Sphera corpus, a collection of early modern texts published between 1472 and 1650. The central challenge, brought forward by Matteo Valeriani and Jochen Büttner, was to analyse the corpus’s vast collection of numerical tables.</p>
<p>Despite initial assessments that the data would be extremely difficult to process computationally, the research goal was to develop an automated method for matching tables based on semantic similarity—a task that had been impossible to conduct at scale using traditional methods.</p>
</section>
<section id="the-xai-historian-workflow" class="level2" data-number="7.15">
<h2 data-number="7.15" class="anchored" data-anchor-id="the-xai-historian-workflow"><span class="header-section-number">7.15</span> The ‘XAI-Historian’ Workflow</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_26.png" class="img-fluid figure-img"></p>
<figcaption>Slide 26</figcaption>
</figure>
</div>
<p>The authors developed a workflow to support what they term the ‘XAI-Historian’—a scholar who leverages AI and its explanations for data-driven hypothesis generation. Rather than applying a large, general foundation model, which performs poorly on such specialised, out-of-domain data, the team engineered a small, custom model.</p>
<p>This model was trained specifically to detect numerical bigrams within the historical tables. Crucially, they used explainable AI to verify that the model functioned as intended. By confirming that it correctly identified identical bigrams across different tables, they could trust its outputs and proceed with large-scale analysis.</p>
</section>
<section id="case-study-print-diversity-and-innovation" class="level2" data-number="7.16">
<h2 data-number="7.16" class="anchored" data-anchor-id="case-study-print-diversity-and-innovation"><span class="header-section-number">7.16</span> Case Study: Print Diversity and Innovation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_28.png" class="img-fluid figure-img"></p>
<figcaption>Slide 28</figcaption>
</figure>
</div>
<p>With a trusted model in place, the team conducted case studies, including an analysis of innovation diffusion using cluster entropy. They analysed the publishing output of various European cities by clustering the representations of their printed tables. By calculating the entropy of each city’s output, they could quantify its diversity; low entropy signified a programme focused on reprinting, whilst high entropy indicated a more varied and innovative output.</p>
<p>The analysis yielded two notable low-entropy cases. It confirmed Frankfurt am Main’s known status as a reprinting hub. More significantly, it uncovered a historical anomaly in Wittenberg. The model detected an unusually low diversity in its print programme, a finding that perfectly matched historical knowledge about the active political control exerted by Protestant reformers, who strictly managed the city’s curriculum.</p>
</section>
<section id="conclusion" class="level2" data-number="7.17">
<h2 data-number="7.17" class="anchored" data-anchor-id="conclusion"><span class="header-section-number">7.17</span> Conclusion</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_007_slide_33.png" class="img-fluid figure-img"></p>
<figcaption>Slide 33</figcaption>
</figure>
</div>
<p>In conclusion, this research demonstrates the successful application of bespoke AI and explainability methods to complex historical data. The work yields verifiable insights that augment traditional scholarship. Whilst the presentation concluded before detailing future challenges related to data scarcity and model capabilities, the authors’ work establishes a strong foundation for a new, computationally-assisted approach to humanities research.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_006.html" class="pagination-link" aria-label="Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_008.html" class="pagination-link" aria-label="Modeling Scientific Reasoning">
        <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Scientific Reasoning</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>