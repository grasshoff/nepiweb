<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gerd Graßhoff">
<meta name="dcterms.date" content="2025-01-01">

<title>8&nbsp; Modeling Science: LLM for the History, Philosophy and Sociology of Science – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_009.html" rel="next">
<link href="./chapter_ai-nepi_007.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-fe5eeb5af71a333b155c360431d06b9a.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-e463572c889c87c7eefd27e1777fa793.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>html{ scroll-behavior: smooth; }</style>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="8&nbsp; Modeling Science: LLM for the History, Philosophy and Sociology of Science – AI-NEPI Conference Proceedings - Enhanced Edition">
<meta property="og:description" content="The presentation addresses the limitations of current Large Language Models (LLMs) for scholarly inquiry, particularly in the history, philosophy, and sociology of science (HPSS). It identifies key missing capabilities in LLMs, including the ability to counter hallucination, understand meaning beyond embedding vectors, formulate justified true statements, avoid repeating unreliable media content, seek best justification, and plan scientific inquiry. The core proposed solution is the conce…">
<meta property="og:image" content="images/ai-nepi_008_slide_01.jpg">
<meta property="og:site_name" content="AI-NEPI Conference Proceedings - Enhanced Edition">
<meta name="twitter:title" content="8&nbsp; Modeling Science: LLM for the History, Philosophy and Sociology of Science – AI-NEPI Conference Proceedings - Enhanced Edition">
<meta name="twitter:description" content="The presentation addresses the limitations of current Large Language Models (LLMs) for scholarly inquiry, particularly in the history, philosophy, and sociology of science (HPSS). It identifies key missing capabilities in LLMs, including the ability to counter hallucination, understand meaning beyond embedding vectors, formulate justified true statements, avoid repeating unreliable media content, seek best justification, and plan scientific inquiry. The core proposed solution is the conce…">
<meta name="twitter:image" content="images/ai-nepi_008_slide_01.jpg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_008.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">A Primer on Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">OpenAlex Mapper: Transdisciplinary Investigations</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Computational HPSS: Tracing Ancient Wisdom’s Influence with VERITRACE</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and Scientific Insights in Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="3">
    <h2 id="toc-title">Table of Contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview"><span class="header-section-number">8.1</span> Overview</a></li>
  <li><a href="#llm-evolution-and-current-state" id="toc-llm-evolution-and-current-state" class="nav-link" data-scroll-target="#llm-evolution-and-current-state"><span class="header-section-number">8.2</span> LLM Evolution and Current State</a></li>
  <li><a href="#missing-capabilities-in-current-llms" id="toc-missing-capabilities-in-current-llms" class="nav-link" data-scroll-target="#missing-capabilities-in-current-llms"><span class="header-section-number">8.3</span> Missing Capabilities in Current LLMs</a></li>
  <li><a href="#validation-and-computational-epistemology" id="toc-validation-and-computational-epistemology" class="nav-link" data-scroll-target="#validation-and-computational-epistemology"><span class="header-section-number">8.4</span> Validation and Computational Epistemology</a></li>
  <li><a href="#working-environment-and-inquiry-example" id="toc-working-environment-and-inquiry-example" class="nav-link" data-scroll-target="#working-environment-and-inquiry-example"><span class="header-section-number">8.5</span> Working Environment and Inquiry Example</a></li>
  <li><a href="#scholarium-curated-scholarly-evidence" id="toc-scholarium-curated-scholarly-evidence" class="nav-link" data-scroll-target="#scholarium-curated-scholarly-evidence"><span class="header-section-number">8.6</span> Scholarium: Curated Scholarly Evidence</a></li>
  <li><a href="#scholarium-registry-instead-of-embeddings" id="toc-scholarium-registry-instead-of-embeddings" class="nav-link" data-scroll-target="#scholarium-registry-instead-of-embeddings"><span class="header-section-number">8.7</span> Scholarium: Registry instead of Embeddings</a></li>
  <li><a href="#user-interface-ai-cockpit" id="toc-user-interface-ai-cockpit" class="nav-link" data-scroll-target="#user-interface-ai-cockpit"><span class="header-section-number">8.8</span> User Interface: AI Cockpit</a></li>
  <li><a href="#fair-infrastructure" id="toc-fair-infrastructure" class="nav-link" data-scroll-target="#fair-infrastructure"><span class="header-section-number">8.9</span> FAIR Infrastructure</a></li>
  <li><a href="#technical-support-opensciencetechnology" id="toc-technical-support-opensciencetechnology" class="nav-link" data-scroll-target="#technical-support-opensciencetechnology"><span class="header-section-number">8.10</span> Technical Support: OpenScienceTechnology</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<div class="quarto-title-block"><div><h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></h1><button type="button" class="btn code-tools-button" id="quarto-code-tools-source"><i class="bi"></i> Show code</button></div></div>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Gerd Graßhoff </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            AI-NEPI Conference Participant
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    The presentation addresses the limitations of current Large Language Models (LLMs) for scholarly inquiry, particularly in the history, philosophy, and sociology of science (HPSS). It identifies key missing capabilities in LLMs, including the ability to counter hallucination, understand meaning beyond embedding vectors, formulate justified true statements, avoid repeating unreliable media content, seek best justification, and plan scientific inquiry. The core proposed solution is the conce…
  </div>
</div>


</header>


<section id="overview" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">8.1</span> Overview</h2>
<p>The presentation addresses the limitations of current Large Language Models (LLMs) for scholarly inquiry, particularly in the history, philosophy, and sociology of science (HPSS). It identifies key missing capabilities in LLMs, including the ability to counter hallucination, understand meaning beyond embedding vectors, formulate justified true statements, avoid repeating unreliable media content, seek best justification, and plan scientific inquiry.</p>
<p>The core proposed solution is the concept of “Validation is all you need,” which involves providing reasons, arguments, and evidence for propositions and actions. This capability is framed within a new proposed discipline called Computational Epistemology, requiring epistemic agency to identify propositions, analyze argumentation, and understand historical actors’ intentions, plans, and actions based on documented traces.</p>
<p>A comprehensive research infrastructure is presented to achieve these goals, comprising five key components:</p>
<ul>
<li><p><em>Scholarium</em> (Evidence): Curated scholarly sources validated by editorial boards, including extensive historical collections like the <em>Opera Omnia Euler</em>, <em>Kepler Gesammelte Werke</em>, and <em>Brahe Opera Omnia</em>.</p></li>
<li><p><em>Scholarium</em> (Registry): A structured database serving as an alternative to embedding-based approaches, containing detailed, historically validated content items such as personal chronologies, communication acts, statements, arguments, and records of the use of language, tools, methods, data, and sources. Access is provided via an AI API and the <em>Model Context Protocol</em> (<em>MCP</em>) API.</p></li>
<li><p>User Interface (<em>AI Cockpit</em>): A working environment, specifically the <em>LettreAI</em> platform on <em>Cursor</em>, integrating multimodal LLMs (<em>Claude</em>, <em>Gemini</em>, <em>Llama</em>, including <em>Gemini 2.5</em> for multimodal capability) and featuring a specialized AI agent named “<em>Bernoulli</em>” for historical queries.</p></li>
<li><p><em>FAIR Infrastructure</em>: Utilizing <em>Zenodo</em>, hosted by CERN, for long-term storage and publication of data, ensuring Findability, Accessibility, Interoperability, and Reusability.</p></li>
<li><p>Technical Support: Provided by the startup <em>OpenScienceTechnology</em>, focusing on running the infrastructure, including an <em>MCP API Server</em>, and adhering to principles of Open Source, Open Access, Open Data, and Open Collaboration to standardize AI access to knowledge.</p></li>
</ul>
<p>The system aims to provide validated, complete answers to complex historical queries by leveraging curated data and instructing LLMs with explicit reasoning rules formulated in natural language. This approach contrasts with reliance solely on unstructured text and embedding vectors, which are deemed insufficient for achieving the required level of justification and completeness for scholarly historical research. The infrastructure is designed to maintain scholarly expertise and ensure the long-term preservation and accessibility of valuable historical data.</p>
</section>
<section id="llm-evolution-and-current-state" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="llm-evolution-and-current-state"><span class="header-section-number">8.2</span> LLM Evolution and Current State</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Large Language Models (LLMs) have undergone rapid evolution. The initial focus was captured by the phrase “Attention is all you need.” This capability was subsequently supplemented by the requirement for “Context is all you need,” necessitating larger context windows and methods such as Retrieval Augmented Generation (RAG).</p>
<p>The latest models now propose that “Thinking is all you need” is also required, focusing on reasoning capabilities, potentially with or without an explicit plan. This represents the current state of LLMs, integrating attention, context handling, and nascent reasoning abilities.</p>
</section>
<section id="missing-capabilities-in-current-llms" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="missing-capabilities-in-current-llms"><span class="header-section-number">8.3</span> Missing Capabilities in Current LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Current LLMs exhibit several critical missing capabilities essential for reliable scholarly work. A significant problem is the lack of an inherent mechanism or “opponent” to effectively counter hallucination, which is the generation of false or nonsensical information.</p>
<p>Furthermore, embedding vectors, a common representation method, are fundamentally not equivalent to the meanings of expressions. LLMs tend to formulate responses that may sound plausible or good but are factually false. They also frequently repeat content sourced from internet media without sufficient validation, treating it as knowledge.</p>
<p>Current models lack the ability to actively seek out and prioritize what is best justified based on evidence or reasoning. Finally, they are unable to formulate effective plans for conducting scientific inquiry. These identified capabilities are absent in existing LLM models, and it is asserted that current technologies offer no realistic prospect of achieving these missing goals.</p>
</section>
<section id="validation-and-computational-epistemology" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="validation-and-computational-epistemology"><span class="header-section-number">8.4</span> Validation and Computational Epistemology</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>A critical requirement identified for advancing LLM capabilities in scholarly domains is validation, summarized as “Validation is all you need.” Validation is defined as the process of providing explicit reasons, arguments, and evidence that support or oppose the truth of a given proposition. It also involves providing reasons for or against the pursuit of specific actions.</p>
<p>To address this fundamental gap in current AI, a new discipline is proposed: Computational Epistemology. This field focuses on developing the methods and methodologies necessary to implement computational validation processes.</p>
<p>Achieving validation requires epistemic agency, which encompasses several key abilities. These include the capacity to identify propositions, which goes beyond merely processing sentences; the ability to analyze and understand argumentation structures within texts and sources; and the capability to identify the intentions, plans, and actions of historical persons as documented and traced in historical documents.</p>
</section>
<section id="working-environment-and-inquiry-example" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="working-environment-and-inquiry-example"><span class="header-section-number">8.5</span> Working Environment and Inquiry Example</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>A working environment designed for validated historical inquiry is demonstrated through a screenshot of a web browser interface. The interface features a PDF viewer on the left, displaying a historical source document (<em>Manger1789.pdf</em>), specifically page 7 of 281, containing old German text related to construction under King Friedrich Wilhelm II.</p>
<p>On the right side, a dark-themed panel titled “Personen und Aufgaben in der Bibliothek” houses the search query input and results display areas. The example historical problem addressed is the long-standing dispute among historians of science regarding the involvement and potential responsibility of the mathematician Leonard Euler in the significant failure of the Sanssouci castle water fountain construction in the 18th century. The goal of the inquiry within this environment is to obtain a validated, reliable, and factually correct answer grounded in proven evidence, moving beyond mere hearsay.</p>
<p>An example query formulated in German is “<em>Rekonstruiere welche Personen an der Wasserfontaine welche Arbeiten ausführten</em>,” which translates to “Reconstruct which persons performed which work on the water fountain.” The system provides validated results in a numbered list format. For this specific query, the results identify the key individuals involved: Nahl, a sculptor, who created the drawings and small models and received 200 Thaler; Benkert and Heymüller, who took on the task of producing the models in the required size under a contract dated June 6, 1746, and were paid 1,970 Thaler; and Giese, who was responsible for casting the figures from lead over the core pieces, processing approximately 600 Zentner of lead, and received 6,000 Thaler.</p>
<p>The output references a specific XML file, <em>Manger1789_p81-91.xml</em>. The underlying platform for this working environment is the <em>Cursor</em> environment, which allows the use of AI agents. The specific agent employed for these historical inquiries is named “<em>Bernoulli</em>.” A key challenge highlighted is that obtaining such validated answers requires more than simply reading a single PDF source; it necessitates the ability to search across <em>all</em> available sources, a task for which standard indexing and token-based approaches are deemed insufficient.</p>
</section>
<section id="scholarium-curated-scholarly-evidence" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="scholarium-curated-scholarly-evidence"><span class="header-section-number">8.6</span> Scholarium: Curated Scholarly Evidence</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_08.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>The first key component of the infrastructure is the <em>Scholarium</em> for Evidence. This component relies on the oversight of a Curated Scholarly Editorial Board, ensuring the scholarly reliability of the sources.</p>
<p>Examples of these foundational curated sources include the <em>Opera Omnia Euler</em>, a monumental collection comprising 86 volumes of Euler’s work, which underwent scholarly editing for approximately 120 years by various scholars and was completed two years prior. This comprehensive edition includes all of Euler’s letters and his 866 publications. Complementary scholarly reliable sources integrated into this component include the <em>Kepler Gesammelte Werke</em> and the <em>Brahe Opera Omnia</em>.</p>
</section>
<section id="scholarium-registry-instead-of-embeddings" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="scholarium-registry-instead-of-embeddings"><span class="header-section-number">8.7</span> Scholarium: Registry instead of Embeddings</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The second key component is the <em>Scholarium</em> as a Registry, which serves as a novel substitution for conventional embedding-based approaches. This component is a curated database containing a very detailed inventory of content items representing historically proven activities, all rigorously validated by sources.</p>
<p>The types of content recorded include personal actions, various communication acts such as letters, publications, and reports, as well as statements, implications, arguments, and inquiries. The registry also meticulously documents the use of language, terminology, and concepts by historical figures, along with their use of concepts, relations, models, methods, tools, devices, data, information, evidence, and sources. Access to this detailed and validated historical record is provided through both a dedicated AI API and the <em>Model Context Protocol</em> (<em>MCP</em>) API.</p>
</section>
<section id="user-interface-ai-cockpit" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="user-interface-ai-cockpit"><span class="header-section-number">8.8</span> User Interface: AI Cockpit</h2>
<p>The user interface component, referred to as the <em>AI Cockpit</em>, operates on the <em>LettreAI</em> platform within the <em>Cursor</em> environment. This interface integrates multiple accessible multimodal LLM models, including <em>Claude</em>, <em>Gemini</em>, and <em>Llama</em>.</p>
<p>The system leverages the capabilities of multimodal models, specifically mentioning <em>Gemini 2.5</em>, which can combine information from both text and images, a feature deemed beneficial for solving the requirements of the historical inquiry tasks.</p>
</section>
<section id="fair-infrastructure" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="fair-infrastructure"><span class="header-section-number">8.9</span> FAIR Infrastructure</h2>
<p>A crucial component is the <em>FAIR Infrastructure</em>, designed for the long-term storage and publication of the project’s data while adhering to the FAIR principles (Findability, Accessibility, Interoperability, and Reusability).</p>
<p>The specific tool utilized for this purpose is <em>Zenodo</em>, which is hosted by CERN in Geneva. <em>Zenodo</em> provides the necessary capabilities to host the project’s data reliably for many years.</p>
</section>
<section id="technical-support-opensciencetechnology" class="level2" data-number="8.10">
<h2 data-number="8.10" class="anchored" data-anchor-id="technical-support-opensciencetechnology"><span class="header-section-number">8.10</span> Technical Support: OpenScienceTechnology</h2>
<p>Technical support for the infrastructure is provided by the startup <em>OpenScienceTechnology</em>. This entity is responsible for running the system’s infrastructure and specifically provides an <em>MCP API Server</em>.</p>
<p>The technical support operates under principles of Open Source, Open Access, Open Data, and Open Collaboration. The <em>MCP API Server</em> plays a key role in attempting to standardize AI access APIs to knowledge on a worldwide scale through a standardized interface, facilitating open collaboration.</p>


<!-- -->

</section>

</main> <!-- /main -->
<script>
document.addEventListener('DOMContentLoaded', function() {
  // Create burger menu button
  const toggleButton = document.createElement('button');
  toggleButton.className = 'sidebar-toggle';
  toggleButton.setAttribute('aria-label', 'Toggle sidebar');
  toggleButton.innerHTML = `
    <div class="burger-icon">
      <span></span>
      <span></span>
      <span></span>
    </div>
  `;
  
  // Create backdrop for mobile
  const backdrop = document.createElement('div');
  backdrop.className = 'sidebar-backdrop';
  
  // Add elements to page
  document.body.appendChild(toggleButton);
  document.body.appendChild(backdrop);
  
  // Get sidebar and main content elements
  const sidebar = document.querySelector('.sidebar') || 
                 document.querySelector('.quarto-sidebar') || 
                 document.querySelector('.sidebar-navigation');
  const mainContent = document.querySelector('main') || 
                     document.querySelector('.main-content') || 
                     document.querySelector('.quarto-container') || 
                     document.body;
  
  // State management
  let sidebarOpen = window.innerWidth > 768; // Start open on desktop, closed on mobile
  
  // Initialize sidebar state
  function initializeSidebar() {
    if (window.innerWidth <= 768) {
      sidebarOpen = false;
    }
    updateSidebarState();
  }
  
  // Update sidebar state and classes
  function updateSidebarState() {
    if (sidebar) {
      if (sidebarOpen) {
        sidebar.classList.remove('collapsed');
        toggleButton.classList.add('sidebar-open');
        mainContent.classList.add('sidebar-open');
        mainContent.classList.remove('sidebar-closed');
        if (window.innerWidth <= 768) {
          backdrop.classList.add('active');
        }
      } else {
        sidebar.classList.add('collapsed');
        toggleButton.classList.remove('sidebar-open');
        mainContent.classList.remove('sidebar-open');
        mainContent.classList.add('sidebar-closed');
        backdrop.classList.remove('active');
      }
    }
    
    // Store state in localStorage
    localStorage.setItem('sidebarOpen', sidebarOpen);
  }
  
  // Toggle sidebar
  function toggleSidebar() {
    sidebarOpen = !sidebarOpen;
    updateSidebarState();
  }
  
  // Close sidebar (for chapter links)
  function closeSidebar() {
    if (window.innerWidth <= 768) { // Only auto-close on mobile
      sidebarOpen = false;
      updateSidebarState();
    }
  }
  
  // Event listeners
  toggleButton.addEventListener('click', toggleSidebar);
  backdrop.addEventListener('click', toggleSidebar);
  
  // Auto-close sidebar when clicking chapter links
  if (sidebar) {
    const chapterLinks = sidebar.querySelectorAll('a[href]');
    chapterLinks.forEach(link => {
      link.addEventListener('click', function(e) {
        // Small delay to allow navigation to start
        setTimeout(closeSidebar, 100);
      });
    });
  }
  
  // Handle window resize
  window.addEventListener('resize', function() {
    if (window.innerWidth > 768 && !sidebarOpen) {
      sidebarOpen = true;
      updateSidebarState();
    } else if (window.innerWidth <= 768 && sidebarOpen) {
      sidebarOpen = false;
      updateSidebarState();
    }
  });
  
  // Handle escape key
  document.addEventListener('keydown', function(e) {
    if (e.key === 'Escape' && sidebarOpen && window.innerWidth <= 768) {
      closeSidebar();
    }
  });
  
  // Restore saved state from localStorage
  const savedState = localStorage.getItem('sidebarOpen');
  if (savedState !== null) {
    sidebarOpen = savedState === 'true';
  }
  
  // Initialize
  initializeSidebar();
  
  // Add keyboard navigation support
  toggleButton.addEventListener('keydown', function(e) {
    if (e.key === 'Enter' || e.key === ' ') {
      e.preventDefault();
      toggleSidebar();
    }
  });
  
  // Improve accessibility
  toggleButton.setAttribute('role', 'button');
  toggleButton.setAttribute('tabindex', '0');
  
  // Update aria-expanded attribute
  function updateAriaExpanded() {
    toggleButton.setAttribute('aria-expanded', sidebarOpen);
  }
  
  // Call updateAriaExpanded whenever sidebar state changes
  const originalUpdateSidebarState = updateSidebarState;
  updateSidebarState = function() {
    originalUpdateSidebarState();
    updateAriaExpanded();
  };
  
  updateAriaExpanded();
  
  // Ensure TOC sticky positioning works properly
  function ensureTOCSticky() {
    // Find all possible TOC elements
    const tocSelectors = [
      '#TOC',
      '.table-of-contents',
      '.quarto-sidebar-toc',
      '.toc',
      '.quarto-toc',
      'nav[role="doc-toc"]',
      '.margin-sidebar',
      '.sidebar-right',
      '.quarto-margin-sidebar',
      '.column-margin'
    ];
    
    let toc = null;
    for (const selector of tocSelectors) {
      toc = document.querySelector(selector);
      if (toc) break;
    }
    
    if (toc) {
      console.log('Found TOC element:', toc.className || toc.id);
      
      // Force sticky positioning with important styles
      toc.style.setProperty('position', 'sticky', 'important');
      toc.style.setProperty('top', '1rem', 'important');
      toc.style.setProperty('max-height', 'calc(100vh - 2rem)', 'important');
      toc.style.setProperty('overflow-y', 'auto', 'important');
      toc.style.setProperty('z-index', '100', 'important');
      
      // Ensure parent containers support sticky
      let parent = toc.parentElement;
      while (parent && parent !== document.body) {
        parent.style.setProperty('position', 'relative', 'important');
        parent.style.setProperty('height', 'auto', 'important');
        parent = parent.parentElement;
      }
      
      // Add scroll event listener to maintain visibility
      let lastScrollTop = 0;
      const scrollHandler = function() {
        const scrollTop = window.pageYOffset || document.documentElement.scrollTop;
        
        // Ensure TOC remains visible and properly positioned
        if (toc && window.innerWidth > 768) {
          toc.style.setProperty('position', 'sticky', 'important');
          toc.style.setProperty('top', '1rem', 'important');
        }
        
        lastScrollTop = scrollTop;
      };
      
      // Remove existing scroll listeners to avoid duplicates
      window.removeEventListener('scroll', scrollHandler);
      window.addEventListener('scroll', scrollHandler, { passive: true });
      
      // Also apply to any nested TOC elements
      const nestedTocs = toc.querySelectorAll('#TOC, .toc, .table-of-contents');
      nestedTocs.forEach(nestedToc => {
        nestedToc.style.setProperty('position', 'sticky', 'important');
        nestedToc.style.setProperty('top', '0', 'important');
      });
    } else {
      console.log('No TOC element found');
    }
  }
  
  // Initialize TOC sticky behavior
  ensureTOCSticky();
  
  // Re-initialize periodically to ensure it stays sticky
  setInterval(ensureTOCSticky, 2000);
  
  // Re-initialize on window resize
  window.addEventListener('resize', function() {
    setTimeout(ensureTOCSticky, 100);
  });
  
  // Re-initialize if content changes
  const observer = new MutationObserver(function(mutations) {
    mutations.forEach(function(mutation) {
      if (mutation.type === 'childList') {
        setTimeout(ensureTOCSticky, 100);
      }
    });
  });
  
  observer.observe(document.body, {
    childList: true,
    subtree: true
  });
  
  // Force re-initialization after page load
  window.addEventListener('load', function() {
    setTimeout(ensureTOCSticky, 500);
  });
});
</script>

<style>
/* Additional styles for better integration */
body {
  overflow-x: hidden;
}

.sidebar-toggle {
  -webkit-tap-highlight-color: transparent;
}

/* Ensure smooth transitions on all relevant elements */
.sidebar,
.sidebar-toggle,
.main-content,
.sidebar-backdrop {
  will-change: transform, opacity, margin;
}

/* Focus styles for accessibility */
.sidebar-toggle:focus {
  outline: 2px solid white;
  outline-offset: 2px;
}

/* Prevent text selection on burger icon */
.burger-icon {
  user-select: none;
  -webkit-user-select: none;
  -moz-user-select: none;
  -ms-user-select: none;
}
</style> 
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
    const viewSource = window.document.getElementById('quarto-view-source') ||
                       window.document.getElementById('quarto-code-tools-source');
    if (viewSource) {
      const sourceUrl = viewSource.getAttribute("data-quarto-source-url");
      viewSource.addEventListener("click", function(e) {
        if (sourceUrl) {
          // rstudio viewer pane
          if (/\bcapabilities=\b/.test(window.location)) {
            window.open(sourceUrl);
          } else {
            window.location.href = sourceUrl;
          }
        } else {
          const modal = new bootstrap.Modal(document.getElementById('quarto-embedded-source-code-modal'));
          modal.show();
        }
        return false;
      });
    }
    function toggleCodeHandler(show) {
      return function(e) {
        const detailsSrc = window.document.querySelectorAll(".cell > details > .sourceCode");
        for (let i=0; i<detailsSrc.length; i++) {
          const details = detailsSrc[i].parentElement;
          if (show) {
            details.open = true;
          } else {
            details.removeAttribute("open");
          }
        }
        const cellCodeDivs = window.document.querySelectorAll(".cell > .sourceCode");
        const fromCls = show ? "hidden" : "unhidden";
        const toCls = show ? "unhidden" : "hidden";
        for (let i=0; i<cellCodeDivs.length; i++) {
          const codeDiv = cellCodeDivs[i];
          if (codeDiv.classList.contains(fromCls)) {
            codeDiv.classList.remove(fromCls);
            codeDiv.classList.add(toCls);
          } 
        }
        return false;
      }
    }
    const hideAllCode = window.document.getElementById("quarto-hide-all-code");
    if (hideAllCode) {
      hideAllCode.addEventListener("click", toggleCodeHandler(false));
    }
    const showAllCode = window.document.getElementById("quarto-show-all-code");
    if (showAllCode) {
      showAllCode.addEventListener("click", toggleCodeHandler(true));
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
            // target, if specified
            link.setAttribute("target", "_blank");
            if (link.getAttribute("rel") === null) {
              link.setAttribute("rel", "noopener");
            }
            // default icon
            link.classList.add("external");
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_007.html" class="pagination-link" aria-label="Explainable AI and Scientific Insights in Humanities">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and Scientific Insights in Humanities</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_009.html" class="pagination-link" aria-label="The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav><div class="modal fade" id="quarto-embedded-source-code-modal" tabindex="-1" aria-labelledby="quarto-embedded-source-code-modal-label" aria-hidden="true"><div class="modal-dialog modal-dialog-scrollable"><div class="modal-content"><div class="modal-header"><h5 class="modal-title" id="quarto-embedded-source-code-modal-label">Source Code</h5><button class="btn-close" data-bs-dismiss="modal"></button></div><div class="modal-body"><div class="">
<div class="sourceCode" id="cb1" data-shortcodes="false"><pre class="sourceCode numberSource markdown number-lines code-with-copy"><code class="sourceCode markdown"><span id="cb1-1"><a href="#cb1-1"></a><span class="co">---</span></span>
<span id="cb1-2"><a href="#cb1-2"></a><span class="an">abstract:</span><span class="co"> "\n      The presentation addresses the limitations of current Large Language\</span></span>
<span id="cb1-3"><a href="#cb1-3"></a><span class="co">  \ Models (LLMs) for scholarly inquiry, particularly in the history, philosophy,\</span></span>
<span id="cb1-4"><a href="#cb1-4"></a><span class="co">  \ and sociology of science (HPSS). It identifies key missing capabilities in LLMs,\</span></span>
<span id="cb1-5"><a href="#cb1-5"></a><span class="co">  \ including the ability to counter hallucination, understand meaning beyond embedding\</span></span>
<span id="cb1-6"><a href="#cb1-6"></a><span class="co">  \ vectors, formulate justified true statements, avoid repeating unreliable media\</span></span>
<span id="cb1-7"><a href="#cb1-7"></a><span class="co">  \ content, seek best justification, and plan scientific inquiry. The core proposed\</span></span>
<span id="cb1-8"><a href="#cb1-8"></a><span class="co">  \ solution is the conce..."</span></span>
<span id="cb1-9"><a href="#cb1-9"></a><span class="an">author:</span></span>
<span id="cb1-10"><a href="#cb1-10"></a></span>
<span id="cb1-11"><a href="#cb1-11"></a><span class="co">- affiliation: AI-NEPI Conference Participant</span></span>
<span id="cb1-12"><a href="#cb1-12"></a><span class="co">  name: Gerd Graßhoff</span></span>
<span id="cb1-13"><a href="#cb1-13"></a><span class="an">bibliography:</span><span class="co"> bibliography.bib</span></span>
<span id="cb1-14"><a href="#cb1-14"></a><span class="an">date:</span><span class="co"> '2025'</span></span>
<span id="cb1-15"><a href="#cb1-15"></a><span class="co">---</span></span>
<span id="cb1-16"><a href="#cb1-16"></a></span>
<span id="cb1-17"><a href="#cb1-17"></a><span class="fu"># Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span>
<span id="cb1-18"><a href="#cb1-18"></a></span>
<span id="cb1-19"><a href="#cb1-19"></a><span class="fu">## Overview</span></span>
<span id="cb1-20"><a href="#cb1-20"></a></span>
<span id="cb1-21"><a href="#cb1-21"></a>The presentation addresses the limitations of current Large Language Models (LLMs) for scholarly inquiry, particularly in the history, philosophy, and sociology of science (HPSS). It identifies key missing capabilities in LLMs, including the ability to counter hallucination, understand meaning beyond embedding vectors, formulate justified true statements, avoid repeating unreliable media content, seek best justification, and plan scientific inquiry.</span>
<span id="cb1-22"><a href="#cb1-22"></a></span>
<span id="cb1-23"><a href="#cb1-23"></a>The core proposed solution is the concept of "Validation is all you need," which involves providing reasons, arguments, and evidence for propositions and actions. This capability is framed within a new proposed discipline called Computational Epistemology, requiring epistemic agency to identify propositions, analyze argumentation, and understand historical actors' intentions, plans, and actions based on documented traces.</span>
<span id="cb1-24"><a href="#cb1-24"></a></span>
<span id="cb1-25"><a href="#cb1-25"></a>A comprehensive research infrastructure is presented to achieve these goals, comprising five key components:</span>
<span id="cb1-26"><a href="#cb1-26"></a></span>
<span id="cb1-27"><a href="#cb1-27"></a><span class="ss">-   </span>*Scholarium* (Evidence): Curated scholarly sources validated by editorial boards, including extensive historical collections like the *Opera Omnia Euler*, *Kepler Gesammelte Werke*, and *Brahe Opera Omnia*.</span>
<span id="cb1-28"><a href="#cb1-28"></a></span>
<span id="cb1-29"><a href="#cb1-29"></a><span class="ss">-   </span>*Scholarium* (Registry): A structured database serving as an alternative to embedding-based approaches, containing detailed, historically validated content items such as personal chronologies, communication acts, statements, arguments, and records of the use of language, tools, methods, data, and sources. Access is provided via an AI API and the *Model Context Protocol* (*MCP*) API.</span>
<span id="cb1-30"><a href="#cb1-30"></a></span>
<span id="cb1-31"><a href="#cb1-31"></a><span class="ss">-   </span>User Interface (*AI Cockpit*): A working environment, specifically the *LettreAI* platform on *Cursor*, integrating multimodal LLMs (*Claude*, *Gemini*, *Llama*, including *Gemini 2.5* for multimodal capability) and featuring a specialized AI agent named "*Bernoulli*" for historical queries.</span>
<span id="cb1-32"><a href="#cb1-32"></a></span>
<span id="cb1-33"><a href="#cb1-33"></a><span class="ss">-   </span>*FAIR Infrastructure*: Utilizing *Zenodo*, hosted by CERN, for long-term storage and publication of data, ensuring Findability, Accessibility, Interoperability, and Reusability.</span>
<span id="cb1-34"><a href="#cb1-34"></a></span>
<span id="cb1-35"><a href="#cb1-35"></a><span class="ss">-   </span>Technical Support: Provided by the startup *OpenScienceTechnology*, focusing on running the infrastructure, including an *MCP API Server*, and adhering to principles of Open Source, Open Access, Open Data, and Open Collaboration to standardize AI access to knowledge.</span>
<span id="cb1-36"><a href="#cb1-36"></a></span>
<span id="cb1-37"><a href="#cb1-37"></a>The system aims to provide validated, complete answers to complex historical queries by leveraging curated data and instructing LLMs with explicit reasoning rules formulated in natural language. This approach contrasts with reliance solely on unstructured text and embedding vectors, which are deemed insufficient for achieving the required level of justification and completeness for scholarly historical research. The infrastructure is designed to maintain scholarly expertise and ensure the long-term preservation and accessibility of valuable historical data.</span>
<span id="cb1-38"><a href="#cb1-38"></a></span>
<span id="cb1-39"><a href="#cb1-39"></a><span class="fu">## LLM Evolution and Current State</span></span>
<span id="cb1-40"><a href="#cb1-40"></a></span>
<span id="cb1-41"><a href="#cb1-41"></a><span class="al">![Slide 01](images/ai-nepi_008_slide_01.jpg)</span></span>
<span id="cb1-42"><a href="#cb1-42"></a></span>
<span id="cb1-43"><a href="#cb1-43"></a>Large Language Models (LLMs) have undergone rapid evolution. The initial focus was captured by the phrase "Attention is all you need." This capability was subsequently supplemented by the requirement for "Context is all you need," necessitating larger context windows and methods such as Retrieval Augmented Generation (RAG).</span>
<span id="cb1-44"><a href="#cb1-44"></a></span>
<span id="cb1-45"><a href="#cb1-45"></a>The latest models now propose that "Thinking is all you need" is also required, focusing on reasoning capabilities, potentially with or without an explicit plan. This represents the current state of LLMs, integrating attention, context handling, and nascent reasoning abilities.</span>
<span id="cb1-46"><a href="#cb1-46"></a></span>
<span id="cb1-47"><a href="#cb1-47"></a><span class="fu">## Missing Capabilities in Current LLMs</span></span>
<span id="cb1-48"><a href="#cb1-48"></a></span>
<span id="cb1-49"><a href="#cb1-49"></a><span class="al">![Slide 01](images/ai-nepi_008_slide_01.jpg)</span></span>
<span id="cb1-50"><a href="#cb1-50"></a></span>
<span id="cb1-51"><a href="#cb1-51"></a>Current LLMs exhibit several critical missing capabilities essential for reliable scholarly work. A significant problem is the lack of an inherent mechanism or "opponent" to effectively counter hallucination, which is the generation of false or nonsensical information.</span>
<span id="cb1-52"><a href="#cb1-52"></a></span>
<span id="cb1-53"><a href="#cb1-53"></a>Furthermore, embedding vectors, a common representation method, are fundamentally not equivalent to the meanings of expressions. LLMs tend to formulate responses that may sound plausible or good but are factually false. They also frequently repeat content sourced from internet media without sufficient validation, treating it as knowledge.</span>
<span id="cb1-54"><a href="#cb1-54"></a></span>
<span id="cb1-55"><a href="#cb1-55"></a>Current models lack the ability to actively seek out and prioritize what is best justified based on evidence or reasoning. Finally, they are unable to formulate effective plans for conducting scientific inquiry. These identified capabilities are absent in existing LLM models, and it is asserted that current technologies offer no realistic prospect of achieving these missing goals.</span>
<span id="cb1-56"><a href="#cb1-56"></a></span>
<span id="cb1-57"><a href="#cb1-57"></a><span class="fu">## Validation and Computational Epistemology</span></span>
<span id="cb1-58"><a href="#cb1-58"></a></span>
<span id="cb1-59"><a href="#cb1-59"></a><span class="al">![Slide 02](images/ai-nepi_008_slide_02.jpg)</span></span>
<span id="cb1-60"><a href="#cb1-60"></a></span>
<span id="cb1-61"><a href="#cb1-61"></a>A critical requirement identified for advancing LLM capabilities in scholarly domains is validation, summarized as "Validation is all you need." Validation is defined as the process of providing explicit reasons, arguments, and evidence that support or oppose the truth of a given proposition. It also involves providing reasons for or against the pursuit of specific actions.</span>
<span id="cb1-62"><a href="#cb1-62"></a></span>
<span id="cb1-63"><a href="#cb1-63"></a>To address this fundamental gap in current AI, a new discipline is proposed: Computational Epistemology. This field focuses on developing the methods and methodologies necessary to implement computational validation processes.</span>
<span id="cb1-64"><a href="#cb1-64"></a></span>
<span id="cb1-65"><a href="#cb1-65"></a>Achieving validation requires epistemic agency, which encompasses several key abilities. These include the capacity to identify propositions, which goes beyond merely processing sentences; the ability to analyze and understand argumentation structures within texts and sources; and the capability to identify the intentions, plans, and actions of historical persons as documented and traced in historical documents.</span>
<span id="cb1-66"><a href="#cb1-66"></a></span>
<span id="cb1-67"><a href="#cb1-67"></a><span class="fu">## Working Environment and Inquiry Example</span></span>
<span id="cb1-68"><a href="#cb1-68"></a></span>
<span id="cb1-69"><a href="#cb1-69"></a><span class="al">![Slide 04](images/ai-nepi_008_slide_04.jpg)</span></span>
<span id="cb1-70"><a href="#cb1-70"></a></span>
<span id="cb1-71"><a href="#cb1-71"></a>A working environment designed for validated historical inquiry is demonstrated through a screenshot of a web browser interface. The interface features a PDF viewer on the left, displaying a historical source document (*Manger1789.pdf*), specifically page 7 of 281, containing old German text related to construction under King Friedrich Wilhelm II.</span>
<span id="cb1-72"><a href="#cb1-72"></a></span>
<span id="cb1-73"><a href="#cb1-73"></a>On the right side, a dark-themed panel titled "Personen und Aufgaben in der Bibliothek" houses the search query input and results display areas. The example historical problem addressed is the long-standing dispute among historians of science regarding the involvement and potential responsibility of the mathematician Leonard Euler in the significant failure of the Sanssouci castle water fountain construction in the 18th century. The goal of the inquiry within this environment is to obtain a validated, reliable, and factually correct answer grounded in proven evidence, moving beyond mere hearsay.</span>
<span id="cb1-74"><a href="#cb1-74"></a></span>
<span id="cb1-75"><a href="#cb1-75"></a>An example query formulated in German is "*Rekonstruiere welche Personen an der Wasserfontaine welche Arbeiten ausführten*," which translates to "Reconstruct which persons performed which work on the water fountain." The system provides validated results in a numbered list format. For this specific query, the results identify the key individuals involved: Nahl, a sculptor, who created the drawings and small models and received 200 Thaler; Benkert and Heymüller, who took on the task of producing the models in the required size under a contract dated June 6, 1746, and were paid 1,970 Thaler; and Giese, who was responsible for casting the figures from lead over the core pieces, processing approximately 600 Zentner of lead, and received 6,000 Thaler.</span>
<span id="cb1-76"><a href="#cb1-76"></a></span>
<span id="cb1-77"><a href="#cb1-77"></a>The output references a specific XML file, *Manger1789_p81-91.xml*. The underlying platform for this working environment is the *Cursor* environment, which allows the use of AI agents. The specific agent employed for these historical inquiries is named "*Bernoulli*." A key challenge highlighted is that obtaining such validated answers requires more than simply reading a single PDF source; it necessitates the ability to search across *all* available sources, a task for which standard indexing and token-based approaches are deemed insufficient.</span>
<span id="cb1-78"><a href="#cb1-78"></a></span>
<span id="cb1-79"><a href="#cb1-79"></a><span class="fu">## Scholarium: Curated Scholarly Evidence</span></span>
<span id="cb1-80"><a href="#cb1-80"></a></span>
<span id="cb1-81"><a href="#cb1-81"></a><span class="al">![Slide 08](images/ai-nepi_008_slide_08.jpg)</span></span>
<span id="cb1-82"><a href="#cb1-82"></a></span>
<span id="cb1-83"><a href="#cb1-83"></a>The first key component of the infrastructure is the *Scholarium* for Evidence. This component relies on the oversight of a Curated Scholarly Editorial Board, ensuring the scholarly reliability of the sources.</span>
<span id="cb1-84"><a href="#cb1-84"></a></span>
<span id="cb1-85"><a href="#cb1-85"></a>Examples of these foundational curated sources include the *Opera Omnia Euler*, a monumental collection comprising 86 volumes of Euler's work, which underwent scholarly editing for approximately 120 years by various scholars and was completed two years prior. This comprehensive edition includes all of Euler's letters and his 866 publications. Complementary scholarly reliable sources integrated into this component include the *Kepler Gesammelte Werke* and the *Brahe Opera Omnia*.</span>
<span id="cb1-86"><a href="#cb1-86"></a></span>
<span id="cb1-87"><a href="#cb1-87"></a><span class="fu">## Scholarium: Registry instead of Embeddings</span></span>
<span id="cb1-88"><a href="#cb1-88"></a></span>
<span id="cb1-89"><a href="#cb1-89"></a><span class="al">![Slide 09](images/ai-nepi_008_slide_09.jpg)</span></span>
<span id="cb1-90"><a href="#cb1-90"></a></span>
<span id="cb1-91"><a href="#cb1-91"></a>The second key component is the *Scholarium* as a Registry, which serves as a novel substitution for conventional embedding-based approaches. This component is a curated database containing a very detailed inventory of content items representing historically proven activities, all rigorously validated by sources.</span>
<span id="cb1-92"><a href="#cb1-92"></a></span>
<span id="cb1-93"><a href="#cb1-93"></a>The types of content recorded include personal actions, various communication acts such as letters, publications, and reports, as well as statements, implications, arguments, and inquiries. The registry also meticulously documents the use of language, terminology, and concepts by historical figures, along with their use of concepts, relations, models, methods, tools, devices, data, information, evidence, and sources. Access to this detailed and validated historical record is provided through both a dedicated AI API and the *Model Context Protocol* (*MCP*) API.</span>
<span id="cb1-94"><a href="#cb1-94"></a></span>
<span id="cb1-95"><a href="#cb1-95"></a><span class="fu">## User Interface: AI Cockpit</span></span>
<span id="cb1-96"><a href="#cb1-96"></a></span>
<span id="cb1-97"><a href="#cb1-97"></a>The user interface component, referred to as the *AI Cockpit*, operates on the *LettreAI* platform within the *Cursor* environment. This interface integrates multiple accessible multimodal LLM models, including *Claude*, *Gemini*, and *Llama*.</span>
<span id="cb1-98"><a href="#cb1-98"></a></span>
<span id="cb1-99"><a href="#cb1-99"></a>The system leverages the capabilities of multimodal models, specifically mentioning *Gemini 2.5*, which can combine information from both text and images, a feature deemed beneficial for solving the requirements of the historical inquiry tasks.</span>
<span id="cb1-100"><a href="#cb1-100"></a></span>
<span id="cb1-101"><a href="#cb1-101"></a><span class="fu">## FAIR Infrastructure</span></span>
<span id="cb1-102"><a href="#cb1-102"></a></span>
<span id="cb1-103"><a href="#cb1-103"></a>A crucial component is the *FAIR Infrastructure*, designed for the long-term storage and publication of the project's data while adhering to the FAIR principles (Findability, Accessibility, Interoperability, and Reusability).</span>
<span id="cb1-104"><a href="#cb1-104"></a></span>
<span id="cb1-105"><a href="#cb1-105"></a>The specific tool utilized for this purpose is *Zenodo*, which is hosted by CERN in Geneva. *Zenodo* provides the necessary capabilities to host the project's data reliably for many years.</span>
<span id="cb1-106"><a href="#cb1-106"></a></span>
<span id="cb1-107"><a href="#cb1-107"></a><span class="fu">## Technical Support: OpenScienceTechnology</span></span>
<span id="cb1-108"><a href="#cb1-108"></a></span>
<span id="cb1-109"><a href="#cb1-109"></a>Technical support for the infrastructure is provided by the startup *OpenScienceTechnology*. This entity is responsible for running the system's infrastructure and specifically provides an *MCP API Server*.</span>
<span id="cb1-110"><a href="#cb1-110"></a></span>
<span id="cb1-111"><a href="#cb1-111"></a>The technical support operates under principles of Open Source, Open Access, Open Data, and Open Collaboration. The *MCP API Server* plays a key role in attempting to standardize AI access APIs to knowledge on a worldwide scale through a standardized interface, facilitating open collaboration.</span></code><button title="Copy to Clipboard" class="code-copy-button" data-in-quarto-modal=""><i class="bi"></i></button></pre></div>
</div></div></div></div></div>
</div> <!-- /content -->




<script src="site_libs/quarto-html/zenscroll-min.js"></script>
</body></html>