<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.17">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Paul Näger">
<meta name="dcterms.date" content="2025-06-21">

<title>12&nbsp; Applying Retrieval-Augmented Generation to Philosophical Research: A Case Study and Methodological Insights – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_015.html" rel="next">
<link href="./chapter_ai-nepi_011.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-c2d8198b7f72dec16de60f0cb3fab69f.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-a0afd4a9b901cc50d8ed64d4ec5e2aec.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_012.html"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Applying Retrieval-Augmented Generation to Philosophical Research: A Case Study and Methodological Insights</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header sidebar-header-stacked">
      <a href="./index.html" class="sidebar-logo-link">
      </a>
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">AI-assisted Methods for History and Philosophy of Science Workshop: Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Investigating the transdiciplinary application of model templates through projective methods</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Scientific Insights, Transparency, and Applications in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Scientific Reasoning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers - the mixed use of LLM’s and semantic artifacts to support the understanding of science dynamics</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Applying Retrieval-Augmented Generation to Philosophical Research: A Case Study and Methodological Insights</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural Pursuit: The Case of Quantum Gravity</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Making Transformer-Based LLMs Time-Aware: A Proof of Concept</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Towards Interpretable Models: Bridging Traditional and Deep Learning Methods for Tracing Linguistic Change in English Scientific Writing</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">From Source to Structure – Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#scholarly-challenges-of-large-language-models" id="toc-scholarly-challenges-of-large-language-models" class="nav-link" data-scroll-target="#scholarly-challenges-of-large-language-models"><span class="header-section-number">12.1</span> Scholarly Challenges of Large Language Models</a></li>
  <li><a href="#a-case-study-in-philosophical-rag" id="toc-a-case-study-in-philosophical-rag" class="nav-link" data-scroll-target="#a-case-study-in-philosophical-rag"><span class="header-section-number">12.2</span> A Case Study in Philosophical RAG</a></li>
  <li><a href="#system-interface-and-comparative-analysis" id="toc-system-interface-and-comparative-analysis" class="nav-link" data-scroll-target="#system-interface-and-comparative-analysis"><span class="header-section-number">12.3</span> System Interface and Comparative Analysis</a></li>
  <li><a href="#optimising-hyperparameters-and-chunk-size" id="toc-optimising-hyperparameters-and-chunk-size" class="nav-link" data-scroll-target="#optimising-hyperparameters-and-chunk-size"><span class="header-section-number">12.4</span> Optimising Hyperparameters and Chunk Size</a></li>
  <li><a href="#conclusion-and-future-directions" id="toc-conclusion-and-future-directions" class="nav-link" data-scroll-target="#conclusion-and-future-directions"><span class="header-section-number">12.5</span> Conclusion and Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Applying Retrieval-Augmented Generation to Philosophical Research: A Case Study and Methodological Insights</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Paul Näger <a href="mailto:paul.naeger@cis.lmu.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            LMU München
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter presents a methodological exploration into applying Retrieval-Augmented Generation (RAG) systems to enhance philosophical research. It confronts the inherent limitations of standard Large Language Models (<em>LLMs</em>), including their inability to access full texts, their propensity for hallucination, their constrained context windows, and their lack of source attribution. The authors propose the RAG architecture as a robust solution, integrating a specific corpus—such as the works of Aristotle or Einstein—with an <em>LLM</em> to furnish verifiable, context-rich answers.</p>
<p>A practical case study documents the development of a RAG system that uses the <em>Stanford Encyclopedia of Philosophy</em> (<em>SEP</em>) as its knowledge base. This project reveals that a naive implementation yields poor results, necessitating significant refinement of models, hyperparameters, and algorithms like reranking. The investigation highlights the critical role of hyperparameter optimisation, particularly chunk size. For the highly structured <em>SEP</em> corpus, chunking by main section surprisingly outperformed more granular methods.</p>
<p>The chapter concludes that whilst RAG systems offer profound advantages for scholarly tasks by reducing hallucinations and enabling citations, their effectiveness is highly contingent on the corpus, the nature of the research questions, and rigorous evaluation by domain experts. Future work points towards developing more flexible, agentic RAG systems capable of discerning between different query types.</p>
</section>
<section id="scholarly-challenges-of-large-language-models" class="level2" data-number="12.1">
<h2 data-number="12.1" class="anchored" data-anchor-id="scholarly-challenges-of-large-language-models"><span class="header-section-number">12.1</span> Scholarly Challenges of Large Language Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Standard Large Language Models can produce differentiated answers to complex philosophical questions, such as analysing Aristotle’s theory of matter or tracing the evolution of Einstein’s concept of locality. Their utility for deep scholarly research, however, is constrained by several fundamental problems. A Retrieval-Augmented Generation system offers a structured approach to overcome these limitations.</p>
<p>The core challenge with <em>LLMs</em> is their lack of direct access to full-text sources. Although trained on vast datasets, their training mechanism is explicitly designed to learn generalisable patterns of text production, not to memorise and recall texts verbatim. Consequently, when prompted for a specific quotation, an <em>LLM</em> might either refuse or, more problematically, hallucinate a response. Such an outcome is antithetical to philosophical research, which demands precise engagement with the fine-grained formulations of original texts.</p>
<p>Furthermore, the context window of <em>LLMs</em>, whilst growing, remains a significant constraint. A model like <em>ChatGPT 4.0</em> offers a 128,000-token context, yet this is quickly exhausted when dealing with the large corpora typical of scholarly inquiry. RAG systems directly address these issues. The architecture retrieves relevant documents from a specified data source—for instance, the complete works of a philosopher—using methods like semantic or hybrid search. These retrieved text chunks then augment the user’s prompt, feeding the <em>LLM</em> with the exact textual evidence needed to formulate a grounded response. This process not only provides access to the verbatim text but also solves the critical problem of attribution, as the system can cite the sources for its claims, much like the functionality seen in tools such as <em>Perplexity</em>.</p>
</section>
<section id="a-case-study-in-philosophical-rag" class="level2" data-number="12.2">
<h2 data-number="12.2" class="anchored" data-anchor-id="a-case-study-in-philosophical-rag"><span class="header-section-number">12.2</span> A Case Study in Philosophical RAG</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The central ambition in applying RAG to philosophy is to facilitate a deep, interactive dialogue with scholarly corpora, such as the complete works of John Locke. This approach promises significant benefits for both didactics and advanced research. For students, it offers an intuitive pathway into complex texts, allowing them to move from broad inquiries to specific epistemological questions. For researchers, RAG systems can function as reliable tools for looking up facts, exploring unexamined corpora, and identifying key passages for close reading. The ultimate goal is for these systems to assist in answering detailed research questions directly.</p>
<p>To explore this potential, the authors developed a prototype RAG system using the <em>Stanford Encyclopedia of Philosophy</em> (<em>SEP</em>) as its knowledge base, with the initial aim of creating a useful tool for the philosophical community. The team scraped the <em>SEP</em> content into Markdown to serve as the data source. However, a straightforward, textbook implementation of the RAG architecture yielded surprisingly poor results; the answers were often inferior to those generated by a standalone <em>LLM</em> like <em>ChatGPT</em>. This discovery shifted the project’s focus towards rigorous optimisation.</p>
<p>Improving the system’s performance necessitated a process of extensive adjustment, involving modifications to the models, their hyperparameters, and the introduction of more complex algorithms such as reranking. This optimisation work is largely a matter of trial and error, guided by theoretical principles but ultimately validated by empirical results. A significant challenge emerged in this phase: the evaluation of output quality. Unlike historical queries for atomic facts, philosophical questions elicit complex, unstructured propositions. Developing robust standards to evaluate the factual correctness of these nuanced answers is a non-trivial task that remains a key hurdle.</p>
</section>
<section id="system-interface-and-comparative-analysis" class="level2" data-number="12.3">
<h2 data-number="12.3" class="anchored" data-anchor-id="system-interface-and-comparative-analysis"><span class="header-section-number">12.3</span> System Interface and Comparative Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_25.png" class="img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
<p>The project team developed a custom frontend to facilitate interaction with and evaluation of the <em>Stanford Encyclopedia of Philosophy</em> RAG system. The interface, comprising a few thousand lines of code, provides users with controls to configure key hyperparameters, including prompt length and the number of documents to retrieve, alongside a field for submitting their query.</p>
<p>A central feature of the design is its comparative output display, which is structured to aid analysis. On the left, the system shows a benchmark answer generated by the chosen <em>LLM</em> operating in isolation. On the right, it presents the corresponding answer from the RAG-augmented system. This side-by-side layout enables a direct and immediate comparison, making it easier to assess the value added by the retrieval process.</p>
<p>To ensure transparency and aid in debugging, the system’s output concludes with a comprehensive list of the texts found during the retrieval stage. This list details the source article names and the specific section headings that the system identified as relevant. Crucially, it also indicates which of these text chunks were successfully included in the final augmented prompt and which were ultimately excluded due to the <em>LLM</em>’s prompt length limitations, providing clear insight into the retrieval and augmentation process.</p>
</section>
<section id="optimising-hyperparameters-and-chunk-size" class="level2" data-number="12.4">
<h2 data-number="12.4" class="anchored" data-anchor-id="optimising-hyperparameters-and-chunk-size"><span class="header-section-number">12.4</span> Optimising Hyperparameters and Chunk Size</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_32.png" class="img-fluid figure-img"></p>
<figcaption>Slide 32</figcaption>
</figure>
</div>
<p>The authors conducted experiments to optimise key hyperparameters, focusing specifically on the ‘chunk size’ used for text retrieval. They considered three primary chunking strategies: using a fixed number of words, a common practice in computer science; splitting the text by paragraphs; or dividing it by semantic sections.</p>
<p>To some surprise, the investigation revealed that using the main sections of the <em>Stanford Encyclopedia of Philosophy</em> articles as the retrieval units yielded the best results. This outcome was unexpected because the embedding model’s context limit was just over 500 words, whereas the average length of a main section in the corpus was around 3,000 words.</p>
<p>The team’s hypothesis for this result centres on the unique structure of the data source. The <em>SEP</em> is a highly systematised and well-ordered work. It is likely that the initial 500 words of each major section effectively summarise its core arguments, providing the embedding model with enough information to assess its relevance to a query accurately. This finding underscores a critical lesson: the optimal chunking strategy is not universal but is instead highly contingent on the specific nature of the corpus and the research questions posed. Consequently, this approach might not transfer well to more heterogeneous texts. Future plans involve experimenting with embedding models that possess longer context windows to explore potential further improvements.</p>
</section>
<section id="conclusion-and-future-directions" class="level2" data-number="12.5">
<h2 data-number="12.5" class="anchored" data-anchor-id="conclusion-and-future-directions"><span class="header-section-number">12.5</span> Conclusion and Future Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_012_slide_40.png" class="img-fluid figure-img"></p>
<figcaption>Slide 40</figcaption>
</figure>
</div>
<p>Retrieval-Augmented Generation systems present clear advantages for scientific and scholarly work. They successfully integrate verbatim corpora and specialised domain knowledge, a capability that dramatically reduces the incidence of <em>LLM</em> hallucinations. Moreover, their ability to cite relevant source documents makes them, in principle, exceptionally well-suited to assisting with academic tasks.</p>
<p>Their practical application, however, requires caution. RAG systems are not off-the-shelf solutions; they demand careful configuration, as the appropriate settings for retrieval and generation depend heavily on the specific corpus and the kinds of questions being asked. The evaluation of their output is therefore crucial, demanding a representative set of test questions and expected answers—a task for which domain experts are indispensable.</p>
<p>Several open challenges remain. The quality of a RAG system’s answer degrades significantly if no relevant documents are found in the retrieval phase, a scenario that necessitates careful prompt engineering. A notable, counter-intuitive finding is that these systems often perform poorly on broad, overview questions. The likely reason is that the RAG process forces the <em>LLM</em> to focus on the local information contained within the retrieved text chunks. This local focus can distract the model from synthesising information and adopting the wide perspective needed to answer a general query effectively.</p>
<p>To address this, future development must move towards more flexible, agentic RAG systems. Such systems would be capable of discerning between different types of questions and dynamically adjusting their information processing strategy, paving the way for more sophisticated scholarly assistants.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_011.html" class="pagination-link" aria-label="Chatting with Papers - the mixed use of LLM's and semantic artifacts to support the understanding of science dynamics">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers - the mixed use of LLM’s and semantic artifacts to support the understanding of science dynamics</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Plural Pursuit: The Case of Quantum Gravity">
        <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural Pursuit: The Case of Quantum Gravity</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>