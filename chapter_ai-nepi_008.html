<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Gerd Graßhoff">
<meta name="dcterms.date" content="2025-06-21">

<title>8&nbsp; LLM: Evolution of competence – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_009.html" rel="next">
<link href="./chapter_ai-nepi_007.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_008.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">LLM: Evolution of competence</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">LLM: Evolution of competence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#evolution-of-large-language-model-competence" id="toc-evolution-of-large-language-model-competence" class="nav-link" data-scroll-target="#evolution-of-large-language-model-competence"><span class="header-section-number">8.1</span> Evolution of Large Language Model Competence</a></li>
  <li><a href="#addressing-critical-limitations-in-large-language-models" id="toc-addressing-critical-limitations-in-large-language-models" class="nav-link" data-scroll-target="#addressing-critical-limitations-in-large-language-models"><span class="header-section-number">8.2</span> Addressing Critical Limitations in Large Language Models</a></li>
  <li><a href="#computational-epistemology-and-epistemic-agency-for-llms" id="toc-computational-epistemology-and-epistemic-agency-for-llms" class="nav-link" data-scroll-target="#computational-epistemology-and-epistemic-agency-for-llms"><span class="header-section-number">8.3</span> Computational Epistemology and Epistemic Agency for LLMs</a></li>
  <li><a href="#ai-powered-historical-inquiry-the-euler-workspace" id="toc-ai-powered-historical-inquiry-the-euler-workspace" class="nav-link" data-scroll-target="#ai-powered-historical-inquiry-the-euler-workspace"><span class="header-section-number">8.4</span> AI-Powered Historical Inquiry: The Euler Workspace</a></li>
  <li><a href="#scholarium-a-curated-scholarly-evidence-base" id="toc-scholarium-a-curated-scholarly-evidence-base" class="nav-link" data-scroll-target="#scholarium-a-curated-scholarly-evidence-base"><span class="header-section-number">8.5</span> Scholarium: A Curated Scholarly Evidence Base</a></li>
  <li><a href="#the-ai-cockpit-user-interface" id="toc-the-ai-cockpit-user-interface" class="nav-link" data-scroll-target="#the-ai-cockpit-user-interface"><span class="header-section-number">8.6</span> The AI Cockpit User Interface</a></li>
  <li><a href="#fair-infrastructure-for-research-data" id="toc-fair-infrastructure-for-research-data" class="nav-link" data-scroll-target="#fair-infrastructure-for-research-data"><span class="header-section-number">8.7</span> FAIR Infrastructure for Research Data</a></li>
  <li><a href="#open-science-technology-and-standardised-ai-access" id="toc-open-science-technology-and-standardised-ai-access" class="nav-link" data-scroll-target="#open-science-technology-and-standardised-ai-access"><span class="header-section-number">8.8</span> Open Science Technology and Standardised AI Access</a></li>
  <li><a href="#additional-visual-materials" id="toc-additional-visual-materials" class="nav-link" data-scroll-target="#additional-visual-materials"><span class="header-section-number">8.9</span> Additional Visual Materials</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">LLM: Evolution of competence</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Gerd Graßhoff <a href="mailto:gerd.grasshoff@hu-berlin.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Humboldt Universität zu Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The authors meticulously chart the rapid evolution of Large Language Models (LLMs), progressing from foundational ‘attention’ mechanisms to advanced ‘thinking’ capabilities. Their work critically examines the current limitations inherent in LLMs, particularly concerning factual accuracy, semantic understanding, and the capacity for rigorous scientific inquiry. Proposing ‘validation’ as the crucial next frontier, the authors introduce <em>computational epistemology</em> as a novel discipline specifically designed to address these identified gaps. A key focus of their research involves cultivating an ‘epistemic agency’ within LLMs, enabling these models to furnish reasoned arguments, provide robust evidence, and identify propositions that transcend mere sentences.</p>
<p>The practical application of these concepts manifests within a bespoke working environment, the <em>AI Cockpit</em>. This innovative system leverages multimodal LLMs, including <em>Gemini 2.5</em>, <em>Claude</em>, and <em>Llama</em>, alongside an AI agent named <em>Bernoulli</em>, to meticulously analyse historical documents. The underlying infrastructure relies upon a <em>Scholarium</em>—a meticulously curated, scholarly-edited database of primary sources, such as the <em>Opera Omnia Euler</em>. This <em>Scholarium</em> serves as a validated alternative to conventional embedding-based approaches. Furthermore, the authors underscore the paramount importance of a FAIR (Findability, Accessibility, Interoperability, Reusability) data infrastructure, exemplified by <em>Zenodo</em>. They also advocate for open science principles through <em>OpenScienceTechnology</em>, a dedicated initiative that provides technical support, including an <em>MCP API Server</em> for standardised global AI access to knowledge.</p>
</section>
<section id="evolution-of-large-language-model-competence" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="evolution-of-large-language-model-competence"><span class="header-section-number">8.1</span> Evolution of Large Language Model Competence</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>Large Language Models have undergone a remarkably swift evolution, progressing through distinct phases of competence. The authors observe that initially, their foundational capability was encapsulated by the principle ‘Attention is all you need’, enabling basic conversational interactions. Subsequently, this capability evolved to incorporate ‘Context is all you need’, necessitating a larger contextual understanding, often facilitated by techniques such as <em>Retrieval-Augmented Generation</em> (RAGs). The latest models now propose ‘Thinking is all you need’, indicating an advancement towards more sophisticated reasoning, whether with or without a predefined plan. This trajectory clearly illustrates a progression from fundamental conversational AI to advanced reasoning capabilities. Nevertheless, a critical question persists: do these advancements truly fulfil all requirements, or do essential components still remain elusive?</p>
</section>
<section id="addressing-critical-limitations-in-large-language-models" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="addressing-critical-limitations-in-large-language-models"><span class="header-section-number">8.2</span> Addressing Critical Limitations in Large Language Models</h2>
<p>Current Large Language Models exhibit several critical limitations that necessitate urgent attention. The authors identify a crucial unmet need for an ‘opponent’ mechanism to effectively counter hallucinations, thereby ensuring factual accuracy in generated content. Furthermore, a fundamental technical and philosophical limitation persists: embedding vectors, whilst powerful, do not encapsulate the true meanings of expressions. Consequently, the research team asserts that models must prioritise truthfulness over mere fluency, refraining from formulating statements that sound plausible but are factually incorrect. Beyond this, LLMs should not simply repeat unverified content from internet media; rather, they must critically evaluate information sources. The imperative, the authors contend, is for models to actively seek and present only the best-justified information. Moreover, a significant missing capability involves the LLM’s ability to formulate optimal plans for scientific inquiry. Regrettably, existing technologies offer no discernible path towards achieving these vital goals. Therefore, the authors propose a new paradigm: ‘Validation is all you need’, positing validation as the indispensable next step in LLM development.</p>
</section>
<section id="computational-epistemology-and-epistemic-agency-for-llms" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="computational-epistemology-and-epistemic-agency-for-llms"><span class="header-section-number">8.3</span> Computational Epistemology and Epistemic Agency for LLMs</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The ‘Validation is all you need’ framework, proposed by the authors, establishes stringent requirements for advanced Large Language Models. Such models must demonstrably provide comprehensive reasons, robust arguments, and verifiable evidence both for and against the truth of any given proposition. Furthermore, they should offer reasoned justifications for or against the pursuit of specific actions. To address these complex demands, the research team has introduced a novel discipline: <em>Computational Epistemology</em>. This emerging field focuses on developing the methods and methodologies necessary to bridge the existing validation gap in LLM capabilities. A central tenet of this discipline involves cultivating ‘epistemic agency’ within LLMs. This agency necessitates the ability to identify propositions that transcend simple sentences, to discern arguments embedded within diverse texts and historical sources, and crucially, to comprehend the intentions, plans, and actions of individuals as documented in historical records. The authors have developed a working environment to illustrate these capabilities, exemplified by its application to historical inquiries, such as the contentious construction of Sanssouci castle and Leonhard Euler’s debated involvement.</p>
</section>
<section id="ai-powered-historical-inquiry-the-euler-workspace" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="ai-powered-historical-inquiry-the-euler-workspace"><span class="header-section-number">8.4</span> AI-Powered Historical Inquiry: The Euler Workspace</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The authors presented a live demonstration showcasing the <em>Manger1789.pdf - Euler (Workspace)</em>, an advanced AI-powered research tool crafted for historical document analysis. The interface prominently displays a scanned historical document, such as <em>Manger1789.pdf</em>, on its left pane, enabling users to navigate through extensive primary sources. Conversely, the right pane hosts a dynamic query-response interface, which facilitates direct interaction. Users can formulate complex inquiries, exemplified by the question: ‘Rekonstruiere welche Personen an der Wasserfontaine welche Arbeiten ausführten’ (Reconstruct which persons performed which work on the water fountain). The system then generates validated, qualified answers, meticulously derived from proven evidence rather than mere hearsay. The output typically presents a structured list detailing individuals, their specific contributions, periods of work, remuneration, and both their successes and failures. This entire working environment operates within the <em>Cursor</em> platform, which enables the deployment of AI agents capable of executing a diverse range of tasks, including automated processes. A compelling historical context for this tool involves the long-standing academic dispute surrounding the 18th-century mathematician Leonhard Euler’s precise role and potential culpability in significant construction failures, such as the water fountain at Sanssouci.</p>
</section>
<section id="scholarium-a-curated-scholarly-evidence-base" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="scholarium-a-curated-scholarly-evidence-base"><span class="header-section-number">8.5</span> Scholarium: A Curated Scholarly Evidence Base</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>For rigorous historical inquiry, the authors developed an AI agent, presumptuously named <em>Bernoulli</em>, to interrogate diverse scholarly sources. The challenge extends beyond merely reading individual PDF documents; it necessitates searching and integrating all available sources, which require indexing and content concentration beyond simple tokens. To achieve this, the research team deemed a robust system comprising five or six core components essential. Foremost amongst these is a scholarly curated editorial board, responsible for the meticulous validation of sources. A prime example is the <em>Opera Omnia Euler</em> itself, a monumental 86-volume collection representing 120 years of scholarly endeavour, with all 866 publications and correspondence having been fully edited two years prior.</p>
<p>This <em>Scholarium</em> serves as a sophisticated substitute for conventional embeddings, functioning as a curated database of content items. These items encompass detailed chronologies of actions, expressions, the evolution of terminology, and the use of tools and materials by historical figures. Crucially, every entry undergoes rigorous validation against original historical sources, thereby creating an exhaustive inventory of historically proven activities. Advanced multimodal models, such as the latest <em>Gemini 2.5</em>, can then interrogate these meticulously compiled records, adeptly combining information derived from both text and images. The <em>Scholarium</em> initiative also incorporates other seminal works, including the <em>Kepler Gesammelte Werke</em> and <em>Brahe Opera Omnia</em>, all accessible via a structured digital library environment like the <em>Euler Opera Omnia Viewer</em>, which facilitates navigation through collections, series, volumes, and indices.</p>
</section>
<section id="the-ai-cockpit-user-interface" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="the-ai-cockpit-user-interface"><span class="header-section-number">8.6</span> The AI Cockpit User Interface</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>The authors explicitly identify the previously demonstrated software interface as an <em>AI Cockpit</em>. This user interface, which they designed for comprehensive document analysis, features a scanned historical document prominently displayed on its left pane. Conversely, the right pane hosts an AI-powered analysis and chat interface, which adeptly extracts structured information directly from the document. Several prominent Large Language Models, including <em>Claude</em>, <em>Gemini</em>, and <em>LLama</em>, power this <em>AI Cockpit</em>. Furthermore, the system incorporates <em>LettreAI on Cursor</em>, indicating a more specialised or integrated AI tool operating seamlessly within the user’s interactive environment.</p>
</section>
<section id="fair-infrastructure-for-research-data" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="fair-infrastructure-for-research-data"><span class="header-section-number">8.7</span> FAIR Infrastructure for Research Data</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The project, spearheaded by the authors, rigorously adheres to the FAIR principles—Findability, Accessibility, Interoperability, and Reusability—for all research data. <em>Zenodo</em>, a prominent example of such a FAIR infrastructure, serves as the primary long-term repository for storing and publishing the project’s extensive datasets. Hosted by CERN in Geneva, <em>Zenodo</em> ensures the enduring availability and preservation of these critical research outputs. A visual representation of the <em>Zenodo</em> website highlights its functionalities, including ‘Featured communities’ like the American Astronomical Society Journals, and showcases ‘Recent uploads’, demonstrating its role as an open repository for diverse research outputs, from datasets to publications.</p>
</section>
<section id="open-science-technology-and-standardised-ai-access" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="open-science-technology-and-standardised-ai-access"><span class="header-section-number">8.8</span> Open Science Technology and Standardised AI Access</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p><em>OpenScienceTechnology</em>, a dedicated startup, provides technical support for the project’s infrastructure. This support is firmly rooted in the principles of open science, encompassing Open Source software, Open Access to research outputs, Open Data, and Open Collaboration. A crucial technical component, the <em>MCP API Server</em> (Model Context Protocol API Server), facilitates worldwide access to the project’s data via artificial intelligence models through a standardised API. This initiative, championed by the authors and <em>OpenScienceTechnology</em>, represents a concerted effort to standardise AI access APIs to knowledge within the global community, fostering widespread interoperability and collaborative research endeavours.</p>
</section>
<section id="additional-visual-materials" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="additional-visual-materials"><span class="header-section-number">8.9</span> Additional Visual Materials</h2>
<p>The following slides provide supplementary visual information relevant to the presentation:</p>
<p><img src="images/ai-nepi_008_slide_02.png" class="img-fluid" alt="Slide 02"> <em>The slide, titled ‘LLM: Evolution of competence’, outlines a progression in the capabilities of Large Language Models. It presents three distinct phases or aspects, each introduced by a phrase echoing the title of the seminal </em>Transformer* paper, ‘Attention is all you need’. The first point, ‘“Attention is all you need”’, associates with ‘Chat with <em>GPT</em>’, implying the foundational capability of attention mechanisms for conversational AI. The second point, ‘“Context is all you need”’, links to ‘Larger Context with <em>RAG</em>’ (<em>Retrieval-Augmented Generation</em>), suggesting an evolution towards models that can leverage broader external information for more informed responses. The third and final point, ‘“Thinking is all you need”’, describes ‘Reasoning with/without a plan’, indicating a future or advanced capability of LLMs to perform complex logical operations, potentially with or without explicit pre-defined steps. This slide conceptualises the development trajectory of LLMs from basic conversational ability to advanced reasoning.*</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_007.html" class="pagination-link" aria-label="Explainable AI and AI-based Scientific Insights in the Humanities">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_009.html" class="pagination-link" aria-label="The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>