<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2025-01-01">

<title>Modeling Science – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_009.html" rel="next">
<link href="./chapter_ai-nepi_007.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_008.html"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals, ActDisease Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG in HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#llm-competence-conceptual-evolution-and-persistent-challenges" id="toc-llm-competence-conceptual-evolution-and-persistent-challenges" class="nav-link" data-scroll-target="#llm-competence-conceptual-evolution-and-persistent-challenges"><span class="header-section-number">8.1</span> LLM Competence: Conceptual Evolution and Persistent Challenges</a></li>
  <li><a href="#addressing-llm-limitations-the-imperative-of-validation-and-epistemic-agency" id="toc-addressing-llm-limitations-the-imperative-of-validation-and-epistemic-agency" class="nav-link" data-scroll-target="#addressing-llm-limitations-the-imperative-of-validation-and-epistemic-agency"><span class="header-section-number">8.2</span> Addressing LLM Limitations: The Imperative of Validation and Epistemic Agency</a></li>
  <li><a href="#the-imperative-of-validation-and-epistemic-agency-in-computational-inquiry" id="toc-the-imperative-of-validation-and-epistemic-agency-in-computational-inquiry" class="nav-link" data-scroll-target="#the-imperative-of-validation-and-epistemic-agency-in-computational-inquiry"><span class="header-section-number">8.3</span> The Imperative of Validation and Epistemic Agency in Computational Inquiry</a></li>
  <li><a href="#the-foundational-role-of-curated-sources-in-digital-text-analysis" id="toc-the-foundational-role-of-curated-sources-in-digital-text-analysis" class="nav-link" data-scroll-target="#the-foundational-role-of-curated-sources-in-digital-text-analysis"><span class="header-section-number">8.4</span> The Foundational Role of Curated Sources in Digital Text Analysis</a></li>
  <li><a href="#scholarium-a-novel-platform-for-curated-validated-scholarly-content" id="toc-scholarium-a-novel-platform-for-curated-validated-scholarly-content" class="nav-link" data-scroll-target="#scholarium-a-novel-platform-for-curated-validated-scholarly-content"><span class="header-section-number">8.5</span> Scholarium: A Novel Platform for Curated, Validated Scholarly Content</a></li>
  <li><a href="#scholarium-a-registry-based-framework-for-structured-scholarly-content-and-multimodal-ai-inquiry" id="toc-scholarium-a-registry-based-framework-for-structured-scholarly-content-and-multimodal-ai-inquiry" class="nav-link" data-scroll-target="#scholarium-a-registry-based-framework-for-structured-scholarly-content-and-multimodal-ai-inquiry"><span class="header-section-number">8.6</span> Scholarium: A Registry-Based Framework for Structured Scholarly Content and Multimodal AI Inquiry</a></li>
  <li><a href="#the-ai-cockpit-user-interface-llm-integration-and-data-stewardship" id="toc-the-ai-cockpit-user-interface-llm-integration-and-data-stewardship" class="nav-link" data-scroll-target="#the-ai-cockpit-user-interface-llm-integration-and-data-stewardship"><span class="header-section-number">8.7</span> The AI Cockpit: User Interface, LLM Integration, and Data Stewardship</a></li>
  <li><a href="#zenodo-enabling-fair-data-through-community-and-ai-ready-infrastructure" id="toc-zenodo-enabling-fair-data-through-community-and-ai-ready-infrastructure" class="nav-link" data-scroll-target="#zenodo-enabling-fair-data-through-community-and-ai-ready-infrastructure"><span class="header-section-number">8.8</span> Zenodo: Enabling FAIR Data Through Community and AI-Ready Infrastructure</a></li>
  <li><a href="#opensciencetechnology-pillars-of-sustainable-digital-scholarship" id="toc-opensciencetechnology-pillars-of-sustainable-digital-scholarship" class="nav-link" data-scroll-target="#opensciencetechnology-pillars-of-sustainable-digital-scholarship"><span class="header-section-number">8.9</span> OpenScienceTechnology: Pillars of Sustainable Digital Scholarship</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Modeling Science</h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Gerd Graßhoff <a href="mailto:gerd.grasshoff@hu-berlin.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Humboldt Universität zu Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The chapter, “Modelling Science,” critically examines the role of computational tools, particularly <em>Large Language Models</em> (LLMs), in scientific inquiry and scholarly content generation. It begins by tracing the conceptual evolution of LLM capabilities, acknowledging their significant advancements. However, it immediately pivots to a rigorous analysis of their persistent and fundamental limitations. The authors highlight the pervasive issue of hallucination and the inherent lack of epistemic agency in current LLM outputs, which poses significant challenges to their reliable application in academic and scientific domains. This initial discussion establishes the imperative for a paradigm shift: moving from uncritical reliance on LLM generation to a more robust, validated approach.</p>
<p>A central argument of this chapter is the assertion that “Validation is all you need.” This principle posits that any proposition or action, especially within scholarly contexts, demands rigorous support and verification. This underpins the subsequent introduction of practical solutions designed to address the identified LLM deficiencies. The discussion then emphasises the foundational role of meticulously curated sources, illustrating this through a demonstration of software for digital text analysis. This sets the stage for the unveiling of <em>Scholarium</em>, a novel, registry-based platform conceived as a comprehensive, curated scholarly database. Distinct from conventional embedding-centric systems, <em>Scholarium</em> champions a structured approach to managing and validating scholarly content, thereby facilitating multimodal AI inquiry by prioritising data integrity and verifiable provenance.</p>
<p>To operationalise this vision, the chapter introduces the <em>AI Cockpit</em> as the primary user interface. This interface is designed to seamlessly integrate LLM capabilities within a framework of robust data stewardship and advanced document analysis, emphasising the controlled application of AI within a validated environment. Furthermore, the discussion extends to the foundational infrastructure supporting this ecosystem, highlighting platforms like <em>Zenodo</em> as exemplars of FAIR (Findable, Accessible, Interoperable, Reusable) data principles. These principles are crucial for developing community-driven and AI-ready scholarly resources. The chapter concludes by outlining the guiding philosophy of <em>OpenScienceTechnology</em>, which emphasises principles of sustainability, openness, and technical support. Collectively, these components articulate a compelling vision for a new era of digital scholarship that leverages AI’s potential whilst rigorously upholding scientific integrity and epistemic responsibility.</p>
</section>
<section id="llm-competence-conceptual-evolution-and-persistent-challenges" class="level2" data-number="8.1">
<h2 data-number="8.1" class="anchored" data-anchor-id="llm-competence-conceptual-evolution-and-persistent-challenges"><span class="header-section-number">8.1</span> LLM Competence: Conceptual Evolution and Persistent Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>Slide 2, titled “LLM: Evolution of competence,” outlines a conceptual progression in the development of <em>Large Language Models</em> (LLMs). This evolution begins with the foundational concept of “Attention is all you need” [Vaswani et al., 2017], which marked a significant leap in sequence processing and epitomises early conversational models like <em>Chat with GPT</em>. The progression then moves to “Context is all you need,” recognising the importance of incorporating broader external information. This is often achieved through <em>Retrieval-Augmented Generation</em> (RAG) [Lewis et al., 2020], which provides a larger and more relevant context for LLM responses. The aspirational third stage, “Thinking is all you need,” points towards models capable of genuine reasoning, whether through pre-defined plans or more emergent cognitive processes.</p>
<p>However, despite this depicted evolution, a critical examination reveals significant unmet needs and fundamental limitations within current LLM technologies. A core challenge lies in countering hallucinations, as current models often prioritise fluency and coherence over factual accuracy. This issue stems from a deeper conceptual misunderstanding: embedding vectors, whilst powerful for representing semantic similarity, are not synonymous with the “meanings of impressions [or] expressions” in a true cognitive sense. The authors contend that LLMs should not formulate responses that merely “sound good but are false,” nor uncritically repeat “what others put out on media, internet media,” as such outputs do not constitute genuine knowledge or justified answers.</p>
<p>Crucially, existing models fundamentally lack the capacity for higher-order cognitive functions such as seeking “what is best justified” or the ability to “make plans for scientific inquiry.” These capabilities, essential for true intelligence and academic rigour, are entirely missing from current LLM architectures. The presenter emphatically concludes that “no model can do that,” indicating a profound gap that current technological paradigms offer “no hope” of achieving. This suggests that the “evolution of competence” depicted on the slide is, in many critical aspects, far from complete.</p>
</section>
<section id="addressing-llm-limitations-the-imperative-of-validation-and-epistemic-agency" class="level2" data-number="8.2">
<h2 data-number="8.2" class="anchored" data-anchor-id="addressing-llm-limitations-the-imperative-of-validation-and-epistemic-agency"><span class="header-section-number">8.2</span> Addressing LLM Limitations: The Imperative of Validation and Epistemic Agency</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>Slide 3, titled “What is missing?”, critically examines fundamental limitations and necessary improvements for <em>Large Language Models</em> (LLMs). A primary concern is the pervasive issue of hallucination; the authors propose introducing an ‘Opponent to counter hallucination’ to ensure factual accuracy and reliability. Furthermore, the slide highlights a crucial conceptual misunderstanding, asserting that ‘Embedding vectors are NOT meanings of expressions’. This underscores the need for a deeper, more nuanced understanding of linguistic and semantic representation beyond mere statistical associations. These points collectively articulate the pressing need for LLMs to move beyond superficial linguistic generation towards grounded, verifiable knowledge.</p>
<p>Building upon these identified gaps, the slide prescribes vital ethical and epistemological directives for LLM development. These include strict adherence to truthfulness—“Do not formulate what sounds good but is false”—and a caution against uncritical dissemination: “Do not repeat what others put out as internet media.” Instead, the authors contend that LLMs must adhere to principles that guide them to “Seek what is best justified” and to “Make best plan for inquiry,” emphasising a commitment to reasoned thought and rigorous investigation. The presenter powerfully frames the overarching solution to these challenges as “validation,” positing it as the essential element for providing reasons, arguments, and evidence for or against the truth of a proposition, and critically, for or against the pursuit of actions.</p>
<p>To bridge this validation gap and foster genuine epistemic capabilities in LLMs, the presenter proposes a new discipline: <em>computational epistemology</em>. This emerging field aims to develop the methods and methodologies required to imbue AI with what the authors term “epistemic agency.” This crucial capability extends beyond mere sentence generation. It enables LLMs to identify propositions within complex texts, discern arguments in diverse sources (including historical inquiries), and interpret the intentions, plans, and actions of individuals documented within historical records. Ultimately, the authors aim to equip LLMs with the capacity for critical assessment and justified reasoning, moving them towards a more robust and ethically sound form of artificial intelligence.</p>
</section>
<section id="the-imperative-of-validation-and-epistemic-agency-in-computational-inquiry" class="level2" data-number="8.3">
<h2 data-number="8.3" class="anchored" data-anchor-id="the-imperative-of-validation-and-epistemic-agency-in-computational-inquiry"><span class="header-section-number">8.3</span> The Imperative of Validation and Epistemic Agency in Computational Inquiry</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The foundational premise of this discussion asserts that “Validation is all you need,” emphasising that any proposition or course of action necessitates robust support. Validation, in this context, extends beyond mere assertion; it demands comprehensive reasons, compelling arguments, and concrete evidence both for and against the truth of a statement, as well as for or against the pursuit of specific actions. This rigorous approach is intrinsically linked to the field of <em>Computational Epistemology</em>, which seeks to formalise and automate the processes of knowledge acquisition, justification, and reasoning. Central to this framework, the authors define <em>Epistemic Agency</em> as the capacity to identify propositions—moving beyond mere linguistic sentences to grasp underlying claims—engage in sophisticated argumentation, and comprehend the intentions, plans, and actions of individuals.</p>
<p>The authors apply this theoretical framework practically within a computational working environment designed to tackle complex inquiries. This is illustrated by a historical case study concerning the 18th-century construction of Sanssouci castle. A long-standing historical dispute revolves around the precise involvement of the renowned mathematician Leonhard Euler in this project and whether his contribution, or that of others, led to one of the biggest construction failures of the era. To address such open questions, the system provides an “inquiry window” where users can formulate precise questions, such as “Reconstruct which persons performed which work on the water fountain.” The objective is not merely to retrieve information, but to obtain a “validated answer”—a qualified, reliable response supported by proven evidence, free from hearsay.</p>
<p>To assist in these inquiries, the system employs an AI agent, presumptively named <em>Bernoulli</em>, which embodies the principles of epistemic agency. This agent navigates and processes vast quantities of historical sources, moving far beyond the limitations of simply reading a single PDF or relying on basic indexing and token matching. The true challenge lies in aggregating and intelligently synthesising information from all available sources to construct a coherent, evidence-based narrative. This computational approach aims to provide the depth of validation and analytical rigour demanded by the slide’s core premise, transforming intricate historical debates into computationally tractable and verifiable inquiries.</p>
</section>
<section id="the-foundational-role-of-curated-sources-in-digital-text-analysis" class="level2" data-number="8.4">
<h2 data-number="8.4" class="anchored" data-anchor-id="the-foundational-role-of-curated-sources-in-digital-text-analysis"><span class="header-section-number">8.4</span> The Foundational Role of Curated Sources in Digital Text Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Slide 5 visually presents a live demonstration of a sophisticated software application designed by the authors for digital humanities research. The interface on the left pane displays a historical document, specifically a text titled ‘Allerdurchlauchtigsten, Großmächtigsten König und Herrn Friedrich Wilhelm dem Zweiten König von Preußen’, indicating a focus on historical and archival materials. Complementing this, the right pane, labelled ‘Personen und Aufgaben in der Bibliothek’, showcases the platform’s capability for structured information extraction. It highlights entities such as ‘Nahl (Bildhauer)’, ‘Benkert und Heymüller’, and ‘Giese’, along with associated monetary values and actions. This demonstrates the software’s utility in uncovering specific details and relationships within complex historical narratives.</p>
<p>Crucial to the efficacy of such advanced digital analysis, as the presenter elaborates, is the underlying quality of the source material. The authors emphasise the involvement of a “scholarly curated editorial board which has worked on the sources” as a key component for successful scholarly work in this domain. This highlights that whilst digital tools provide powerful analytical capabilities, their output is only as reliable as the input data, necessitating meticulous human scholarship in preparing and verifying historical texts.</p>
<p>The <em>Opera Omnia</em> of Euler exemplifies the immense scale and dedication required for such foundational work. This monumental project, comprising 86 volumes, involved approximately 120 years of sustained effort by numerous scholars. It culminated in the complete editing of all Euler’s letters and 866 publications just two years prior. This rigorous, long-term scholarly endeavour in text preparation is fundamental, providing the high-fidelity, meticulously edited digital sources that enable the precise and insightful text analysis capabilities demonstrated by the application.</p>
</section>
<section id="scholarium-a-novel-platform-for-curated-validated-scholarly-content" class="level2" data-number="8.5">
<h2 data-number="8.5" class="anchored" data-anchor-id="scholarium-a-novel-platform-for-curated-validated-scholarly-content"><span class="header-section-number">8.5</span> Scholarium: A Novel Platform for Curated, Validated Scholarly Content</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The sixth slide introduces <em>Scholarium</em>, a pioneering platform designed by the authors as a comprehensive, curated scholarly database, distinct from conventional data embeddings. As highlighted by the presenter, this innovative system provides a structured, validated source for historical information, moving beyond typical data representation methods. The slide visually reinforces this by showcasing examples of meticulously curated scholarly works such as the <em>Opera Bernoulli Euler</em>, <em>Kepler Gesammelte Werke</em>, and <em>Brahe Opera Omnia</em>, underscoring the platform’s commitment to complete and authoritative historical records.</p>
<p><em>Scholarium</em>’s core strength lies in its ability to compile highly detailed, chronologically organised inventories of historically proven activities. The presenter elaborated on the depth of this curation, which encompasses chronologies of actions, expressions communicated between individuals, the evolving use of terminology and language by a person, and even the historical application of tools and material objects. This granular level of detail ensures a rich, contextually grounded understanding of historical figures and their contributions, all rigorously validated by primary sources and forming a very detailed inventory of historical records.</p>
<p>The visual component of the slide, featuring a screenshot of a digital library interface displaying ‘LEONHARD EULER BRIEFWECHSEL OPERA OMNIA SERIES QUARTA A: COMMERCIUM EPISTOLICUM VOL. I,’ exemplifies the practical application of <em>Scholarium</em>’s curated content. This screenshot perfectly illustrates how the platform provides direct access to meticulously organised and historically verified records, such as extensive correspondences, which are fundamental to academic research and understanding the intellectual lineage of historical thought.</p>
</section>
<section id="scholarium-a-registry-based-framework-for-structured-scholarly-content-and-multimodal-ai-inquiry" class="level2" data-number="8.6">
<h2 data-number="8.6" class="anchored" data-anchor-id="scholarium-a-registry-based-framework-for-structured-scholarly-content-and-multimodal-ai-inquiry"><span class="header-section-number">8.6</span> Scholarium: A Registry-Based Framework for Structured Scholarly Content and Multimodal AI Inquiry</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The authors introduce <em>Scholarium</em> as a novel framework centred on a registry-based approach for managing and curating scholarly content, explicitly positioning itself as an alternative to embedding-centric systems. This structured methodology supports a “Curated Scholarly Editorial Board,” implying a robust system for organising and validating academic contributions. The framework meticulously categorises various dimensions of scholarly work, including personal actions like communication acts (e.g., publications, reports), and the nuanced nature of statements (e.g., implications, arguments, inquiries). Furthermore, it captures the specific academic methodologies employed, detailing the use of language, terminology, concepts, relations, models, methods, tools, devices, data, information, evidence, and sources, thereby providing a granular and comprehensive record of scholarly endeavours.</p>
<p>To significantly enhance the utility of these precisely recorded elements, the authors integrate them with advanced artificial intelligence capabilities. The slide highlights the presence of both an AI API and a <em>Model Context Protocol</em> (MCP) API, as evidenced by the <em>Anthropic</em> webpage screenshot. This indicates a strategic design to enable programmatic interaction with sophisticated AI models, allowing for structured and context-aware inquiry into the amassed scholarly data. These “records,” once established, become readily queryable by accessible multimodal AI models.</p>
<p>Crucially, the presenter emphasises that such models, exemplified by the latest versions of <em>Gemini 2.5</em>, are particularly well-suited for the task due to their ability to seamlessly combine and process information from diverse modalities, including text and images. This multimodal capability is vital for effectively extracting insights and solving complex analytical requirements from the rich, categorised content stored within the <em>Scholarium</em> registry, thereby facilitating a deeper understanding and interaction with scholarly knowledge.</p>
</section>
<section id="the-ai-cockpit-user-interface-llm-integration-and-data-stewardship" class="level2" data-number="8.7">
<h2 data-number="8.7" class="anchored" data-anchor-id="the-ai-cockpit-user-interface-llm-integration-and-data-stewardship"><span class="header-section-number">8.7</span> The AI Cockpit: User Interface, LLM Integration, and Data Stewardship</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>Slide 8 introduces the <em>AI Cockpit</em>, which serves as the primary user interface for the system. It facilitates advanced document analysis and information extraction. As depicted on the left side of the slide, this interface boasts robust integration with a variety of leading <em>Large Language Models</em> (LLMs), including <em>Claude</em>, <em>Gemini</em>, <em>Llama</em>, and the specialised <em>LettreAI</em> on <em>Cursor</em>. This multi-model support ensures flexibility and powerful analytical capabilities for diverse document types and analytical tasks. The accompanying screenshot on the right visually demonstrates the <em>AI Cockpit</em>’s operational view, displaying a historical document such as ‘Manger1789.pdf’ alongside its associated analysis pane. This showcases the system’s ability to perform structured information extraction directly within the intuitive interface.</p>
<p>The data generated through the <em>AI Cockpit</em>’s powerful extraction capabilities necessitates a robust and sustainable strategy for storage and dissemination. To address this, the project team commits to adhering to FAIR (Findable, Accessible, Interoperable, Reusable) data principles. The authors have selected <em>Zenodo</em>, a repository hosted by CERN in Geneva, as their long-term solution for storing and publishing research data. This choice is critical for ensuring the longevity and broad accessibility of the valuable structured information extracted by the system.</p>
<p><em>Zenodo</em>’s infrastructure provides a reliable and persistent platform, enabling the hosting of these research data for many years. This thereby supports open science and facilitates future research and validation. This comprehensive approach, combining a sophisticated AI-powered user interface for data extraction with a dedicated, FAIR-compliant repository, establishes a complete pipeline for academic research data management, from initial processing to long-term preservation and publication.</p>
</section>
<section id="zenodo-enabling-fair-data-through-community-and-ai-ready-infrastructure" class="level2" data-number="8.8">
<h2 data-number="8.8" class="anchored" data-anchor-id="zenodo-enabling-fair-data-through-community-and-ai-ready-infrastructure"><span class="header-section-number">8.8</span> Zenodo: Enabling FAIR Data Through Community and AI-Ready Infrastructure</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>Slide 9, titled ‘FAIR Infrastructure,’ provides a concrete illustration of these principles through the <em>Zenodo</em> platform, prominently featured with its subtitle. <em>Zenodo</em> serves as a vital open repository that enables researchers to share and discover various types of research outputs, including datasets, publications, and software. As depicted in the accompanying screenshot, <em>Zenodo</em> facilitates community engagement and content discoverability through features such as ‘Featured communities,’ exemplified by ‘AAS Journals,’ which outlines specific publishing and community submission processes. The platform also highlights ‘Recent uploads,’ showcasing how new research outputs, such as the specific dataset “Wide spectral range optical characterization of terbium gallium garnet (TGG) single crystal by universal dispersion mode” uploaded by Franka, Daniel et al., become immediately available and discoverable to the wider scientific community.</p>
<p>Beyond its user-facing functionalities, dedicated technical expertise underpins the robust operation of such an infrastructure. Entities like <em>Open Science Technology</em>, a startup instrumental in maintaining the platform’s technical stability and evolving capabilities, provide this critical support. A significant development in this regard is the implementation of a <em>Model Context Protocol</em> (MCP) API server. This server specifically standardises the access of artificial intelligence models to the vast trove of data hosted on the platform, thereby facilitating worldwide inquiries and automated knowledge extraction. This forward-looking approach directly addresses the growing need for machine-actionable data, significantly enhancing the interoperability and reusability aspects of FAIR principles.</p>
<p>Whilst acknowledging the dynamic landscape of technological advancements, this initiative represents a proactive attempt to standardise AI access APIs for global scientific knowledge. This commitment to standardisation, coupled with an ethos of open collaboration, ensures that the infrastructure remains adaptable and accessible, not only for human users but also for emerging AI-driven research paradigms. By continually developing such sophisticated access mechanisms, <em>Zenodo</em> reinforces its role as a pivotal component in the evolving ecosystem of open science and FAIR data.</p>
</section>
<section id="opensciencetechnology-pillars-of-sustainable-digital-scholarship" class="level2" data-number="8.9">
<h2 data-number="8.9" class="anchored" data-anchor-id="opensciencetechnology-pillars-of-sustainable-digital-scholarship"><span class="header-section-number">8.9</span> OpenScienceTechnology: Pillars of Sustainable Digital Scholarship</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_008_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>Slide 10, “Technical Support: <em>OpenScienceTechnology</em>,” outlines the foundational principles governing the technical and operational philosophy of the presented scholarly support system. These principles—Open Source, Open Access, Open Data (supported by components like the <em>Model Context Protocol</em> (MCP) API Server), and Open Collaboration—are central to ensuring the longevity and utility of digital scholarly achievements. The speaker underscored the critical importance of a maintained infrastructure for scientific achievements, citing the 110-year legacy of the Euler edition as a testament to sustained scholarly work. This long-term perspective highlights the necessity of these open principles to prevent digital projects from “evaporating” once initial funding ceases, a prevalent issue in digital humanities.</p>
<p>A key aspect of this framework is the commitment to Open Access and Open Data, which directly addresses common pitfalls in digital scholarship. The speaker emphasised the proactive resolution of copyright issues, contrasting this with traditional publishing models that often impose exclusive rights, leading to project “dead ends.” This commitment ensures that valuable scholarly work remains accessible and usable for future research. Furthermore, the discussion on <em>computational epistemology</em> reinforced the need for ‘Open Data’ that is not merely available but also complete and structured. Whilst not inherently against unstructured texts, the system advocates for their use in a structured manner to facilitate precise and verifiable answers. This is particularly crucial for historical research where complete chronologies and negations demand robust, prepared data beyond the capabilities of current unstructured AI approaches like embeddings or RAG.</p>
<p>The principles of Open Source and Open Collaboration underpin the transferability and scalability of this approach across diverse scholarly domains. The speaker acknowledged the inherent friction between maintaining high quality and achieving broad scalability, suggesting that collaborative frameworks are essential to bridge this gap. The vision extends to developing <em>computational epistemology</em> where models can be explicitly instructed with rules for causal reasoning, propositional logic, and scientific experimental justification. This highlights how Open Collaboration in developing and applying such methodologies, coupled with careful data curation strategies for LLM applications, can enable more rigorous and reliable scholarly engagement with AI, ensuring that human expertise remains central whilst leveraging technological advancements. Ultimately, this comprehensive approach fosters a sustainable and ethically sound future for digital scholarship.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_007.html" class="pagination-link" aria-label="Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_009.html" class="pagination-link" aria-label="The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs">
        <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>