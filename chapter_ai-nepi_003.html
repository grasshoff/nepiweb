<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Arno Simons">
<meta name="dcterms.date" content="2025-06-21">

<title>3&nbsp; Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_004.html" rel="next">
<link href="./chapter_ai-nepi_001.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_003.html"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">LLM: Evolution of competence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#additional-visual-materials" id="toc-additional-visual-materials" class="nav-link" data-scroll-target="#additional-visual-materials"><span class="header-section-number">3.1</span> Additional Visual Materials</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Arno Simons </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            TU Berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter systematically explores Large Language Models (LLMs), detailing their foundational architectures, methods for domain adaptation, and specific applications within the History, Philosophy, and Sociology of Science (HPSS). The discussion commences by establishing a primer on LLMs, tracing their evolution from the seminal <em>Transformer</em> architecture, pioneered by Vaswani and colleagues in 2017, to specialised models such as <em>BERT</em> (Devlin et al., 2018) and <em>GPT</em> (Radford et al., 2018). The authors meticulously differentiate between encoder-based models, which offer bidirectional, full-context understanding, and decoder-based models, characterised by their unidirectional, generative capabilities, thereby highlighting their distinct strengths.</p>
<p>Subsequently, the chapter elucidates various strategies for adapting these models to specific scientific domains and tasks. These methods encompass pre-training, continued pre-training, fine-tuning for classification, prompt-based approaches, and contrastive learning, exemplified by <em>Sentence BERT</em>. The discussion then turns to advanced LLM systems, including Retrieval-Augmented Generation (<em>RAG</em>) pipelines and multi-LLM agents, which integrate multiple models and external tools to enhance performance and broaden their utility.</p>
<p>The chapter then delineates a comprehensive taxonomy of LLM applications pertinent to HPSS research, categorising them into four key areas: handling data and sources, analysing knowledge structures, understanding knowledge dynamics, and examining knowledge practices. Finally, the authors address critical challenges inherent in applying LLMs to HPSS, such as the historical evolution of concepts, the imperative for reconstructive and critical perspectives, and issues of data sparsity and multilingualism. The chapter concludes by advocating for increased LLM literacy, the development of shared datasets and benchmarks, and the strategic integration of LLM capabilities whilst preserving core HPSS methodologies, thereby fostering new opportunities for bridging qualitative and quantitative research.</p>
</section>
<section id="additional-visual-materials" class="level2" data-number="3.1">
<h2 data-number="3.1" class="anchored" data-anchor-id="additional-visual-materials"><span class="header-section-number">3.1</span> Additional Visual Materials</h2>
<p>The following slides provide supplementary visual information relevant to the presentation:</p>
<p><img src="images/ai-nepi_003_slide_02.png" class="img-fluid" alt="Slide 02"> This slide presents the chapter’s agenda, whimsically titled ‘Today’s Menu’. The title and the subsequent list of topics appear on a dark, chalkboard-like image, framed by a wooden easel, lending a rustic, inviting aesthetic. The listed sections of the presentation are: ‘Primer on LLMs’, ‘Applications in HPSS’, and ‘Reflections’. This structure indicates that the chapter will first introduce Large Language Models (LLMs), then discuss their specific applications within the History, Philosophy, and Sociology of Science (HPSS), and conclude with broader insights.</p>
<p><img src="images/ai-nepi_003_slide_03.png" class="img-fluid" alt="Slide 03"> This slide displays a comprehensive diagram of the <em>Transformer</em> model architecture, a foundational component of modern Large Language Models. Labelled ‘Figure 1: The <em>Transformer</em> - model architecture’, the diagram attributes this seminal work to Vaswani and colleagues (2017), referencing their paper, <em>Attention is all you need</em>. The architecture divides into two primary sections: an <em>Encoder</em> on the left and a <em>Decoder</em> on the right, both enclosed within a rounded rectangular outline. Arrows indicate data flow, commencing with ‘Words’ converting to ‘Numbers’ before entering the <em>Encoder</em>, and similarly from ‘Numbers’ to ‘Word(s)’ upon exiting the <em>Decoder</em>. Both <em>Encoder</em> and <em>Decoder</em> sections feature stacks of identical layers, denoted by ‘Nx’. Each layer in both sections incorporates ‘Multi-Head Attention’ mechanisms, ‘Add &amp; Norm’ operations, and ‘Feed Forward’ networks. The <em>Decoder</em> specifically includes ‘Masked Multi-Head Attention’ and accepts ‘Outputs (shifted right)’ as input, leading to ‘Output Probabilities’ via ‘Linear’ and ‘Softmax’ layers. ‘Input Embedding’ and ‘Positional Encoding’ are shown at the input stages for both <em>Encoder</em> and <em>Decoder</em>. The diagram visually elucidates how the <em>Transformer</em> processes input sequences and generates output sequences through attention mechanisms.</p>
<p><img src="images/ai-nepi_003_slide_04.png" class="img-fluid" alt="Slide 04"> This slide overlays the previous <em>Transformer</em> architecture diagram, maintaining the ‘Transformer’ title at the top. The primary alteration involves fading out the <em>Decoder</em> section of the diagram, along with its associated text labels, rendering it less prominent. Conversely, the <em>Encoder</em> section, encompassing its components such as ‘Input Embedding’, ‘Positional Encoding’, ‘Nx’ layers with ‘Multi-Head Attention’, ‘Add &amp; Norm’, and ‘Feed Forward’ blocks, remains fully visible and highlighted. The labels ‘Words -&gt; Numbers’ and ‘Inputs’ also retain their clarity. The caption ‘Figure 1: The <em>Transformer</em> - model architecture.’ and the citation ‘Vaswani et al.&nbsp;2017: Attention is all you need’ persist at the bottom. This visual emphasis directs attention specifically to the <em>Encoder</em>’s pivotal role and internal structure within the <em>Transformer</em> model.</p>
<p><img src="images/ai-nepi_003_slide_05.png" class="img-fluid" alt="Slide 05"> This slide continues the progressive revelation of the <em>Transformer</em> diagram, maintaining its focus on the <em>Encoder</em> section. A new, prominent <em>BERT</em> block now appears on the left, conceptually representing the <em>Encoder</em>. This <em>BERT</em> block is labelled ‘bidirectional full-context’ and incorporates internal components such as ‘LLMs for HPSS ?’ and ‘Vocab’, suggesting how domain-specific knowledge or applications might integrate. The <em>BERT</em> block also displays a grid-like structure, likely representing its internal layers or attention mechanisms. The original <em>Transformer Encoder</em> diagram, with its ‘Input Embedding’, ‘Positional Encoding’, and ‘Nx’ layers, remains visible to the right of the new <em>BERT</em> block, albeit slightly faded, indicating that the <em>BERT</em> block serves as a conceptual representation of the <em>Encoder</em>’s function. The <em>Decoder</em> section of the main <em>Transformer</em> diagram remains faded from the previous slide. A new citation, ‘Devlin et al.&nbsp;2018. <em>BERT</em>: Pre-training of…’, is added to the bottom left, alongside the original ‘Vaswani et al.&nbsp;2017’ citation, acknowledging the <em>BERT</em> model’s origin. The slide title ‘Transformer’ remains at the top, and the figure caption ‘Figure 1: The <em>Transformer</em> - model architecture.’ is positioned at the bottom centre.</p>
<p><img src="images/ai-nepi_003_slide_06.png" class="img-fluid" alt="Slide 06"> This slide duplicates the immediately preceding slide, preserving the identical visual state and textual content. The ‘Transformer’ title remains at the top. The <em>BERT</em> block, labelled ‘bidirectional full-context’ and containing ‘LLMs for HPSS ?’ and ‘Vocab’, is prominently displayed on the left, representing the <em>Encoder</em>. The detailed internal structure of the <em>Encoder</em> from the original <em>Transformer</em> diagram persists, albeit faded, positioned to the right of the <em>BERT</em> block. The <em>Decoder</em> section of the <em>Transformer</em> diagram remains faded. The citations ‘Devlin et al.&nbsp;2018. <em>BERT</em>: Pre-training of…’ and ‘Vaswani et al.&nbsp;2017: Attention is all you need’ are present at the bottom, alongside the figure caption ‘Figure 1: The <em>Transformer</em> - model architecture.’. This repetition suggests a deliberate pause or continued discussion on the <em>BERT</em> model’s role within the <em>Encoder</em> context before further modifications are introduced.</p>
<p><img src="images/ai-nepi_003_slide_07.png" class="img-fluid" alt="Slide 07"> This slide continues the incremental build-up of the <em>Transformer</em> diagram. The <em>BERT</em> block, representing the <em>Encoder</em> and labelled ‘bidirectional full-context’ with ‘LLMs for HPSS ?’ and ‘Vocab’, remains prominently displayed on the left. The detailed internal structure of the <em>Encoder</em> from the original <em>Transformer</em> diagram persists, albeit faded, to the right of the <em>BERT</em> block. The significant change on this slide is the full visibility and highlighting of the <em>Decoder</em> section of the main <em>Transformer</em> diagram, which was previously faded. This includes all its components: ‘Masked Multi-Head Attention’, ‘Add &amp; Norm’, ‘Feed Forward’, ‘Linear’, ‘Softmax’, ‘Output Probabilities’, ‘Outputs (shifted right)’, and the ‘Numbers -&gt; Word(s)’ flow. The slide title ‘Transformer’ remains at the top, and both citations, ‘Devlin et al.&nbsp;2018. <em>BERT</em>: Pre-training of…’ and ‘Vaswani et al.&nbsp;2017: Attention is all you need’, along with the figure caption ‘Figure 1: The <em>Transformer</em> - model architecture.’, are present at the bottom. This step re-introduces the full <em>Transformer</em> architecture whilst still emphasising the <em>BERT</em>-like <em>Encoder</em>.</p>
<p><img src="images/ai-nepi_003_slide_08.png" class="img-fluid" alt="Slide 08"> This slide presents the final, comprehensive comparison within the <em>Transformer</em> architecture, illustrating both <em>BERT</em> and <em>GPT</em> models. The ‘Transformer’ title remains at the top. On the left, the <em>BERT</em> block, representing the <em>Encoder</em>, is fully visible and labelled ‘bidirectional full-context’, including ‘LLMs for HPSS ?’ and ‘Vocab’ components. The original detailed <em>Encoder</em> diagram persists, albeit faded. On the right, a new <em>GPT</em> block is introduced, representing the <em>Decoder</em>, and is labelled ‘unidirectional generative’. This <em>GPT</em> block also includes ‘LLMs for HPSS ?’ and ‘Vocab’ components, along with a similar internal grid structure. The original detailed <em>Decoder</em> diagram persists, albeit faded, to the left of the new <em>GPT</em> block. The data flow arrows ‘Words -&gt; Numbers’ and ‘Numbers -&gt; Word(s)’ are clearly depicted for both sides. Three citations are now present at the bottom: ‘Devlin et al.&nbsp;2018. <em>BERT</em>: Pre-training of…’ for <em>BERT</em>, ‘Vaswani et al.&nbsp;2017: Attention is all you need’ for the core <em>Transformer</em>, and ‘Radford et al.&nbsp;2018. Improving Language…’ for <em>GPT</em>. The figure caption ‘Figure 1: The <em>Transformer</em> - model architecture.’ remains in the centre. This slide effectively contrasts the <em>Encoder</em>-only (<em>BERT</em>) and <em>Decoder</em>-only (<em>GPT</em>) applications of the <em>Transformer</em>, explaining their respective ‘bidirectional full-context’ and ‘unidirectional generative’ capabilities.</p>
<p><img src="images/ai-nepi_003_slide_09.png" class="img-fluid" alt="Slide 09"> This slide duplicates the previous one, displaying the complete comparative diagram of the <em>Transformer</em> architecture with specific implementations of <em>BERT</em> and <em>GPT</em>. The title ‘Transformer’ remains at the top. The left side features the <em>BERT</em> block, representing the <em>Encoder</em>, labelled ‘bidirectional full-context’ and including ‘LLMs for HPSS ?’ and ‘Vocab’. The original detailed <em>Encoder</em> diagram is faded behind it. The right side features the <em>GPT</em> block, representing the <em>Decoder</em>, labelled ‘unidirectional generative’ and also including ‘LLMs for HPSS ?’ and ‘Vocab’. The original detailed <em>Decoder</em> diagram is faded behind it. The data flow ‘Words -&gt; Numbers’ and ‘Numbers -&gt; Word(s)’ is shown. All three citations are present at the bottom: ‘Devlin et al.&nbsp;2018. <em>BERT</em>: Pre-training of…’, ‘Vaswani et al.&nbsp;2017: Attention is all you need’, and ‘Radford et al.&nbsp;2018. Improving Language…’. The figure caption ‘Figure 1: The <em>Transformer</em> - model architecture.’ is also present. This slide serves to reinforce the visual comparison of <em>BERT</em>’s encoder-based, bidirectional processing versus <em>GPT</em>’s decoder-based, unidirectional generative capabilities.</p>
<p><img src="images/ai-nepi_003_slide_10.png" class="img-fluid" alt="Slide 10"> This slide presents a detailed timeline chart, aptly titled ‘Scientific LLMs’, which showcases the development and release of various language models specifically designed for scientific text processing from 2018 to 2024. The y-axis delineates years, from 2018 at the bottom to 2024 at the top, whilst the x-axis categorises models by their architectural type: ‘Others’, ‘Enc-Dec.’ (Encoder-Decoder), ‘Decoders’, and ‘Encoders’. Each model is represented by a coloured bubble or label, with a legend indicating ‘Open-Source’ (white text on coloured background) and ‘Closed-Source’ (black text on white background). Numerous model names populate the timeline, including, but not limited to, <em>FLAIR</em>, <em>BERT</em>, <em>GPT2</em>, <em>RoBERTa</em>, <em>BioBERT</em>, <em>Clinical Flair</em>, <em>Galactica</em>, <em>BioGPT</em>, <em>OpenGPT</em>, <em>SciBERT</em>, <em>MatSciBERT</em>, <em>ChemBERTa</em>, <em>K2</em>, <em>Lightweight</em>, <em>BioOptimus</em>, <em>Med-PaLM</em>, <em>PubMedBERT</em>, <em>ClinicalLongformer</em>, <em>PubMedELECTRA</em>, <em>ChemBERTa-2</em>, <em>BioELECTRA</em>, and <em>ClinicalBERT</em>. This chart, sourced from Ho and colleagues’ 2024 survey, <em>A Survey of Pre-trained Language Models for Processing Scientific Text</em>, visually demonstrates the rapid proliferation of scientific LLMs and their architectural diversity over time.</p>
<p><img src="images/ai-nepi_003_slide_11.png" class="img-fluid" alt="Slide 11"> This slide, titled ‘Domain and task adaptation via training’, presents a conceptual overview of four distinct methods for adapting Large Language Models (LLMs) to specific domains and tasks. The slide is structured into four quadrants, each depicting a different adaptation strategy using simplified LLM block diagrams:</p>
<ul>
<li><p><em>Pretraining</em>: This section illustrates two LLM blocks, each featuring ‘Vocab’ and ‘LLMs for HPSS ?’ components, connected by a dotted line, implying a continuous learning process.</p></li>
<li><p><em>Extra Parameters</em>: This quadrant depicts two LLM blocks, each with ‘LLMs for HPSS ?’ and ‘Vocab’, augmented by additional ‘Extra Parameters’ boxes above them. These are labelled ‘Positive’, ‘Tool’, ‘Sentiment’, ‘NER’, and ‘Field’, suggesting the integration of task-specific layers.</p></li>
<li><p><em>Prompt Based</em>: This section features two LLM blocks with ‘Vocab’ and ‘LLMs for HPSS ?’, demonstrating how prompts such as ‘LLMs for HPSS [mask] / ?’ and ‘LLMs stands for’ guide the model, yielding outputs like ‘Yes’ and ‘Large Language Model’.</p></li>
<li><p><em>Contrastive</em>: This quadrant shows two ‘Pooling’ layers connected to LLM blocks, with a ‘Similarity’ score of ‘0.85’ indicated, representing methods that learn by comparing inputs.</p></li>
</ul>
<p>Each LLM block consistently includes ‘LLMs for HPSS ?’ and ‘Vocab’ labels, emphasising the application context. The diagrams employ simplified representations of neural network layers to convey the architectural modifications or input strategies for adaptation.</p>
<p><img src="images/ai-nepi_003_slide_12.png" class="img-fluid" alt="Slide 12"> This slide, titled ‘Domain and task adaptation via <em>RAG</em>’, illustrates the process of Retrieval-Augmented Generation. The diagram divides into two main conceptual phases: ‘Retrieval’ on the left and ‘Generation’ on the right. The ‘Retrieval’ section commences with ‘Documents’, represented by two LLM-like blocks labelled ‘Expert interviews are…’ and ‘Language models are…’, each connected to a ‘Pooling’ layer. A ‘Query’, originating from a thinking emoji icon and asking ‘What are LLMs?’, enters a ‘Pooling’ layer. This query then undergoes a ‘Similarity’ comparison (with values ‘0.1’ and ‘0.8’ indicated) against the pooled document representations, leading to a ‘Retrieved Document’. The ‘Generation’ section displays an LLM block with ‘Vocab’ and ‘LLMs are tools for…’ components. Both the ‘Retrieved Document’ and the original ‘Query’ (‘What are LLMs?’) feed into this generation block, which subsequently produces an output, indicated by ‘What are Language models are…’. The overall flow demonstrates how external knowledge, derived from documents, is retrieved based on a query and then utilised to augment the LLM’s generation process, thereby providing more informed and accurate responses. The thinking emoji at the bottom represents the user’s initial query.</p>
<p><img src="images/ai-nepi_003_slide_13.png" class="img-fluid" alt="Slide 13"> This slide, titled ‘Key distinctions’, provides a concise overview of important differentiating factors among Large Language Models (LLMs). This text-only slide organises these distinctions into four main categories, each accompanied by a brief explanation or examples:</p>
<ul>
<li><p><em>Architecture/Pretraining</em>: This distinction elaborates on the fundamental structural designs of <em>Transformer</em> models, encompassing ‘Encoder-based vs.&nbsp;Decoder-based vs.&nbsp;Encoder-Decoder-based’ architectures.</p></li>
<li><p><em>Fine-tuning</em>: Described as ‘Various strategies’, this category indicates the diverse approaches employed to adapt pre-trained models to specific tasks or datasets.</p></li>
<li><p><em>Embeddings</em>: This category differentiates between ‘Word vs.&nbsp;Sentence’ embeddings, highlighting the granularity at which text is numerically represented.</p></li>
<li><p><em>Level of abstraction</em>: This distinction considers LLMs at different operational scales, from ‘LLMs vs.&nbsp;Pipelines vs.&nbsp;Agents’, suggesting that LLMs can function as standalone models, integrate into multi-step workflows, or act as autonomous agents.</p></li>
</ul>
<p><img src="images/ai-nepi_003_slide_14.png" class="img-fluid" alt="Slide 14"> This slide, titled ‘Applications in HPSS’ (History, Philosophy, and Sociology of Science), provides a detailed breakdown of how Large Language Models can be applied within these academic fields. The applications are organised into four main categories, each with specific examples:</p>
<ul>
<li><p><em>Dealing with data and sources</em>: This includes ‘Parsing and extracting (publication types, acknowledgements, citations)’ for automated information retrieval, and ‘Interacting with sources (summarisation, <em>RAG</em>-type chatting)’ for dynamic engagement with textual data.</p></li>
<li><p><em>Knowledge structures</em>: This covers ‘Entity extraction (scientific instruments, celestial bodies, chemicals)’ for identifying specific concepts or objects, and ‘Mappings (disciplines, interdisciplinary fields, science-policy discourses)’ for understanding relationships between academic domains.</p></li>
<li><p><em>Knowledge dynamics</em>: This section focuses on ‘Conceptual histories (“theory” in DH, “virtual” and “Planck” in physics)’ for tracking concept evolution, and ‘Novelty (breakthrough papers, emerging technologies)’ for identifying innovation.</p></li>
<li><p><em>Knowledge practices</em>: This final category includes ‘Argument reconstruction (premises &amp; conclusions, causality)’ for analysing logical structures, ‘Citation context analysis (purpose, sentiment)’ for understanding scholarly referencing, and ‘Discourse analysis (hedge sentences, jargon, boundary work)’ for examining social and rhetorical aspects of scientific communication.</p></li>
</ul>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_001.html" class="pagination-link" aria-label="Large Language Models for the History, Philosophy, and Sociology of Science">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_004.html" class="pagination-link" aria-label="Introducing OpenAlex Mapper">
        <span class="nav-page-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>