<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francis Lareau &amp; Christophe Malaterre">

<title>14&nbsp; Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_017.html" rel="next">
<link href="./chapter_ai-nepi_015.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_016.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Solutions for Academic Information Retrieval: The Ghostwriter and EverythingData Approach</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#research-question-and-methodological-approach" id="toc-research-question-and-methodological-approach" class="nav-link" data-scroll-target="#research-question-and-methodological-approach"><span class="header-section-number">14.1</span> Research Question and Methodological Approach</a></li>
  <li><a href="#material-astrobiology-corpus-for-qualitative-comparison" id="toc-material-astrobiology-corpus-for-qualitative-comparison" class="nav-link" data-scroll-target="#material-astrobiology-corpus-for-qualitative-comparison"><span class="header-section-number">14.2</span> Material: Astrobiology Corpus for Qualitative Comparison</a></li>
  <li><a href="#methodology-quantitative-analysis-metrics" id="toc-methodology-quantitative-analysis-metrics" class="nav-link" data-scroll-target="#methodology-quantitative-analysis-metrics"><span class="header-section-number">14.3</span> Methodology: Quantitative Analysis Metrics</a></li>
  <li><a href="#results-adjusted-rand-index-between-topic-models" id="toc-results-adjusted-rand-index-between-topic-models" class="nav-link" data-scroll-target="#results-adjusted-rand-index-between-topic-models"><span class="header-section-number">14.4</span> Results: Adjusted Rand Index Between Topic Models</a></li>
  <li><a href="#results-lda-full-text-versus-abstracts-and-titles" id="toc-results-lda-full-text-versus-abstracts-and-titles" class="nav-link" data-scroll-target="#results-lda-full-text-versus-abstracts-and-titles"><span class="header-section-number">14.5</span> Results: LDA Full-text Versus Abstracts and Titles</a></li>
  <li><a href="#results-bertopic-full-text-versus-abstracts-and-titles" id="toc-results-bertopic-full-text-versus-abstracts-and-titles" class="nav-link" data-scroll-target="#results-bertopic-full-text-versus-abstracts-and-titles"><span class="header-section-number">14.6</span> Results: BERTopic Full-text Versus Abstracts and Titles</a></li>
  <li><a href="#results-lda---comparing-top-words" id="toc-results-lda---comparing-top-words" class="nav-link" data-scroll-target="#results-lda---comparing-top-words"><span class="header-section-number">14.7</span> Results: LDA - Comparing Top-words</a></li>
  <li><a href="#results-bertopic---comparing-top-words" id="toc-results-bertopic---comparing-top-words" class="nav-link" data-scroll-target="#results-bertopic---comparing-top-words"><span class="header-section-number">14.8</span> Results: BERTopic - Comparing Top-words</a></li>
  <li><a href="#results-of-quantitative-analysis-coherence" id="toc-results-of-quantitative-analysis-coherence" class="nav-link" data-scroll-target="#results-of-quantitative-analysis-coherence"><span class="header-section-number">14.9</span> Results of Quantitative Analysis: Coherence</a></li>
  <li><a href="#results-of-quantitative-analysis-diversity" id="toc-results-of-quantitative-analysis-diversity" class="nav-link" data-scroll-target="#results-of-quantitative-analysis-diversity"><span class="header-section-number">14.10</span> Results of Quantitative Analysis: Diversity</a></li>
  <li><a href="#results-of-quantitative-analysis-joint-recall" id="toc-results-of-quantitative-analysis-joint-recall" class="nav-link" data-scroll-target="#results-of-quantitative-analysis-joint-recall"><span class="header-section-number">14.11</span> Results of Quantitative Analysis: Joint Recall</a></li>
  <li><a href="#summary-of-model-performance" id="toc-summary-of-model-performance" class="nav-link" data-scroll-target="#summary-of-model-performance"><span class="header-section-number">14.12</span> Summary of Model Performance</a></li>
  <li><a href="#discussion-and-conclusion" id="toc-discussion-and-conclusion" class="nav-link" data-scroll-target="#discussion-and-conclusion"><span class="header-section-number">14.13</span> Discussion and Conclusion</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Francis Lareau &amp; Christophe Malaterre <a href="mailto:francislareau@hotmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Université du Québec à Montréal; Université de Sherbrooke; CIRST
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This chapter details a comparative study assessing the efficacy of <em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em> models when applied to distinct textual levels: titles, abstracts, and full texts within a scientific corpus. The authors aimed to ascertain whether topic modelling on titles or abstracts suffices, or if full-text analysis remains indispensable, particularly given the substantial resources required for its processing.</p>
<p>Their methodology involved constituting a corpus of scientific articles, segmenting these into titles, abstracts, and full texts, and subsequently applying both <em>LDA</em> and <em>BERTopic</em> approaches. A comprehensive analysis, encompassing both qualitative and quantitative methods, facilitated the comparison of the resulting topic models. Key quantitative metrics included the <em>Adjusted Rand Index</em>, <em>Topic Diversity</em>, <em>Joint Recall</em>, and <em>Coherence CV</em>.</p>
<p>The authors’ findings indicate that title-based models generally exhibit poor performance, whilst abstract models consistently demonstrate robust and meaningful topic extraction, often aligning well with full-text models. Full-text models, whilst offering comprehensive coverage, can present challenges such as loosely defined topics or class-size imbalances, particularly with <em>BERTopic</em>. Ultimately, the study recommends employing topic modelling on abstracts or full texts with either <em>LDA</em> or <em>BERTopic</em>, provided such approaches do not lead to misclassification of relevant documents.</p>
</section>
<section id="research-question-and-methodological-approach" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="research-question-and-methodological-approach"><span class="header-section-number">14.1</span> Research Question and Methodological Approach</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>This research addresses a critical inquiry: whether applying topic modelling solely to titles or abstracts suffices, or if full-text analysis remains an indispensable requirement. This question gains particular urgency given the substantial resources demanded for the acquisition, preprocessing, and subsequent analysis of extensive full-text corpora.</p>
<p>To investigate this, the authors meticulously constituted a corpus of scientific articles. They then systematically identified and segmented the title, abstract, and full-text sections from each article. Subsequently, they applied two prominent topic modelling approaches—<em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em>—to each of these textual levels. The resulting topic models underwent rigorous analysis and comparison, employing both qualitative and quantitative methodologies.</p>
<p>The overall workflow involved segmenting the scientific corpus into titles, abstracts, and full texts. Each segment then served as input for both <em>LDA</em> and <em>BERTopic</em> models. The outputs from these models were then subjected to both qualitative and quantitative scrutiny. This comprehensive approach aimed to provide robust insights into the comparative performance of these models across different textual granularities.</p>
<p>Beyond this specific investigation, topic modelling itself stands as a vital analytical instrument for processing vast scientific literature, especially within the history, philosophy, and sociology of science. Historically, researchers have deployed topic modelling for diverse tasks, including discerning research trends and paradigm shifts, identifying thematic substructures and interrelationships, and charting the evolution of scientific vocabulary. These prior applications have consistently involved various textual structures, ranging from titles and abstracts to complete full texts.</p>
</section>
<section id="material-astrobiology-corpus-for-qualitative-comparison" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="material-astrobiology-corpus-for-qualitative-comparison"><span class="header-section-number">14.2</span> Material: Astrobiology Corpus for Qualitative Comparison</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The authors grounded this study in an extensive topic analysis of an astrobiology corpus, previously detailed by Malaterre and Lareau in 2023. Following a thorough evaluation process, they selected a full-text <em>LDA</em> model comprising 25 distinct topics as the primary material for comparison.</p>
<p>Their analysis of these 25 topics involved a meticulous examination of their most representative words and documents, enabling the authors to assign a descriptive name to each topic based on its key terms. Subsequently, they compared the topics by calculating their mutual correlation, a metric derived from the topics’ presence within the documents. A community detection algorithm then identified four thematic clusters, designated by letters A, B, C, and D, and visually distinguished by red, green, yellow, and blue colours, respectively.</p>
<p>A graphical representation visually conveys these findings, illustrating the correlations amongst the 25 topics. This graph incorporates topic labels and the colour variations corresponding to their thematic clusters. Crucially, the thickness of the lines connecting topics denotes the strength of their correlation, whilst the size of each circle reflects the topic’s overall prevalence across all documents. This comprehensive analytical framework enables a robust qualitative comparison of the six distinct topic models under investigation.</p>
</section>
<section id="methodology-quantitative-analysis-metrics" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="methodology-quantitative-analysis-metrics"><span class="header-section-number">14.3</span> Methodology: Quantitative Analysis Metrics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>For the quantitative dimension of this study, the authors employed four distinct metrics to compare the various topic models. Firstly, the <em>Adjusted Rand Index</em> (<em>ARI</em>) served to evaluate the similarity between two document clusterings, with a correction applied for chance agreement. This metric precisely quantifies the extent to which documents cluster together, or diverge, across different models.</p>
<p>Secondly, <em>Topic Diversity</em> assessed the proportion of distinct top words, thereby determining whether individual topics within a given model were characterised by unique vocabulary. Thirdly, <em>Joint Recall</em> measured the average document-topic recall in relation to any topic’s top words, evaluating how effectively these top words collectively represented the documents assigned to each topic. Finally, <em>Coherence CV</em>, calculated as the average cosine relative distance between top words within topics, provided an assessment of whether these top words formed a semantically meaningful grouping. Each of these metrics is underpinned by specific mathematical formulations, ensuring rigorous quantitative comparison.</p>
</section>
<section id="results-adjusted-rand-index-between-topic-models" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="results-adjusted-rand-index-between-topic-models"><span class="header-section-number">14.4</span> Results: Adjusted Rand Index Between Topic Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The <em>Adjusted Rand Index</em> (<em>ARI</em>) provides crucial insights into the similarities amongst the six topic models. A value of zero for this metric indicates a clustering equivalent to random assignment. Analysis of the heatmap reveals that the <em>LDA</em> model applied to titles stands out as the most distinct, consistently demonstrating poor similarity with all other models, as evidenced by <em>ARI</em> values below 0.20, depicted by yellow hues in the visualisation.</p>
<p>Conversely, the remaining models generally exhibit a superior overall match, with <em>ARI</em> values consistently exceeding 0.20. Notably, <em>BERTopic</em> models display a stronger internal correspondence, with their inter-model <em>ARI</em> values typically surpassing 0.35. The <em>BERTopic</em> abstract model emerges as particularly central within this network of similarities, demonstrating robust correspondence with every other model, apart from the outlier <em>LDA</em> title model, with values consistently above 0.30. The heatmap visually encapsulates these relationships, where warmer colours signify higher degrees of similarity between the compared topic models.</p>
</section>
<section id="results-lda-full-text-versus-abstracts-and-titles" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="results-lda-full-text-versus-abstracts-and-titles"><span class="header-section-number">14.5</span> Results: LDA Full-text Versus Abstracts and Titles</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>A more granular analysis of the <em>LDA</em> models provides detailed insights into their interrelationships. Table A, which compares the <em>LDA</em> full-text model with the <em>LDA</em> abstract model, indicates a generally good overall fit. This strong correspondence is evident from the reddish diagonal in the table, signifying that each topic from one model typically aligns with a topic from the other, sharing a high proportion of common documents.</p>
<p>However, this alignment is not without dynamic shifts. Three full-text <em>LDA</em> topics effectively disappear, represented by long horizontal dark grey lines. Conversely, three full-text topics fragment into multiple topics within the abstract model, visible as short horizontal dark grey lines. The abstract model also sees the emergence of three entirely new topics, marked by long vertical dark grey lines, whilst three topics arise from mergers, again indicated by short horizontal dark grey lines. Furthermore, one small class, comprising fewer than 50 documents, is discernible within the abstract topics.</p>
<p>In stark contrast, Table B, comparing the <em>LDA</em> full-text model with the <em>LDA</em> title model, reveals a poor overall fit. This disparity necessitates substantial reorganisation, manifested by a proliferation of vertical and horizontal dark lines across the table. This indicates that numerous full-text topics vanish, whilst a considerable number of new abstract topics emerge, highlighting a significant divergence in thematic representation.</p>
</section>
<section id="results-bertopic-full-text-versus-abstracts-and-titles" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="results-bertopic-full-text-versus-abstracts-and-titles"><span class="header-section-number">14.6</span> Results: BERTopic Full-text Versus Abstracts and Titles</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>Analysis of the <em>BERTopic</em> models, when compared against the <em>LDA</em> full-text baseline, reveals varied performance. Table C, which juxtaposes <em>LDA</em> full-text with <em>BERTopic</em> full-text, indicates an average overall fit. Within this comparison, eight <em>LDA</em> topics vanish along the horizontal axis, whilst six <em>LDA</em> topics fragment into the <em>BERTopic</em> model. Conversely, the vertical axis shows the emergence of five new <em>BERTopic</em> topics, with one topic resulting from mergers. A notable observation from the total document count is the presence of four small classes alongside one exceptionally large class.</p>
<p>Moving to Table D, the comparison between <em>LDA</em> full-text and <em>BERTopic</em> abstract demonstrates a relatively good overall fit. Here, four <em>LDA</em> topics disappear, whilst six topics undergo splitting. The vertical axis reveals two new <em>BERTopic</em> topics appearing and four topics resulting from mergers. Crucially, this model maintains balanced class sizes.</p>
<p>Finally, Table E, comparing <em>LDA</em> full-text with <em>BERTopic</em> title, again indicates an average overall fit. In this instance, seven <em>LDA</em> topics disappear, and one topic splits. The vertical axis shows seven new <em>BERTopic</em> topics emerging, with one topic resulting from a merger. The total document count for this model highlights three small classes and one large class. These heatmaps collectively illustrate the proportions of shared documents between topics across these diverse model comparisons.</p>
</section>
<section id="results-lda---comparing-top-words" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="results-lda---comparing-top-words"><span class="header-section-number">14.7</span> Results: LDA - Comparing Top-words</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>An examination of the top words within the <em>LDA</em> models revealed that topics were generally well-formed across all iterations. The authors observed several robust topics that maintained strong correspondence across the full-text, abstract, and title models. The topic “A-Radiation-spore” serves as a prime example of this consistency.</p>
<p>Conversely, certain topics from the full-text model fragmented into multiple, more granular topics within both the abstract and title models. For instance, the splitting of “A-Life-civilization” proved semantically coherent, yielding a broader topic encompassing research in astrobiology. However, the fragmentation of “B-Chemistry” presented a more ambiguous case, necessitating further analysis for clear interpretation.</p>
<p>Furthermore, the study identified instances where topics from the full-text model coalesced into new, merged topics within the abstract and title models. A notable example is the merger of “B-Amino-acid” and “B-Protein-gene-rna” in the <em>LDA</em> abstract model. This particular consolidation formed a more general topic, which aligns logically with the underlying subject matter. The visual representation provides side-by-side tables illustrating the top words for selected topics across these <em>LDA</em> models.</p>
</section>
<section id="results-bertopic---comparing-top-words" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="results-bertopic---comparing-top-words"><span class="header-section-number">14.8</span> Results: BERTopic - Comparing Top-words</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>Continuing the assessment of top words, the three <em>BERTopic</em> models also yielded relatively well-formed topics. The robustness of “A-Radiation-spore” persisted across all models, including <em>LDA</em> Full-text, <em>BERTopic</em> Full-text, <em>BERTopic</em> Abstract, and <em>BERTopic</em> Title, underscoring its consistent thematic representation.</p>
<p>Whilst “A-Life-civilization” generally maintained its stability across the <em>BERTopic</em> models, it exhibited some instances of splitting. This fragmentation led to the emergence of more narrowly defined topics specifically pertaining to extraterrestrial life. Similarly, the “B-Chemistry” topic also underwent splitting across the <em>BERTopic</em> models, resulting in a series of more focused thematic areas. The visual data provides comparative tables of top words from selected topics across these models.</p>
</section>
<section id="results-of-quantitative-analysis-coherence" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="results-of-quantitative-analysis-coherence"><span class="header-section-number">14.9</span> Results of Quantitative Analysis: Coherence</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The coherence metric, specifically <em>Coherence CV</em>, provides a quantitative assessment of the semantic meaningfulness of the top words within each topic. Across a range of topics from 5 to 50, distinct patterns emerged. Models based on titles consistently exhibited the poorest coherence. Conversely, abstract models demonstrably outperformed full-text models in this regard.</p>
<p>Furthermore, <em>BERTopic</em> models generally achieved superior coherence compared to <em>LDA</em>, particularly for abstract and title-based analyses. However, this performance differential tended to diminish as the number of topics increased, indicating a convergence in coherence scores at higher topic counts. Ultimately, the <em>BERTopic</em> abstract model unequivocally emerged as the leading performer in terms of topic coherence. A line graph visually represents these trends, plotting the <em>Coherence CV</em> for each of the six models against varying numbers of topics.</p>
</section>
<section id="results-of-quantitative-analysis-diversity" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="results-of-quantitative-analysis-diversity"><span class="header-section-number">14.10</span> Results of Quantitative Analysis: Diversity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Regarding the diversity of top words characterising the topics, a clear trend emerged: diversity generally diminishes as the number of topics increases. Within this context, models derived from titles consistently offered the highest diversity, surpassing their abstract or full-text counterparts.</p>
<p>Moreover, <em>BERTopic</em> models demonstrated superior diversity compared to <em>LDA</em> across the board. The <em>BERTopic</em> title model ultimately emerged as the top performer in terms of diversity, with the <em>BERTopic</em> full-text model closely trailing. A line graph visually illustrates these diversity trends for each of the six models across varying topic counts.</p>
</section>
<section id="results-of-quantitative-analysis-joint-recall" class="level2" data-number="14.11">
<h2 data-number="14.11" class="anchored" data-anchor-id="results-of-quantitative-analysis-joint-recall"><span class="header-section-number">14.11</span> Results of Quantitative Analysis: Joint Recall</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>The <em>Joint Recall</em> metric assesses the efficacy with which the top words collectively represent every document assigned to a given topic. Analysis revealed that models based on titles consistently yielded the poorest recall. Conversely, full-text models demonstrated superior performance compared to their abstract and title counterparts.</p>
<p>In terms of algorithmic performance, <em>LDA</em> models generally exhibited better <em>Joint Recall</em> than <em>BERTopic</em>. The <em>LDA</em> full-text and <em>BERTopic</em> full-text models emerged as the leading performers in this category, with the <em>BERTopic</em> abstract model following very closely behind. A line graph visually depicts the micro <em>Joint Recall</em> for each of the six models across a range of topic numbers.</p>
</section>
<section id="summary-of-model-performance" class="level2" data-number="14.12">
<h2 data-number="14.12" class="anchored" data-anchor-id="summary-of-model-performance"><span class="header-section-number">14.12</span> Summary of Model Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>The authors compiled the individual assessment results to offer a holistic perspective on the models’ performance. For each criterion—overall fit, top-words, coherence, diversity, and joint recall—a circular representation indicates performance: a black circle denotes the highest score, a white circle signifies a lesser score, and a half-black, half-white circle indicates intermediate performance. Crucially, the study underscores that no single model emerges as universally superior; rather, diverse research objectives inherently dictate varying needs and, consequently, different model choices.</p>
<p>For instance, if the primary objective involves the discovery of main topics without stringent requirements for precise document classification, then issues such as poor recall or large class sizes might be acceptable. In such scenarios, the <em>BERTopic</em> Full-text model performed commendably, albeit with some observed class imbalance. Similarly, whilst far from optimal, the <em>BERTopic</em> Title model did yield certain robust topics that were consistently identified across other models.</p>
<p>Conversely, if the aim is to achieve maximum document coverage across all topics, then neither <em>BERTopic</em> Full-text nor <em>BERTopic</em> Title is recommended, as both approaches lead to large document classes and, in the case of <em>BERTopic</em> Title, poor recall. Furthermore, the <em>LDA</em> Title model receives a general non-recommendation due to its consistently poor performance across nearly all assessments. In essence, the study advocates for conducting topic modelling on either abstracts or full texts, employing either <em>LDA</em> or <em>BERTopic</em>, provided that such applications do not result in the misclassification of documents pertinent to specific topics.</p>
</section>
<section id="discussion-and-conclusion" class="level2" data-number="14.13">
<h2 data-number="14.13" class="anchored" data-anchor-id="discussion-and-conclusion"><span class="header-section-number">14.13</span> Discussion and Conclusion</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>This research yields several pivotal findings. Firstly, title models consistently exhibit poor performance, primarily attributable to the inherent lack of information within titles, which can consequently lead to erroneous document classification. Nevertheless, the <em>BERTopic</em> title model, surprisingly, generated numerous meaningful topics, suggesting that future efforts might focus on striking a balance between precisely defined topics and comprehensive document coverage.</p>
<p>Secondly, full-text models occasionally encounter difficulties in processing vast quantities of information. With <em>LDA</em>, topics can become more broadly defined and encompass wider coverage, potentially including secondary or transverse themes such as methodologies. Conversely, <em>BERTopic</em>, when applied to full texts, can produce overly narrow topics, resulting in inadequate document coverage and issues with class size.</p>
<p>Thirdly, abstract models consistently demonstrate strong performance with summary information. Their results align remarkably well with the <em>LDA</em> full-text model, as well as with both <em>LDA</em> and <em>BERTopic</em> abstract models. This consistency underscores their utility in capturing core thematic content.</p>
<p>Fourthly, the study highlights the notable robustness of topics. Across the board, the authors identified highly similar topics, a finding that facilitates the application of meta-analytic methods to pinpoint the most enduring and robust themes. Moreover, this consistency suggests the potential for employing relative distance metrics across models to identify an optimal solution; in this study, the <em>BERTopic</em> abstract model emerged as such an optimum, performing exceptionally well across all other metrics.</p>
<p>Finally, the findings prompt a consideration of new model development. It appears feasible and potentially beneficial to leverage the structural information inherent in documents—specifically, full text, abstract, and title—to extract more semantically rich sets of top words or topics.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Quantum gravity and plural pursuit in science">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_017.html" class="pagination-link" aria-label="Time-aware large language models towards a novel architecture for historical analysis">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>