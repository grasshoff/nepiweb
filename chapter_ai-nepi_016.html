<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francis Lareau &amp; Christophe Malaterre">
<meta name="dcterms.date" content="2025-01-01">

<title>14&nbsp; Text Granularity and Topic Model Performance – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_017.html" rel="next">
<link href="./chapter_ai-nepi_015.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_016.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">—</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Chatting with Papers</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems in Philosophy and HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">LLMs for Chemical Knowledge Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Interpretable Models for Linguistic Change</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">LLM for HPS Studies: Analyzing the NHGRI Archive</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#text-granularity-and-topic-model-performance" id="toc-text-granularity-and-topic-model-performance" class="nav-link active" data-scroll-target="#text-granularity-and-topic-model-performance"><span class="header-section-number">15</span> Text Granularity and Topic Model Performance</a>
  <ul class="collapse">
  <li><a href="#overview" id="toc-overview" class="nav-link" data-scroll-target="#overview"><span class="header-section-number">15.1</span> Overview</a></li>
  <li><a href="#introduction" id="toc-introduction" class="nav-link" data-scroll-target="#introduction"><span class="header-section-number">15.2</span> Introduction</a></li>
  <li><a href="#study-design" id="toc-study-design" class="nav-link" data-scroll-target="#study-design"><span class="header-section-number">15.3</span> Study Design</a></li>
  <li><a href="#topic-modeling-approaches" id="toc-topic-modeling-approaches" class="nav-link" data-scroll-target="#topic-modeling-approaches"><span class="header-section-number">15.4</span> Topic Modeling Approaches</a></li>
  <li><a href="#material-and-qualitative-analysis" id="toc-material-and-qualitative-analysis" class="nav-link" data-scroll-target="#material-and-qualitative-analysis"><span class="header-section-number">15.5</span> Material and Qualitative Analysis</a></li>
  <li><a href="#quantitative-metrics" id="toc-quantitative-metrics" class="nav-link" data-scroll-target="#quantitative-metrics"><span class="header-section-number">15.6</span> Quantitative Metrics</a></li>
  <li><a href="#adjusted-rand-index-results" id="toc-adjusted-rand-index-results" class="nav-link" data-scroll-target="#adjusted-rand-index-results"><span class="header-section-number">15.7</span> Adjusted Rand Index Results</a></li>
  <li><a href="#lda-model-comparison" id="toc-lda-model-comparison" class="nav-link" data-scroll-target="#lda-model-comparison"><span class="header-section-number">15.8</span> LDA Model Comparison</a></li>
  <li><a href="#bertopic-model-comparison" id="toc-bertopic-model-comparison" class="nav-link" data-scroll-target="#bertopic-model-comparison"><span class="header-section-number">15.9</span> BERTopic Model Comparison</a></li>
  <li><a href="#comparing-top-words" id="toc-comparing-top-words" class="nav-link" data-scroll-target="#comparing-top-words"><span class="header-section-number">15.10</span> Comparing Top Words</a></li>
  <li><a href="#coherence-diversity-and-joint-recall-results" id="toc-coherence-diversity-and-joint-recall-results" class="nav-link" data-scroll-target="#coherence-diversity-and-joint-recall-results"><span class="header-section-number">15.11</span> Coherence, Diversity, and Joint Recall Results</a></li>
  <li><a href="#model-performance-summary" id="toc-model-performance-summary" class="nav-link" data-scroll-target="#model-performance-summary"><span class="header-section-number">15.12</span> Model Performance Summary</a></li>
  <li><a href="#discussion-and-future-directions" id="toc-discussion-and-future-directions" class="nav-link" data-scroll-target="#discussion-and-future-directions"><span class="header-section-number">15.13</span> Discussion and Future Directions</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Text Granularity and Topic Model Performance</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Francis Lareau &amp; Christophe Malaterre <a href="mailto:francislareau@hotmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Université du Québec à Montréal; Université de Sherbrooke; CIRST
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  
<div>
  <div class="abstract">
    <div class="block-title">Abstract</div>
    <p>This study investigates the impact of text granularity (titles, abstracts, full-texts) on the performance of two distinct topic modeling approaches, Latent Dirichlet Allocation (LDA) and BERTopic. The research addresses the practical challenge of significant resource requirements for obtaining, preprocessing, and analyzing full-text corpora by comparing topic models derived from different text levels. A corpus of scientific articles in Astrobiology serves as the material. Six topic models…</p>
  </div>
</div>


</header>


<section id="text-granularity-and-topic-model-performance" class="level1" data-number="15">
<h1 data-number="15"><span class="header-section-number">15</span> Text Granularity and Topic Model Performance</h1>
<section id="overview" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="overview"><span class="header-section-number">15.1</span> Overview</h2>
<p>This study investigates the impact of text granularity (titles, abstracts, full-texts) on the performance of two distinct topic modeling approaches: <em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em>. The research addresses the practical challenge of significant resource requirements for obtaining, preprocessing, and analyzing full-text corpora by comparing topic models derived from different text levels.</p>
<p>A corpus of scientific articles in Astrobiology serves as the material for this study. Six topic models are generated: <em>LDA</em> on titles, abstracts, and full-texts, and <em>BERTopic</em> on titles, abstracts, and full-texts. These models are then analyzed and compared qualitatively and quantitatively using metrics such as Adjusted Rand Index, Topic Diversity, Joint Recall, and Coherence CV.</p>
<p>The qualitative analysis involves comparing topic coherence and the stability of topics across models, referencing a previously established <em>LDA</em> full-text model with 25 topics and 4 thematic clusters. Quantitative results indicate that title-based models generally perform poorly, while abstract models show better coherence and diversity. Full-text models demonstrate superior joint recall.</p>
<p>Specifically, <em>BERTopic</em> Abstract emerges as a strong performer in coherence, and <em>BERTopic</em> Title in diversity, while <em>LDA</em> Fulltext and <em>BERTopic</em> Fulltext excel in joint recall. The study concludes that the optimal choice of text level and topic model depends on specific research objectives. Abstract-based models offer a good balance and consistency with full-text models, while title-based models, despite limitations, can identify robust core topics. The potential for leveraging structural information (titles, abstracts, full-texts) in future models is also discussed.</p>
</section>
<section id="introduction" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="introduction"><span class="header-section-number">15.2</span> Introduction</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>This presentation is delivered by Francis Lareau, a Postdoctoral Fellow affiliated with the University of Sherbrooke and the University of Quebec in Montreal (UQAM). This work is a comparative study conducted with Christophe Malaterre from the University of Quebec in Montreal.</p>
<p>The study focuses on topic modeling, a technique for extracting themes from a corpus. Topic modeling is recognized as an important tool for analyzing large volumes of scientific literature, especially within the history, philosophy, and sociology of science (HPSS).</p>
<p>A problem arises because existing studies utilize different textual structures for topic modeling, namely titles, abstracts, and full text. Obtaining, preprocessing, and analyzing full-text corpora demand significant resources. This prompts the central research question: Is applying topic modeling to titles or abstracts sufficient, or is full-text analysis necessary?</p>
</section>
<section id="study-design" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="study-design"><span class="header-section-number">15.3</span> Study Design</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_02.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>This study addresses the pressing question of whether analyzing titles or abstracts is sufficient for topic modeling, given the substantial resources needed for full-text corpora acquisition, preprocessing, and analysis. The methodology involves a structured workflow.</p>
<p>First, a corpus of scientific articles is constituted. Second, the distinct title, abstract, and full text sections are identified within this corpus. Third, two different topic modeling approaches, <em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em>, are applied separately to each of the three identified text levels: titles, abstracts, and full texts.</p>
<p>This process generates a total of six distinct topic models. Finally, these six resulting topic models undergo both qualitative and quantitative analysis and comparison to evaluate their performance across the different text levels.</p>
</section>
<section id="topic-modeling-approaches" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="topic-modeling-approaches"><span class="header-section-number">15.4</span> Topic Modeling Approaches</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The study compares two distinct topic modeling approaches: <em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em>. Both approaches share fundamental postulates: documents can be represented by numerical vectors, topics are identifiable through linguistic regularities manifested as repetitions, and machine learning facilitates the automatic detection of these regularities.</p>
<p><em>Latent Dirichlet Allocation</em> (<em>LDA</em>) is characterized as a classical statistical method. It employs a classical vector representation technique based on counting words within documents. In the <em>LDA</em> framework, topics are conceptualized as latent variables that adhere to Dirichlet’s law. A key advantage of <em>LDA</em> is its ability to handle long texts, making it suitable for analysis across titles, abstracts, and full texts.</p>
<p>In contrast, <em>BERTopic</em> is described as a modern, modular approach, developed by Martin Grootendorst. It utilizes an LLM-based vector representation method, originally based on <em>BERT</em>, which gives the approach its name. Topics in <em>BERTopic</em> correspond to topological densities of documents, typically identified using clustering algorithms like <em>HDBSCAN</em>.</p>
<p>Historically, <em>BERTopic</em> did not handle long texts efficiently, but recent advancements have addressed this limitation. For this study, a specific embedding model, <em>Stella EN 1.5B V5</em>, was selected for the <em>BERTopic</em> implementation. This model was chosen based on its high ranking on the Massive Text Embedding Benchmark on Hugging Face and its capacity to handle approximately 131,000 tokens, addressing the long text limitation.</p>
</section>
<section id="material-and-qualitative-analysis" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="material-and-qualitative-analysis"><span class="header-section-number">15.5</span> Material and Qualitative Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_06.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The material utilized in this study is an Astrobiology corpus, which was previously subjected to an in-depth topic analysis. This prior analysis, documented in <em>Malaterre &amp; Lareau (2023)</em>, resulted in the selection of a full-text <em>LDA</em> model comprising 25 topics. This model serves as a reference for the current comparative study.</p>
<p>The 25 topics of the reference model were analyzed meticulously. This analysis involved examining the most representative words and documents associated with each topic. Based on this examination, each topic was assigned a descriptive label derived from its key terms.</p>
<p>The relationships between topics were then assessed by calculating their mutual correlation, determined by the co-occurrence of topics within documents. Subsequently, a community detection algorithm was applied to the correlation data, identifying four distinct thematic clusters. These clusters were designated with letters (A, B, C, D) and assigned corresponding colors (red, green, yellow, blue) for visualization.</p>
<p>The results of this reference analysis are represented visually as a graph illustrating the correlations between the 25 topics. The graph displays the topic labels and the color variations indicating their thematic clusters. The thickness of the lines connecting topics represents the strength of their correlation, while the size of the circles representing topics indicates their overall presence across all documents in the corpus. This established and analyzed reference model provides a basis for qualitatively comparing the six topic models generated and investigated in the current comparative study.</p>
</section>
<section id="quantitative-metrics" class="level2" data-number="15.6">
<h2 data-number="15.6" class="anchored" data-anchor-id="quantitative-metrics"><span class="header-section-number">15.6</span> Quantitative Metrics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The quantitative analysis compares the six topic models using four specific metrics:</p>
<ul>
<li><p><em>Adjusted Rand Index</em>: This metric assesses the similarity between two different document clusterings. It is corrected for chance, meaning a value of zero corresponds to a random clustering.</p></li>
<li><p><em>Topic Diversity</em>: This measures the proportion of distinct top words utilized to describe the topics within a single topic model. A higher diversity indicates that topics are characterized by different sets of words.</p></li>
<li><p><em>Joint Recall</em>: This evaluates the extent to which the top words collectively represent the documents assigned to each topic. It provides an average measure of document-topic recall, indicating how well the topic’s representative words can retrieve the documents belonging to that topic.</p></li>
<li><p><em>Coherence CV</em>: This evaluates the semantic meaningfulness of the topic’s top words. It is computed as the average of the cosine relative distance between the top words within each topic, where a higher value suggests greater semantic relatedness among the words and thus more coherent topics.</p></li>
</ul>
</section>
<section id="adjusted-rand-index-results" class="level2" data-number="15.7">
<h2 data-number="15.7" class="anchored" data-anchor-id="adjusted-rand-index-results"><span class="header-section-number">15.7</span> Adjusted Rand Index Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_08.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>The <em>Adjusted Rand Index</em> is employed to quantitatively assess the similarities among the six generated topic models by comparing their document clusterings. A value of zero for this metric signifies a random clustering.</p>
<p>The results indicate that the <em>LDA</em> model trained on titles is the most distinct among all models, as evidenced by low <em>Adjusted Rand Index</em> values, specifically under 0.2, shown in the heatmap comparison.</p>
<p>Conversely, all other models exhibit a better overall match with each other, demonstrating values exceeding 0.2. A notable observation is that the <em>BERTopic</em> models tend to correspond more strongly with each other, with <em>Adjusted Rand Index</em> values generally above 0.35. Furthermore, the <em>BERTopic</em> Abstract model appears to be more central in its similarity profile, showing good correspondence to every other model, with values over 0.30, except for the <em>LDA</em> Title model.</p>
</section>
<section id="lda-model-comparison" class="level2" data-number="15.8">
<h2 data-number="15.8" class="anchored" data-anchor-id="lda-model-comparison"><span class="header-section-number">15.8</span> LDA Model Comparison</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>A more detailed qualitative analysis focuses on comparing the <em>LDA</em> Full-text model with the <em>LDA</em> Abstract and <em>LDA</em> Title models, using heatmaps that visualize the number of shared documents between topics. A reddish diagonal pattern in these heatmaps signifies a good correspondence between topics across models.</p>
<p>Comparing the <em>LDA</em> Full-text model with the <em>LDA</em> Abstract model (Table A) reveals a good overall fit. This is evident from the prominent reddish diagonal, indicating that topics in one model largely correspond to single topics in the other with a high proportion of shared documents.</p>
<p>However, the analysis also identifies specific topic transformations: three full-text topics disappear entirely in the abstract model (represented by long horizontal dark gray lines), three full-text topics split into multiple topics in the abstract model (short horizontal dark gray lines), and three abstract topics are formed by the merger of multiple full-text topics (short horizontal dark gray lines). Additionally, the <em>LDA</em> Abstract model exhibits one small class containing fewer than 50 documents.</p>
<p>In contrast, the comparison between the <em>LDA</em> Full-text model and the <em>LDA</em> Title model (Table B) indicates a poor overall fit, characterized by substantial reorganization of topics. This is visually represented by numerous vertical and horizontal dark lines in the heatmap, signifying that many full-text topics disappear and many new topics emerge in the title model, with little direct correspondence.</p>
</section>
<section id="bertopic-model-comparison" class="level2" data-number="15.9">
<h2 data-number="15.9" class="anchored" data-anchor-id="bertopic-model-comparison"><span class="header-section-number">15.9</span> BERTopic Model Comparison</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_11.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The qualitative comparison extends to the <em>BERTopic</em> models, assessing their correspondence with the <em>LDA</em> Full-text reference model using heatmaps showing shared documents.</p>
<p>Comparing the <em>LDA</em> Full-text model with the <em>BERTopic</em> Full-text model (Table C) shows an average overall fit. The analysis reveals that 8 topics from the <em>LDA</em> Full-text model disappear, and 6 topics split into multiple topics in the <em>BERTopic</em> Full-text model (indicated on the horizontal axis). On the vertical axis, 5 new topics appear in the <em>BERTopic</em> model, and 1 topic results from the merger of <em>LDA</em> topics. The <em>BERTopic</em> Full-text model also exhibits issues with class size, including 4 small classes and 1 very large class.</p>
<p>The comparison between the <em>LDA</em> Full-text model and the <em>BERTopic</em> Abstract model (Table D) indicates a relatively good overall fit. Four <em>LDA</em> topics disappear, and 6 topics split in the <em>BERTopic</em> Abstract model (horizontal axis). Two new topics appear, and 4 topics result from mergers in the <em>BERTopic</em> Abstract model (vertical axis).</p>
<p>Finally, comparing the <em>LDA</em> Full-text model with the <em>BERTopic</em> Title model (Table E) shows an average overall fit. Seven <em>LDA</em> topics disappear, and 1 topic splits in the <em>BERTopic</em> Title model (horizontal axis). Seven new topics appear, and 1 topic results from a merger in the <em>BERTopic</em> Title model (vertical axis). The <em>BERTopic</em> Title model also presents class size issues, with 3 small classes and 1 large class.</p>
</section>
<section id="comparing-top-words" class="level2" data-number="15.10">
<h2 data-number="15.10" class="anchored" data-anchor-id="comparing-top-words"><span class="header-section-number">15.10</span> Comparing Top Words</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>A qualitative assessment involves comparing the top words associated with selected topics across the different models to understand the nature of the topics generated.</p>
<p>Within the <em>LDA</em> models (Full-text, Abstract, and Title), topics are observed to be relatively well-formed. A robust topic, exemplified by “A radiation spore,” demonstrates good correspondence in its top words across all three <em>LDA</em> models.</p>
<p>Splitting of topics is also observed: the “A life civilization” topic from the full-text model splits across the abstract and title models, which is considered sensible as it relates to a general theme of research in astrobiology. The “B chemistry” topic from the full-text model also splits across the abstract and title models, though this particular split is noted as being more challenging to interpret without deeper analysis. Merging of topics occurs as well, such as the “B amino acid” and “B protein gene RNA” topics from the full-text model merging into a single topic in other models, which is deemed sensible as it forms a more general thematic area.</p>
<p>Comparing the <em>BERTopic</em> models (Full-text, Abstract, and Title) with the <em>LDA</em> Full-text model also reveals relatively well-formed topics across all <em>BERTopic</em> models. The robustness of the “A radiation spore” topic is again observed, appearing consistently across all <em>BERTopic</em> models and the <em>LDA</em> Full-text reference. The “A life civilization” topic is relatively stable across the <em>BERTopic</em> models, although some splitting occurs, leading to narrower topics specifically focused on extraterrestrial life. The “B chemistry” topic also splits across the <em>BERTopic</em> models, resulting in more narrow thematic topics.</p>
</section>
<section id="coherence-diversity-and-joint-recall-results" class="level2" data-number="15.11">
<h2 data-number="15.11" class="anchored" data-anchor-id="coherence-diversity-and-joint-recall-results"><span class="header-section-number">15.11</span> Coherence, Diversity, and Joint Recall Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_15.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>Quantitative performance metrics are evaluated for all six topic models across a range of topic numbers, specifically from 5 to 50.</p>
<p>The <em>Coherence CV</em> metric, which assesses the meaningfulness of the topic top words, yields several findings:</p>
<ul>
<li><p>Models trained on titles exhibit the worst coherence.</p></li>
<li><p>Abstract models demonstrate better coherence compared to full-text models.</p></li>
<li><p>Overall, <em>BERTopic</em> models show better coherence than <em>LDA</em> models when applied to abstracts and titles, although this difference becomes less pronounced as the number of topics increases.</p></li>
<li><p>Based on this metric, <em>BERTopic</em> Abstract is identified as the clear winner.</p></li>
</ul>
<p>Regarding <em>Topic Diversity</em>, which measures the proportion of distinct top words, the results show that diversity generally decreases as the number of topics increases:</p>
<ul>
<li><p>Models trained on titles offer the best diversity.</p></li>
<li><p><em>BERTopic</em> models exhibit better diversity than <em>LDA</em> models.</p></li>
<li><p>The winner for diversity is <em>BERTopic</em> Title, closely followed by <em>BERTopic</em> Full-text.</p></li>
</ul>
<p>The <em>Joint Recall</em> metric evaluates how effectively the top words collectively represent the documents classified within each topic:</p>
<ul>
<li><p>Titles yield the worst joint recall.</p></li>
<li><p>Full-text models perform better than their abstract and title counterparts.</p></li>
<li><p><em>LDA</em> models generally show better joint recall than <em>BERTopic</em> models.</p></li>
<li><p>The winners for <em>Joint Recall</em> are <em>LDA</em> Fulltext and <em>BERTopic</em> Fulltext, with <em>BERTopic</em> Abstract performing very closely behind.</p></li>
</ul>
</section>
<section id="model-performance-summary" class="level2" data-number="15.12">
<h2 data-number="15.12" class="anchored" data-anchor-id="model-performance-summary"><span class="header-section-number">15.12</span> Model Performance Summary</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_17.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>A summary table consolidates the performance results, offering an overall view of each model’s strengths and weaknesses across various assessment criteria. The models evaluated are:</p>
<ul>
<li><p><em>LDA</em> Full-text (rated 4*)</p></li>
<li><p><em>LDA</em> Abstract (4.5*)</p></li>
<li><p><em>LDA</em> Title (2.5*)</p></li>
<li><p><em>BERTopic</em> Full-text (4.5*)</p></li>
<li><p><em>BERTopic</em> Abstract (4.5*)</p></li>
<li><p><em>BERTopic</em> Title (3*)</p></li>
</ul>
<p>The assessment criteria include Overall fit, Top-words quality, Coherence, Diversity, and Joint recall. Performance scores are visually represented using circle icons, where a full black circle signifies the highest score and an empty circle indicates a low score. Red crosses highlight specific problems, such as class imbalance.</p>
<p>The analysis indicates that there is no single absolute best model; the optimal choice is contingent upon the specific research objectives. Different objectives necessitate different model characteristics. For instance, if the primary goal is the discovery of main topics without requiring precise classification of every document, issues like poor recall or large classes might be acceptable. In such a scenario, the <em>BERTopic</em> Full-text model performs well, although it exhibits some class imbalance. The <em>BERTopic</em> Title model, while generally less optimal, is capable of producing some robust topics that are also identified by the other models.</p>
</section>
<section id="discussion-and-future-directions" class="level2" data-number="15.13">
<h2 data-number="15.13" class="anchored" data-anchor-id="discussion-and-future-directions"><span class="header-section-number">15.13</span> Discussion and Future Directions</h2>
<p>The discussion highlights several key observations and potential future directions. The poor performance observed in title-based models is primarily attributed to the inherent lack of information in titles compared to abstracts or full texts. This limitation can lead to inaccurate classification of documents, although title models are still capable of identifying meaningful core topics.</p>
<p>Full-text models exhibit distinct characteristics depending on the approach. <em>LDA</em> models applied to full text tend to produce topics that are more loosely defined and broader in coverage, potentially capturing transverse themes such as research methods. <em>BERTopic</em> full-text models, on the other hand, may result in some topics being too narrow, leading to poor document coverage, and can suffer from class-size imbalance problems.</p>
<p>Abstract models demonstrate notable consistency, both between the <em>LDA</em> and <em>BERTopic</em> implementations and in their correspondence with the <em>LDA</em> full-text model. A significant finding is the overall robustness of topics, with very similar thematic areas being identified across the board, regardless of the specific model or text level used.</p>
<p>Future research possibilities include exploiting meta-analysis techniques to systematically identify the most robust topics that consistently appear across multiple models and text levels. Another direction involves using relative distance metrics to determine which model is the most central or representative among the set. Furthermore, the study suggests the potential for developing new topic modeling approaches that explicitly leverage the structural information present in documents (i.e., the distinction between full text, abstract, and titles) to extract more meaningful sets of topics or top words.</p>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Plural pursuit across scales">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Plural pursuit across scales</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_017.html" class="pagination-link" aria-label="Time-Aware Language Models">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>