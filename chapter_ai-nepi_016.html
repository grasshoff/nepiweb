<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francis Lareau &amp; Christophe Malaterre">
<meta name="dcterms.date" content="2025-06-21">

<title>14&nbsp; A Comparative Study of LDA and BERTopic Performance Across Text Levels â€“ AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_017.html" rel="next">
<link href="./chapter_ai-nepi_015.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_016.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">A Comparative Study of LDA and BERTopic Performance Across Text Levels</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Validation is All You Need</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">AI Solutions for Academic Information Retrieval: The Ghostwriter and EverythingData Approach</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">A Comparative Study of LDA and BERTopic Performance Across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#topic-modelling-in-hpss" id="toc-topic-modelling-in-hpss" class="nav-link" data-scroll-target="#topic-modelling-in-hpss"><span class="header-section-number">14.1</span> Topic Modelling in HPSS</a></li>
  <li><a href="#comparing-lda-and-bertopic" id="toc-comparing-lda-and-bertopic" class="nav-link" data-scroll-target="#comparing-lda-and-bertopic"><span class="header-section-number">14.2</span> Comparing <em>LDA</em> and <em>BERTopic</em></a></li>
  <li><a href="#astrobiology-corpus-and-qualitative-framework" id="toc-astrobiology-corpus-and-qualitative-framework" class="nav-link" data-scroll-target="#astrobiology-corpus-and-qualitative-framework"><span class="header-section-number">14.3</span> Astrobiology Corpus and Qualitative Framework</a></li>
  <li><a href="#quantitative-evaluation-metrics" id="toc-quantitative-evaluation-metrics" class="nav-link" data-scroll-target="#quantitative-evaluation-metrics"><span class="header-section-number">14.4</span> Quantitative Evaluation Metrics</a></li>
  <li><a href="#assessing-model-similarity" id="toc-assessing-model-similarity" class="nav-link" data-scroll-target="#assessing-model-similarity"><span class="header-section-number">14.5</span> Assessing Model Similarity</a></li>
  <li><a href="#lda-performance-across-granularities" id="toc-lda-performance-across-granularities" class="nav-link" data-scroll-target="#lda-performance-across-granularities"><span class="header-section-number">14.6</span> <em>LDA</em> Performance Across Granularities</a></li>
  <li><a href="#bertopic-performance-across-granularities" id="toc-bertopic-performance-across-granularities" class="nav-link" data-scroll-target="#bertopic-performance-across-granularities"><span class="header-section-number">14.7</span> <em>BERTopic</em> Performance Across Granularities</a></li>
  <li><a href="#lda-top-word-analysis" id="toc-lda-top-word-analysis" class="nav-link" data-scroll-target="#lda-top-word-analysis"><span class="header-section-number">14.8</span> <em>LDA</em> Top-Word Analysis</a></li>
  <li><a href="#bertopic-top-word-analysis" id="toc-bertopic-top-word-analysis" class="nav-link" data-scroll-target="#bertopic-top-word-analysis"><span class="header-section-number">14.9</span> <em>BERTopic</em> Top-Word Analysis</a></li>
  <li><a href="#performance-by-coherence" id="toc-performance-by-coherence" class="nav-link" data-scroll-target="#performance-by-coherence"><span class="header-section-number">14.10</span> Performance by Coherence</a></li>
  <li><a href="#performance-by-diversity" id="toc-performance-by-diversity" class="nav-link" data-scroll-target="#performance-by-diversity"><span class="header-section-number">14.11</span> Performance by Diversity</a></li>
  <li><a href="#performance-by-joint-recall" id="toc-performance-by-joint-recall" class="nav-link" data-scroll-target="#performance-by-joint-recall"><span class="header-section-number">14.12</span> Performance by Joint Recall</a></li>
  <li><a href="#overall-performance-and-recommendations" id="toc-overall-performance-and-recommendations" class="nav-link" data-scroll-target="#overall-performance-and-recommendations"><span class="header-section-number">14.13</span> Overall Performance and Recommendations</a></li>
  <li><a href="#key-findings-and-future-directions" id="toc-key-findings-and-future-directions" class="nav-link" data-scroll-target="#key-findings-and-future-directions"><span class="header-section-number">14.14</span> Key Findings and Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">A Comparative Study of LDA and BERTopic Performance Across Text Levels</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Francis Lareau &amp; Christophe Malaterre <a href="mailto:francislareau@hotmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            UniversitÃ© du QuÃ©bec Ã  MontrÃ©al; UniversitÃ© de Sherbrooke; CIRST
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>In a comparative study, Francis Lareau and Christophe Malaterre evaluated the performance of Latent Dirichlet Allocation (<em>LDA</em>) and <em>BERTopic</em>, two prominent topic modelling approaches, across various levels of textual granularity. Topic modelling, a computational method for extracting latent themes from a corpus, has become an essential analytical tool for navigating large volumes of scientific literature, particularly within the history, philosophy, and sociology of science (HPSS). The technique facilitates the identification of research trends and paradigm shifts, the discernment of thematic substructures, and the analysis of evolving scientific vocabularies.</p>
<p>Previous applications of topic modelling have drawn upon diverse textual components, including titles, abstracts, and full texts. This observation prompted Lareau and Malaterre to investigate a critical question: does applying topic modelling solely to titles or abstracts suffice, or is full-text analysis indispensable? The question carries significant weight, given the substantial resources required to obtain, preprocess, and analyse comprehensive full-text corpora.</p>
<p>To address this, the authors constituted a corpus of scientific articles, meticulously isolating their title, abstract, and full-text sections. They then applied both <em>LDA</em> and <em>BERTopic</em> to each of these textual components, generating six distinct topic models. Finally, the team subjected these models to rigorous qualitative and quantitative comparison to determine their relative merits.</p>
</section>
<section id="topic-modelling-in-hpss" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="topic-modelling-in-hpss"><span class="header-section-number">14.1</span> Topic Modelling in HPSS</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_02.png" class="img-fluid figure-img"></p>
<figcaption>Slide 02</figcaption>
</figure>
</div>
<p>Topic modelling has established itself as an indispensable tool within the History, Philosophy, and Sociology of Science (HPSS). The method enables scholars to identify research trends and paradigm shifts (Griffiths and Steyvers, 2004) and to reveal the substructures and interrelations of themes (Blei and Lafferty, 2007). Furthermore, it supports the analysis of scientific vocabulary evolution (Chavalarias and Cointet, 2013) and aids in uncovering hidden biases within scientific discourse (Sugimoto et al., 2013).</p>
<p>Academics also employ topic modelling to study the sociology of scientific communities (Gerow et al., 2018), analyse the interdisciplinary nature of various fields (Hyeyoung et al., 2022), and enhance the historiography of both science (Mimno, 2012) and art (Browman, 2023). A crucial observation from this body of work is the varied application of topic modelling to different textual structures, including titles, abstracts, and full texts.</p>
<p>This variety directly informs the central research question posed by Lareau and Malaterre: is a comprehensive full-text analysis truly necessary, or can one achieve comparable results using only titles or abstracts? This inquiry is particularly urgent given the considerable investment of time and resources needed to manage full-text corpora. Their methodology therefore involved a systematic comparison of models derived from each textual level.</p>
</section>
<section id="comparing-lda-and-bertopic" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="comparing-lda-and-bertopic"><span class="header-section-number">14.2</span> Comparing <em>LDA</em> and <em>BERTopic</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>This study provides a rigorous comparison of two leading topic modelling approaches: Latent Dirichlet Allocation (<em>LDA</em>) and <em>BERTopic</em>. Both methodologies operate on shared fundamental postulates: that documents can be represented by numerical vectors, that topics become identifiable through linguistic regularities, and that machine learning can automate the detection of these patterns.</p>
<p><em>LDA</em>, a classical statistical technique, employs a vector representation derived from word counts within documents. In this framework, topics manifest as latent variables adhering to Dirichletâ€™s law. A key advantage of <em>LDA</em> is its capacity to effectively process long texts, making it suitable for analysing titles, abstracts, or full texts.</p>
<p>Conversely, <em>BERTopic</em> represents a more contemporary, modular approach. It leverages vector representations from large language models, originally building upon <em>BERT</em>, from which it derives its name. Within <em>BERTopic</em>, topics correspond to clusters of documents that reflect their topological densities. Whilst traditionally limited in handling extensive texts, recent advancements have enabled <em>BERTopic</em> to process significantly longer documentsâ€”up to approximately 131,000 tokens. Consequently, Lareau and Malaterre specifically tested <em>BERTopic</em> with novel embedding techniques designed to manage such substantial text lengths.</p>
</section>
<section id="astrobiology-corpus-and-qualitative-framework" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="astrobiology-corpus-and-qualitative-framework"><span class="header-section-number">14.3</span> Astrobiology Corpus and Qualitative Framework</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>For their analysis, the authors used an Astrobiology corpus previously explored by Malaterre and Lareau (2023). Following a thorough evaluation, they selected a full-text <em>LDA</em> model comprising 25 distinct topics as a reference. The team meticulously analysed each topic by examining its most representative words and documents, subsequently assigning a descriptive name based on its key terms.</p>
<p>They then calculated the mutual correlation between these topics, based on their co-occurrence within documents. A community detection algorithm subsequently identified four thematic clusters, designated A, B, C, and D, and distinguished by red, green, yellow, and blue colour variations. The findings are presented in a graph that illustrates the correlations amongst the 25 topics, complete with their labels and cluster affiliations. In this visualisation, line thickness signifies correlation strength, whilst circle size indicates a topicâ€™s prevalence across the corpus.</p>
<p>This comprehensive framework facilitates a qualitative comparison of the six topic models. For instance:</p>
<ul>
<li><p>Cluster A (red/pink) encompasses topics such as the effects of space on health (<em>A-CELL-PLANT-ANIMAL</em>), microbial survival (<em>A-RADIATION-SPORE</em>), and social studies of astrobiology (<em>A-LIFE-CIVILIZATION</em>).</p></li>
<li><p>Cluster B (green/teal) includes themes like prebiotic chemistry (<em>B-ORGANIC-MOLECULE</em>), properties of amino acids (<em>B-AMINO-ACID</em>), and the origin of chirality (<em>B-CHIRALITY</em>).</p></li>
<li><p>Cluster C (yellow/orange) features topics such as planetary atmospheres (<em>C-ATMOSPHERE</em>) and the dynamics of planetary systems (<em>C-PLANET-STAR</em>).</p></li>
<li><p>Cluster D (blue) covers areas like geological biosignatures (<em>D-STRUCTURE-GEOLOGY</em>) and the characterisation of Mars (<em>D-MARS</em>).</p></li>
</ul>
</section>
<section id="quantitative-evaluation-metrics" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="quantitative-evaluation-metrics"><span class="header-section-number">14.4</span> Quantitative Evaluation Metrics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>Lareau and Malaterre compared the topic models using four distinct quantitative metrics.</p>
<ul>
<li><p>The <em>Adjusted Rand Index</em> evaluates the similarity between two document clusterings whilst correcting for chance agreement.</p></li>
<li><p><em>Topic diversity</em> quantifies the proportion of unique top words within a given topic model.</p></li>
<li><p><em>Joint recall</em> assesses the extent to which the top words collectively represent the documents classified within each topic.</p></li>
<li><p>The <em>coherence metric</em>, specifically <em>Coherence CV</em>, determines whether the top words meaningfully co-occur by measuring the average cosine relative distance between them. This measure, derived from Syed and Sprout (2017), incorporates Normalised Pointwise Mutual Information (<em>NPMI</em>) and cosine similarity to provide a robust evaluation of topic quality.</p></li>
</ul>
</section>
<section id="assessing-model-similarity" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="assessing-model-similarity"><span class="header-section-number">14.5</span> Assessing Model Similarity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The Adjusted Rand Index provides a clear measure of similarity amongst the six topic models, where a value of zero signifies random clustering. Analysis of this metric reveals that the <em>LDA</em> model applied to titles is the most divergent, consistently yielding values below 0.20. For example, its correlation with the <em>LDA full-text</em> model is a mere 0.13.</p>
<p>In contrast, all other models demonstrate superior overall correspondence, with their Adjusted Rand Index values generally exceeding 0.20. The <em>BERTopic</em> models exhibit a particularly strong internal consistency, with inter-model values frequently surpassing 0.35; the similarity between <em>BERTopic full-text</em> and <em>BERTopic abstract</em> is 0.36, whilst that between <em>BERTopic abstract</em> and <em>BERTopic title</em> is 0.38.</p>
<p>Furthermore, the <em>BERTopic Abstract</em> model emerges as a central configuration, correlating effectively with all other models except for the outlier <em>LDA title</em> model, and consistently achieving values above 0.30.</p>
</section>
<section id="lda-performance-across-granularities" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="lda-performance-across-granularities"><span class="header-section-number">14.6</span> <em>LDA</em> Performance Across Granularities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>A more granular analysis of the <em>LDA</em> models offers detailed insights into their comparative performance. When comparing <em>LDA Full-text</em> with <em>LDA Abstract</em>, as depicted in Table A, the authors observed a generally good fit. This correspondence is evidenced by a high proportion of shared documents between topics, visually represented by a reddish diagonal in the organised data.</p>
<p>However, this comparison also revealed specific structural changes. Three full-text topics disappeared entirely in the abstract model, whilst another three fragmented into multiple, more specific topics. Conversely, three entirely new topics emerged in the abstract model, and three others resulted from the merger of several full-text topics.</p>
<p>In stark contrast, the comparison between <em>LDA Full-text</em> and <em>LDA Title</em>, presented in Table B, demonstrated a poor fit. This significant disparity indicates an extensive reorganisation of topics, characterised by the disappearance of numerous full-text topics and the emergence of many new, unrelated title-based topics.</p>
</section>
<section id="bertopic-performance-across-granularities" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="bertopic-performance-across-granularities"><span class="header-section-number">14.7</span> <em>BERTopic</em> Performance Across Granularities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The authorsâ€™ assessment of the <em>BERTopic</em> models reveals distinct levels of fit across different textual granularities. The comparison between <em>LDA Full-text</em> and <em>BERTopic Full-text</em> (Table C) showed an average overall fit, highlighting significant reorganisation: eight <em>LDA</em> topics disappeared, and six split. Conversely, five new <em>BERTopic</em> topics emerged, and one resulted from a merger. This analysis also identified four small classes and one notably large class, presenting a potential issue with class balance.</p>
<p>In Table D, the comparison between <em>LDA Full-text</em> and <em>BERTopic Abstract</em> indicated a relatively good overall fit. Here, four <em>LDA</em> topics disappeared and six split, whilst two new <em>BERTopic</em> topics appeared and four resulted from mergers. Crucially, the classes remained well-balanced.</p>
<p>Finally, Table E, comparing <em>LDA Full-text</em> with <em>BERTopic Title</em>, showed an average fit. This configuration saw seven <em>LDA</em> topics disappear and one split, whilst seven new <em>BERTopic</em> topics emerged. Similar to the full-text model, this configuration also produced three small classes and one large class. Across all <em>BERTopic</em> models, the top-words assessment consistently indicated well-formed topics, with the <em>A-Radiation spore</em> topic demonstrating remarkable robustness.</p>
</section>
<section id="lda-top-word-analysis" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="lda-top-word-analysis"><span class="header-section-number">14.8</span> <em>LDA</em> Top-Word Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>A detailed assessment of top words across the <em>LDA Full-Text</em>, <em>LDA Abstract</em>, and <em>LDA Title</em> models reveals distinct patterns of topic correspondence and evolution. Certain topics, such as <em>A-Radiation-spore</em> and <em>A-Life-civilization</em>, demonstrate robust consistency across all <em>LDA</em> models. They retain core top words like â€˜radiationâ€™, â€˜sporeâ€™, and â€˜spaceâ€™ for the former, and â€˜lifeâ€™, â€˜civilizationâ€™, and â€˜universeâ€™ for the latter.</p>
<p>Conversely, other topics exhibit splitting behaviour. The <em>B-Chemistry</em> topic, initially characterised by terms such as â€˜reactionâ€™, â€˜productâ€™, and â€˜synthesisâ€™ in the full-text model, fragments across the abstract and title models, yielding distinct sets of top words in each. The authors note that the fragmentation within the <em>LDA title</em> model is particularly challenging to interpret without further analysis.</p>
<p>Furthermore, the team observed instances of topic merger. The <em>B-Amino-acid</em> and <em>B-Protein-gene-RNA</em> topics, distinct in the full-text model, coalesce into new, more generalised topics within both the abstract and title models. This merger, encompassing terms like â€˜proteinâ€™, â€˜codeâ€™, and â€˜geneticâ€™, forms a logically coherent, broader thematic category.</p>
</section>
<section id="bertopic-top-word-analysis" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="bertopic-top-word-analysis"><span class="header-section-number">14.9</span> <em>BERTopic</em> Top-Word Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/images/ai-nepi_016_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>Further assessment of top words across the three <em>BERTopic</em> models consistently revealed well-formed topics. The <em>A-Radiation spore</em> topic, for instance, demonstrated remarkable robustness across all models, maintaining its core thematic focus.</p>
<p>Whilst the <em>A-Life civilization</em> topic also remained comparatively stable, it exhibited some splitting behaviour. This fragmentation led to the formation of narrower, more specific topics centred on extraterrestrial life, incorporating terms such as â€˜fermiâ€™, â€˜drakeâ€™, and â€˜setiâ€™. Similarly, the splitting of the <em>B-Chemistry</em> topic also resulted in more granular themes, featuring terms like â€˜peptideâ€™, â€˜aminoâ€™, and â€˜montmorilloniteâ€™.</p>
<p>Conversely, the <em>B-Amino-acid</em> and <em>B-Protein-gene-RNA</em> topics merged into new, broader categories within the <em>BERTopic</em> models. These consolidated topics encompass terms such as â€˜geneticâ€™, â€˜codeâ€™, and â€˜proteinâ€™, creating more generalised thematic groupings.</p>
</section>
<section id="performance-by-coherence" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="performance-by-coherence"><span class="header-section-number">14.10</span> Performance by Coherence</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>Lareau and Malaterre evaluated the performance of all six models across a range of 5 to 50 topics, focusing first on the <em>Coherence CV</em> metric, which assesses the meaningfulness of a topicâ€™s top words. Their analysis revealed that titles consistently yielded the poorest coherence, with scores generally falling below 0.4.</p>
<p>Conversely, abstract-based models demonstrated superior coherence compared to full-text models, often achieving scores above 0.6. Overall, <em>BERTopic</em> models exhibited better coherence than <em>LDA</em> for both abstracts and titles, with <em>BERTopic Abstract</em> consistently outperforming <em>LDA Abstract</em>. This performance gap, however, tended to diminish as the number of topics increased.</p>
<p>Ultimately, <em>BERTopic Abstract</em> emerged as the clear winner in terms of coherence for its category. Whilst the full-text models, <em>BERTopic Fulltext</em> and <em>LDA Fulltext</em>, generally displayed the highest absolute coherence scoresâ€”typically exceeding 0.7â€”the performance of <em>BERTopic Abstract</em> was exceptional for a model based on summary text.</p>
</section>
<section id="performance-by-diversity" class="level2" data-number="14.11">
<h2 data-number="14.11" class="anchored" data-anchor-id="performance-by-diversity"><span class="header-section-number">14.11</span> Performance by Diversity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>The diversity metric, which quantifies the proportion of distinct top words representing the topics, also underwent rigorous evaluation. The authors observed a general trend where diversity tended to decrease as the number of topics increased.</p>
<p>Notably, models utilising titles consistently offered the best diversity. Furthermore, <em>BERTopic</em> models demonstrated superior diversity compared to <em>LDA</em> across all text types. Ultimately, <em>BERTopic Title</em> emerged as the winner in terms of diversity, closely followed by <em>BERTopic Full-text</em>. In contrast, the full-text models generally yielded the lowest diversity scores.</p>
</section>
<section id="performance-by-joint-recall" class="level2" data-number="14.12">
<h2 data-number="14.12" class="anchored" data-anchor-id="performance-by-joint-recall"><span class="header-section-number">14.12</span> Performance by Joint Recall</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>Joint recall, a metric assessing how effectively top words represent the documents within each topic, provided further insights. The analysis revealed that models utilising titles consistently exhibited the poorest recall. <em>BERTopic Title</em> generally fell below 0.5, and <em>LDA Title</em> remained below 0.6.</p>
<p>Conversely, full-text models significantly outperformed their abstract and title counterparts. <em>BERTopic Fulltext</em> consistently achieved recall values above 0.9, whilst <em>LDA Fulltext</em> approached a perfect 1.0, particularly as the number of topics exceeded 20.</p>
<p>Overall, <em>LDA</em> demonstrated superior joint recall to <em>BERTopic</em> across all textual granularities. <em>LDA Fulltext</em> emerged as the clear winner, with <em>BERTopic Fulltext</em> also showing commendably high recall. The <em>BERTopic Abstract</em> model performed well, achieving values between 0.7 and 0.8.</p>
</section>
<section id="overall-performance-and-recommendations" class="level2" data-number="14.13">
<h2 data-number="14.13" class="anchored" data-anchor-id="overall-performance-and-recommendations"><span class="header-section-number">14.13</span> Overall Performance and Recommendations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>In summarising the overall model performance, Lareau and Malaterre emphasise that no single model represents an absolute optimum. Instead, the most suitable choice depends entirely on the specific research objectives.</p>
<p>For instance, if the primary goal is to discover main topics without requiring precise document classification, then <em>BERTopic</em> on full texts performs commendably, despite some class imbalance. Similarly, whilst <em>BERTopic</em> on titles proved suboptimal in overall metrics, it nonetheless generated robust topics that also appeared in other, better-performing models.</p>
<p>The authors strongly advise against using <em>LDA</em> on titles, given its consistently poor performance across nearly every assessment. They recommend conducting topic modelling on either abstracts or full texts, utilising both <em>LDA</em> and <em>BERTopic</em>. This dual approach allows for a cross-validation of findings, provided the application does not result in the misclassification of documents pertinent to specific topics. The <em>LDA Abstract</em> and <em>BERTopic Abstract</em> models consistently achieved a strong balance of high overall fit, top-word quality, coherence, diversity, and joint recall.</p>
</section>
<section id="key-findings-and-future-directions" class="level2" data-number="14.14">
<h2 data-number="14.14" class="anchored" data-anchor-id="key-findings-and-future-directions"><span class="header-section-number">14.14</span> Key Findings and Future Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_18.png" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
<p>This research yielded several key findings regarding topic modelling performance across different text levels. Firstly, title-based models consistently demonstrated poor performance. The inherent lack of information in titles can lead to the false classification of documents, although the authors note that the <em>BERTopic</em> title model still produced some meaningful topics. This suggests a need to balance well-defined topics with comprehensive document coverage.</p>
<p>Secondly, full-text models presented their own challenges. <em>LDA</em> models, for instance, could produce loosely defined topics with overly broad coverage, whilst <em>BERTopic</em> models sometimes generated overly narrow topics, resulting in poor document coverage and class size imbalances. Thirdly, abstract-based models consistently performed well, exhibiting results that were consistent with the <em>LDA</em> full-text model.</p>
<p>A fourth finding was the notable robustness of certain topics across all models, which facilitates meta-analytic methods for identifying the most stable themes. This consistency also opens the possibility of using relative distance between models to pinpoint an optimal configuration. In this study, <em>BERTopic Abstract</em> emerged as the strongest candidate.</p>
<p>Finally, these findings prompt a crucial question about the future of topic modelling: is it time for new models? Lareau and Malaterre contend that it is, highlighting the potential to leverage structural information from full texts, abstracts, and titles simultaneously to extract even more meaningful sets of topics.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "î§‹";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Quantum gravity and plural pursuit in science">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_017.html" class="pagination-link" aria-label="Time-aware large language models towards a novel architecture for historical analysis">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>