<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francis Lareau &amp; Christophe Malaterre">
<meta name="dcterms.date" content="2025-01-01">

<title>14&nbsp; Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance across Text Levels – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_017.html" rel="next">
<link href="./chapter_ai-nepi_015.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_016.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Transformer’s Legacy: Understanding Large Language Models and their Application in HPSS Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Workflow and Utility of OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Beyond Traditional Views of Science Funding</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#research-rationale-topic-modelling-efficacy-across-textual-levels" id="toc-research-rationale-topic-modelling-efficacy-across-textual-levels" class="nav-link" data-scroll-target="#research-rationale-topic-modelling-efficacy-across-textual-levels"><span class="header-section-number">14.1</span> Research Rationale: Topic Modelling Efficacy Across Textual Levels</a></li>
  <li><a href="#methodology-topic-modelling-approaches-lda-and-bertopic" id="toc-methodology-topic-modelling-approaches-lda-and-bertopic" class="nav-link" data-scroll-target="#methodology-topic-modelling-approaches-lda-and-bertopic"><span class="header-section-number">14.2</span> Methodology: Topic Modelling Approaches – <em>LDA</em> and <em>BERTopic</em></a></li>
  <li><a href="#methodology-material-for-qualitative-comparison-an-astrobiology-corpus" id="toc-methodology-material-for-qualitative-comparison-an-astrobiology-corpus" class="nav-link" data-scroll-target="#methodology-material-for-qualitative-comparison-an-astrobiology-corpus"><span class="header-section-number">14.3</span> Methodology: Material for Qualitative Comparison – An Astrobiology Corpus</a></li>
  <li><a href="#methodology-quantitative-analysis-metrics" id="toc-methodology-quantitative-analysis-metrics" class="nav-link" data-scroll-target="#methodology-quantitative-analysis-metrics"><span class="header-section-number">14.4</span> Methodology: Quantitative Analysis Metrics</a></li>
  <li><a href="#results-adjusted-rand-index-analysis-of-model-similarity" id="toc-results-adjusted-rand-index-analysis-of-model-similarity" class="nav-link" data-scroll-target="#results-adjusted-rand-index-analysis-of-model-similarity"><span class="header-section-number">14.5</span> Results: Adjusted Rand Index Analysis of Model Similarity</a></li>
  <li><a href="#results-qualitative-comparison-of-lda-models" id="toc-results-qualitative-comparison-of-lda-models" class="nav-link" data-scroll-target="#results-qualitative-comparison-of-lda-models"><span class="header-section-number">14.6</span> Results: Qualitative Comparison of <em>LDA</em> Models</a></li>
  <li><a href="#results-qualitative-comparison-involving-bertopic-models" id="toc-results-qualitative-comparison-involving-bertopic-models" class="nav-link" data-scroll-target="#results-qualitative-comparison-involving-bertopic-models"><span class="header-section-number">14.7</span> Results: Qualitative Comparison Involving <em>BERTopic</em> Models</a></li>
  <li><a href="#results-lda-top-words-qualitative-analysis" id="toc-results-lda-top-words-qualitative-analysis" class="nav-link" data-scroll-target="#results-lda-top-words-qualitative-analysis"><span class="header-section-number">14.8</span> Results: <em>LDA</em> Top-Words Qualitative Analysis</a></li>
  <li><a href="#results-bertopic-top-words-qualitative-analysis" id="toc-results-bertopic-top-words-qualitative-analysis" class="nav-link" data-scroll-target="#results-bertopic-top-words-qualitative-analysis"><span class="header-section-number">14.9</span> Results: <em>BERTopic</em> Top-Words Qualitative Analysis</a></li>
  <li><a href="#results-quantitative-analysis-coherence-cv" id="toc-results-quantitative-analysis-coherence-cv" class="nav-link" data-scroll-target="#results-quantitative-analysis-coherence-cv"><span class="header-section-number">14.10</span> Results: Quantitative Analysis – Coherence (CV)</a></li>
  <li><a href="#results-quantitative-analysis-topic-diversity" id="toc-results-quantitative-analysis-topic-diversity" class="nav-link" data-scroll-target="#results-quantitative-analysis-topic-diversity"><span class="header-section-number">14.11</span> Results: Quantitative Analysis – Topic Diversity</a></li>
  <li><a href="#results-quantitative-analysis-joint-recall" id="toc-results-quantitative-analysis-joint-recall" class="nav-link" data-scroll-target="#results-quantitative-analysis-joint-recall"><span class="header-section-number">14.12</span> Results: Quantitative Analysis – Joint Recall</a></li>
  <li><a href="#results-summary-of-model-performance" id="toc-results-summary-of-model-performance" class="nav-link" data-scroll-target="#results-summary-of-model-performance"><span class="header-section-number">14.13</span> Results: Summary of Model Performance</a></li>
  <li><a href="#discussion-and-conclusion-implications-and-future-directions" id="toc-discussion-and-conclusion-implications-and-future-directions" class="nav-link" data-scroll-target="#discussion-and-conclusion-implications-and-future-directions"><span class="header-section-number">14.14</span> Discussion and Conclusion: Implications and Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Francis Lareau &amp; Christophe Malaterre <a href="mailto:francislareau@hotmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Université du Québec à Montréal; Université de Sherbrooke; CIRST
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Researchers Francis Lareau, from the Université de Sherbrooke and the Université du Québec à Montréal, alongside Christophe Malaterre, also from the Université du Québec à Montréal, conducted a comprehensive comparative study. Their investigation sought to determine whether applying topic modelling to titles or abstracts suffices for scientific literature, or if full-text analysis remains indispensable, particularly within the history, philosophy, and sociology of science. This inquiry directly addresses the substantial resources full-text processing demands.</p>
<p>The study meticulously constituted a corpus of scientific articles, subsequently identifying their title, abstract, and full-text sections. Researchers then applied two distinct topic modelling approaches—Latent Dirichlet Allocation (<em>LDA</em>) and <em>BERTopic</em>—to each of these three textual levels. Following this, they rigorously analysed and compared the six resulting topic models.</p>
<p>This comparison employed both qualitative methods, drawing upon a pre-existing detailed analysis of an astrobiology corpus, and quantitative measures. These quantitative metrics included the Adjusted Rand Index, topic diversity, joint recall, and Coherence CV. The findings aim to guide researchers in selecting appropriate text levels for topic modelling, aligning their choices with specific objectives and resource constraints by highlighting performance variations across different models and textual structures.</p>
</section>
<section id="research-rationale-topic-modelling-efficacy-across-textual-levels" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="research-rationale-topic-modelling-efficacy-across-textual-levels"><span class="header-section-number">14.1</span> Research Rationale: Topic Modelling Efficacy Across Textual Levels</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Investigators initiated an inquiry to ascertain the most effective textual level—titles, abstracts, or full-texts—for applying topic modelling techniques to scientific literature. This area holds particular relevance for the history, philosophy, and sociology of science. Topic modelling has, indeed, emerged as a crucial instrument for dissecting substantial volumes of scholarly publications.</p>
<p>This powerful technique enables diverse analytical tasks, such as identifying research trends and paradigm shifts, uncovering thematic substructures and their interrelations, and tracing the evolution of scientific terminology. Observations from existing literature, however, reveal a varied application of topic modelling across these different textual components.</p>
<p>This background prompts a central research question: can analyses restricted to titles or abstracts yield sufficient insights, or does comprehensive full-text analysis remain essential? The considerable resources demanded for obtaining, preprocessing, and analysing complete full-text corpora lend urgency to this question.</p>
<p>To address this, investigators first assembled a corpus of scientific articles. Subsequently, they meticulously identified the title, abstract, and full-text sections for each document. Two distinct topic modelling methodologies, Latent Dirichlet Allocation (<em>LDA</em>) and <em>BERTopic</em>, were then applied to each of these three textual levels. Finally, the six generated topic models underwent rigorous qualitative and quantitative comparison to evaluate their respective performances.</p>
</section>
<section id="methodology-topic-modelling-approaches-lda-and-bertopic" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="methodology-topic-modelling-approaches-lda-and-bertopic"><span class="header-section-number">14.2</span> Methodology: Topic Modelling Approaches – <em>LDA</em> and <em>BERTopic</em></h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_05.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>Investigators employed two distinct topic modelling methodologies: Latent Dirichlet Allocation (<em>LDA</em>) and <em>BERTopic</em>. Both approaches operate on the premise that documents can be translated into numerical vectors. This transformation allows topics to be identified through the analysis of repetitions that highlight linguistic regularities. Machine learning techniques then automate the detection of these underlying patterns.</p>
<p>Latent Dirichlet Allocation, a well-established statistical method, constructs simple vector representations by counting word occurrences within documents. Within this framework, topics manifest as latent variables governed by Dirichlet’s probability distribution. A key advantage of <em>LDA</em> is its capacity to handle extensive texts, rendering it applicable to titles, abstracts, and full-text documents alike.</p>
<p>Conversely, <em>BERTopic</em> offers a more recent, modular alternative. This approach leverages vector representations derived from Large Language Models, with <em>BERT</em> (Bidirectional Encoder Representations from Transformers) serving as its foundational model. In <em>BERTopic</em>, topics emerge as clusters of similar documents.</p>
<p>Whilst earlier iterations of <em>BERTopic</em> faced limitations with long texts, this study incorporated new embedding techniques. These advancements enable the processing of substantial textual inputs, up to approximately 131,000 tokens, thereby extending <em>BERTopic</em>’s utility to full-text analysis.</p>
</section>
<section id="methodology-material-for-qualitative-comparison-an-astrobiology-corpus" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="methodology-material-for-qualitative-comparison-an-astrobiology-corpus"><span class="header-section-number">14.3</span> Methodology: Material for Qualitative Comparison – An Astrobiology Corpus</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>For the qualitative comparison, researchers utilised material from a prior in-depth topic analysis of an astrobiology corpus, detailed in Malaterre &amp; Lareau (2023). Following a thorough evaluation process, they selected an existing Latent Dirichlet Allocation (<em>LDA</em>) full-text model, which featured 25 distinct topics, as a reference. Each of these 25 topics had undergone meticulous analysis, examining its most representative words and associated documents, leading to the generation of a descriptive label for each topic using pertinent keywords.</p>
<p>Subsequently, the interrelations between these topics were quantified. Researchers calculated the mutual correlation based on how topics appeared together within documents. A community detection algorithm then processed these correlations, successfully identifying four overarching thematic clusters. These clusters received designations using letters (A, B, C, D) and distinct colours (red, green, yellow, and blue) for clarity.</p>
<p>The study presented these findings visually, employing a graph that illustrated the correlations between the 25 topics, complete with their assigned labels and colour-coded cluster memberships. In this graphical representation, the thickness of the lines signified the strength of the correlation between connected topics, whilst the size of the circles indicated the overall prevalence of each topic throughout the entire document collection. In essence, this pre-existing, detailed analysis provided a robust qualitative foundation against which the six topic models generated in the current investigation could be systematically compared.</p>
</section>
<section id="methodology-quantitative-analysis-metrics" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="methodology-quantitative-analysis-metrics"><span class="header-section-number">14.4</span> Methodology: Quantitative Analysis Metrics</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_08.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>Researchers employed four distinct metrics for the quantitative analysis to compare the topic models. Firstly, the Adjusted Rand Index (<em>ARI</em>) served to evaluate the similarity between any two document clusterings produced by the models, with a crucial correction for agreements that might occur by chance. An <em>ARI</em> value of zero typically signifies a random clustering.</p>
<p>Secondly, topic diversity was assessed. This metric quantifies the proportion of distinct top words that characterise the topics within a given topic model, indicating whether different topics are described by unique sets of terms. Thirdly, joint recall provided a measure of how well the top words collectively represent the documents classified under each topic. Specifically, it evaluates the average document-topic recall, considering the relationship between a topic’s top words and its associated documents.</p>
<p>Finally, coherence, specifically Coherence CV, was measured. This metric aims to determine if the top words constituting a topic are semantically related and form a meaningful group. Its calculation involves averaging the cosine relative distance between the top words within each topic.</p>
</section>
<section id="results-adjusted-rand-index-analysis-of-model-similarity" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="results-adjusted-rand-index-analysis-of-model-similarity"><span class="header-section-number">14.5</span> Results: Adjusted Rand Index Analysis of Model Similarity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>The application of the Adjusted Rand Index (<em>ARI</em>) across all six topic models revealed varying degrees of similarity between them. As a reminder, an <em>ARI</em> score of zero signifies that the agreement between two clusterings is no better than random. The results, often visualised as a heatmap, indicated that the Latent Dirichlet Allocation (<em>LDA</em>) model applied to titles (<em>LDA Title</em>) was the most distinct. It showed the lowest similarity to the other models, with <em>ARI</em> values generally falling below 0.2.</p>
<p>In contrast, all other models demonstrated a better overall match with one another, achieving <em>ARI</em> values consistently above 0.2. Notably, the <em>BERTopic</em> models exhibited a stronger internal coherence; they tended to align more closely with each other, yielding <em>ARI</em> values that surpassed 0.35. Within this group, the <em>BERTopic</em> model applied to abstracts (<em>BERTopic Abstract</em>) emerged as a somewhat central figure, as it corresponded well with nearly every other model, the only significant exception being the divergent <em>LDA Title</em> model.</p>
</section>
<section id="results-qualitative-comparison-of-lda-models" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="results-qualitative-comparison-of-lda-models"><span class="header-section-number">14.6</span> Results: Qualitative Comparison of <em>LDA</em> Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_09.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>A more detailed qualitative analysis focused on the Latent Dirichlet Allocation (<em>LDA</em>) models. When comparing the <em>LDA</em> full-text model with the <em>LDA</em> abstract model (Table A), researchers observed a good overall fit. This conclusion arose because topics from one model generally found a corresponding match in the other, evidenced by a high proportion of shared documents, which formed a noticeable reddish diagonal in the suitably organised heatmap.</p>
<p>Nevertheless, some transformations occurred: three topics present in the full-text <em>LDA</em> model disappeared in the abstract model, whilst another three full-text topics split into multiple, more granular topics within the abstract representation. Conversely, three entirely new topics emerged in the <em>LDA</em> abstract model, and three other abstract topics appeared to be the result of mergers from the full-text model. An additional observation was the presence of one small class, or topic, in the <em>LDA</em> abstract model, encompassing fewer than 50 documents.</p>
<p>The comparison between the <em>LDA</em> full-text model and the <em>LDA</em> title model (Table B) revealed a starkly different picture. Here, the fit was poor, indicating substantial reorganisation of thematic structures. Numerous topics from the full-text model disappeared when moving to the title-based model, and concurrently, many new topics emerged that were specific to the <em>LDA</em> title analysis. The heatmap for this comparison displayed a profusion of dark vertical and horizontal lines, visually underscoring the extensive restructuring of topics.</p>
</section>
<section id="results-qualitative-comparison-involving-bertopic-models" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="results-qualitative-comparison-involving-bertopic-models"><span class="header-section-number">14.7</span> Results: Qualitative Comparison Involving <em>BERTopic</em> Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_11.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>Investigators then examined the <em>BERTopic</em> models in comparison. When contrasting the <em>BERTopic</em> full-text model with the original <em>LDA</em> full-text model (Table C), they found an average overall fit. From the perspective of the <em>LDA</em> full-text topics, eight disappeared in the <em>BERTopic</em> full-text representation, and six were split into more granular topics. Conversely, five new topics emerged within the <em>BERTopic</em> full-text model, and one topic appeared to be the result of a merger. This model, however, presented class size issues: specifically, four small classes and one extremely large class.</p>
<p>Next, comparing the <em>BERTopic</em> abstract model against the <em>LDA</em> abstract model (Table D), researchers noted a relatively good overall fit. In this transition, four topics from the <em>LDA</em> abstract model disappeared, whilst six were split. The <em>BERTopic</em> abstract model introduced two new topics and featured four topics that resulted from mergers. Importantly, the class sizes in this <em>BERTopic</em> abstract model were generally balanced.</p>
<p>Finally, the comparison between the <em>BERTopic</em> title model and the <em>LDA</em> title model (Table E) indicated an average fit. Seven topics from the <em>LDA</em> title model were absent in the <em>BERTopic</em> title model, and one <em>LDA</em> title topic was split. The <em>BERTopic</em> title model, in turn, presented seven new topics and one topic formed by a merger. This model also exhibited class size concerns, with three small classes and one large class.</p>
</section>
<section id="results-lda-top-words-qualitative-analysis" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="results-lda-top-words-qualitative-analysis"><span class="header-section-number">14.8</span> Results: <em>LDA</em> Top-Words Qualitative Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>A qualitative assessment of the top words defining topics within the Latent Dirichlet Allocation (<em>LDA</em>) models revealed that, generally, the topics were relatively well-formed across the full-text, abstract, and title variations. Investigators observed instances of robust topics that maintained a strong correspondence across all three <em>LDA</em> models. A notable example was the topic labelled “A-Radiation spore” in the <em>LDA</em> full-text model, which aligned closely with semantically similar topics in both the <em>LDA</em> abstract model (characterised by top words such as “radiation,” “spore,” and “space”) and the <em>LDA</em> title model (with top words including “space,” “simulated,” and “spore”).</p>
<p>Furthermore, some topics identified in the full-text model underwent splitting, fragmenting into several distinct topics within the abstract and title models. For instance, the “A-Life civilization” topic from the full-text analysis split, and one of its resultant components in the abstract model cohered into a general theme concerning research and astrobiology; this particular split was deemed logical. Another full-text topic, “B-Chemistry,” also fragmented, though its resulting divisions proved more challenging to interpret readily without deeper investigation.</p>
<p>Conversely, the analysis also identified instances of topic merging. Certain topics from the full-text model consolidated into new, more encompassing topics in the other <em>LDA</em> models. For example, the distinct full-text topics “B-Amino-acid” and “B-Protein-gene-rna” merged within the <em>LDA</em> abstract model. This fusion created a broader, more generalised topic, a development considered to be a sensible thematic consolidation.</p>
</section>
<section id="results-bertopic-top-words-qualitative-analysis" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="results-bertopic-top-words-qualitative-analysis"><span class="header-section-number">14.9</span> Results: <em>BERTopic</em> Top-Words Qualitative Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_14.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>Continuing the top-words assessment with the three <em>BERTopic</em> models (full-text, abstract, and title), researchers again found that the topics were, on the whole, relatively well-formed when compared against the <em>LDA</em> full-text baseline. The previously identified robust topic, “A-Radiation spore,” demonstrated its stability by maintaining good correspondence across all <em>BERTopic</em> model variations as well.</p>
<p>The topic “A-Life-civilization,” also from the <em>LDA</em> full-text model, showed relative stability when analysed with <em>BERTopic</em> across the different text levels. However, it did undergo some degree of splitting here and there. These divisions typically resulted in the formation of narrower, more specific topics pertaining to extraterrestrial life. Similarly, the “B-Chemistry” topic from the <em>LDA</em> full-text model, when subjected to <em>BERTopic</em> analysis across the full-text, abstract, and title inputs, also tended to split. This fragmentation consistently led to the emergence of more narrowly focused chemical themes.</p>
</section>
<section id="results-quantitative-analysis-coherence-cv" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="results-quantitative-analysis-coherence-cv"><span class="header-section-number">14.10</span> Results: Quantitative Analysis – Coherence (CV)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_15.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>Researchers then presented the performance metrics for all six models, considering a range of topic numbers from 5 to 50. Beginning with coherence (specifically Coherence CV), which assesses the semantic relatedness of a topic’s top words, several patterns emerged. The analysis revealed that models based on titles consistently yielded the poorest coherence scores.</p>
<p>Comparing text levels, abstract-based models generally demonstrated superior coherence to their full-text counterparts. When contrasting the modelling techniques, <em>BERTopic</em> typically outperformed Latent Dirichlet Allocation (<em>LDA</em>) in terms of coherence for both abstract and title inputs. However, this advantage for <em>BERTopic</em> tended to lessen as the specified number of topics for the models rose. Across all configurations, the <em>BERTopic Abstract</em> model clearly emerged as the top performer for this particular metric.</p>
</section>
<section id="results-quantitative-analysis-topic-diversity" class="level2" data-number="14.11">
<h2 data-number="14.11" class="anchored" data-anchor-id="results-quantitative-analysis-topic-diversity"><span class="header-section-number">14.11</span> Results: Quantitative Analysis – Topic Diversity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_16.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The analysis of topic diversity, which measures the extent to which topics are described by distinct sets of words, showed a general trend: diversity tended to decrease as the number of topics in the models increased. Models constructed from titles offered better diversity scores when compared to their abstract or full-text equivalents.</p>
<p>Regarding the modelling techniques, <em>BERTopic</em> consistently achieved higher diversity scores than Latent Dirichlet Allocation (<em>LDA</em>). The <em>BERTopic Title</em> model emerged as the winner for this metric, although the <em>BERTopic Full-text</em> model followed very closely in performance.</p>
</section>
<section id="results-quantitative-analysis-joint-recall" class="level2" data-number="14.12">
<h2 data-number="14.12" class="anchored" data-anchor-id="results-quantitative-analysis-joint-recall"><span class="header-section-number">14.12</span> Results: Quantitative Analysis – Joint Recall</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_17.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>Joint recall, a metric that evaluates how effectively the top words of a topic collectively represent all documents classified within that topic, yielded further insights. Models based on titles demonstrated the poorest performance in terms of joint recall. Conversely, full-text models generally outperformed their abstract and title-based counterparts on this measure.</p>
<p>When comparing the two primary modelling techniques, Latent Dirichlet Allocation (<em>LDA</em>) tended to achieve better joint recall than <em>BERTopic</em>. The <em>LDA Full-text</em> model and the <em>BERTopic Full-text</em> model emerged as the top performers for joint recall, with the <em>BERTopic Abstract</em> model also demonstrating strong results, following very closely behind.</p>
</section>
<section id="results-summary-of-model-performance" class="level2" data-number="14.13">
<h2 data-number="14.13" class="anchored" data-anchor-id="results-summary-of-model-performance"><span class="header-section-number">14.13</span> Results: Summary of Model Performance</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_17.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>To provide a consolidated view, researchers assembled the various results into a summary table. This table depicted the performance of each of the six models—<em>LDA Full-text</em>, <em>LDA Abstract</em>, <em>LDA Title</em>, <em>BERTopic Full-text</em>, <em>BERTopic Abstract</em>, and <em>BERTopic Title</em>—across several assessment categories: overall fit, top-words quality, coherence, diversity, and joint recall. Performance levels were visually represented using circles, where a fully black circle indicated the highest score and a white circle denoted the lowest.</p>
<p>It is crucial to recognise that these results do not point to a single, universally superior model. The optimal choice invariably depends on the specific research objectives and needs of the investigator. For instance, if the primary aim involves discovering major thematic trends, and the precise classification of every single document is not paramount, then metrics like poor recall or the presence of a large class of unassigned documents might not present critical drawbacks.</p>
<p>Conversely, if the objective demands that all identified topics comprehensively cover the maximum number of relevant documents, then certain models become less suitable. Specifically, researchers do not recommend <em>BERTopic Full-text</em> and <em>BERTopic Title</em> for such tasks, as they both tended to produce large groups of unclassified documents; <em>BERTopic Title</em> also suffered from poor recall. The <em>LDA Title</em> model is likewise not advised for this scenario, given its generally weak performance across almost all assessment criteria.</p>
<p>In light of these findings, the researchers generally recommend performing topic modelling on either abstracts or full-texts, using either <em>LDA</em> or <em>BERTopic</em>. This recommendation comes with the important proviso that the chosen combination does not lead to significant misclassification of documents pertinent to the topics of interest.</p>
</section>
<section id="discussion-and-conclusion-implications-and-future-directions" class="level2" data-number="14.14">
<h2 data-number="14.14" class="anchored" data-anchor-id="discussion-and-conclusion-implications-and-future-directions"><span class="header-section-number">14.14</span> Discussion and Conclusion: Implications and Future Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_016_slide_17.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>The research culminated in several key findings and pointed towards future avenues of exploration. Firstly, title-based models generally exhibited poor performance. A plausible explanation for this lies in the inherent lack of informational content within titles alone, which can consequently lead to the misclassification of documents. Nevertheless, it is noteworthy that even the <em>BERTopic Title</em> model managed to identify a number of meaningful topics, suggesting that the utility of titles is not entirely negligible. This highlights a potential need to strike a balance between achieving well-defined topics and ensuring adequate document coverage for each topic.</p>
<p>Secondly, full-text models presented their own set of challenges. With Latent Dirichlet Allocation (<em>LDA</em>) applied to full-texts, topics sometimes appeared more loosely defined and broader in their thematic scope. Furthermore, such models occasionally identified transverse topics—for instance, those related to methodology—which might be secondary to the primary research themes of interest. <em>BERTopic</em>, when applied to full-texts, sometimes produced topics that were overly narrow. This specificity could lead to poor document coverage and contribute to problems with class size, such as the emergence of extremely large, undifferentiated clusters of documents.</p>
<p>Thirdly, abstract-based models demonstrated commendable performance. The results derived from abstracts showed consistency between both <em>LDA</em> and <em>BERTopic</em> approaches. Moreover, these abstract models aligned well with the <em>LDA</em> full-text model, indicating that abstracts often provide a balanced and effective summary of information suitable for topic modelling.</p>
<p>A fourth significant observation concerned the robustness of topics. Overall, the study found that very similar thematic structures emerged across the diverse range of models and text levels analysed. This consistency opens possibilities for employing meta-analytic techniques to pinpoint the most robust and consistently identified topics. Furthermore, the relative distances or similarities between models (such as those measured by the Adjusted Rand Index) could potentially be used to identify an optimal or most central model. In this particular study, the <em>BERTopic Abstract</em> model appeared to fulfil such a role, performing strongly across various metrics.</p>
<p>Lastly, the findings prompt consideration of new modelling approaches. Researchers hypothesise that it might be feasible to develop novel models, or refine existing ones, by explicitly leveraging the structural information inherent in scientific articles—that is, the distinct characteristics of full-texts, abstracts, and titles. Such an approach could potentially lead to the extraction of an even more meaningful and nuanced set of topics or defining top-words.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_017.html" class="pagination-link" aria-label="Time-Aware Language Models">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>