<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Francis Lareau &amp; Christophe Malaterre">
<meta name="dcterms.date" content="2025-01-01">

<title>14&nbsp; Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_017.html" rel="next">
<link href="./chapter_ai-nepi_015.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-85125aaa381e97e617f4eb7319a810c2.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_016.html"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: A Primer and Critical Reflections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Philosophy at Scale: Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification in Historical Patient Organisation Periodicals: A Methodological Report</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">VERITRACE Traces de la Vérité: The reappropriation of ancient wisdom in early modern natural philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Possible applications of RAG systems in philosophy</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#research-question-and-study-design" id="toc-research-question-and-study-design" class="nav-link" data-scroll-target="#research-question-and-study-design"><span class="header-section-number">14.1</span> Research Question and Study Design</a></li>
  <li><a href="#topic-modelling-methodologies" id="toc-topic-modelling-methodologies" class="nav-link" data-scroll-target="#topic-modelling-methodologies"><span class="header-section-number">14.2</span> Topic Modelling Methodologies</a></li>
  <li><a href="#corpus-and-qualitative-comparison-framework" id="toc-corpus-and-qualitative-comparison-framework" class="nav-link" data-scroll-target="#corpus-and-qualitative-comparison-framework"><span class="header-section-number">14.3</span> Corpus and Qualitative Comparison Framework</a></li>
  <li><a href="#quantitative-analysis-metrics" id="toc-quantitative-analysis-metrics" class="nav-link" data-scroll-target="#quantitative-analysis-metrics"><span class="header-section-number">14.4</span> Quantitative Analysis Metrics</a></li>
  <li><a href="#results-adjusted-rand-index-analysis" id="toc-results-adjusted-rand-index-analysis" class="nav-link" data-scroll-target="#results-adjusted-rand-index-analysis"><span class="header-section-number">14.5</span> Results: Adjusted Rand Index Analysis</a></li>
  <li><a href="#results-lda-model-inter-comparisons" id="toc-results-lda-model-inter-comparisons" class="nav-link" data-scroll-target="#results-lda-model-inter-comparisons"><span class="header-section-number">14.6</span> Results: LDA Model Inter-Comparisons</a></li>
  <li><a href="#results-bertopic-model-inter-comparisons" id="toc-results-bertopic-model-inter-comparisons" class="nav-link" data-scroll-target="#results-bertopic-model-inter-comparisons"><span class="header-section-number">14.7</span> Results: BERTopic Model Inter-Comparisons</a></li>
  <li><a href="#results-lda-top-word-correspondence" id="toc-results-lda-top-word-correspondence" class="nav-link" data-scroll-target="#results-lda-top-word-correspondence"><span class="header-section-number">14.8</span> Results: LDA Top-Word Correspondence</a></li>
  <li><a href="#results-bertopic-top-word-correspondence" id="toc-results-bertopic-top-word-correspondence" class="nav-link" data-scroll-target="#results-bertopic-top-word-correspondence"><span class="header-section-number">14.9</span> Results: BERTopic Top-Word Correspondence</a></li>
  <li><a href="#results-coherence-performance" id="toc-results-coherence-performance" class="nav-link" data-scroll-target="#results-coherence-performance"><span class="header-section-number">14.10</span> Results: Coherence Performance</a></li>
  <li><a href="#results-diversity-performance" id="toc-results-diversity-performance" class="nav-link" data-scroll-target="#results-diversity-performance"><span class="header-section-number">14.11</span> Results: Diversity Performance</a></li>
  <li><a href="#results-joint-recall-performance" id="toc-results-joint-recall-performance" class="nav-link" data-scroll-target="#results-joint-recall-performance"><span class="header-section-number">14.12</span> Results: Joint Recall Performance</a></li>
  <li><a href="#overall-model-performance-summary" id="toc-overall-model-performance-summary" class="nav-link" data-scroll-target="#overall-model-performance-summary"><span class="header-section-number">14.13</span> Overall Model Performance Summary</a></li>
  <li><a href="#discussion-and-future-directions" id="toc-discussion-and-future-directions" class="nav-link" data-scroll-target="#discussion-and-future-directions"><span class="header-section-number">14.14</span> Discussion and Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></h1>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Francis Lareau &amp; Christophe Malaterre <a href="mailto:francislareau@hotmail.com" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Université du Québec à Montréal; Université de Sherbrooke; CIRST
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The authors conducted a comparative study, systematically evaluating the performance of <em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em> across distinct textual granularities: titles, abstracts, and full texts. This investigation addresses a pivotal inquiry within topic modelling, a crucial analytical tool for scrutinising extensive volumes of scientific literature, particularly within the history, philosophy, and sociology of science. Topic modelling extracts themes from corpora, enabling the identification of research trends, paradigm shifts, substructures, interrelations of themes, and the evolution of scientific vocabulary.</p>
<p>The study’s core objective was to ascertain whether analysing titles or abstracts suffices for robust topic modelling, or if full-text analysis remains indispensable. This question arises given the substantial resources required for obtaining, preprocessing, and analysing comprehensive corpora. To achieve this, the research team constituted a corpus of scientific articles, meticulously identifying and segmenting title, abstract, and full-text sections. Subsequently, they applied both <em>LDA</em> and <em>BERTopic</em> approaches to each textual level. A dual analytical framework, encompassing both qualitative and quantitative methods, then facilitated the comparison of the resulting topic models. This rigorous methodology involved assessing model similarities, topic diversity, joint recall, and coherence, whilst leveraging a well-known astrobiology corpus for qualitative validation.</p>
</section>
<section id="research-question-and-study-design" class="level2" data-number="14.1">
<h2 data-number="14.1" class="anchored" data-anchor-id="research-question-and-study-design"><span class="header-section-number">14.1</span> Research Question and Study Design</h2>
<p>This research addresses a pivotal question within the domain of topic modelling: does analysing titles or abstracts provide sufficient data, or does full-text analysis remain a prerequisite? Topic modelling, a technique for extracting thematic content from textual corpora, has emerged as an indispensable tool for scrutinising extensive scientific literature, particularly within the history, philosophy, and sociology of science. Indeed, scholars employ it for diverse tasks, including identifying research trends, discerning paradigm shifts, uncovering substructures, mapping thematic interrelations, and tracing the evolution of scientific vocabulary.</p>
<p>Crucially, existing studies apply topic modelling across various textual structures, encompassing titles, abstracts, and complete articles. This practice, however, raises a significant concern: obtaining, preprocessing, and analysing full-text corpora demand considerable resources. Consequently, the efficiency of utilising shorter textual forms becomes a pressing inquiry.</p>
<p>To investigate this, the authors meticulously constituted a corpus of scientific articles. They then precisely identified and isolated the title, abstract, and full-text sections within each document. Subsequently, they applied two distinct topic modelling approaches—<em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em>—to each of these textual levels. A comprehensive analytical framework, integrating both qualitative and quantitative methods, facilitated the systematic comparison of the resultant topic models. This rigorous design ensured a thorough evaluation of performance across different model types and textual granularities.</p>
</section>
<section id="topic-modelling-methodologies" class="level2" data-number="14.2">
<h2 data-number="14.2" class="anchored" data-anchor-id="topic-modelling-methodologies"><span class="header-section-number">14.2</span> Topic Modelling Methodologies</h2>
<p>The study employed two principal topic modelling methodologies: <em>Latent Dirichlet Allocation</em> (<em>LDA</em>) and <em>BERTopic</em>. Both approaches fundamentally postulate that documents can be represented as numerical vectors. Within this framework, topics become identifiable through the detection of linguistic regularities, specifically repetitions, whilst machine learning algorithms facilitate the automatic discovery of these patterns.</p>
<p><em>LDA</em>, a classical statistical technique, constructs simple vector representations by counting words within documents. In this established approach, topics manifest as latent variables, adhering to Dirichlet’s law. Crucially, <em>LDA</em> readily accommodates extensive textual content, allowing for its application to titles, abstracts, or full texts.</p>
<p>Conversely, <em>BERTopic</em> represents a more recent, modular methodology. It leverages <em>Large Language Model</em> (<em>LLM</em>)-based vector representations, originally drawing upon <em>BERT</em>, which lends the approach its name. Here, topics emerge as clusters of documents. Historically, <em>BERTopic</em> struggled with processing lengthy texts; however, for this investigation, the authors integrated a novel embedding technique. This advancement significantly enhanced <em>BERTopic</em>’s capacity, enabling it to process approximately 131,000 tokens, thereby facilitating its application to full-text analysis.</p>
</section>
<section id="corpus-and-qualitative-comparison-framework" class="level2" data-number="14.3">
<h2 data-number="14.3" class="anchored" data-anchor-id="corpus-and-qualitative-comparison-framework"><span class="header-section-number">14.3</span> Corpus and Qualitative Comparison Framework</h2>
<p>The study’s qualitative comparisons drew upon a meticulously analysed astrobiology corpus, previously detailed by Malaterre and Lareau in 2023. Following a comprehensive evaluation, the authors selected a full-text <em>LDA</em> model comprising 25 distinct topics to serve as a foundational reference.</p>
<p>Scholars meticulously analysed these 25 topics, examining their most representative words and documents. This process facilitated the generation of a concise label for each topic, derived directly from its key terms. Subsequently, they compared the topics by calculating their mutual correlation, a metric based on the topics’ presence within individual documents. A community detection algorithm then identified four distinct thematic clusters, designated A, B, C, and D, and visually distinguished by red, green, yellow, and blue hues respectively.</p>
<p>A graphical representation visually conveyed these findings, illustrating the correlations amongst the 25 topics, complete with their assigned labels and cluster affiliations. In this visualisation, the thickness of the connecting lines denoted the strength of the correlation between topics, whilst the size of each circular node indicated the topic’s overall prevalence across the entire document collection. This established analytical framework provided a robust basis for the qualitative assessment of the six topic models under investigation.</p>
</section>
<section id="quantitative-analysis-metrics" class="level2" data-number="14.4">
<h2 data-number="14.4" class="anchored" data-anchor-id="quantitative-analysis-metrics"><span class="header-section-number">14.4</span> Quantitative Analysis Metrics</h2>
<p>For quantitative analysis, the authors employed four distinct metrics to rigorously compare the topic models.</p>
<ul>
<li><p>Firstly, the Adjusted Rand Index (<em>ARI</em>) served to evaluate the similarity between any two document clusterings, whilst correcting for chance agreement. This metric precisely assessed the degree to which documents tended to cluster together across different models.</p></li>
<li><p>Secondly, Topic Diversity quantified the proportion of distinct top words within a given topic model, thereby evaluating whether individual topics were indeed characterised by unique vocabularies.</p></li>
<li><p>Thirdly, Joint Recall measured the average document-topic recall in relation to any topic’s top words. This metric critically assessed how effectively the top words collectively represented the documents assigned to each topic.</p></li>
<li><p>Finally, Coherence CV, calculated as the average cosine relative distance between top words within topics, determined whether the constituent words of a topic exhibited a meaningful semantic relationship.</p></li>
</ul>
</section>
<section id="results-adjusted-rand-index-analysis" class="level2" data-number="14.5">
<h2 data-number="14.5" class="anchored" data-anchor-id="results-adjusted-rand-index-analysis"><span class="header-section-number">14.5</span> Results: Adjusted Rand Index Analysis</h2>
<p>The Adjusted Rand Index (<em>ARI</em>) provided initial insights into the similarities amongst the six topic models. A score of zero on this metric signifies a random clustering, establishing a baseline for comparison. Analysis revealed that the <em>LDA</em> model applied to titles exhibited the most pronounced dissimilarity from all other models, consistently registering <em>ARI</em> values below 0.2 within the heatmap.</p>
<p>Conversely, the remaining models generally achieved a superior overall match, with <em>ARI</em> scores exceeding 0.2. Notably, <em>BERTopic</em> models demonstrated a stronger mutual fit, consistently yielding values above 0.35. Amongst these, the <em>BERTopic</em> abstract model emerged as particularly central, correlating effectively with every other model, save for the outlier <em>LDA</em> title model.</p>
</section>
<section id="results-lda-model-inter-comparisons" class="level2" data-number="14.6">
<h2 data-number="14.6" class="anchored" data-anchor-id="results-lda-model-inter-comparisons"><span class="header-section-number">14.6</span> Results: LDA Model Inter-Comparisons</h2>
<p>A more granular analysis of the <em>LDA</em> models provided detailed insights into their inter-relationships. Comparing <em>LDA</em> Full-text with <em>LDA</em> Abstract (Table A) revealed a generally strong fit. A distinct reddish diagonal in the table indicated that each topic from one model largely corresponded to a topic in the other, sharing a high proportion of common documents. Despite this overall alignment, some dynamic shifts occurred: three full-text <em>LDA</em> topics entirely disappeared, whilst another three split into multiple topics within the abstract model. Concurrently, three novel abstract topics emerged, and three abstract topics resulted from the merger of others. Furthermore, one small class within the abstract topics contained fewer than 50 documents.</p>
<p>In stark contrast, the comparison between <em>LDA</em> Full-text and <em>LDA</em> Title (Table B) demonstrated a poor fit, necessitating substantial reorganisation. This disparity manifested as numerous full-text topics vanishing and a proliferation of new topics appearing within the title model, underscoring the limited correspondence between these two textual granularities for <em>LDA</em>.</p>
</section>
<section id="results-bertopic-model-inter-comparisons" class="level2" data-number="14.7">
<h2 data-number="14.7" class="anchored" data-anchor-id="results-bertopic-model-inter-comparisons"><span class="header-section-number">14.7</span> Results: BERTopic Model Inter-Comparisons</h2>
<p>Analysis of the <em>BERTopic</em> models, particularly in comparison with <em>LDA</em> Full-text, revealed varied levels of correspondence. Comparing <em>LDA</em> Full-text with <em>BERTopic</em> Full-text (Table C) indicated an average overall fit. Within this comparison, eight topics from the <em>LDA</em> model disappeared, whilst six topics split into the <em>BERTopic</em> model. Conversely, five new topics emerged within the <em>BERTopic</em> model, and one topic resulted from mergers. Furthermore, the document distribution showed four small classes alongside one notably large class.</p>
<p>The comparison between <em>LDA</em> Full-text and <em>BERTopic</em> Abstract (Table D) demonstrated a relatively good fit. Here, four topics disappeared, six topics split, two new topics appeared, and four topics resulted from mergers.</p>
<p>Finally, examining <em>LDA</em> Full-text against <em>BERTopic</em> Title (Table E) again indicated an average overall fit. In this instance, seven topics disappeared, whilst one topic split. Simultaneously, seven new topics emerged, and one topic resulted from a merger. The document distribution for this comparison revealed three small classes and one large class.</p>
</section>
<section id="results-lda-top-word-correspondence" class="level2" data-number="14.8">
<h2 data-number="14.8" class="anchored" data-anchor-id="results-lda-top-word-correspondence"><span class="header-section-number">14.8</span> Results: LDA Top-Word Correspondence</h2>
<p>An examination of the top words within the <em>LDA</em> models revealed that topics generally maintained a relatively well-formed structure across all iterations. The authors identified several robust topics exhibiting strong correspondence across every <em>LDA</em> model; “A-Radiation spore” serves as a prime example of such consistency.</p>
<p>Conversely, certain topics from the full-text model fragmented across the abstract and title models. For instance, “A-Life civilization” split into multiple sub-topics, a division that logically aligned with the broader theme of research in astrobiology. However, the fragmentation of “B-Chemistry” proved more challenging to interpret without deeper investigation.</p>
<p>Furthermore, the analysis uncovered instances where topics from the full-text model merged into new, consolidated topics within the abstract and title models. The fusion of “B-Amino-acid” and “B-Protein-gene-RNA” exemplified this phenomenon, forming a more generalised and coherent thematic unit.</p>
</section>
<section id="results-bertopic-top-word-correspondence" class="level2" data-number="14.9">
<h2 data-number="14.9" class="anchored" data-anchor-id="results-bertopic-top-word-correspondence"><span class="header-section-number">14.9</span> Results: BERTopic Top-Word Correspondence</h2>
<p>Continuing the assessment of top words, the three <em>BERTopic</em> models consistently yielded relatively well-formed topics. Notably, “A-Radiation spore” again demonstrated remarkable robustness, maintaining its coherence across all <em>BERTopic</em> iterations. Similarly, “A-Life civilization” remained comparatively stable across the models, albeit with some observed splitting.</p>
<p>This fragmentation of “A-Life civilization” specifically led to the emergence of narrower topics, focusing precisely on extraterrestrial life. Furthermore, the splitting of “B-Chemistry” across the <em>BERTopic</em> models also resulted in more specialised, narrower thematic categories.</p>
</section>
<section id="results-coherence-performance" class="level2" data-number="14.10">
<h2 data-number="14.10" class="anchored" data-anchor-id="results-coherence-performance"><span class="header-section-number">14.10</span> Results: Coherence Performance</h2>
<p>An evaluation of the models’ coherence, a metric assessing the meaningfulness of topic top words, revealed distinct performance patterns across a range of 5 to 50 topics. Titles consistently yielded the poorest coherence scores, indicating a less meaningful grouping of their constituent words. Conversely, abstract models generally demonstrated superior coherence compared to their full-text counterparts.</p>
<p>Across the board, <em>BERTopic</em> models exhibited better coherence than <em>LDA</em>, particularly for abstract and title analyses. However, this performance gap narrowed as the number of topics increased. Ultimately, the <em>BERTopic</em> Abstract model emerged as the unequivocal leader in terms of coherence.</p>
</section>
<section id="results-diversity-performance" class="level2" data-number="14.11">
<h2 data-number="14.11" class="anchored" data-anchor-id="results-diversity-performance"><span class="header-section-number">14.11</span> Results: Diversity Performance</h2>
<p>Assessing the diversity of top words representing the topics, a clear trend emerged: diversity generally diminished as the number of topics increased. Titles, surprisingly, offered the highest diversity amongst all models, suggesting a broader range of unique words characterising their topics.</p>
<p>Furthermore, <em>BERTopic</em> consistently outperformed <em>LDA</em> in terms of diversity. Ultimately, the <em>BERTopic</em> Title model secured the top position for diversity, with <em>BERTopic</em> Full-text closely trailing.</p>
</section>
<section id="results-joint-recall-performance" class="level2" data-number="14.12">
<h2 data-number="14.12" class="anchored" data-anchor-id="results-joint-recall-performance"><span class="header-section-number">14.12</span> Results: Joint Recall Performance</h2>
<p>The joint recall metric, which evaluates the efficacy of top words in collectively representing documents classified within each topic, revealed distinct performance hierarchies. Titles consistently yielded the poorest recall scores, indicating a limited ability of their top words to capture the full scope of associated documents. Conversely, full-text models demonstrated superior recall compared to both their abstract and title counterparts.</p>
<p>Between the two primary approaches, <em>LDA</em> generally exhibited better joint recall than <em>BERTopic</em>. Ultimately, <em>LDA</em> Full-text and <em>BERTopic</em> Full-text emerged as joint leaders in this category, with <em>BERTopic</em> Abstract following very closely behind.</p>
</section>
<section id="overall-model-performance-summary" class="level2" data-number="14.13">
<h2 data-number="14.13" class="anchored" data-anchor-id="overall-model-performance-summary"><span class="header-section-number">14.13</span> Overall Model Performance Summary</h2>
<p>The authors compiled the comprehensive results into a summary table, visually representing each model’s performance across various assessments using a graded circle system: black denoted the highest score, whilst white indicated the lowest. Crucially, this synthesis underscored the absence of an absolute “best” model, as varying research objectives inherently dictate differing needs and, consequently, distinct model choices.</p>
<p>Consider, for instance, an objective focused solely on discovering main topics, where precise document classification is not paramount. In such a scenario, issues like poor recall or significant class imbalance might prove negligible. Here, full-text <em>BERTopic</em> performed commendably, despite exhibiting some class imbalance. Similarly, whilst far from optimal, title <em>BERTopic</em> nonetheless generated several robust topics that consistently appeared across other models. Conversely, the authors strongly advise against employing <em>LDA</em> Title, given its consistently poor performance across nearly all assessment criteria.</p>
<p>Ultimately, the study recommends conducting topic modelling on either abstract or full-text data, utilising both <em>LDA</em> and <em>BERTopic</em>, provided such an approach does not result in the misclassification of documents pertinent to the identified topics.</p>
</section>
<section id="discussion-and-future-directions" class="level2" data-number="14.14">
<h2 data-number="14.14" class="anchored" data-anchor-id="discussion-and-future-directions"><span class="header-section-number">14.14</span> Discussion and Future Directions</h2>
<p>This research yielded several crucial findings, informing future approaches to topic modelling. Firstly, title models consistently demonstrated poor performance. This deficiency likely stems from the inherent lack of information within titles, which can lead to the false classification of documents. Nevertheless, the <em>BERTopic</em> title model surprisingly revealed several meaningful topics, suggesting a potential balance between well-defined topics and comprehensive document coverage remains achievable.</p>
<p>Secondly, full-text models, whilst offering comprehensive data, sometimes struggle to process vast quantities of information effectively. With <em>LDA</em>, topics can become more loosely defined and broader in scope, occasionally encompassing secondary themes such as methodology. Conversely, <em>BERTopic</em>, when applied to full text, can generate overly narrow topics, resulting in inadequate document coverage and issues with class size.</p>
<p>Thirdly, abstract models consistently performed well with summary information. Notably, the results obtained from <em>LDA</em> full text exhibited strong consistency with both abstract models, underscoring their utility. Fourthly, the study revealed a remarkable robustness of topics across all models. The authors identified very similar topics across the board, a consistency that facilitates the application of meta-analytic methods to pinpoint the most robust thematic elements. Moreover, leveraging the relative distance across models could enable the identification of an optimal solution, as exemplified by the <em>BERTopic</em> abstract model in this study, which performed exceptionally well across numerous metrics.</p>
<p>Finally, the findings prompt consideration of new model paradigms. It appears feasible to exploit the inherent structural information—encompassing full text, abstracts, and titles—to extract more semantically meaningful sets of topics or top words, thereby advancing the precision and utility of topic modelling.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_015.html" class="pagination-link" aria-label="Quantum Gravity and Plural Pursuit in Science">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_017.html" class="pagination-link" aria-label="Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis">
        <span class="nav-page-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>