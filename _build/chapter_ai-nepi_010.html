<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.13">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Christian Boulanger, David Carreto Fidalgo &amp; Andreas Wagner">
<meta name="dcterms.date" content="2025-01-01">

<title>10&nbsp; Parsing Footnotes in Law and Humanities Scholarship with Large Language Models – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_011.html" rel="next">
<link href="./chapter_ai-nepi_009.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-a126389619fad6dbfb296a5315d49fef.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_010.html"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-full">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: A Primer and Critical Reflections</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">```</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title"><code>&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDA0Lmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjQ8L3NwYW4+LS08c3Bhbi1jbGFzcz0nY2hhcHRlci10aXRsZSc+YGBgPC9zcGFuPg=="} [&lt;span class='chapter-number'&gt;5&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">```</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modelling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">SDG-Research in Bibliometric DBs - LLMs for HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG Systems for Philosophical Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title"><code>&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDA2Lmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjY8L3NwYW4+LS08c3Bhbi1jbGFzcz0nY2hhcHRlci10aXRsZSc+YGBgPC9zcGFuPg=="} [&lt;span class='chapter-number'&gt;7&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;Explainable AI and AI-based Scientific Insights in the Humanities&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDA3Lmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjc8L3NwYW4+LS08c3Bhbi1jbGFzcz0nY2hhcHRlci10aXRsZSc+RXhwbGFpbmFibGUtQUktYW5kLUFJLWJhc2VkLVNjaWVudGlmaWMtSW5zaWdodHMtaW4tdGhlLUh1bWFuaXRpZXM8L3NwYW4+"} [&lt;span class='chapter-number'&gt;8&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;Modelling Science: LLM for the History, Philosophy and Sociology of Science&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDA4Lmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjg8L3NwYW4+LS08c3Bhbi1jbGFzcz0nY2hhcHRlci10aXRsZSc+TW9kZWxsaW5nLVNjaWVuY2U6LUxMTS1mb3ItdGhlLUhpc3RvcnksLVBoaWxvc29waHktYW5kLVNvY2lvbG9neS1vZi1TY2llbmNlPC9zcGFuPg=="} [&lt;span class='chapter-number'&gt;9&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;SDG-Research in Bibliometric DBs - LLMs for HPSS&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDA5Lmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjk8L3NwYW4+LS08c3Bhbi1jbGFzcz0nY2hhcHRlci10aXRsZSc+U0RHLVJlc2VhcmNoLWluLUJpYmxpb21ldHJpYy1EQnMtLS1MTE1zLWZvci1IUFNTPC9zcGFuPg=="} [&lt;span class='chapter-number'&gt;10&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;Parsing Footnotes in Law and Humanities Scholarship with Large Language Models&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDEwLmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjEwPC9zcGFuPi0tPHNwYW4tY2xhc3M9J2NoYXB0ZXItdGl0bGUnPlBhcnNpbmctRm9vdG5vdGVzLWluLUxhdy1hbmQtSHVtYW5pdGllcy1TY2hvbGFyc2hpcC13aXRoLUxhcmdlLUxhbmd1YWdlLU1vZGVsczwvc3Bhbj4="} [&lt;span class='chapter-number'&gt;11&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;Science dynamics and AI&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDExLmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjExPC9zcGFuPi0tPHNwYW4tY2xhc3M9J2NoYXB0ZXItdGl0bGUnPlNjaWVuY2UtZHluYW1pY3MtYW5kLUFJPC9zcGFuPg=="} [&lt;span class='chapter-number'&gt;12&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;RAG Systems for Philosophical Research&lt;/span&gt;]{.hidden .quarto-markdown-envelope-contents render-id="cXVhcnRvLWludC1zaWRlYmFyOi9jaGFwdGVyX2FpLW5lcGlfMDEyLmh0bWw8c3Bhbi1jbGFzcz0nY2hhcHRlci1udW1iZXInPjEyPC9zcGFuPi0tPHNwYW4tY2xhc3M9J2NoYXB0ZXItdGl0bGUnPlJBRy1TeXN0ZW1zLWZvci1QaGlsb3NvcGhpY2FsLVJlc2VhcmNoPC9zcGFuPg=="} [&lt;span class='chapter-number'&gt;13&lt;/span&gt;&nbsp; &lt;span class='chapter-title'&gt;</code>markdown</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">```</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Unlocking Science’s Hidden Dynamics: A Computational Approach to Archival Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Transforming Biographical Sources into Knowledge Graphs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#challenges-in-humanities-citation-graph-generation" id="toc-challenges-in-humanities-citation-graph-generation" class="nav-link" data-scroll-target="#challenges-in-humanities-citation-graph-generation"><span class="header-section-number">10.1</span> Challenges in Humanities Citation Graph Generation</a></li>
  <li><a href="#large-language-models-and-footnote-complexity" id="toc-large-language-models-and-footnote-complexity" class="nav-link" data-scroll-target="#large-language-models-and-footnote-complexity"><span class="header-section-number">10.2</span> Large Language Models and Footnote Complexity</a></li>
  <li><a href="#developing-a-tei-annotated-gold-standard" id="toc-developing-a-tei-annotated-gold-standard" class="nav-link" data-scroll-target="#developing-a-tei-annotated-gold-standard"><span class="header-section-number">10.3</span> Developing a TEI-Annotated Gold Standard</a></li>
  <li><a href="#llamore-a-python-package-for-reference-extraction" id="toc-llamore-a-python-package-for-reference-extraction" class="nav-link" data-scroll-target="#llamore-a-python-package-for-reference-extraction"><span class="header-section-number">10.4</span> <em>Llamore</em>: A Python Package for Reference Extraction</a></li>
  <li><a href="#performance-analysis-and-future-directions" id="toc-performance-analysis-and-future-directions" class="nav-link" data-scroll-target="#performance-analysis-and-future-directions"><span class="header-section-number">10.5</span> Performance Analysis and Future Directions</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content column-body" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Parsing Footnotes in Law and Humanities Scholarship with Large Language Models</span></h1>
</div>


<div class="quarto-title-meta-author column-body">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Christian Boulanger, David Carreto Fidalgo &amp; Andreas Wagner <a href="mailto:boulanger@lhlt.mpg.de" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Max Planck Institute for Legal History and Legal Theory
          </p>
      </div>
  </div>

<div class="quarto-title-meta column-body">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>Researchers have long grappled with the persistent challenge of extracting citation data from the complex footnotes prevalent in law and humanities scholarship. Historically, bibliometric databases have offered inadequate coverage for these domains. This deficiency stems primarily from a lack of commercial interest, a focus on impact factors over intellectual history, and the inherent complexity of humanities footnotes. Moreover, traditional machine learning tools consistently demonstrate poor performance in parsing these intricate structures. Consequently, this project explores the utility of Large Language Models (LLMs) and Vision Language Models (VLMs) as a more effective solution.</p>
<p>A central tenet of this research involves establishing a robust testing and evaluation framework. To this end, scholars are developing a high-quality gold standard dataset, meticulously annotated using TEI XML encoding. This standard, well-established within the digital humanities, facilitates comprehensive representation of citation phenomena, including crucial contextual information. Furthermore, it ensures interoperability with existing tools such as <em>Grobid</em>, enabling direct performance comparisons.</p>
<p>To operationalise this approach, engineers crafted <em>Llamore</em>, a lightweight Python package. <em>Llamore</em> extracts citation data from raw text or PDFs, exporting it into TEI-formatted XML files. Crucially, it also evaluates extraction performance against gold standard references using an F1-score metric, which accounts for precision and recall through an unbalanced assignment problem. Initial evaluations reveal that whilst <em>Llamore</em>’s resource consumption exceeds that of traditional tools like <em>Grobid</em> for biomedical literature, it significantly outperforms <em>Grobid</em> when processing the challenging, footnoted humanities data. Future work aims to expand the training data, refine evaluation metrics, and enhance <em>Llamore</em>’s capabilities to capture contextual citation information and resolve complex stylistic variations.</p>
</section>
<section id="challenges-in-humanities-citation-graph-generation" class="level2" data-number="10.1">
<h2 data-number="10.1" class="anchored" data-anchor-id="challenges-in-humanities-citation-graph-generation"><span class="header-section-number">10.1</span> Challenges in Humanities Citation Graph Generation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01: Visual representation of a complex citation graph.</figcaption>
</figure>
</div>
<p>Researchers confront a significant challenge: Large Language Models and other algorithms currently struggle with the intricate footnotes characteristic of law and humanities scholarship. Generating comprehensive citation graphs from these sources represents a primary objective of our work. Such graphs prove invaluable for intellectual history, enabling scholars to discern patterns and relationships within knowledge production, trace intellectual influences, and quantify the reception of published ideas. For instance, one can readily identify the most cited authors within a specific journal over a defined period, as demonstrated by an analysis of the <em>Journal of Law and Society</em> between 1994 and 2003.</p>
<p>A fundamental impediment arises from the extremely poor coverage of historical Social Sciences and Humanities (SSH) literature within existing bibliometric data sources. Leading platforms, including <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em>, exhibit substantial deficiencies in this regard. <em>Web of Science</em> and <em>Scopus</em>, moreover, impose prohibitive costs and restrictive licensing terms, hindering open research initiatives. Whilst <em>OpenAlex</em> offers an open-access alternative, it too lacks comprehensive coverage for many A-journals, pre-digital content, and non-English language publications. For example, the <em>Zeitschrift für Rechtssoziologie</em>, established in 1980, shows negligible citation data before the 2000s within these widely used databases.</p>
<p>Several factors contribute to this persistent data gap. Commercial entities demonstrate limited financial interest in humanities scholarship, unlike their engagement with STEM, medicine, and economics. Furthermore, these databases prioritise “impact factor” metrics for scientific evaluation, a focus that diverges significantly from the needs of intellectual history research. Crucially, the pervasive use of complex footnotes within humanities literature presents a unique parsing challenge, which traditional systems have consistently struggled to overcome.</p>
</section>
<section id="large-language-models-and-footnote-complexity" class="level2" data-number="10.2">
<h2 data-number="10.2" class="anchored" data-anchor-id="large-language-models-and-footnote-complexity"><span class="header-section-number">10.2</span> Large Language Models and Footnote Complexity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07: Illustration depicting the complexity of “footnotes from hell” with embedded commentary and non-reference text.</figcaption>
</figure>
</div>
<p>A second, equally pressing problem arises from the inherent complexity of humanities footnotes, often termed “footnotes from hell.” These structures frequently incorporate extensive commentary, extraneous content, and non-reference text, embedding the actual citations within considerable noise. Traditional instruments for extracting such information necessitate laborious manual annotation. Moreover, conventional machine learning tools, including those based on conditional random forests, consistently exhibit poor performance when faced with these intricate structures. For instance, the ExCite Performance study (Boulanger/Iurshina 2022) reported low extraction and segmentation accuracies across various training datasets, with combined data yielding an extraction accuracy of merely 0.22 and segmentation accuracy of 0.47. This highlights the limitations of previous approaches.</p>
<p>Consequently, researchers have turned to Large Language Models (LLMs) as a promising alternative. Initial experiments in 2022, utilising models such as <em>text-davinci-003</em>, demonstrated LLMs’ considerable capacity for extracting references from highly unstructured textual data. Newer models offer even greater potential, whilst Vision Language Models (VLMs) extend this capability to direct processing of PDF documents. Developers employ various methods, including prompt engineering, Retrieval-Augmented Generation (RAG), and fine-tuning, to optimise these models for specific tasks. RAG, for example, enhances LLM outputs by retrieving relevant information from a knowledge base before generating a response, thereby improving accuracy and reducing hallucinations.</p>
<p>Nevertheless, a crucial concern persists regarding the trustworthiness of LLM-generated results, particularly the risk of hallucinations. A notable incident involved a lawyer who, relying on <em>ChatGPT</em>, submitted a federal court filing citing at least six non-existent cases. Addressing this fundamental issue demands a robust testing and evaluation solution. Such a solution requires a high-quality gold standard dataset, a flexible framework capable of adapting to the rapidly evolving technology landscape, and solid testing algorithms to generate comparable performance metrics.</p>
</section>
<section id="developing-a-tei-annotated-gold-standard" class="level2" data-number="10.3">
<h2 data-number="10.3" class="anchored" data-anchor-id="developing-a-tei-annotated-gold-standard"><span class="header-section-number">10.3</span> Developing a TEI-Annotated Gold Standard</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_13.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 13: Diagram illustrating the multi-stage process of TEI XML annotation for footnotes.</figcaption>
</figure>
</div>
<p>To address the need for reliable evaluation, researchers have embarked upon compiling a comprehensive training and evaluation dataset, employing TEI XML encoding. This choice rests upon several compelling reasons. TEI XML represents a well-established, precisely specified, and comprehensive standard for text interchange within the digital humanities. Crucially, it encompasses a far broader range of phenomena than more restrictive bibliographical standards, such as <em>CSL</em> or <em>BibTeX</em>. Indeed, TEI extends beyond mere reference management, allowing for the encoding of citations, cross-references, and other contextual markup, which proves vital for classifying citation intention. Furthermore, adopting this standard enables the project to leverage existing digital editions, text collections, and corpora, thereby enhancing the generalisation and robustness of the developed mechanisms.</p>
<p>Nevertheless, the TEI standard presents its own set of challenges, both conceptual and technical. Conceptual difficulties arise in differentiating between pointers (references to a specific part of a text) and references (full bibliographical entries), whilst technical complexities involve managing constrained elements (e.g., specific fields within a citation) versus elliptic material (e.g., abbreviations like <em>ibid.</em> or <em>op. cit.</em>). Despite these hurdles, the dataset’s establishment progresses steadily. The encoding process involves multiple stages: capturing PDF screenshots, segmenting reference strings to distinguish them from non-reference footnote text, and finally, generating parsed structured data.</p>
<p>The dataset currently comprises 1,100 footnotes and endnotes, drawn from 25 articles across 10 Directory of Open Access Journals (DOAJ) titles. It specifically focuses on humanities scholarship, particularly legal and historical texts, and encompasses a diverse range of languages, including French, German, Spanish, Italian, and Portuguese, spanning the period from 1958 to 2018. Researchers estimate the dataset will contain over 1,600 references, with individual occurrences encoded separately to preserve contextual information. Notably, the project adjusted its strategy midway, shifting to Open Access journals and incorporating PDFs to facilitate Vision Language Model (VLM) mechanisms and enable the full publication of the dataset.</p>
<p>The interoperability afforded by the TEI XML standard offers a significant advantage, enabling seamless integration with existing tooling. <em>Grobid</em>, a widely recognised tool for reference and information extraction, notably utilises TEI XML for its training and evaluation processes. Consequently, this shared data format permits direct performance comparisons with <em>Grobid</em> and facilitates the exchange of training data, benefiting both the project and the broader research community.</p>
</section>
<section id="llamore-a-python-package-for-reference-extraction" class="level2" data-number="10.4">
<h2 data-number="10.4" class="anchored" data-anchor-id="llamore-a-python-package-for-reference-extraction"><span class="header-section-number">10.4</span> <em>Llamore</em>: A Python Package for Reference Extraction</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_14.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 14: Workflow diagram showing <em>Llamore</em> processing text/PDFs to TEI XML and evaluating against gold standards.</figcaption>
</figure>
</div>
<p>Researchers have developed <em>Llamore</em>, a Python package acronym for “Large LANguage MOdels for Reference Extraction.” This tool facilitates two primary functions: extracting citation data from raw text or PDF inputs using multimodal Large Language Models, and subsequently evaluating the extraction performance. The workflow proceeds from text or PDF documents, through <em>Llamore</em>, to produce references in TEI XML format. These extracted references then undergo comparison with gold standard references, yielding an F1-score as an evaluation metric.</p>
<p>Crafting <em>Llamore</em> involved two key objectives. Firstly, the package needed to remain lightweight, comprising fewer than 2,000 lines of code. Crucially, <em>Llamore</em> operates as an interface to a model of the user’s choosing, rather than embedding any specific model directly. Secondly, this design ensures broad compatibility with both open and closed Large Language Models and Vision Language Models, offering flexibility to researchers.</p>
<p>Implementing <em>Llamore</em> proves straightforward. Users can install the package directly from PyPI using <code>pip install llamore</code>. For extraction, one imports the relevant extractor, such as <em>GeminiExtractor</em> or <em>OpenaiExtractor</em>, then instantiates it with an API key. The extractor processes either a PDF file path or a raw input string, returning a collection of references that can then be exported to a TEI XML file. Notably, the <em>OpenaiExtractor</em> provides compatibility with numerous open model serving frameworks, including <em>Olama</em> and <em>VLLM</em>, which offer OpenAI-compatible API endpoints. For evaluation, users import the <em>F1</em> class, configure it (e.g., <code>levenshtein_distance=0</code> for exact matches), and compute the macro average F1-score by supplying both the extracted and gold references.</p>
<p><em>Llamore</em> employs the F1-score, a widely recognised metric for comparing structured data, to assess extraction performance. This score combines precision (the ratio of correctly identified elements to all predicted elements) and recall (the ratio of correctly identified elements to all actual elements in the gold standard) into a single harmonic mean. A perfect extraction yields an F1-score of 1, whilst an F1-score of 0 indicates no matches. For instance, in comparing an extracted reference to a gold standard, <em>Llamore</em> identifies matches for <code>analytic_title</code>, <code>monographic_title</code>, <code>authors.surname</code>, and <code>publication_date</code>, whilst noting a minor discrepancy in <code>authors.forename</code> due to an extraneous character in the gold reference. Furthermore, <em>Llamore</em> addresses the complex task of aligning extracted references with gold references by framing it as an unbalanced assignment problem. The tool computes F1 scores for every possible combination, constructs a matrix, and then maximises the total F1-score whilst ensuring a unique assignment, utilising SciPy’s solver for this optimisation. Significantly, the system penalises both missing and hallucinated references by assigning them an F1-score of zero.</p>
</section>
<section id="performance-analysis-and-future-directions" class="level2" data-number="10.5">
<h2 data-number="10.5" class="anchored" data-anchor-id="performance-analysis-and-future-directions"><span class="header-section-number">10.5</span> Performance Analysis and Future Directions</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_010_slide_20.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 20: Bar chart comparing <em>Llamore</em> and <em>Grobid</em> F1 scores on biomedical and humanities datasets.</figcaption>
</figure>
</div>
<p>Initial performance evaluations provide crucial insights into <em>Llamore</em>’s efficacy across diverse datasets. When tested on the <em>PLOS 1000 Dataset</em>, which comprises 1,000 biomedical PDFs and demands exact matches, <em>Grobid</em> achieved an F1 score of 0.61, whilst <em>Llamore</em>, utilising <em>Gemini 2.0 Flash</em>, attained a comparable F1 score of 0.62. However, for literature on which <em>Grobid</em> was specifically trained, it demonstrates superior efficiency, operating considerably faster and with fewer computational resources; <em>Llamore</em>’s compute requirements, conversely, are orders of magnitude greater.</p>
<p>A more compelling distinction emerges when evaluating performance on the project’s bespoke humanities dataset, which features complex footnotes and also requires exact matches. Here, <em>Grobid</em> struggles significantly, yielding an F1 score of only 0.14, largely due to its training data being out of distribution for such intricate structures. In stark contrast, <em>Llamore</em> (<em>Gemini 2.0 Flash</em>) achieves an F1 score of 0.45, representing a threefold improvement in performance. This initial evaluation clearly demonstrates <em>Llamore</em>’s superior capability in handling the unique challenges posed by humanities footnotes, validating the utility of LLMs for this specific domain. Nevertheless, this current performance metric pertains solely to pure reference extraction, excluding the capture of contextual information or cross-referencing.</p>
<p>Future work outlines several key objectives. Researchers plan to generate additional training data and further refine the test metrics to encompass a broader range of citation phenomena. Crucially, they aim to extend <em>Llamore</em>’s capabilities to support citations in context, discerning whether a work is cited approvingly or critically. Furthermore, the tool will incorporate features for resolving <em>op cit.</em> references, identifying specific pages cited, and quantifying multiple citations to the same work.</p>
<p>Addressing these enhancements will necessitate overcoming several challenges. These include the wide variation in citation styles (e.g., differentiating between volumes and pages, or first page versus cited page), the complexities of multilingual terminology (e.g., diverse contributor roles like “eds” or “hrsg. v.”, and special terms such as <em>passim</em>, <em>ibid</em>, or <em>n.d.</em>), the intricacies of canonical citations prevalent in fields like Bible studies or Roman law, and the accurate handling of ellipses, abbreviations, and cross-references. Overcoming these hurdles will significantly enhance <em>Llamore</em>’s utility for advanced scholarly analysis. ```</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation column-body">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_009.html" class="pagination-link" aria-label="SDG-Research in Bibliometric DBs - LLMs for HPSS">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">SDG-Research in Bibliometric DBs - LLMs for HPSS</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_011.html" class="pagination-link" aria-label="Science dynamics and AI">
        <span class="nav-page-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>