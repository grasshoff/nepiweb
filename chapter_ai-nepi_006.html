<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jeffrey Wolf">
<meta name="dcterms.date" content="2025-06-21">

<title>6&nbsp; The VERITRACE Project – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_007.html" rel="next">
<link href="./chapter_ai-nepi_005.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_006.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models in History, Philosophy, and Sociology of Science: Architectures, Adaptation, and Applications</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">LLM: Evolution of competence</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG systems solve central problems of LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum gravity and plural pursuit in science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-aware large language models towards a novel architecture for historical analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#project-overview-and-core-objectives" id="toc-project-overview-and-core-objectives" class="nav-link" data-scroll-target="#project-overview-and-core-objectives"><span class="header-section-number">6.1</span> Project Overview and Core Objectives</a></li>
  <li><a href="#computational-approaches-to-history-philosophy-and-sociology-of-science-hpss" id="toc-computational-approaches-to-history-philosophy-and-sociology-of-science-hpss" class="nav-link" data-scroll-target="#computational-approaches-to-history-philosophy-and-sociology-of-science-hpss"><span class="header-section-number">6.2</span> Computational Approaches to History, Philosophy, and Sociology of Science (HPSS)</a></li>
  <li><a href="#data-set-characteristics-and-analytical-techniques" id="toc-data-set-characteristics-and-analytical-techniques" class="nav-link" data-scroll-target="#data-set-characteristics-and-analytical-techniques"><span class="header-section-number">6.3</span> Data Set Characteristics and Analytical Techniques</a></li>
  <li><a href="#core-challenges-and-initial-llm-applications" id="toc-core-challenges-and-initial-llm-applications" class="nav-link" data-scroll-target="#core-challenges-and-initial-llm-applications"><span class="header-section-number">6.4</span> Core Challenges and Initial LLM Applications</a></li>
  <li><a href="#llms-as-judges-for-metadata-enrichment-motivation-and-challenges" id="toc-llms-as-judges-for-metadata-enrichment-motivation-and-challenges" class="nav-link" data-scroll-target="#llms-as-judges-for-metadata-enrichment-motivation-and-challenges"><span class="header-section-number">6.5</span> LLMs as Judges for Metadata Enrichment: Motivation and Challenges</a></li>
  <li><a href="#automating-bibliographic-record-matching" id="toc-automating-bibliographic-record-matching" class="nav-link" data-scroll-target="#automating-bibliographic-record-matching"><span class="header-section-number">6.6</span> Automating Bibliographic Record Matching</a></li>
  <li><a href="#llm-bench-for-match-evaluation" id="toc-llm-bench-for-match-evaluation" class="nav-link" data-scroll-target="#llm-bench-for-match-evaluation"><span class="header-section-number">6.7</span> LLM Bench for Match Evaluation</a></li>
  <li><a href="#prompt-guidelines-and-llm-output-analysis" id="toc-prompt-guidelines-and-llm-output-analysis" class="nav-link" data-scroll-target="#prompt-guidelines-and-llm-output-analysis"><span class="header-section-number">6.8</span> Prompt Guidelines and LLM Output Analysis</a></li>
  <li><a href="#veritrace-web-application-alpha-version-and-technical-approach" id="toc-veritrace-web-application-alpha-version-and-technical-approach" class="nav-link" data-scroll-target="#veritrace-web-application-alpha-version-and-technical-approach"><span class="header-section-number">6.9</span> VERITRACE Web Application: Alpha Version and Technical Approach</a></li>
  <li><a href="#data-processing-pipeline-for-web-application" id="toc-data-processing-pipeline-for-web-application" class="nav-link" data-scroll-target="#data-processing-pipeline-for-web-application"><span class="header-section-number">6.10</span> Data Processing Pipeline for Web Application</a></li>
  <li><a href="#veritrace-data-processing-pipeline-details" id="toc-veritrace-data-processing-pipeline-details" class="nav-link" data-scroll-target="#veritrace-data-processing-pipeline-details"><span class="header-section-number">6.11</span> VERITRACE Data Processing Pipeline Details</a></li>
  <li><a href="#veritrace-web-application-explore-section-and-metadata" id="toc-veritrace-web-application-explore-section-and-metadata" class="nav-link" data-scroll-target="#veritrace-web-application-explore-section-and-metadata"><span class="header-section-number">6.12</span> VERITRACE Web Application: Explore Section and Metadata</a></li>
  <li><a href="#veritrace-search-functionality" id="toc-veritrace-search-functionality" class="nav-link" data-scroll-target="#veritrace-search-functionality"><span class="header-section-number">6.13</span> VERITRACE Search Functionality</a></li>
  <li><a href="#veritrace-search-interface-and-query-specificity" id="toc-veritrace-search-interface-and-query-specificity" class="nav-link" data-scroll-target="#veritrace-search-interface-and-query-specificity"><span class="header-section-number">6.14</span> VERITRACE Search Interface and Query Specificity</a></li>
  <li><a href="#future-analytical-capabilities-the-analyse-module" id="toc-future-analytical-capabilities-the-analyse-module" class="nav-link" data-scroll-target="#future-analytical-capabilities-the-analyse-module"><span class="header-section-number">6.15</span> Future Analytical Capabilities: The ‘Analyse’ Module</a></li>
  <li><a href="#veritrace-read-section-digital-facsimiles-and-metadata" id="toc-veritrace-read-section-digital-facsimiles-and-metadata" class="nav-link" data-scroll-target="#veritrace-read-section-digital-facsimiles-and-metadata"><span class="header-section-number">6.16</span> VERITRACE Read Section: Digital Facsimiles and Metadata</a></li>
  <li><a href="#veritrace-match-tool-textual-similarity-and-customisation" id="toc-veritrace-match-tool-textual-similarity-and-customisation" class="nav-link" data-scroll-target="#veritrace-match-tool-textual-similarity-and-customisation"><span class="header-section-number">6.17</span> VERITRACE Match Tool: Textual Similarity and Customisation</a></li>
  <li><a href="#text-matching-methodologies-lexical-semantic-and-hybrid" id="toc-text-matching-methodologies-lexical-semantic-and-hybrid" class="nav-link" data-scroll-target="#text-matching-methodologies-lexical-semantic-and-hybrid"><span class="header-section-number">6.18</span> Text Matching Methodologies: Lexical, Semantic, and Hybrid</a></li>
  <li><a href="#lexical-match-results-and-semantic-match-expectations" id="toc-lexical-match-results-and-semantic-match-expectations" class="nav-link" data-scroll-target="#lexical-match-results-and-semantic-match-expectations"><span class="header-section-number">6.19</span> Lexical Match Results and Semantic Match Expectations</a></li>
  <li><a href="#lexical-match-highlighting-and-semantic-match-results" id="toc-lexical-match-highlighting-and-semantic-match-results" class="nav-link" data-scroll-target="#lexical-match-highlighting-and-semantic-match-results"><span class="header-section-number">6.20</span> Lexical Match Highlighting and Semantic Match Results</a></li>
  <li><a href="#semantic-matching-interface-and-progress" id="toc-semantic-matching-interface-and-progress" class="nav-link" data-scroll-target="#semantic-matching-interface-and-progress"><span class="header-section-number">6.21</span> Semantic Matching Interface and Progress</a></li>
  <li><a href="#semantic-match-results-and-model-adequacy" id="toc-semantic-match-results-and-model-adequacy" class="nav-link" data-scroll-target="#semantic-match-results-and-model-adequacy"><span class="header-section-number">6.22</span> Semantic Match Results and Model Adequacy</a></li>
  <li><a href="#future-challenges-and-model-selection" id="toc-future-challenges-and-model-selection" class="nav-link" data-scroll-target="#future-challenges-and-model-selection"><span class="header-section-number">6.23</span> Future Challenges and Model Selection</a></li>
  <li><a href="#additional-visual-materials" id="toc-additional-visual-materials" class="nav-link" data-scroll-target="#additional-visual-materials"><span class="header-section-number">6.24</span> Additional Visual Materials</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">The VERITRACE Project</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Jeffrey Wolf <a href="mailto:jeffrey.charles.wolf@vub.be" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Vrije Universiteit Brussel (VUB)
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">June 21, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The VERITRACE project, a five-year ERC Starting Grant (2023-2028), operates from the Vrije Universiteit Brussel (VUB) under the distinguished leadership of Research Professor Cornelis J. Schilt. This ambitious initiative meticulously investigates the profound influence of early modern ‘ancient wisdom’ traditions upon natural philosophy. Professor Schilt and his team aim to trace the enduring impact of seminal texts such as the <em>Chaldean Oracles</em>, <em>Sibylline Oracles</em>, <em>Orphic Hymns</em>, and the <em>Corpus Hermeticum</em> on intellectual giants like Isaac Newton and Johannes Kepler. Concurrently, they endeavour to uncover a broader, frequently overlooked network of related works, aptly termed the ‘great Unread’.</p>
<p>The VERITRACE team employs sophisticated computational methods to facilitate large-scale multilingual exploration. Their approach identifies textual reuse, discerning both direct lexical overlaps and subtle semantic similarities, whilst also revealing hidden networks of texts, passages, themes, topics, and authors. This rigorous investigation further seeks to illuminate novel patterns within the intellectual history and philosophy of science. Utilising a diverse multilingual dataset of approximately 430,000 printed texts from 1540 to 1728, meticulously sourced from Early English Books Online (EEBO), Gallica, and the Bavarian State Library, the team applies state-of-the-art digital techniques. These include advanced keyword search, precise text matching, nuanced topic modelling, and insightful sentiment analysis.</p>
<p>Core challenges for the project encompass the variable quality of Optical Character Recognition (OCR), the complexities of early modern typography and semantics across at least six languages, and the sheer volume of data. To address these hurdles, the team leverages Large Language Models (LLMs) for both metadata enrichment, employing <em>GPT</em>-based LLMs as discerning ‘judges’, and semantic encoding, utilising <em>BERT</em>-based LLMs for robust vector embeddings. A newly developed web application, currently in its alpha version, provides essential functionalities for corpus exploration, advanced search, and text matching. Future plans for this application include the integration of powerful analytical tools such as topic modelling and diachronic analysis. Comprising five members, including Professor Schilt as PI, a classicist, and historians, the VERITRACE team adeptly navigates significant computational and methodological complexities in its pursuit of comprehensive historical analysis.</p>
</section>
<section id="project-overview-and-core-objectives" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="project-overview-and-core-objectives"><span class="header-section-number">6.1</span> Project Overview and Core Objectives</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The VERITRACE project, a five-year ERC Starting Grant awarded from 2023 to 2028, operates from the Vrije Universiteit Brussel (VUB) under the leadership of Research Professor Cornelis J. Schilt. This initiative comprises a five-member team, including a classicist, historians, and a digital humanities specialist, who collectively aim to trace the profound influence of an early modern ‘ancient wisdom’ tradition on the evolution of natural philosophy and science.</p>
<p>Professor Schilt and his colleagues specifically focus on a close-reading corpus of 140 works, encompassing seminal texts such as the <em>Chaldean Oracles</em>, the <em>Sibylline Oracles</em>, the <em>Orphic Hymns</em>, and the <em>Corpus Hermeticum</em>. Historical evidence confirms the significant impact of these works; for instance, Isaac Newton engaged with the <em>Sibylline Oracles</em>, whilst Johannes Kepler demonstrated familiarity with the <em>Corpus Hermeticum</em>. Beyond these well-known connections, the project endeavours to uncover a much broader, often overlooked network of texts and intellectual relationships within this tradition, collectively termed the ‘great Unread’. These works, frequently authored by lesser-known figures, typically remain outside the primary focus of historical scholarship, yet they offer crucial insights into the intellectual landscape of the early modern period.</p>
</section>
<section id="computational-approaches-to-history-philosophy-and-sociology-of-science-hpss" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="computational-approaches-to-history-philosophy-and-sociology-of-science-hpss"><span class="header-section-number">6.2</span> Computational Approaches to History, Philosophy, and Sociology of Science (HPSS)</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The VERITRACE project fundamentally aims to advance the field of History, Philosophy, and Sociology of Science (HPSS) through the application of sophisticated computational methodologies. Professor Schilt and his team are developing tools for large-scale multilingual exploration, primarily through advanced keyword search capabilities. Crucially, the initiative seeks to identify textual re-use within an extensive, multilingual corpus, distinguishing between direct lexical overlaps and more subtle indirect semantic similarities. This capability effectively functions as an ‘Early Modern Plagiarism Detector’, enabling the detection of unacknowledged textual appropriation.</p>
<p>Furthermore, the project strives to uncover previously ignored networks of texts, passages, themes, topics, and authors, thereby illuminating hidden intellectual connections. Ultimately, these computational investigations are poised to reveal novel patterns and insights into the intellectual history and philosophy of science.</p>
</section>
<section id="data-set-characteristics-and-analytical-techniques" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="data-set-characteristics-and-analytical-techniques"><span class="header-section-number">6.3</span> Data Set Characteristics and Analytical Techniques</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>To achieve its ambitious objectives, the VERITRACE team has assembled a substantial and diverse multilingual dataset. They focus exclusively on printed works from approximately 1540 to 1728, concluding shortly after Isaac Newton’s death. This extensive corpus comprises around 430,000 texts in at least six different languages.</p>
<p>The researchers meticulously gathered these digital texts from three primary sources: Early English Books Online (EEBO), Gallica (the digital library of the French National Library), and the Bavarian State Library, which constitutes the largest single contributor to the dataset. Leveraging this rich collection, the team applies state-of-the-art digital techniques, including advanced keyword search functionalities, sophisticated text matching algorithms, topic modelling for thematic discovery, and sentiment analysis to discern emotional tones, amongst other analytical methods.</p>
</section>
<section id="core-challenges-and-initial-llm-applications" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="core-challenges-and-initial-llm-applications"><span class="header-section-number">6.4</span> Core Challenges and Initial LLM Applications</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The VERITRACE project confronts several formidable challenges inherent in processing historical texts at scale. Firstly, the team contends with highly variable Optical Character Recognition (OCR) quality, as libraries provide texts in raw formats—including XML, HOCR, and HTML files—without corresponding ground truth page images. This initial data quality significantly impacts all subsequent processing stages.</p>
<p>Secondly, the project navigates the complexities of early modern typography and the evolving semantics of at least six distinct languages, presenting considerable linguistic hurdles. Thirdly, the sheer volume of data—hundreds of thousands of texts printed across Europe over approximately two centuries—necessitates robust computational strategies. To address these challenges, the team currently employs Large Language Models (LLMs) in two principal capacities. On the decoder side, <em>GPT</em>-based LLMs assist in enriching and cleaning metadata, effectively acting as ‘judges’ to refine bibliographic information. Concurrently, on the encoder side, <em>BERT</em>-based LLMs generate vector embeddings, encoding the semantic meaning of sentences and short passages within the textual corpus to facilitate precise text matching.</p>
</section>
<section id="llms-as-judges-for-metadata-enrichment-motivation-and-challenges" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="llms-as-judges-for-metadata-enrichment-motivation-and-challenges"><span class="header-section-number">6.5</span> LLMs as Judges for Metadata Enrichment: Motivation and Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>A fundamental motivation for the VERITRACE project involves leveraging the Universal Short Title Catalogue (USTC) as a high-quality source for metadata enrichment. The primary objective is to map VERITRACE’s internal records onto USTC’s comprehensive entries, thereby generating ‘enriched’ metadata that demands significantly less manual cleaning.</p>
<p>However, this process presents a considerable challenge: whilst some mapping can be automated using existing external identifiers, the vast majority of VERITRACE records currently lack such identifiers and remain uncleaned. Consequently, the project faces the complex task of matching these records at scale, a process that proves exceedingly tedious for human review. The Universal Short Title Catalogue, accessible at https://www.ustc.ac.uk, serves as the authoritative reference for this enrichment endeavour.</p>
</section>
<section id="automating-bibliographic-record-matching" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="automating-bibliographic-record-matching"><span class="header-section-number">6.6</span> Automating Bibliographic Record Matching</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_08.png" class="img-fluid figure-img"></p>
<figcaption>Slide 08</figcaption>
</figure>
</div>
<p>The VERITRACE team seeks to automate the arduous task of comparing bibliographic metadata pairs to ascertain whether they represent the same underlying printed text. Previously, each team member undertook the extremely tedious manual review of 10,000 such pairs. To mitigate this, the researchers initially generate potential matches using a fuzzy matching algorithm, which assigns a match score to each pair.</p>
<p>The ultimate aim is for Large Language Models (LLMs) to perform these yes/no decisions at scale, critically providing detailed reasoning for each determination. However, this LLM-based approach has not yet achieved full functionality. The models frequently produce hallucinations, and whilst requesting more structured output can reduce these, it often results in generic, less helpful reasoning, indicating an ongoing challenge in balancing precision with informative responses.</p>
</section>
<section id="llm-bench-for-match-evaluation" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="llm-bench-for-match-evaluation"><span class="header-section-number">6.7</span> LLM Bench for Match Evaluation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_09.png" class="img-fluid figure-img"></p>
<figcaption>Slide 09</figcaption>
</figure>
</div>
<p>To address the challenge of automated bibliographic record matching, the VERITRACE project proposes ‘The LLM Bench’, a sophisticated panel of Large Language Models designed to evaluate potential matches. This system employs a tiered model configuration: <em>llama3:8b</em> serves as the primary model, prized for its power and accuracy; <em>qwen2:5.7b</em> acts as a secondary model, offering architectural diversity; <em>mixtral:8x7b</em> functions as a tiebreaker, possessing greater power than the initial two; and <em>llama3.3:latest</em> is designated as an expert model, reserved exclusively for complex edge cases requiring human review.</p>
<p>The process involves feeding pairs of bibliographic records—one from a low-quality metadata source and the other from a high-quality source—through this chain of LLMs. Each model provides a judgment (match or non-match), accompanied by detailed reasoning and confidence levels. Subsequently, the team validates these LLM decisions against ground truth data, with the VERITRACE team conducting a final review to ensure accuracy and refine the system.</p>
</section>
<section id="prompt-guidelines-and-llm-output-analysis" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="prompt-guidelines-and-llm-output-analysis"><span class="header-section-number">6.8</span> Prompt Guidelines and LLM Output Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_10.png" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>The VERITRACE team has established comprehensive prompt guidelines, termed ‘MATCHING_GUIDELINES’, to direct the LLMs in determining bibliographic record matches. These guidelines prioritise title content, whilst accounting for minor formatting differences, and emphasise author alignment, publication dates within a one-year window, and corroborating place/printer information.</p>
<p>Specific match criteria mandate identical core work in titles, precise or near-precise dates, matching or equivalent publication places, recognisable printer variations, and substantial author overlap. Conversely, non-match indicators include significantly divergent titles, dates exceeding a one-year difference, unexplained discrepancies in places or printers, and distinct authors or edition variations. An illustrative example demonstrates a ‘Ground Truth’ of ‘NON-MATCH’ yet a ‘Final Decision’ of ‘MATCH’ with high confidence (87.7%), driven by the tiebreaker model. The reasoning provided highlights factors such as title similarity, identical authors and dates, and equivalent publication places, even when language discrepancies exist. A significant ongoing challenge, however, stems from hallucinations in the output of the open-source LLMs employed. Whilst requesting more structured output mitigates these hallucinations, it often results in generic, less informative reasoning, presenting a delicate balance for the researchers to refine.</p>
</section>
<section id="veritrace-web-application-alpha-version-and-technical-approach" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="veritrace-web-application-alpha-version-and-technical-approach"><span class="header-section-number">6.9</span> VERITRACE Web Application: Alpha Version and Technical Approach</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The VERITRACE project has developed an ‘alpha’ version of its web application, which remains in its nascent stages and is not yet publicly accessible, currently residing on the presenter’s local machine. This application represents a future promise of the project’s capabilities, serving primarily as a testing and development platform.</p>
<p>The engineers are currently evaluating a <em>BERT</em>-based Large Language Model, specifically <em>LaBSE</em>, for generating vector embeddings that represent every passage within the extensive textual corpus. However, initial assessments suggest that whilst <em>LaBSE</em> functions in certain scenarios, it will likely prove insufficient for the project’s comprehensive requirements. Due to its early developmental stage, the application is demonstrated through static screenshots rather than a live, interactive website.</p>
</section>
<section id="data-processing-pipeline-for-web-application" class="level2" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="data-processing-pipeline-for-web-application"><span class="header-section-number">6.10</span> Data Processing Pipeline for Web Application</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The VERITRACE web application relies on an Elasticsearch database as its backend, necessitating a complex and extensive data processing pipeline to transform raw text into a usable format. This pipeline involves numerous critical steps, each demanding significant optimisation.</p>
<p>Initially, the system extracts text into standardised text files, subsequently generating precise mappings of all character positions. Further stages include segmenting documents into manageable units and rigorously assessing the Optical Character Recognition (OCR) quality, a particularly challenging task given the raw nature of the input. Each of these stages, whilst seemingly straightforward, requires considerable time and effort—potentially a week per stage—to optimise fully, underscoring the intricate background work underpinning the application’s functionality.</p>
</section>
<section id="veritrace-data-processing-pipeline-details" class="level2" data-number="6.11">
<h2 data-number="6.11" class="anchored" data-anchor-id="veritrace-data-processing-pipeline-details"><span class="header-section-number">6.11</span> VERITRACE Data Processing Pipeline Details</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_13.png" class="img-fluid figure-img"></p>
<figcaption>Slide 13</figcaption>
</figure>
</div>
<p>The VERITRACE project employs a sophisticated 15-stage data processing pipeline, currently running with 40% overall progress, indicating six completed stages. A detailed status summary reveals eight pending stages, one actively running, and no failures or skips. The pipeline’s configuration specifies parameters such as a working directory, file and error policies, input directory, dashboard port (8080), and settings for dependency verification and browser interaction.</p>
<p>Completed stages include batch processing (1.3s), character position generation (5.3s), page extraction (7.3s), language analysis (4m 35s), language map generation (0.7s), and OCR quality assessment (12.7s). The ‘segment documents’ stage is presently active, whilst subsequent stages, such as filtering segments, tracking relationships, unifying JSON, enriching MongoDB, and enriching sequences, remain pending. This complex pipeline transforms raw XML, HOCR, and HTML files into a format suitable for Elasticsearch, with vector embeddings generated towards its conclusion, each stage demanding meticulous optimisation.</p>
</section>
<section id="veritrace-web-application-explore-section-and-metadata" class="level2" data-number="6.12">
<h2 data-number="6.12" class="anchored" data-anchor-id="veritrace-web-application-explore-section-and-metadata"><span class="header-section-number">6.12</span> VERITRACE Web Application: Explore Section and Metadata</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_14.png" class="img-fluid figure-img"></p>
<figcaption>Slide 14</figcaption>
</figure>
</div>
<p>The VERITRACE web application organises its functionalities into five primary sections: Explore, Search, Match, Analyse, and Read. The ‘Explore’ section serves as a comprehensive hub for corpus statistics and metadata exploration, currently presenting 427,305 metadata records directly from a Mongo database.</p>
<p>This section offers various visualisations, including pie charts for language distribution and data sources, a bar chart detailing documents by decade, and a donut chart illustrating top publication places. Furthermore, the ‘Metadata Explorer’ enables users to browse and filter documents based on their metadata attributes. Crucially, the system performs granular language identification on every text, down to approximately 50 characters, to accurately account for multilingual content. For instance, a text might be identified as 15% Greek and 85% Latin, classifying it as substantively multilingual. The application also attempts to assess OCR quality on a page-by-page basis, a challenging endeavour given the absence of ground truth page images.</p>
</section>
<section id="veritrace-search-functionality" class="level2" data-number="6.13">
<h2 data-number="6.13" class="anchored" data-anchor-id="veritrace-search-functionality"><span class="header-section-number">6.13</span> VERITRACE Search Functionality</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>For most scholars, the primary point of engagement with the VERITRACE web application will be its robust search functionality. Whilst the current prototype operates on a limited corpus of 132 files, rather than the full 400,000-plus, its index already occupies 15 gigabytes, indicating that the complete online corpus will span many terabytes.</p>
<p>A basic keyword search, for example, for ‘Hermes’, rapidly retrieves 22 documents with 332 total matches in 107 milliseconds, including works like ‘Hermes Trismegisti Erkännuß…’ by Hermes (1706) and ‘Hermes theologus…’ by Wodenote (1649). Conversely, a more refined, structured query such as ‘author:kepler ’hermes’’ significantly narrows the results, yielding just one document with two total matches in a mere 17 milliseconds. This specific result points to Kepler’s ‘Prodromus Dissertationum Cosmographicarum…’ from 1621, which contains the phrase ‘Hermes tuus.’. This comparison effectively demonstrates the enhanced precision attainable through the use of structured queries within the digital humanities search environment.</p>
</section>
<section id="veritrace-search-interface-and-query-specificity" class="level2" data-number="6.14">
<h2 data-number="6.14" class="anchored" data-anchor-id="veritrace-search-interface-and-query-specificity"><span class="header-section-number">6.14</span> VERITRACE Search Interface and Query Specificity</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The VERITRACE search interface consistently displays corpus statistics, indicating 132 unique files, over 16.9 million total segments, and an index size of 15.37 gigabytes for the ‘veritrace_2025_a2’ dataset. A general keyword search for ‘hermes’, for example, rapidly retrieves 22 documents with 332 total matches in 107 milliseconds, including works like ‘Hermes Trismegisti Erkännuß…’ by Hermes (1706) and ‘Hermes theologus…’ by Wodenote (1649).</p>
<p>Conversely, a more refined, structured query such as ‘author:kepler ’hermes’’ significantly narrows the results, yielding just one document with two total matches in a mere 17 milliseconds. This specific result points to Kepler’s ‘Prodromus Dissertationum Cosmographicarum…’ from 1621, which contains the phrase ‘Hermes tuus.’. This comparison effectively demonstrates the enhanced precision attainable through the use of structured queries within the digital humanities search environment.</p>
</section>
<section id="future-analytical-capabilities-the-analyse-module" class="level2" data-number="6.15">
<h2 data-number="6.15" class="anchored" data-anchor-id="future-analytical-capabilities-the-analyse-module"><span class="header-section-number">6.15</span> Future Analytical Capabilities: The ‘Analyse’ Module</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_17.png" class="img-fluid figure-img"></p>
<figcaption>Slide 17</figcaption>
</figure>
</div>
<p>Whilst currently unimplemented, the ‘Analyse’ section of the VERITRACE website is slated to host a suite of advanced analytical tools. Future functionalities will include Topic Modelling, enabling users to discover prevalent themes across the entire corpus or within selected documents. Additionally, the platform will integrate Latent Semantic Analysis (LSA) for assessing document similarity and Diachronic Analysis, designed to visualise linguistic and conceptual shifts over extended historical periods. The development team actively incorporates insights from contemporary research and community feedback to inform the meticulous implementation of these sophisticated analytical capabilities.</p>
</section>
<section id="veritrace-read-section-digital-facsimiles-and-metadata" class="level2" data-number="6.16">
<h2 data-number="6.16" class="anchored" data-anchor-id="veritrace-read-section-digital-facsimiles-and-metadata"><span class="header-section-number">6.16</span> VERITRACE Read Section: Digital Facsimiles and Metadata</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_18.png" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
<p>The VERITRACE platform incorporates a dedicated ‘Read’ section, designed to provide scholars with access to high-quality digital facsimiles of historical texts, moving beyond raw OCR output. This section integrates a Mirador viewer, enabling users to read PDFs of every text within the corpus, much like a conventional library website.</p>
<p>Alongside the visual facsimile, comprehensive metadata is readily available. For instance, a document such as ‘Mercurii Trismegisti Pymander…’ by Hermes, Trismegistus, published in 1534, is presented with extensive bibliographic details including its creator, full title, printer, publication place, and date. Furthermore, granular language information, OCR quality assessments, and detailed document statistics enhance the scholarly utility of each entry.</p>
</section>
<section id="veritrace-match-tool-textual-similarity-and-customisation" class="level2" data-number="6.17">
<h2 data-number="6.17" class="anchored" data-anchor-id="veritrace-match-tool-textual-similarity-and-customisation"><span class="header-section-number">6.17</span> VERITRACE Match Tool: Textual Similarity and Customisation</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_19.png" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>The VERITRACE Match Tool is meticulously designed to identify textual reuse and similarities between documents, primarily leveraging vector embeddings. This versatile tool supports various comparison modes: users can compare a single document against another, conduct multi-document comparisons (e.g., Newton’s Latin <em>Opticks</em> against all of Kepler’s works), or even attempt a full corpus comparison, though the latter presents significant computational challenges regarding processing power and user waiting times.</p>
<p>Crucially, the tool offers extensive customisation through a multitude of parameters, allowing users to fine-tune the matching algorithms. Lexical matching, for instance, includes adjustable parameters such as minimum similarity (0.65), maximum results (100), and Jaccard/BM25 weights. Semantic matching, conversely, features settings for minimum similarity (0.85), short passage thresholds, and vector normalisation. A hybrid matching option combines both approaches with adjustable weighting. Additional parameters govern corpus matching batch sizes and query settings. A key case study involves comparing Newton’s Latin and English <em>Opticks</em> to evaluate both lexical and semantic matches, demonstrating the tool’s capacity for cross-lingual analysis.</p>
</section>
<section id="text-matching-methodologies-lexical-semantic-and-hybrid" class="level2" data-number="6.18">
<h2 data-number="6.18" class="anchored" data-anchor-id="text-matching-methodologies-lexical-semantic-and-hybrid"><span class="header-section-number">6.18</span> Text Matching Methodologies: Lexical, Semantic, and Hybrid</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_20.png" class="img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
<p>The VERITRACE Match Tool employs two fundamental types of text matching: lexical and semantic, with a hybrid option combining both. Lexical matching identifies textually similar passages based on keyword overlap and vocabulary similarity. However, this approach proves ineffective across different languages, as direct lexical matches are unlikely. Consequently, for the project’s multilingual corpus, semantic matching becomes indispensable. This method utilises vector embeddings to identify conceptually similar passages, even when they share no common linguistic vocabulary, thereby enabling cross-lingual conceptual comparisons. A hybrid approach allows for the combination of both methods with adjustable weighting.</p>
<p>Furthermore, the tool offers distinct matching modes: ‘Standard’ for balanced performance, ‘Comprehensive’ for maximum recall (albeit slower), and ‘Selective’ for higher precision (faster). A crucial ‘sanity check’ involves a lexical match between Newton’s Latin <em>Opticks</em> (1719) and its English counterpart (1718). As anticipated, the ‘Standard’ mode yields no matches, confirming the ineffectiveness of lexical matching across languages. Interestingly, the ‘Comprehensive’ mode reveals three matches, likely indicating instances of English text, such as a preface, embedded within the Latin edition.</p>
</section>
<section id="lexical-match-results-and-semantic-match-expectations" class="level2" data-number="6.19">
<h2 data-number="6.19" class="anchored" data-anchor-id="lexical-match-results-and-semantic-match-expectations"><span class="header-section-number">6.19</span> Lexical Match Results and Semantic Match Expectations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_21.png" class="img-fluid figure-img"></p>
<figcaption>Slide 21</figcaption>
</figure>
</div>
<p>The VERITRACE system visually presents lexical match results with automatic highlighting of shared terms, displaying the source passage on the left and the comparison passage on the right, alongside a similarity score. A ‘sanity check’ involving a lexical comparison of Newton’s English <em>Opticks</em> (1718) against itself demonstrates the system’s precision: it yields a 100% normalised match score, a 99.7% coverage score, and a perfect 100% quality score. This comparison, involving 1,140 passages and over 1.2 million individual comparisons, completes in 23 seconds, identifying 1,137 estimated matches, all falling within the 90-100% similarity range.</p>
<p>Crucially, when performing a semantic match between a text and its translation, such as the Latin and English versions of <em>Opticks</em>, the researchers anticipate reasonable matches. Despite significant lexical differences, the conceptual similarity between a text and its translation should be accurately captured by semantic embeddings.</p>
</section>
<section id="lexical-match-highlighting-and-semantic-match-results" class="level2" data-number="6.20">
<h2 data-number="6.20" class="anchored" data-anchor-id="lexical-match-highlighting-and-semantic-match-results"><span class="header-section-number">6.20</span> Lexical Match Highlighting and Semantic Match Results</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_22.png" class="img-fluid figure-img"></p>
<figcaption>Slide 22</figcaption>
</figure>
</div>
<p>The VERITRACE system provides automatic highlighting for lexical matches, identifying terms based on overlap and BM25 relevance ranking. This process successfully analyses 1,137 passages, skipping only three deemed too short for matching. Examples demonstrate precise 100% similarity scores for identical or near-identical passages, such as descriptions of ‘Mercury’ in various forms or discussions of chemical solutions and physical phenomena.</p>
<p>When conducting semantic matches between the Latin and English versions of Newton’s <em>Opticks</em>, the results generally appear reasonable, even in the presence of OCR issues, with conceptually similar passages, such as those discussing ‘colors’, aligning effectively. However, the match score functionality requires further development; whilst the quality score remains high, the coverage score is inconsistent. This discrepancy might be partially explained by the Latin edition being considerably longer than its English counterpart. Nevertheless, broader queries suggest that the current embedding model, <em>LaBSE</em>, is ultimately inadequate for the project’s complex requirements.</p>
</section>
<section id="semantic-matching-interface-and-progress" class="level2" data-number="6.21">
<h2 data-number="6.21" class="anchored" data-anchor-id="semantic-matching-interface-and-progress"><span class="header-section-number">6.21</span> Semantic Matching Interface and Progress</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_23.png" class="img-fluid figure-img"></p>
<figcaption>Slide 23</figcaption>
</figure>
</div>
<p>The VERITRACE interface for semantic matching offers clear configuration options. Users select from ‘Lexical’, ‘Semantic’ (the default for conceptual comparisons), or ‘Hybrid’ match types, whilst also choosing a ‘Standard’, ‘Comprehensive’, or ‘Selective’ matching mode to balance performance and accuracy. A prominent ‘Run Text Matching’ button initiates the analysis. Results are then presented across three distinct tabs: ‘Match Summary’, ‘Match Details’, and ‘Visualization’. During the comparison process, a progress bar indicates the current status, such as ‘Comparing documents… (20%)’, alongside an instruction to run the matching to view results. This module specifically aims to evaluate translation quality through rigorous text comparison.</p>
</section>
<section id="semantic-match-results-and-model-adequacy" class="level2" data-number="6.22">
<h2 data-number="6.22" class="anchored" data-anchor-id="semantic-match-results-and-model-adequacy"><span class="header-section-number">6.22</span> Semantic Match Results and Model Adequacy</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_24.png" class="img-fluid figure-img"></p>
<figcaption>Slide 24</figcaption>
</figure>
</div>
<p>When conducting semantic matches between the Latin and English versions of Newton’s <em>Opticks</em>, the results generally appear reasonable, even in the presence of OCR issues, with corresponding paragraphs discussing concepts like ‘Mercury’ and ‘colours’ aligning effectively. The system reports a combined match score of 58%, with a coverage score of 36.9% and a high quality score of 91.2%. Analysis of the 421 estimated matches reveals that whilst some achieve 90-100% similarity, the majority fall within the 70-90% range. The Latin query document contains 1,996 passages, compared to 1,140 in the English comparison document, and the query completes 2.2 million comparisons in 25 seconds.</p>
<p>Despite these promising indicators, the project team expresses concern that the current embedding model, <em>LaBSE</em>, is likely inadequate for the task. This inadequacy may stem from ‘out-of-domain model collapse’, a phenomenon observed when models trained on modern languages are applied to historical, multilingual texts, leading to suboptimal performance.</p>
</section>
<section id="future-challenges-and-model-selection" class="level2" data-number="6.23">
<h2 data-number="6.23" class="anchored" data-anchor-id="future-challenges-and-model-selection"><span class="header-section-number">6.23</span> Future Challenges and Model Selection</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_25.png" class="img-fluid figure-img"></p>
<figcaption>Slide 25</figcaption>
</figure>
</div>
<p>The VERITRACE project faces several critical challenges on the horizon, particularly concerning model selection and data quality. Whilst <em>LaBSE</em> serves as an initial choice for vector embeddings, the researchers acknowledge the potential superiority of other models, such as <em>XLM-Roberta</em>, <em>intfloat multilingual-e5-large</em>, or <em>historical mBERT</em>, each presenting distinct trade-offs in terms of storage requirements and inference time. A key strategic question remains whether to fine-tune a base model specifically on the project’s unique historical corpus, given its distinct characteristics, or to persist with existing pre-trained models.</p>
<p>Furthermore, the evolving nature of semantic meaning across centuries poses a significant hurdle; ensuring that texts from 1540 and 1700, written in different languages, occupy a coherent vector space presents a complex problem. Poor OCR quality, a pervasive issue, fundamentally impacts all downstream processes, including the crucial segmentation of texts into sentences and passages. Re-OCR’ing the entire corpus is not feasible, prompting considerations of re-OCR’ing only the lowest quality texts or actively seeking out existing high-quality versions. Finally, scaling and performance represent substantial future concerns; current queries on a mere 132 texts take 15 seconds, implying considerable challenges when expanding to the full 430,000-text corpus, necessitating robust solutions for managing computational resources and query times.</p>
</section>
<section id="additional-visual-materials" class="level2" data-number="6.24">
<h2 data-number="6.24" class="anchored" data-anchor-id="additional-visual-materials"><span class="header-section-number">6.24</span> Additional Visual Materials</h2>
<p>The following slides provide supplementary visual information relevant to the presentation:</p>
<p><img src="images/ai-nepi_006_slide_26.png" class="img-fluid" alt="Slide 26"> <em>The slide is titled ‘Issues on the Horizon,’ indicating a discussion of future challenges and considerations. The background is a light beige, framed by a thick black border. In the top right corner, a decorative element features stylized plant branches with leaves, rendered in a light purple or lavender color, extending from the corner into the slide area. The content is presented as a series of bullet points addressing various technical and methodological concerns. The first point discusses model selection, stating that ‘LaBSE is just a starting choice – there are other embedding models that might work better: XLM-Roberta, intfloat multilingual-e5-large, historical mBERT, or others. All have trade-offs.’ This highlights the need to evaluate different embedding models for specific tasks. The second point poses a strategic question: ‘Or is this a losing battle and we ought to fine-tune one of these base models on our historical corpus?’ This suggests a debate between using off-the-shelf models versus domain-specific fine-tuning. The third issue addresses diachronic semantic change: ‘Semantic meaning changes over time – how to handle that across centuries?’ This points to the challenge of applying modern language models to historical texts where word meanings may have evolved. The fourth bullet focuses on data quality, specifically OCR errors: ‘Poor-quality OCR would seem to affect everything downstream. Not feasible to re-OCR our entire corpus. Re-OCR the very poor-quality texts? Invest time to find existing high-quality versions?’ This outlines the significant problem of noisy historical data and potential strategies for mitigation. The fifth point notes that ‘Scaling and performance will increasingly become an issue,’ indicating future challenges with computational resources as data volumes grow. Finally, the slide concludes with an open invitation for collaboration or guidance: ‘Advice very welcome!’</em></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_005.html" class="pagination-link" aria-label="Genre Classification for Historical Medical Periodicals">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_007.html" class="pagination-link" aria-label="Explainable AI and AI-based Scientific Insights in the Humanities">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Explainable AI and AI-based Scientific Insights in the Humanities</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>