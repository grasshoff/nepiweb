<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.14">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Jeffrey Wolf">
<meta name="dcterms.date" content="2025-01-01">

<title>6&nbsp; Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project – AI-NEPI Conference Proceedings</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_007.html" rel="next">
<link href="./chapter_ai-nepi_005.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-8f1af79587c2686b78fe4e1fbadd71ab.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-7d85b766abd26745604bb74d2576c60a.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles.css">
</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_006.html"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_001.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_003.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy, and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_004.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Introducing OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_005.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals, ActDisease Project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_006.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_007.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_008.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Computational Epistemology and Large Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">The Representation of SDG-Related Research in Bibliometric Databases: A Conceptual Inquiry via LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Extracting Citation Data from Law and Humanities Scholarship Using LLMs and a Specialized Gold Standard Dataset</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">RAG in HPSS</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit in Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of LDA and BERTopic Performance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models: Towards a Novel Architecture for Historical Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Our current understanding of funders of science is a limited view.</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#about-the-veritrace-project" id="toc-about-the-veritrace-project" class="nav-link" data-scroll-target="#about-the-veritrace-project"><span class="header-section-number">6.1</span> About the VERITRACE Project</a></li>
  <li><a href="#computational-methodologies-for-hpss" id="toc-computational-methodologies-for-hpss" class="nav-link" data-scroll-target="#computational-methodologies-for-hpss"><span class="header-section-number">6.2</span> Computational Methodologies for HPSS</a></li>
  <li><a href="#large-scale-multilingual-data-set-and-analytical-techniques" id="toc-large-scale-multilingual-data-set-and-analytical-techniques" class="nav-link" data-scroll-target="#large-scale-multilingual-data-set-and-analytical-techniques"><span class="header-section-number">6.3</span> Large-Scale Multilingual Data Set and Analytical Techniques</a></li>
  <li><a href="#overcoming-data-challenges-with-large-language-models" id="toc-overcoming-data-challenges-with-large-language-models" class="nav-link" data-scroll-target="#overcoming-data-challenges-with-large-language-models"><span class="header-section-number">6.4</span> Overcoming Data Challenges with Large Language Models</a></li>
  <li><a href="#experimental-application-of-llms-for-metadata-enrichment" id="toc-experimental-application-of-llms-for-metadata-enrichment" class="nav-link" data-scroll-target="#experimental-application-of-llms-for-metadata-enrichment"><span class="header-section-number">6.5</span> Experimental Application of LLMs for Metadata Enrichment</a></li>
  <li><a href="#the-veritrace-web-application-alpha-version" id="toc-the-veritrace-web-application-alpha-version" class="nav-link" data-scroll-target="#the-veritrace-web-application-alpha-version"><span class="header-section-number">6.6</span> The VERITRACE Web Application: Alpha Version</a></li>
  <li><a href="#the-complex-data-processing-pipeline" id="toc-the-complex-data-processing-pipeline" class="nav-link" data-scroll-target="#the-complex-data-processing-pipeline"><span class="header-section-number">6.7</span> The Complex Data Processing Pipeline</a></li>
  <li><a href="#corpus-exploration-and-metadata-management" id="toc-corpus-exploration-and-metadata-management" class="nav-link" data-scroll-target="#corpus-exploration-and-metadata-management"><span class="header-section-number">6.8</span> Corpus Exploration and Metadata Management</a></li>
  <li><a href="#advanced-search-and-analytical-capabilities" id="toc-advanced-search-and-analytical-capabilities" class="nav-link" data-scroll-target="#advanced-search-and-analytical-capabilities"><span class="header-section-number">6.9</span> Advanced Search and Analytical Capabilities</a></li>
  <li><a href="#text-viewing-and-the-veritrace-match-tool" id="toc-text-viewing-and-the-veritrace-match-tool" class="nav-link" data-scroll-target="#text-viewing-and-the-veritrace-match-tool"><span class="header-section-number">6.10</span> Text Viewing and the VERITRACE Match Tool</a></li>
  <li><a href="#lexical-matching-case-study-newtons-opticks" id="toc-lexical-matching-case-study-newtons-opticks" class="nav-link" data-scroll-target="#lexical-matching-case-study-newtons-opticks"><span class="header-section-number">6.11</span> Lexical Matching Case Study: Newton’s Opticks</a></li>
  <li><a href="#semantic-matching-and-future-challenges" id="toc-semantic-matching-and-future-challenges" class="nav-link" data-scroll-target="#semantic-matching-and-future-challenges"><span class="header-section-number">6.12</span> Semantic Matching and Future Challenges</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Jeffrey Wolf <a href="mailto:jeffrey.charles.wolf@vub.be" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            Vrije Universiteit Brussel (VUB)
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>The <em>VERITRACE</em> project, a five-year <em>ERC</em> Starting Grant initiative (2023-2028) entitled “Traces de la Verité: The reappropriation of ancient wisdom in early modern natural philosophy,” operates from the Vrije Universiteit Brussel (<em>VUB</em>). Research Professor Cornelis J. Schilt leads the project team, which comprises five members: a classicist, two historians, and Dr.&nbsp;Jeffrey Wolf, who serves as the digital humanities specialist. This ambitious endeavour meticulously traces the influence of the early modern ‘ancient wisdom’ or <em>Prisca Sapientia</em> tradition on the development of natural philosophy during the early modern period.</p>
<p>The team focuses on a core corpus of 140 works, including seminal texts such as the Chaldean Oracles, the Sibylline Oracles, the Orphic Hymns, and the <em>Corpus Hermeticum</em>. Historical evidence confirms the tradition’s profound impact; for instance, Isaac Newton engaged with the Sibylline Oracles, whilst Johannes Kepler demonstrated familiarity with the <em>Corpus Hermeticum</em>. Beyond these well-documented instances, the <em>VERITRACE</em> team seeks to uncover a much broader, often overlooked, network of texts and authors—dubbed the ‘great unread’—that also engaged with this tradition.</p>
<p>To achieve these objectives, the project employs a computational approach to the History, Philosophy, and Sociology of Science (<em>HPSS</em>). This approach involves large-scale, multilingual exploration to identify both direct (lexical) and indirect (semantic) textual re-use across a vast corpus. Functioning akin to an “early modern plagiarism detector,” the system aims to reveal ignored networks of texts, passages, themes, topics, and authors, potentially uncovering novel patterns in intellectual history.</p>
<p>The <em>VERITRACE</em> team leverages a diverse multilingual dataset of approximately 430,000 printed texts, spanning nearly 200 years (1540-1728). These texts originate from three primary digital sources: <em>Early English Books Online</em> (<em>EEBO</em>), <em>Gallica</em> (French National Library), and the Bavarian State Library. State-of-the-art digital techniques—including keyword search, text matching, topic modelling, and sentiment analysis—facilitate the analysis of this extensive corpus.</p>
<p>Significant challenges arise from variable <em>OCR</em> quality in raw library-provided texts, the complexities of early modern typography and semantics across multiple languages, and the sheer volume of data. The <em>VERITRACE</em> team addresses these by utilising Large Language Models (<em>LLMs</em>) in two key ways: <em>GPT</em>-based <em>LLMs</em> serve as “judges” for enriching and cleaning metadata, whilst <em>BERT</em>-based <em>LLMs</em> generate vector embeddings to encode the semantic meaning of textual passages for advanced matching.</p>
<p>The <em>VERITRACE</em> web application, currently in its alpha version, provides a user interface for these capabilities. It features sections for corpus statistics, a metadata explorer, a keyword search function, planned analytical tools (topic modelling, <em>LSA</em>, diachronic analysis), a text reader, and a sophisticated text matching tool. This application operates on an <em>Elasticsearch</em> backend. Despite its promising capabilities, the project faces ongoing challenges related to <em>LLM</em> hallucinations in metadata processing, the adequacy of current embedding models (such as <em>LaBSE</em>) for historical multilingual data, semantic drift over time, and the substantial scaling and performance requirements for processing the full corpus.</p>
</section>
<section id="about-the-veritrace-project" class="level2" data-number="6.1">
<h2 data-number="6.1" class="anchored" data-anchor-id="about-the-veritrace-project"><span class="header-section-number">6.1</span> About the VERITRACE Project</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_03.png" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> project, a five-year <em>ERC</em> Starting Grant initiative (2023-2028), bears the full title “Traces de la Verité: The reappropriation of ancient wisdom in early modern natural philosophy.” Based at the Vrije Universiteit Brussel (<em>VUB</em>), this significant undertaking operates under the leadership of its Principal Investigator, Research Professor Cornelis J. Schilt. Professor Schilt’s team comprises five dedicated members: a classicist, two historians, and Dr.&nbsp;Jeffrey Wolf, who serves as the digital humanities specialist.</p>
<p>A core objective for the <em>VERITRACE</em> team involves meticulously tracing the influence of the early modern ‘ancient wisdom’ tradition, also known as <em>Prisca Sapientia</em>, upon the evolution of early modern natural philosophy and science. This tradition manifests in a specific corpus of 140 key texts, which form the team’s close reading focus. Notable examples include the Chaldean Oracles, the Sibylline Oracles, the Orphic Hymns, and, perhaps most famously, the <em>Corpus Hermeticum</em>.</p>
<p>Historical evidence already confirms the profound impact of this tradition on scientific thought; for instance, Isaac Newton demonstrably read the Sibylline Oracles, whilst Johannes Kepler possessed a deep understanding of the <em>Corpus Hermeticum</em>. Nevertheless, the <em>VERITRACE</em> team aims to delve deeper, seeking to uncover a far broader array of networks and texts that engaged with this ancient wisdom. This includes a vast collection of works often termed the ‘great unread,’ which historians have typically overlooked due to their sheer volume and authorship by lesser-known figures.</p>
</section>
<section id="computational-methodologies-for-hpss" class="level2" data-number="6.2">
<h2 data-number="6.2" class="anchored" data-anchor-id="computational-methodologies-for-hpss"><span class="header-section-number">6.2</span> Computational Methodologies for HPSS</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_04.png" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> team establishes a robust framework for computational History, Philosophy, and Sociology of Science (<em>HPSS</em>), primarily aiming to facilitate large-scale, multilingual exploration within historical research. A key capability involves identifying textual re-use, distinguishing between direct and indirect forms. Direct re-use encompasses lexical similarities, such as direct quotations that may remain uncited. Conversely, indirect re-use focuses on semantic connections, identifying paraphrases or conceptually similar passages, even when direct linguistic overlap is minimal.</p>
<p>This functionality effectively creates an “early modern plagiarism detector,” enabling scholars to discern subtle and overt textual appropriations. Ultimately, this approach seeks to uncover previously ignored networks of texts, passages, themes, topics, and authors, thereby enriching our understanding of intellectual connections. Through this systematic analysis, the <em>VERITRACE</em> team anticipates revealing novel patterns within the intellectual history and philosophy of science. Furthermore, the system incorporates dedicated tools for comprehensive keyword searching, enhancing the exploratory capabilities.</p>
</section>
<section id="large-scale-multilingual-data-set-and-analytical-techniques" class="level2" data-number="6.3">
<h2 data-number="6.3" class="anchored" data-anchor-id="large-scale-multilingual-data-set-and-analytical-techniques"><span class="header-section-number">6.3</span> Large-Scale Multilingual Data Set and Analytical Techniques</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_05.png" class="img-fluid figure-img"></p>
<figcaption>Slide 05</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> team has assembled a substantial and diverse multilingual dataset, exclusively comprising printed works; handwritten materials remain outside the current scope. This extensive collection draws from three distinct multilingual data sources, encompassing texts in at least six different languages. The temporal span of the corpus covers approximately 200 years, commencing in 1540 and concluding in 1728, shortly after Isaac Newton’s death.</p>
<p>Specifically, the primary data sources include the <em>Early English Books Online</em> (<em>EEBO</em>), which offers freely downloadable content, alongside materials acquired from <em>Gallica</em>, the digital library of the French National Library. The Bavarian State Library constitutes the largest contributor to the corpus. Cumulatively, these sources provide approximately 430,000 texts for analysis. To explore this vast dataset, the <em>VERITRACE</em> team employs state-of-the-art digital techniques, including keyword search, sophisticated text matching algorithms, topic modelling, and sentiment analysis, amongst other advanced methodologies.</p>
</section>
<section id="overcoming-data-challenges-with-large-language-models" class="level2" data-number="6.4">
<h2 data-number="6.4" class="anchored" data-anchor-id="overcoming-data-challenges-with-large-language-models"><span class="header-section-number">6.4</span> Overcoming Data Challenges with Large Language Models</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_06.png" class="img-fluid figure-img"></p>
<figcaption>Slide 06</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> project confronts several core challenges inherent in processing historical textual data. Firstly, the variable quality of Optical Character Recognition (<em>OCR</em>) presents a significant hurdle. Libraries supply raw text in various formats—including <em>XML</em>, <em>HOCR</em>, and <em>HTML</em> files—without accompanying ground truth page images. This absence profoundly impacts all subsequent downstream processing stages. Secondly, the complexities of early modern typography and semantics, spanning at least six different languages, introduce further difficulties. Finally, the sheer volume of data—hundreds of thousands of texts printed across Europe over two centuries—necessitates robust computational strategies.</p>
<p>To address these challenges, the <em>VERITRACE</em> team integrates Large Language Models (<em>LLMs</em>) in two distinct capacities. On the decoder side, <em>GPT</em>-based <em>LLMs</em> function as “judges” to enrich and clean the project’s metadata. This application remains a work in progress, not yet fully functional. Conversely, on the encoder side, <em>BERT</em>-based <em>LLMs</em> generate vector embeddings. These embeddings serve to encode the semantic meaning of sentences and short passages within the textual corpus, thereby facilitating the crucial text matching functionalities.</p>
</section>
<section id="experimental-application-of-llms-for-metadata-enrichment" class="level2" data-number="6.5">
<h2 data-number="6.5" class="anchored" data-anchor-id="experimental-application-of-llms-for-metadata-enrichment"><span class="header-section-number">6.5</span> Experimental Application of LLMs for Metadata Enrichment</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_07.png" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> team has explored an experimental application of <em>LLMs</em> to automate the highly tedious process of comparing bibliographic metadata records. The primary task involves determining whether pairs of records—originating from both low-quality and high-quality sources such as the <em>Universal Short Title Catalogue</em> (<em>USTC</em>)—refer to the same underlying printed text. This process previously necessitated individual team members reviewing as many as 10,000 such pairs, highlighting the critical need for automation.</p>
<p>The adopted <em>LLM</em> approach employs a “bench” or “panel of judges,” comprising a chain of <em>LLMs</em>, including Primary, Secondary, Tiebreaker, and Expert models for handling edge cases. These models are tasked with judging matches, providing detailed reasoning, and assigning confidence levels to each decision. The <em>VERITRACE</em> team validates <em>LLM</em> outputs through comparison against a ground truth dataset, followed by a final review. The system incorporates extensive prompt guidelines, specifying field priorities, match criteria, and non-match indicators, to guide the <em>LLMs</em>’ decision-making process.</p>
<p>Currently, this remains a work in progress. A major challenge stems from hallucinations in the <em>LLM</em> output, where models generate non-existent records. Whilst requesting more structured output can mitigate hallucinations, this often results in more generic and less helpful responses, particularly in the reasoning provided. Consequently, striking the right balance proves challenging, often described as “more art than science.” Despite these difficulties, the approach holds significant potential for substantial time savings. The project currently utilises open-source models, such as <em>Llama</em>, for these operations.</p>
</section>
<section id="the-veritrace-web-application-alpha-version" class="level2" data-number="6.6">
<h2 data-number="6.6" class="anchored" data-anchor-id="the-veritrace-web-application-alpha-version"><span class="header-section-number">6.6</span> The VERITRACE Web Application: Alpha Version</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_11.png" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> web application currently exists in an alpha version, representing an extremely new development that remains unavailable to the public. Its primary purpose involves demonstrating the project’s envisioned future capabilities. Engineers are presently testing a <em>BERT</em>-based Large Language Model, specifically <em>LaBSE</em>, to generate vector embeddings for every passage within the textual corpus. However, initial assessments suggest this model will likely prove “not good enough” for the project’s comprehensive requirements, despite demonstrating functionality in specific instances. For the current presentation, screenshots serve as a substitute for a live demonstration of the website.</p>
</section>
<section id="the-complex-data-processing-pipeline" class="level2" data-number="6.7">
<h2 data-number="6.7" class="anchored" data-anchor-id="the-complex-data-processing-pipeline"><span class="header-section-number">6.7</span> The Complex Data Processing Pipeline</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_12.png" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> team relies upon a complex, 15-stage data processing pipeline, meticulously designed to transform raw textual data—received in formats such as <em>XML</em>, <em>HOCR</em>, and <em>HTML</em>—into a structured form suitable for the backend <em>Elasticsearch</em> database. This intricate process involves numerous critical stages, including the extraction of text into standardised text files, the generation of precise position mappings, robust text segmentation, and comprehensive <em>OCR</em> quality assessment. Each of these stages demands careful optimisation to ensure data integrity and usability. Crucially, the generation of vector embeddings occurs towards the end of this pipeline. This entire workflow necessitates significant background effort, underscoring that the process is far from a simple, automated operation.</p>
</section>
<section id="corpus-exploration-and-metadata-management" class="level2" data-number="6.8">
<h2 data-number="6.8" class="anchored" data-anchor-id="corpus-exploration-and-metadata-management"><span class="header-section-number">6.8</span> Corpus Exploration and Metadata Management</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_15.png" class="img-fluid figure-img"></p>
<figcaption>Slide 15</figcaption>
</figure>
</div>
<p>The <em>VERITRACE</em> web application organises its functionalities into five primary sections: Explore, Metadata Explorer, Search, Analyse, Read, and Match. The Explore section serves to provide comprehensive statistics about the corpus, drawing data directly from a <em>Mongo</em> database. Currently, this section displays information for 427,305 metadata records, detailing aspects such as language distribution, data sources, documents by decade, and publication places.</p>
<p>Beyond this overview, the Metadata Explorer enables users to delve into the rich metadata associated with each individual text. For instance, examining “Sibyllina oraculo, ex veteribus codicibus emendata” reveals detailed bibliographic information. A crucial feature involves language identification, which processes every text down to approximately 50 characters. This granular approach is essential because many early modern texts are multilingual, whilst their primary metadata often indicates only a single language. For “Sibyllina oraculo,” this process identified 15% of the text as Greek and 85% as Latin, clearly indicating its substantively multilingual nature. Furthermore, the system assesses <em>OCR</em> quality on a page-by-page basis, rather than assigning a single quality metric to an entire book. This assessment presents a significant challenge, however, as it must be performed solely on the raw text due to the absence of ground truth page images.</p>
</section>
<section id="advanced-search-and-analytical-capabilities" class="level2" data-number="6.9">
<h2 data-number="6.9" class="anchored" data-anchor-id="advanced-search-and-analytical-capabilities"><span class="header-section-number">6.9</span> Advanced Search and Analytical Capabilities</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_16.png" class="img-fluid figure-img"></p>
<figcaption>Slide 16</figcaption>
</figure>
</div>
<p>The web application incorporates a robust Search section, offering standard keyword search functionality. For example, a query for “Hermes” within the current prototype corpus of 132 files yields 22 documents containing 332 matches. Whilst this prototype index already occupies 15 gigabytes, the full corpus is projected to require terabytes of storage. Beyond basic keyword searches, the system supports complex <em>Elasticsearch</em> queries, enabling users to perform highly specific investigations. These include field queries, such as <code>author:kepler 'hermes'</code>, alongside boolean operators (AND, OR), nested queries, and proximity queries, which allow users to specify terms appearing within a defined word distance, for instance, “Hermes and Plato mentioned within 10 words.”</p>
<p>A dedicated Analyse section is also planned, though not yet implemented. This future component will integrate advanced analytical tools, including Topic Modelling, Latent Semantic Analysis (<em>LSA</em>), and Diachronic Analysis, further enhancing scholarly exploration of the corpus.</p>
</section>
<section id="text-viewing-and-the-veritrace-match-tool" class="level2" data-number="6.10">
<h2 data-number="6.10" class="anchored" data-anchor-id="text-viewing-and-the-veritrace-match-tool"><span class="header-section-number">6.10</span> Text Viewing and the VERITRACE Match Tool</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_19.png" class="img-fluid figure-img"></p>
<figcaption>Slide 19</figcaption>
</figure>
</div>
<p>The web application features a Read section, enabling scholars to view original text images. This functionality integrates a <em>Mirador</em> viewer, providing access to <em>PDFs</em> of every text within the corpus, alongside their associated metadata.</p>
<p>Crucially, the <em>VERITRACE</em> Match Tool serves as the primary mechanism for identifying textual re-use across different documents. This tool offers various comparison modes: users can compare a single document against another, or against a collection of multiple documents—for example, comparing Newton’s Latin <em>Opticks</em> with all of Kepler’s works present in the database. A more ambitious goal involves enabling comparisons of a single text against the entire corpus, though this presents significant computational challenges regarding processing time and user experience.</p>
<p>The tool provides extensive user control, exposing numerous parameters for fine-tuning, such as setting a minimum similarity score. It supports distinct match types: lexical matching, which employs keyword analysis to identify vocabulary similarities, and semantic matching, which utilises vector embeddings to uncover conceptually similar passages, even in the absence of shared vocabulary—a vital feature for multilingual analysis. Furthermore, a hybrid matching option combines both approaches with adjustable weighting. Users can also select from different matching modes: a standard mode, a comprehensive mode that demands more computing power and time but aims for exhaustive results, and a faster mode for quicker queries.</p>
</section>
<section id="lexical-matching-case-study-newtons-opticks" class="level2" data-number="6.11">
<h2 data-number="6.11" class="anchored" data-anchor-id="lexical-matching-case-study-newtons-opticks"><span class="header-section-number">6.11</span> Lexical Matching Case Study: Newton’s Opticks</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_20.png" class="img-fluid figure-img"></p>
<figcaption>Slide 20</figcaption>
</figure>
</div>
<p>A case study involving Isaac Newton’s Latin edition of <em>Opticks</em> (1719) and its English counterpart (1718) demonstrates the lexical matching capabilities. Given the distinct languages, a lexical match was expected to yield no results. Indeed, when run in standard mode, the tool confirmed this expectation, finding no matches, which serves as a crucial sanity check for the system’s design. However, employing the comprehensive mode revealed three matches. This outcome suggests the Latin edition likely incorporates some English text, possibly within a preface or other ancillary sections.</p>
<p>The system presents a detailed match summary, including a quality score reflecting the average similarity of the matches and a coverage score indicating the proportion of text covered by these matches. For instance, a query might involve approximately 1.3 million comparisons to generate its results. The match overview further details source and comparison passages, providing individual similarity scores and automatically highlighting matching terms to facilitate user analysis.</p>
</section>
<section id="semantic-matching-and-future-challenges" class="level2" data-number="6.12">
<h2 data-number="6.12" class="anchored" data-anchor-id="semantic-matching-and-future-challenges"><span class="header-section-number">6.12</span> Semantic Matching and Future Challenges</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_006_slide_26.png" class="img-fluid figure-img"></p>
<figcaption>Slide 26</figcaption>
</figure>
</div>
<p>When applying semantic matching to Newton’s Latin and English <em>Opticks</em>, significant matches were anticipated, given that one text is largely a translation of the other, implying strong conceptual similarity. Indeed, the semantic matches appear reasonable despite existing <em>OCR</em> issues, with passages discussing similar concepts, such as colours, aligning effectively.</p>
<p>Nevertheless, the semantic model’s performance exhibits certain limitations. The overall match score remains underdeveloped and lacks accuracy, whilst the quality score, though appearing high (e.g., 91.2%), contrasts with a low coverage score (e.g., 36.9%). This low coverage might accurately reflect genuine differences in text length or content between the editions, as the Latin version is notably longer. Overall, based on other queries, the current embedding model, <em>LaBSE</em>, is deemed inadequate for the task. The <em>VERITRACE</em> team hypothesises that this inadequacy stems from an “out-of-domain model collapse,” as the model was trained on modern languages rather than early modern texts, which possess distinct semantics, typography, and <em>OCR</em> quality.</p>
<p>Several critical issues remain on the horizon for the project. The choice of embedding model is paramount; whilst <em>LaBSE</em> served as a starting point, alternatives such as <em>XLM-Roberta</em>, <em>intfloat multilingual-e5-large</em>, or historical <em>mBERT</em> warrant investigation, each presenting trade-offs between accuracy, storage requirements, and inference time. A key consideration involves whether to fine-tune a base model on the project’s unique historical corpus, given its distinct characteristics. Furthermore, the challenge of semantic drift—how meaning changes across centuries and different languages (e.g., from 1540 to 1700)—requires careful methodological consideration.</p>
<p>The pervasive issue of poor <em>OCR</em> quality significantly affects all downstream processes, including the fundamental task of segmenting text into sentences and passages. Re-<em>OCR</em>ing the entire corpus is not feasible; therefore, solutions may involve re-<em>OCR</em>ing only the very poor-quality texts or investing time in sourcing existing high-quality versions. Finally, scaling and performance present substantial challenges. The current prototype, comprising merely 132 texts, already incurs query times of 15 seconds. Scaling this to the full corpus of 430,000 texts, which will amount to terabytes of data, necessitates robust solutions to ensure usability and responsiveness.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./chapter_ai-nepi_005.html" class="pagination-link" aria-label="Genre Classification for Historical Medical Periodicals, ActDisease Project">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals, ActDisease Project</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_007.html" class="pagination-link" aria-label="Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.">
        <span class="nav-page-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities.</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>