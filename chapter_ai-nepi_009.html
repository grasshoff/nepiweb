<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.8.11">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Matteo Ottaviani &amp; Stephan Stahlschmidt">
<meta name="dcterms.date" content="2025-01-01">

<title>9&nbsp; Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases – AI-NEPI Conference Proceedings - Enhanced Edition</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./chapter_ai-nepi_010.html" rel="next">
<link href="./ai-nepi_008_chapter.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js" type="module"></script>
<script src="site_libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="site_libs/quarto-html/axe/axe-check.js" type="module"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting-09b140d2d032adf2aedb8b099be3ee13.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap-350fb9e808f7eb2950c9598fb3f8c4a0.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


</head>

<body class="nav-sidebar floating quarto-light">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./chapter_ai-nepi_009.html"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">AI-NEPI Conference Proceedings - Enhanced Edition</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">AI-NEPI Conference Proceedings - Enhanced Edition</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_001_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Large Language Models for the History, Philosophy and Sociology of Science (Workshop)</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_003_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">The Transformer’s Legacy: Understanding Large Language Models and their Application in HPSS Research</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_004_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">The Workflow and Utility of OpenAlex Mapper</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_005_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Genre Classification for Historical Medical Periodicals</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_006_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Towards Computational HPSS: Tracing the Influence of the Ancient Wisdom Tradition on Early Modern Science using the LLM-powered Semantic Matching Tool of the VERITRACE project</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_007_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Interpretability for LLMs: Transparency, Applications and Scientific Insights in the Humanities</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./ai-nepi_008_chapter.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_009.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_010.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_011.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Science Dynamics and AI</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_012.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">Retrieval Augmented Generation (RAG) in Philosophical Research: Applications and Methodological Challenges</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_015.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Quantum Gravity and Plural Pursuit: A Multi-Scale Investigation</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_016.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Titles, Abstracts, or Full-Texts? A Comparative Study of <em>LDA</em> and <em>BERTopic</em> Performance across Text Levels</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_017.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Time-Aware Language Models</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_018.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Leverage Large Language Models for Metadata Enrichment and Diachronic Analysis of Chemical Knowledge in Historical Scientific Texts</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_019.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Modelling Context and its Interplay in Language Variation and Change: A Pilot Study on the Chemical Revolution</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_020.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">Beyond Traditional Views of Science Funding</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chapter_ai-nepi_021.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">19</span>&nbsp; <span class="chapter-title">From Source to Structure: Extracting Knowledge Graphs with LLMs</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">20</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#overview" id="toc-overview" class="nav-link active" data-scroll-target="#overview">Overview</a></li>
  <li><a href="#background-and-motivation-the-performative-nature-of-bibliometric-databases" id="toc-background-and-motivation-the-performative-nature-of-bibliometric-databases" class="nav-link" data-scroll-target="#background-and-motivation-the-performative-nature-of-bibliometric-databases"><span class="header-section-number">9.1</span> Background and Motivation: The Performative Nature of Bibliometric Databases</a></li>
  <li><a href="#case-study-llms-for-sdg-research-analysis" id="toc-case-study-llms-for-sdg-research-analysis" class="nav-link" data-scroll-target="#case-study-llms-for-sdg-research-analysis"><span class="header-section-number">9.2</span> Case Study: <em>LLMs</em> for <em>SDG</em> Research Analysis</a></li>
  <li><a href="#methodological-design-dependencies-actors-data-and-initial-classification-comparisons" id="toc-methodological-design-dependencies-actors-data-and-initial-classification-comparisons" class="nav-link" data-scroll-target="#methodological-design-dependencies-actors-data-and-initial-classification-comparisons"><span class="header-section-number">9.3</span> Methodological Design: Dependencies, Actors, Data, and Initial Classification Comparisons</a></li>
  <li><a href="#llm-implementation-distilgpt2-selection-and-fine-tuning" id="toc-llm-implementation-distilgpt2-selection-and-fine-tuning" class="nav-link" data-scroll-target="#llm-implementation-distilgpt2-selection-and-fine-tuning"><span class="header-section-number">9.4</span> <em>LLM</em> Implementation: <em>DistilGPT2</em> Selection and Fine-Tuning</a></li>
  <li><a href="#benchmarking-sdg-targets-and-prompt-engineering" id="toc-benchmarking-sdg-targets-and-prompt-engineering" class="nav-link" data-scroll-target="#benchmarking-sdg-targets-and-prompt-engineering"><span class="header-section-number">9.5</span> Benchmarking: <em>SDG</em> Targets and Prompt Engineering</a></li>
  <li><a href="#research-design-and-analytical-workflow" id="toc-research-design-and-analytical-workflow" class="nav-link" data-scroll-target="#research-design-and-analytical-workflow"><span class="header-section-number">9.6</span> Research Design and Analytical Workflow</a></li>
  <li><a href="#llm-response-analysis-uncovering-biases" id="toc-llm-response-analysis-uncovering-biases" class="nav-link" data-scroll-target="#llm-response-analysis-uncovering-biases"><span class="header-section-number">9.7</span> <em>LLM</em> Response Analysis: Uncovering Biases</a></li>
  <li><a href="#synthesis-and-limitations" id="toc-synthesis-and-limitations" class="nav-link" data-scroll-target="#synthesis-and-limitations"><span class="header-section-number">9.8</span> Synthesis and Limitations</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Leveraging Large Language Models to Assess Biases in Sustainable Development Goal Classifications Across Major Bibliometric Databases</span></h1>
</div>


<div class="quarto-title-meta-author">
  <div class="quarto-title-meta-heading">Author</div>
  <div class="quarto-title-meta-heading">Affiliation</div>
  
    <div class="quarto-title-meta-contents">
    <p class="author">Matteo Ottaviani &amp; Stephan Stahlschmidt <a href="mailto:ottaviani@dzhw.eu" class="quarto-title-author-email"><i class="bi bi-envelope"></i></a> </p>
  </div>
  <div class="quarto-title-meta-contents">
        <p class="affiliation">
            DZHW berlin
          </p>
      </div>
  </div>

<div class="quarto-title-meta">

      
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">January 1, 2025</p>
    </div>
  </div>
  
    
  </div>
  


</header>


<section id="overview" class="level2 unnumbered">
<h2 class="unnumbered anchored" data-anchor-id="overview">Overview</h2>
<p>This study critically examines the capacity of Large Language Models (<em>LLMs</em>) to assess biases within publications classified under the Sustainable Development Goals (<em>SDGs</em>) across three major bibliometric databases: <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em>. A primary objective involved employing <em>LLMs</em>, specifically a fine-tuned <em>DistilGPT2</em> model, not only to detect these biases but also to demonstrate the feasibility of automating information extraction for informing research policy and decision-making.</p>
<p>The research team selected five <em>SDGs</em> pertaining to socioeconomic inequalities—<em>SDG4</em> (Quality Education), <em>SDG5</em> (Gender Equality), <em>SDG10</em> (Reduced Inequalities), <em>SDG8</em> (Decent Work and Economic Growth), and <em>SDG9</em> (Industry, Innovation, and Infrastructure). They processed a common corpus of over 15 million publications, indexed across all three databases between January 2015 and July 2023. By fine-tuning separate <em>DistilGPT2</em> instances for each <em>SDG</em> and database combination, utilising publication titles and abstracts, the team developed a robust method to benchmark <em>LLM</em>-generated content against official <em>SDG</em> targets. This involved crafting specific prompts derived from these targets and meticulously analysing the <em>LLM</em> responses across dimensions such as locations, actors, data/metrics, and thematic focuses.</p>
<p>Key findings revealed a significant, systematic omission in the database classifications concerning disadvantaged individuals, the poorest nations, and numerous underrepresented topics explicitly mentioned in <em>SDG</em> targets. Conversely, the classifications demonstrated a marked emphasis on economic superpowers and highly developed countries. The study also highlighted divergent methodologies amongst the databases, with <em>Web of Science</em> exhibiting a more theoretical orientation compared to the empirical leanings of <em>Scopus</em> and <em>OpenAlex</em>. These outcomes underscore the profound influence of ostensibly objective bibliometric classification practices on the perceived landscape of <em>SDG</em>-related research, potentially impacting resource allocation and policy formulation.</p>
</section>
<section id="background-and-motivation-the-performative-nature-of-bibliometric-databases" class="level2" data-number="9.1">
<h2 data-number="9.1" class="anchored" data-anchor-id="background-and-motivation-the-performative-nature-of-bibliometric-databases"><span class="header-section-number">9.1</span> Background and Motivation: The Performative Nature of Bibliometric Databases</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_01.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 01</figcaption>
</figure>
</div>
<p>Matteo Ottaviani and Stephan Stahlschmidt initiated an investigation into the application of Large Language Models (<em>LLMs</em>) for assessing biases within scientific publications, as classified by major bibliometric databases. This work acknowledges the critical role that bibliometric databases, such as <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em>, fulfil within the sociology of science. Indeed, these platforms significantly influence the behaviours and decisions of academics, researchers, funding bodies, and policymakers alike.</p>
<p>These databases, however, are far from neutral entities; they respond to diverse political and commercial interests, inherently possessing a performative nature. This performativity shapes how the science system is understood and how value is attributed within it—a concept explored by scholars such as Whitley (2000) and Winkler (1988). The current study specifically considers <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em>.</p>
<p>Building upon prior research examining the labelling of Sustainable Development Goals (<em>SDGs</em>) and the construction of search queries, this study addresses a persistent challenge. Armitage et al.&nbsp;(2020), for instance, observed that <em>SDG</em> labelling by various providers yielded disparate results with minimal overlap. Such classification discrepancies can foster divergent perceptions of research priorities. Consequently, these disparities may profoundly impact resource allocation and policy decisions, frequently intertwined with underlying political and commercial interests. This investigation, therefore, scrutinises the aggregate effects arising from how bibliometric databases process metadata and how this subsequently influences diverse stakeholders.</p>
</section>
<section id="case-study-llms-for-sdg-research-analysis" class="level2" data-number="9.2">
<h2 data-number="9.2" class="anchored" data-anchor-id="case-study-llms-for-sdg-research-analysis"><span class="header-section-number">9.2</span> Case Study: <em>LLMs</em> for <em>SDG</em> Research Analysis</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_04.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 04</figcaption>
</figure>
</div>
<p>This investigation centres on a case study analysing the representation of United Nations Sustainable Development Goals (<em>SDGs</em>) within bibliometric data, as detailed by Ottaviani &amp; Stahlschmidt (2024). A primary motivation for this research stems from a desire to comprehend the aggregated effects on how <em>SDG</em>-related research is portrayed in bibliometric databases, particularly given the prospective integration of <em>LLM</em>-based analytical tools. To this end, the investigators employed relatively small pre-trained Large Language Models, selecting <em>DistilGPT2</em> for its specific characteristics.</p>
<p>The core methodological approach involved fine-tuning these <em>LLMs</em>. Researchers trained separate models on distinct subsets of publication abstracts, with each subset corresponding to a particular <em>SDG</em> classification provided by one of the bibliometric databases under review. This strategy enabled the <em>LLM</em> technology to fulfil a dual role: firstly, as an instrument for detecting inherent data biases; and secondly, as a demonstration of concept. This latter role explored the feasibility of <em>LLMs</em> in automating information extraction processes, thereby informing decision-making within the research domain. Ultimately, the project aimed to conduct a broadly applicable exercise, assessing these aggregate effects and gauging their potential impact on research policy.</p>
</section>
<section id="methodological-design-dependencies-actors-data-and-initial-classification-comparisons" class="level2" data-number="9.3">
<h2 data-number="9.3" class="anchored" data-anchor-id="methodological-design-dependencies-actors-data-and-initial-classification-comparisons"><span class="header-section-number">9.3</span> Methodological Design: Dependencies, Actors, Data, and Initial Classification Comparisons</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_03.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 03</figcaption>
</figure>
</div>
<p>The researchers conceptualised a chain of dependencies to frame their analysis. This chain posits that <em>SDG</em> classification practices define “Research on <em>SDGs</em>,” which in turn informs decision-making aimed at aligning with these goals, ultimately impacting socioeconomic inequalities. Various actors—including researchers, small and medium-sized enterprises (<em>SMEs</em>), and governments—process this “Research on <em>SDGs</em>.” The introduction of an <em>LLM</em> as a bias detector, it is posited, influences the adoption of <em>LLMs</em> in research policy, which itself can affect socioeconomic inequalities.</p>
<p>The study focused on three principal bibliometric databases: the proprietary <em>Web of Science</em> (Clarivate, US) and <em>Scopus</em> (Elsevier, UK), alongside the open-access <em>OpenAlex</em> (formerly Microsoft, US). Researchers selected five <em>SDGs</em> directly relating to socioeconomic inequalities. These comprised <em>SDG4</em> (Quality Education), <em>SDG5</em> (Gender Equality), and <em>SDG10</em> (Reduced Inequalities) for the socio-equity dimension, complemented by <em>SDG8</em> (Decent Work and Economic Growth) and <em>SDG9</em> (Industry, Innovation, and Infrastructure) for the economic development dimension.</p>
<p>A substantial dataset formed the basis of the analysis: a jointly indexed subset of 15,471,336 publications. These publications, shared across all three databases and identified via exact DOI matching, spanned from January 2015 to July 2023. Investigators then applied the distinct <em>SDG</em> classification standards of <em>Web of Science</em>, <em>Scopus</em>, and <em>OpenAlex</em> to this common corpus for the five chosen <em>SDGs</em>. This process yielded three unique subsets of publications for each <em>SDG</em>, one corresponding to each database’s classification.</p>
<p>Initial comparisons of these <em>SDG</em>-classified papers revealed a strikingly low overlap amongst the databases, a finding consistent with earlier work by Armitage (2020). For instance, concerning <em>SDG4</em> (Quality Education), only 7.2% of the relevant publications in the shared corpus were classified as such by all three databases. Similarly low intersection rates were observed for <em>SDG5</em> (Gender Equality) at 4.8%, <em>SDG10</em> (Reduced Inequalities) at 2.9%, <em>SDG8</em> (Decent Work) at 2.5%, and <em>SDG9</em> (Industry/Innovation) at a mere 2.0%. An interesting anomaly noted was that <em>Web of Science</em> classified approximately 10% of its <em>SDG5</em>-related publications as originating from the field of mathematics, including topics like geometrical differential equations, indicating potential classification idiosyncrasies.</p>
</section>
<section id="llm-implementation-distilgpt2-selection-and-fine-tuning" class="level2" data-number="9.4">
<h2 data-number="9.4" class="anchored" data-anchor-id="llm-implementation-distilgpt2-selection-and-fine-tuning"><span class="header-section-number">9.4</span> <em>LLM</em> Implementation: <em>DistilGPT2</em> Selection and Fine-Tuning</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_07.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 07</figcaption>
</figure>
</div>
<p>Investigators initially conceived of building bespoke Large Language Models, each trained exclusively on publications classified under a specific <em>SDG</em> by a particular bibliometric database. However, developing <em>LLMs</em> entirely from scratch proved a prohibitively resource-intensive endeavour. Consequently, the team adopted a pragmatic compromise: fine-tuning an existing, pre-trained <em>LLM</em> known for having limited prior knowledge, using publication abstracts as the training material.</p>
<p>The choice fell upon <em>DistilGPT2</em>. This selection was deliberate, as prominent commercial and large open-source <em>LLMs</em> were deemed ineligible. Such models often possess pre-existing knowledge about <em>SDGs</em> and strong semantic associations derived from their extensive training datasets, which can include sources like Wikipedia and Reddit discussions. <em>DistilGPT2</em>, in contrast, is a lightweight, English-speaking variant of the open-source <em>GPT2</em> model that utilises a technique called “distillation,” as described by Sanh (2019). With 82 million parameters—significantly fewer than models like <em>GPT-4</em>—<em>DistilGPT2</em> offered feasibility for working with proprietary datasets; importantly, it was assessed to have no significant prior semantic understanding of the specific publication domain or the prompts to be used.</p>
<p>The fine-tuning procedure involved creating 15 distinct <em>LLM</em> instances: one for each of the five selected <em>SDGs</em>, replicated across the three bibliometric databases. For this fine-tuning, researchers utilised the titles and abstracts of the classified publications. The task was structured such that the <em>LLM</em>, when given a new title as a prompt, would generate a new abstract, with the training aimed at maximising the similarity of this output to the characteristics of the source corpus.</p>
</section>
<section id="benchmarking-sdg-targets-and-prompt-engineering" class="level2" data-number="9.5">
<h2 data-number="9.5" class="anchored" data-anchor-id="benchmarking-sdg-targets-and-prompt-engineering"><span class="header-section-number">9.5</span> Benchmarking: <em>SDG</em> Targets and Prompt Engineering</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_10.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 10</figcaption>
</figure>
</div>
<p>To evaluate the fine-tuned <em>LLMs</em>, researchers developed a benchmarking methodology rooted in the official structure of the UN Sustainable Development Goals. Each <em>SDG</em> is defined by a series of specific targets; for the <em>SDGs</em> under analysis, this typically ranged from eight to twelve targets per goal. For instance, <em>SDG4</em> (Quality Education) includes targets such as ensuring all children complete primary and secondary education (Target 4.1), providing access to early childhood development, guaranteeing equal access to vocational and tertiary education for all, enhancing youth and adult skills for employment, eliminating gender disparities in education, and ensuring literacy and numeracy for all learners by 2030, as outlined in the UN’s 2030 Agenda for <em>SDGs</em>.</p>
<p>Based on this structure, the team implemented a systematic prompt generation strategy. For every individual target within each of the five selected <em>SDGs</em>, ten distinct questions, or prompts, were carefully crafted. Each of these prompts was designed to probe different aspects and nuances of its corresponding target. This meticulous process yielded a specific set of 80 to 120 prompts for each <em>SDG</em>.</p>
<p>These target-derived prompts formed the cornerstone of the benchmarking standard. Their primary purpose was to establish a ground truth against which the <em>LLM</em> responses could be measured, thereby defining compliance with the stated objectives of the <em>SDGs</em>. Furthermore, this approach facilitated the identification of “biases” or significant informational omissions. The underlying rationale is straightforward: if an <em>LLM</em>, fine-tuned on a corpus of literature purportedly related to a specific <em>SDG</em>, cannot generate relevant responses to prompts directly addressing that <em>SDG</em>’s official targets, it indicates that information crucial to those targets is either missing or substantially underrepresented within the dataset upon which the <em>LLM</em> was trained. This method provides a systematic way to assess both the completeness of the information captured by the database classifications and the potential biases therein.</p>
</section>
<section id="research-design-and-analytical-workflow" class="level2" data-number="9.6">
<h2 data-number="9.6" class="anchored" data-anchor-id="research-design-and-analytical-workflow"><span class="header-section-number">9.6</span> Research Design and Analytical Workflow</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_11.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 11</figcaption>
</figure>
</div>
<p>The comprehensive research design involved several distinct stages, beginning with the input data: sets of publication abstracts classified under a specific Sustainable Development Goal (<em>SDG#</em>) by one of the three bibliometric databases (<em>DB#</em>). Each of these curated sets of abstracts then served as the training material to fine-tune an instance of the <em>DistilGPT-2</em> model. This procedure resulted in a collection of specialised <em>LLMs</em>, each uniquely adapted to the content associated with a particular <em>SDG</em> as represented by a specific database (denoted as Fine-tuned <em>DistilGPT-2 SDG# DB#</em>).</p>
<p>Subsequently, the prompting process commenced. Researchers utilised the previously developed sets of prompts, each tailored to a specific <em>SDG#</em>. These prompts were systematically inputted into the corresponding fine-tuned <em>DistilGPT-2</em> model. To explore the variability in <em>LLM</em> output and ensure robustness, the team applied three distinct decoding strategies for generating responses: top-k sampling, nucleus (or top-p) sampling, and contrastive search. This approach yielded three distinct sets of responses for every <em>SDG</em> and database combination, reflecting the nuances of each decoding method.</p>
<p>For the initial analysis of these generated responses, researchers applied a filter based on the words used in the original prompts. Following this, noun phrases were extracted from the filtered responses, creating a structured dataset of key terms (Noun phrases <em>SDG# DB#</em>). However, the analytical scrutiny extended beyond this. To ensure a thorough and nuanced comparison, investigators also conducted direct searches within the full text of the <em>LLM</em>-generated responses, complementing the insights derived from noun phrase analysis.</p>
</section>
<section id="llm-response-analysis-uncovering-biases" class="level2" data-number="9.7">
<h2 data-number="9.7" class="anchored" data-anchor-id="llm-response-analysis-uncovering-biases"><span class="header-section-number">9.7</span> <em>LLM</em> Response Analysis: Uncovering Biases</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_12.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 12</figcaption>
</figure>
</div>
<p>Researchers analysed the <em>LLM</em>-generated responses by matching the extracted noun phrases against the official targets of each Sustainable Development Goal. This analysis was structured around four key data dimensions: Locations, Actors, Data/Metrics, and Focuses. For every <em>SDG</em> under review, the team assessed the degree of compliance with its targets and identified any discernible biases. Importantly, this process also highlighted differences in how the three bibliometric databases represented <em>SDG</em>-related research.</p>
<p>An illustrative example using <em>SDG4</em> (Quality Education) revealed significant omissions. The <em>LLM</em> responses, reflecting the underlying database classifications, inadequately addressed numerous geographical areas, including most African countries (with the exception of South Africa), other developing nations, Least Developed Countries (<em>LDCs</em>), and Small Island Developing States (<em>SIDS</em>). Similarly, critical groups of actors were systematically overlooked, such as vulnerable populations, persons with disabilities, indigenous peoples, and children in vulnerable situations. Many crucial thematic focuses pertinent to <em>SDG4</em> were also underrepresented or entirely missing from the <em>LLM</em> outputs. These included vocational training, scholarships, the creation of safe and inclusive learning environments, education for sustainable lifestyles, human rights education, the promotion of peace and non-violence, global citizenship, the appreciation of cultural diversity, and even fundamental aspects like free primary and secondary education and tertiary education.</p>
<p>Extending these observations across all five selected <em>SDGs</em>, several patterns emerged. Regarding locations, <em>LDCs</em> received scant attention, with Sub-Saharan Africa being mentioned primarily in the context of <em>SDG8</em>. The United States held an “undoubted monopoly” in terms of mentions, followed by South Africa and China, and then the UK and Australia. In the realm of metrics and data, the <em>LLMs</em> frequently recalled specific surveys like the Demographic and Health Surveys (<em>DHS</em>) and World Values Survey (<em>WVS</em>) as data sources. Various indicators, benchmarks, and research methodologies—spanning theoretical, empirical, and thematic analyses, as well as market dynamics and macroeconomics—were also identified, with semantic networks formed after fine-tuning indicating recurrent survey data.</p>
<p>A consistent and concerning finding related to actors: discriminated and vulnerable categories were systematically overlooked across all analysed <em>SDGs</em>. Even when prompts specifically targeted these groups for different <em>SDGs</em>, the <em>LLMs</em> failed to generate substantial, macro-level responses. In terms of thematic focuses, many <em>SDG</em>-specific sensitive topics, such as human trafficking, human exploitation, and migration, were notably absent. Furthermore, the analysis discerned database-specific tendencies. Across three different <em>SDGs</em>, <em>Web of Science</em>’s classified literature leaned towards a more theoretical approach. Conversely, both <em>Scopus</em> and <em>OpenAlex</em> appeared to favour and represent more empirical research.</p>
</section>
<section id="synthesis-and-limitations" class="level2" data-number="9.8">
<h2 data-number="9.8" class="anchored" data-anchor-id="synthesis-and-limitations"><span class="header-section-number">9.8</span> Synthesis and Limitations</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="images/ai-nepi_009_slide_18.jpg" class="img-fluid figure-img"></p>
<figcaption>Slide 18</figcaption>
</figure>
</div>
<p>The investigation’s findings highlight a critical issue: employing Large Language Models as an analytical instrument, mediating between the <em>SDG</em> classifications provided by bibliometric databases and their interpretation by policymakers, uncovers a systematic deficiency in the underlying data. Specifically, scientific publications, as classified under various <em>SDGs</em>, frequently overlook the most disadvantaged categories of individuals, the poorest nations, and numerous underrepresented topics that are, in fact, explicit focuses of the <em>SDG</em> targets themselves. In stark contrast, the classified literature demonstrates considerable attention towards economic superpowers and rapidly developing countries. These results unequivocally show how an ostensibly objective, science-informed practice such as the bibliometric classification of <em>SDGs</em> can wield a decisive influence on perceived research landscapes and priorities.</p>
<p>Researchers also acknowledged several inherent methodological limitations. Large Language Models exhibit high sensitivity to a range of factors. These include the specific model architecture chosen, although <em>DistilGPT2</em> was selected for its suitability to the task. The nature of the training data is also paramount; this was partly addressed by utilising three distinct databases, which provided varied training corpora for the <em>LLMs</em>. Furthermore, hyper-parameters, general model parameters, and the chosen decoding strategy all significantly influence <em>LLM</em> behaviour. The impact of decoding strategy was partially mitigated by employing three different recognised methods (top-k, nucleus sampling, and contrastive search). Finally, whilst the study employed a general framework, the use of more developed or specialised <em>LLM</em> architectures could potentially reveal different or more nuanced outcomes. Despite efforts to account for variations in training data and decoding strategies, these elements remain influential variables in <em>LLM</em> performance and output.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./ai-nepi_008_chapter.html" class="pagination-link" aria-label="Modeling Science: LLM for the History, Philosophy and Sociology of Science">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Modeling Science: LLM for the History, Philosophy and Sociology of Science</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./chapter_ai-nepi_010.html" class="pagination-link" aria-label="Large Language Models for Footnote Parsing in Law and Humanities Scholarship">
        <span class="nav-page-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Large Language Models for Footnote Parsing in Law and Humanities Scholarship</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>